{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.660377358490567, "episode_len_mean": 19.18867924528302, "episode_media": {}, "episodes_this_iter": 53, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.830188679245284, "policy1": -11.830188679245284}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15747125584390642, "mean_inference_ms": 1.4664286012031236, "mean_action_processing_ms": 0.09671199064123603, "mean_env_wait_ms": 0.1639350224103347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1017, "timesteps_this_iter": 32, "agent_timesteps_total": 2034, "timers": {"learn_time_ms": 340.87, "learn_throughput": 93.877, "update_time_ms": 5.255}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1017, "num_agent_steps_sampled": 2034, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1017, "num_target_updates": 1}, "done": false, "episodes_total": 53, "training_iteration": 1, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-42", "timestamp": 1648815882, "time_this_iter_s": 2.9246225357055664, "time_total_s": 2.9246225357055664, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "time_since_restore": 2.9246225357055664, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 26.060000000000002, "ram_util_percent": 54.28000000000001}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.06896551724138, "episode_len_mean": 19.25862068965517, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -12.53448275862069, "policy1": -12.53448275862069}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15744518305251037, "mean_inference_ms": 1.4657114825260835, "mean_action_processing_ms": 0.09671564999875513, "mean_env_wait_ms": 0.16391312094772448, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1117, "timesteps_this_iter": 32, "agent_timesteps_total": 2234, "timers": {"learn_time_ms": 62.56, "learn_throughput": 511.507, "update_time_ms": 4.853}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1117, "num_agent_steps_sampled": 2234, "num_steps_trained": 192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 384, "last_target_update_ts": 1017, "num_target_updates": 1}, "done": false, "episodes_total": 58, "training_iteration": 2, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-42", "timestamp": 1648815882, "time_this_iter_s": 0.3163022994995117, "time_total_s": 3.240924835205078, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b0e0>"}, "time_since_restore": 3.240924835205078, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.61904761904762, "episode_len_mean": 19.317460317460316, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -12.80952380952381, "policy1": -12.80952380952381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15745119110860228, "mean_inference_ms": 1.465126964079612, "mean_action_processing_ms": 0.09676171877528739, "mean_env_wait_ms": 0.1639732929936794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1217, "timesteps_this_iter": 32, "agent_timesteps_total": 2434, "timers": {"learn_time_ms": 6.62, "learn_throughput": 4833.592, "update_time_ms": 4.362}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1217, "num_agent_steps_sampled": 2434, "num_steps_trained": 352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 704, "last_target_update_ts": 1137, "num_target_updates": 2}, "done": false, "episodes_total": 63, "training_iteration": 3, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-42", "timestamp": 1648815882, "time_this_iter_s": 0.32585597038269043, "time_total_s": 3.5667808055877686, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b440>"}, "time_since_restore": 3.5667808055877686, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 27.1, "ram_util_percent": 54.4}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.608695652173914, "episode_len_mean": 19.115942028985508, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -12.304347826086957, "policy1": -12.304347826086957}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15744309348249672, "mean_inference_ms": 1.4640678859860383, "mean_action_processing_ms": 0.09681222260563792, "mean_env_wait_ms": 0.16398970481332176, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1319, "timesteps_this_iter": 32, "agent_timesteps_total": 2638, "timers": {"learn_time_ms": 6.197, "learn_throughput": 5163.968, "update_time_ms": 3.896}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1319, "num_agent_steps_sampled": 2638, "num_steps_trained": 544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1088, "last_target_update_ts": 1253, "num_target_updates": 3}, "done": false, "episodes_total": 69, "training_iteration": 4, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-43", "timestamp": 1648815883, "time_this_iter_s": 0.3324594497680664, "time_total_s": 3.899240255355835, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b5f0>"}, "time_since_restore": 3.899240255355835, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.6, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.8, "policy1": -11.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15745531409540206, "mean_inference_ms": 1.4626151110019008, "mean_action_processing_ms": 0.09681907880518842, "mean_env_wait_ms": 0.16396022337831165, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1425, "timesteps_this_iter": 32, "agent_timesteps_total": 2850, "timers": {"learn_time_ms": 6.405, "learn_throughput": 4996.119, "update_time_ms": 4.567}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1425, "num_agent_steps_sampled": 2850, "num_steps_trained": 736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1472, "last_target_update_ts": 1365, "num_target_updates": 4}, "done": false, "episodes_total": 75, "training_iteration": 5, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-43", "timestamp": 1648815883, "time_this_iter_s": 0.3489565849304199, "time_total_s": 4.248196840286255, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "time_since_restore": 4.248196840286255, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 25.9, "ram_util_percent": 54.5}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.625, "episode_len_mean": 19.0625, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.8125, "policy1": -11.8125}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15745272658205162, "mean_inference_ms": 1.461372030175476, "mean_action_processing_ms": 0.09683596926993099, "mean_env_wait_ms": 0.16395817563384324, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1525, "timesteps_this_iter": 32, "agent_timesteps_total": 3050, "timers": {"learn_time_ms": 6.599, "learn_throughput": 4849.397, "update_time_ms": 4.428}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1525, "num_agent_steps_sampled": 3050, "num_steps_trained": 896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1792, "last_target_update_ts": 1485, "num_target_updates": 5}, "done": false, "episodes_total": 80, "training_iteration": 6, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-43", "timestamp": 1648815883, "time_this_iter_s": 0.3160688877105713, "time_total_s": 4.564265727996826, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b560>"}, "time_since_restore": 4.564265727996826, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.647058823529413, "episode_len_mean": 19.11764705882353, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.823529411764707, "policy1": -11.823529411764707}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1574673732464963, "mean_inference_ms": 1.4603668883847838, "mean_action_processing_ms": 0.09688312049836595, "mean_env_wait_ms": 0.16399577609250598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1625, "timesteps_this_iter": 32, "agent_timesteps_total": 3250, "timers": {"learn_time_ms": 6.433, "learn_throughput": 4974.546, "update_time_ms": 4.031}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1625, "num_agent_steps_sampled": 3250, "num_steps_trained": 1056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2112, "last_target_update_ts": 1605, "num_target_updates": 6}, "done": false, "episodes_total": 85, "training_iteration": 7, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-44", "timestamp": 1648815884, "time_this_iter_s": 0.32605552673339844, "time_total_s": 4.890321254730225, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b440>"}, "time_since_restore": 4.890321254730225, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 26.6, "ram_util_percent": 54.5}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.142857142857142, "episode_len_mean": 19.043956043956044, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -11.571428571428571, "policy1": -11.571428571428571}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15746416306711608, "mean_inference_ms": 1.4589527483714124, "mean_action_processing_ms": 0.09691408446598158, "mean_env_wait_ms": 0.16400759164052647, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1733, "timesteps_this_iter": 32, "agent_timesteps_total": 3466, "timers": {"learn_time_ms": 6.153, "learn_throughput": 5200.303, "update_time_ms": 3.882}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1733, "num_agent_steps_sampled": 3466, "num_steps_trained": 1248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2496, "last_target_update_ts": 1713, "num_target_updates": 7}, "done": false, "episodes_total": 91, "training_iteration": 8, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-44", "timestamp": 1648815884, "time_this_iter_s": 0.33951640129089355, "time_total_s": 5.229837656021118, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b320>"}, "time_since_restore": 5.229837656021118, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.979591836734695, "episode_len_mean": 18.846938775510203, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.989795918367347, "policy1": -10.989795918367347}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16], "policy_policy0_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0], "policy_policy1_reward": [-20.0, 10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1575403428574734, "mean_inference_ms": 1.457902871608479, "mean_action_processing_ms": 0.09700537854329182, "mean_env_wait_ms": 0.16408606053560731, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1847, "timesteps_this_iter": 32, "agent_timesteps_total": 3694, "timers": {"learn_time_ms": 6.565, "learn_throughput": 4874.211, "update_time_ms": 3.986}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1847, "num_agent_steps_sampled": 3694, "num_steps_trained": 1472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2944, "last_target_update_ts": 1831, "num_target_updates": 8}, "done": false, "episodes_total": 98, "training_iteration": 9, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-45", "timestamp": 1648815885, "time_this_iter_s": 0.5339939594268799, "time_total_s": 5.763831615447998, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c54b830>"}, "time_since_restore": 5.763831615447998, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 54.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.5, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.75, "policy1": -10.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576137820266853, "mean_inference_ms": 1.4566257889469716, "mean_action_processing_ms": 0.09710229522241537, "mean_env_wait_ms": 0.1641659411720682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1955, "timesteps_this_iter": 32, "agent_timesteps_total": 3910, "timers": {"learn_time_ms": 6.513, "learn_throughput": 4912.909, "update_time_ms": 3.911}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 1955, "num_agent_steps_sampled": 3910, "num_steps_trained": 1664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3328, "last_target_update_ts": 1935, "num_target_updates": 9}, "done": false, "episodes_total": 104, "training_iteration": 10, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-45", "timestamp": 1648815885, "time_this_iter_s": 0.35473084449768066, "time_total_s": 6.118562459945679, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c573200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c54b5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c573200>"}, "time_since_restore": 6.118562459945679, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 27.8, "ram_util_percent": 54.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.3, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.65, "policy1": -10.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15770722653383154, "mean_inference_ms": 1.455685699926718, "mean_action_processing_ms": 0.09721681505401214, "mean_env_wait_ms": 0.16429153496325294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2055, "timesteps_this_iter": 32, "agent_timesteps_total": 4110, "timers": {"learn_time_ms": 6.448, "learn_throughput": 4963.068, "update_time_ms": 4.319}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2055, "num_agent_steps_sampled": 4110, "num_steps_trained": 1824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3648, "last_target_update_ts": 2055, "num_target_updates": 10}, "done": false, "episodes_total": 109, "training_iteration": 11, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-45", "timestamp": 1648815885, "time_this_iter_s": 0.3425610065460205, "time_total_s": 6.461123466491699, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5694d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c573170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5694d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c573170>"}, "time_since_restore": 6.461123466491699, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.46, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.23, "policy1": -10.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1578205189656715, "mean_inference_ms": 1.4544392917058446, "mean_action_processing_ms": 0.09735067857218702, "mean_env_wait_ms": 0.16444303468907223, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2163, "timesteps_this_iter": 32, "agent_timesteps_total": 4326, "timers": {"learn_time_ms": 6.586, "learn_throughput": 4859.123, "update_time_ms": 4.311}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2163, "num_agent_steps_sampled": 4326, "num_steps_trained": 2016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4032, "last_target_update_ts": 2163, "num_target_updates": 11}, "done": false, "episodes_total": 115, "training_iteration": 12, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-46", "timestamp": 1648815886, "time_this_iter_s": 0.36029767990112305, "time_total_s": 6.821421146392822, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55d5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55d5f0>"}, "time_since_restore": 6.821421146392822, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 27.3, "ram_util_percent": 54.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.08, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.54, "policy1": -9.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 22.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0], "episode_lengths": [20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20], "policy_policy0_reward": [-10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 11.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1579306370807992, "mean_inference_ms": 1.4529834526457968, "mean_action_processing_ms": 0.09747642183799876, "mean_env_wait_ms": 0.16458153933422406, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2264, "timesteps_this_iter": 32, "agent_timesteps_total": 4528, "timers": {"learn_time_ms": 6.58, "learn_throughput": 4863.19, "update_time_ms": 3.751}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2264, "num_agent_steps_sampled": 4528, "num_steps_trained": 2208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4416, "last_target_update_ts": 2264, "num_target_updates": 12}, "done": false, "episodes_total": 121, "training_iteration": 13, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-46", "timestamp": 1648815886, "time_this_iter_s": 0.33257555961608887, "time_total_s": 7.153996706008911, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c569b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c569a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c569b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c569a70>"}, "time_since_restore": 7.153996706008911, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.08, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.54, "policy1": -9.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1580273260167569, "mean_inference_ms": 1.451365463401743, "mean_action_processing_ms": 0.09758546280203366, "mean_env_wait_ms": 0.16471034235697535, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2373, "timesteps_this_iter": 32, "agent_timesteps_total": 4746, "timers": {"learn_time_ms": 6.395, "learn_throughput": 5004.278, "update_time_ms": 3.831}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2373, "num_agent_steps_sampled": 4746, "num_steps_trained": 2400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4800, "last_target_update_ts": 2373, "num_target_updates": 13}, "done": false, "episodes_total": 127, "training_iteration": 14, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-47", "timestamp": 1648815887, "time_this_iter_s": 0.3520934581756592, "time_total_s": 7.50609016418457, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5734d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5734d0>"}, "time_since_restore": 7.50609016418457, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 21.4, "ram_util_percent": 50.7}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.44, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.22, "policy1": -9.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 0.0, -40.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 0.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.158140250466059, "mean_inference_ms": 1.4497719778406517, "mean_action_processing_ms": 0.09769987367937247, "mean_env_wait_ms": 0.16484636416686563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2481, "timesteps_this_iter": 32, "agent_timesteps_total": 4962, "timers": {"learn_time_ms": 6.614, "learn_throughput": 4838.436, "update_time_ms": 4.002}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2481, "num_agent_steps_sampled": 4962, "num_steps_trained": 2592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5184, "last_target_update_ts": 2481, "num_target_updates": 14}, "done": false, "episodes_total": 133, "training_iteration": 15, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-47", "timestamp": 1648815887, "time_this_iter_s": 0.3687443733215332, "time_total_s": 7.8748345375061035, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "time_since_restore": 7.8748345375061035, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.44, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.22, "policy1": -9.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15821779492801025, "mean_inference_ms": 1.4484122372929544, "mean_action_processing_ms": 0.09779513417769398, "mean_env_wait_ms": 0.16495615974144645, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2581, "timesteps_this_iter": 32, "agent_timesteps_total": 5162, "timers": {"learn_time_ms": 6.407, "learn_throughput": 4994.52, "update_time_ms": 4.081}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2581, "num_agent_steps_sampled": 5162, "num_steps_trained": 2752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5504, "last_target_update_ts": 2481, "num_target_updates": 14}, "done": false, "episodes_total": 138, "training_iteration": 16, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-47", "timestamp": 1648815887, "time_this_iter_s": 0.324521541595459, "time_total_s": 8.199356079101562, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55de60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55de60>"}, "time_since_restore": 8.199356079101562, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 17.9, "ram_util_percent": 48.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 12.0, 4.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0], "episode_lengths": [20, 6, 14, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14], "policy_policy0_reward": [-10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0], "policy_policy1_reward": [-10.0, 14.0, 6.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15828884781913874, "mean_inference_ms": 1.4465061006198152, "mean_action_processing_ms": 0.09789820507883107, "mean_env_wait_ms": 0.16506143802474738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2690, "timesteps_this_iter": 32, "agent_timesteps_total": 5380, "timers": {"learn_time_ms": 6.384, "learn_throughput": 5012.744, "update_time_ms": 3.917}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2690, "num_agent_steps_sampled": 5380, "num_steps_trained": 2944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5888, "last_target_update_ts": 2601, "num_target_updates": 15}, "done": false, "episodes_total": 144, "training_iteration": 17, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-48", "timestamp": 1648815888, "time_this_iter_s": 0.3459150791168213, "time_total_s": 8.545271158218384, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "time_since_restore": 8.545271158218384, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.34, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.67, "policy1": -8.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15836564297958747, "mean_inference_ms": 1.4440655845738872, "mean_action_processing_ms": 0.09800990280589335, "mean_env_wait_ms": 0.16517521524418557, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2804, "timesteps_this_iter": 32, "agent_timesteps_total": 5608, "timers": {"learn_time_ms": 6.226, "learn_throughput": 5139.724, "update_time_ms": 3.781}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2804, "num_agent_steps_sampled": 5608, "num_steps_trained": 3168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6336, "last_target_update_ts": 2720, "num_target_updates": 16}, "done": false, "episodes_total": 151, "training_iteration": 18, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-48", "timestamp": 1648815888, "time_this_iter_s": 0.3759794235229492, "time_total_s": 8.921250581741333, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5733b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5733b0>"}, "time_since_restore": 8.921250581741333, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 18.1, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.54, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.27, "policy1": -8.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15839995283725275, "mean_inference_ms": 1.4423062025293785, "mean_action_processing_ms": 0.09807196121894181, "mean_env_wait_ms": 0.16523516759366122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2904, "timesteps_this_iter": 32, "agent_timesteps_total": 5808, "timers": {"learn_time_ms": 6.082, "learn_throughput": 5261.79, "update_time_ms": 3.676}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 2904, "num_agent_steps_sampled": 5808, "num_steps_trained": 3328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6656, "last_target_update_ts": 2824, "num_target_updates": 17}, "done": false, "episodes_total": 156, "training_iteration": 19, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-48", "timestamp": 1648815888, "time_this_iter_s": 0.29688191413879395, "time_total_s": 9.218132495880127, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5777a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5777a0>"}, "time_since_restore": 9.218132495880127, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.24, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.62, "policy1": -7.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 8.0, -40.0, -20.0, -20.0, 28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0], "episode_lengths": [20, 16, 20, 20, 20, 6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0], "policy_policy1_reward": [-20.0, 4.0, -20.0, -10.0, -10.0, 14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15842393194298915, "mean_inference_ms": 1.4402715102372474, "mean_action_processing_ms": 0.0981206499717108, "mean_env_wait_ms": 0.165274054032483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3019, "timesteps_this_iter": 32, "agent_timesteps_total": 6038, "timers": {"learn_time_ms": 6.298, "learn_throughput": 5081.176, "update_time_ms": 3.714}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3019, "num_agent_steps_sampled": 6038, "num_steps_trained": 3520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7040, "last_target_update_ts": 2939, "num_target_updates": 18}, "done": false, "episodes_total": 162, "training_iteration": 20, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-49", "timestamp": 1648815889, "time_this_iter_s": 0.3657369613647461, "time_total_s": 9.583869457244873, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c573200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "time_since_restore": 9.583869457244873, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.12, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.56, "policy1": -7.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -40.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [6, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [14.0, -20.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15844688444521468, "mean_inference_ms": 1.4388839741468158, "mean_action_processing_ms": 0.09816241550691865, "mean_env_wait_ms": 0.1653205927422352, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3119, "timesteps_this_iter": 32, "agent_timesteps_total": 6238, "timers": {"learn_time_ms": 6.748, "learn_throughput": 4742.106, "update_time_ms": 3.913}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3119, "num_agent_steps_sampled": 6238, "num_steps_trained": 3680, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7360, "last_target_update_ts": 3059, "num_target_updates": 19}, "done": false, "episodes_total": 167, "training_iteration": 21, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-49", "timestamp": 1648815889, "time_this_iter_s": 0.3311648368835449, "time_total_s": 9.915034294128418, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c577710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "time_since_restore": 9.915034294128418, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.64, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.82, "policy1": -7.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1584721146467284, "mean_inference_ms": 1.4374549530241063, "mean_action_processing_ms": 0.09822489121910678, "mean_env_wait_ms": 0.16539576102359596, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3227, "timesteps_this_iter": 32, "agent_timesteps_total": 6454, "timers": {"learn_time_ms": 6.508, "learn_throughput": 4917.085, "update_time_ms": 3.831}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3227, "num_agent_steps_sampled": 6454, "num_steps_trained": 3872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 7744, "last_target_update_ts": 3179, "num_target_updates": 20}, "done": false, "episodes_total": 173, "training_iteration": 22, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-50", "timestamp": 1648815890, "time_this_iter_s": 0.34714436531066895, "time_total_s": 10.262178659439087, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55de60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5734d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55de60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5734d0>"}, "time_since_restore": 10.262178659439087, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 20.9, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.32, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.66, "policy1": -7.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15847047859825417, "mean_inference_ms": 1.435996039243615, "mean_action_processing_ms": 0.09826461290933995, "mean_env_wait_ms": 0.16544030797745501, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3341, "timesteps_this_iter": 32, "agent_timesteps_total": 6682, "timers": {"learn_time_ms": 6.153, "learn_throughput": 5200.403, "update_time_ms": 3.632}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3341, "num_agent_steps_sampled": 6682, "num_steps_trained": 4064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8128, "last_target_update_ts": 3287, "num_target_updates": 21}, "done": false, "episodes_total": 179, "training_iteration": 23, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-50", "timestamp": 1648815890, "time_this_iter_s": 0.3389585018157959, "time_total_s": 10.601137161254883, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5777a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5777a0>"}, "time_since_restore": 10.601137161254883, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.32, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.66, "policy1": -7.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 8, 20, 20, 20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15844323812520794, "mean_inference_ms": 1.4346113092505386, "mean_action_processing_ms": 0.0982635905234862, "mean_env_wait_ms": 0.16543053687754555, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3441, "timesteps_this_iter": 32, "agent_timesteps_total": 6882, "timers": {"learn_time_ms": 6.034, "learn_throughput": 5303.078, "update_time_ms": 3.577}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3441, "num_agent_steps_sampled": 6882, "num_steps_trained": 4224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8448, "last_target_update_ts": 3401, "num_target_updates": 22}, "done": false, "episodes_total": 184, "training_iteration": 24, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-50", "timestamp": 1648815890, "time_this_iter_s": 0.29685378074645996, "time_total_s": 10.897990942001343, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "time_since_restore": 10.897990942001343, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.96, "episode_len_mean": 18.28, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.48, "policy1": -7.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 14.0, 30.0, -20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0], "episode_lengths": [20, 20, 20, 13, 5, 20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 7.0, 15.0, -10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15840941319871024, "mean_inference_ms": 1.4329667873712055, "mean_action_processing_ms": 0.09825447769120003, "mean_env_wait_ms": 0.16541734534373972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3541, "timesteps_this_iter": 32, "agent_timesteps_total": 7082, "timers": {"learn_time_ms": 6.08, "learn_throughput": 5262.801, "update_time_ms": 3.568}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3541, "num_agent_steps_sampled": 7082, "num_steps_trained": 4416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8832, "last_target_update_ts": 3513, "num_target_updates": 23}, "done": false, "episodes_total": 190, "training_iteration": 25, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-51", "timestamp": 1648815891, "time_this_iter_s": 0.3180539608001709, "time_total_s": 11.216044902801514, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5693b0>"}, "time_since_restore": 11.216044902801514, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.8, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.9, "policy1": -7.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 8.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 16, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 4.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15833188554521327, "mean_inference_ms": 1.431365595676763, "mean_action_processing_ms": 0.09821171504722098, "mean_env_wait_ms": 0.16537227742994265, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3641, "timesteps_this_iter": 32, "agent_timesteps_total": 7282, "timers": {"learn_time_ms": 6.418, "learn_throughput": 4985.615, "update_time_ms": 3.732}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3641, "num_agent_steps_sampled": 7282, "num_steps_trained": 4576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9152, "last_target_update_ts": 3621, "num_target_updates": 24}, "done": false, "episodes_total": 195, "training_iteration": 26, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-51", "timestamp": 1648815891, "time_this_iter_s": 0.31234192848205566, "time_total_s": 11.52838683128357, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fab00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fab00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "time_since_restore": 11.52838683128357, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.8, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.9, "policy1": -7.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0], "episode_lengths": [8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15820421743768015, "mean_inference_ms": 1.4293547029584197, "mean_action_processing_ms": 0.09813293494245474, "mean_env_wait_ms": 0.16529761999705875, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3757, "timesteps_this_iter": 32, "agent_timesteps_total": 7514, "timers": {"learn_time_ms": 6.55, "learn_throughput": 4885.388, "update_time_ms": 3.756}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3757, "num_agent_steps_sampled": 7514, "num_steps_trained": 4768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9536, "last_target_update_ts": 3737, "num_target_updates": 25}, "done": false, "episodes_total": 201, "training_iteration": 27, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-51", "timestamp": 1648815891, "time_this_iter_s": 0.36112284660339355, "time_total_s": 11.889509677886963, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "time_since_restore": 11.889509677886963, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.14, "episode_len_mean": 18.37, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.57, "policy1": -7.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 8, 20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15801804181145473, "mean_inference_ms": 1.4267193849840276, "mean_action_processing_ms": 0.0980011015727619, "mean_env_wait_ms": 0.1651318564050387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3872, "timesteps_this_iter": 32, "agent_timesteps_total": 7744, "timers": {"learn_time_ms": 6.322, "learn_throughput": 5061.974, "update_time_ms": 3.681}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3872, "num_agent_steps_sampled": 7744, "num_steps_trained": 4992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9984, "last_target_update_ts": 3852, "num_target_updates": 26}, "done": false, "episodes_total": 208, "training_iteration": 28, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-52", "timestamp": 1648815892, "time_this_iter_s": 0.3737783432006836, "time_total_s": 12.263288021087646, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "time_since_restore": 12.263288021087646, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 17.3, "ram_util_percent": 48.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.24, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.62, "policy1": -7.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 12.0, 10.0, 16.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0], "episode_lengths": [20, 20, 14, 15, 12, 20, 20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 6.0, 5.0, 8.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1578402410809427, "mean_inference_ms": 1.4244421438594759, "mean_action_processing_ms": 0.09787895438044308, "mean_env_wait_ms": 0.16496961378288122, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3985, "timesteps_this_iter": 32, "agent_timesteps_total": 7970, "timers": {"learn_time_ms": 6.381, "learn_throughput": 5014.973, "update_time_ms": 3.943}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 3985, "num_agent_steps_sampled": 7970, "num_steps_trained": 5184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10368, "last_target_update_ts": 3965, "num_target_updates": 27}, "done": false, "episodes_total": 214, "training_iteration": 29, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-52", "timestamp": 1648815892, "time_this_iter_s": 0.37097859382629395, "time_total_s": 12.63426661491394, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fa70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fa70>"}, "time_since_restore": 12.63426661491394, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 16.9, "ram_util_percent": 48.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.54, "episode_len_mean": 18.57, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.27, "policy1": -8.27}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 22.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 9, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 11.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15765303096664354, "mean_inference_ms": 1.4222421769679534, "mean_action_processing_ms": 0.09776080563846459, "mean_env_wait_ms": 0.16480964847543553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4101, "timesteps_this_iter": 32, "agent_timesteps_total": 8202, "timers": {"learn_time_ms": 6.356, "learn_throughput": 5034.971, "update_time_ms": 3.962}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4101, "num_agent_steps_sampled": 8202, "num_steps_trained": 5376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10752, "last_target_update_ts": 4081, "num_target_updates": 28}, "done": false, "episodes_total": 220, "training_iteration": 30, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-52", "timestamp": 1648815892, "time_this_iter_s": 0.3580198287963867, "time_total_s": 12.992286443710327, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fab00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fab00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "time_since_restore": 12.992286443710327, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.96, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.48, "policy1": -8.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0], "episode_lengths": [20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0], "policy_policy1_reward": [-20.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15750415792579298, "mean_inference_ms": 1.4205226829261028, "mean_action_processing_ms": 0.09767327908094298, "mean_env_wait_ms": 0.16468168480695003, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4201, "timesteps_this_iter": 32, "agent_timesteps_total": 8402, "timers": {"learn_time_ms": 6.419, "learn_throughput": 4984.874, "update_time_ms": 3.788}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4201, "num_agent_steps_sampled": 8402, "num_steps_trained": 5536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11072, "last_target_update_ts": 4201, "num_target_updates": 29}, "done": false, "episodes_total": 225, "training_iteration": 31, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-53", "timestamp": 1648815893, "time_this_iter_s": 0.31278061866760254, "time_total_s": 13.30506706237793, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "time_since_restore": 13.30506706237793, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.28, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.14, "policy1": -8.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.157293400973908, "mean_inference_ms": 1.4181468948397953, "mean_action_processing_ms": 0.09755374305043092, "mean_env_wait_ms": 0.16450358311038915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4315, "timesteps_this_iter": 32, "agent_timesteps_total": 8630, "timers": {"learn_time_ms": 6.557, "learn_throughput": 4880.272, "update_time_ms": 3.841}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4315, "num_agent_steps_sampled": 8630, "num_steps_trained": 5728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11456, "last_target_update_ts": 4315, "num_target_updates": 30}, "done": false, "episodes_total": 232, "training_iteration": 32, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-53", "timestamp": 1648815893, "time_this_iter_s": 0.3679041862487793, "time_total_s": 13.672971248626709, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa560>"}, "time_since_restore": 13.672971248626709, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.56, "episode_len_mean": 18.38, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.78, "policy1": -7.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 10.0, -20.0, 12.0, 20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 15, 20, 14, 10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 5.0, -10.0, 6.0, 10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15711708944635241, "mean_inference_ms": 1.416069721603479, "mean_action_processing_ms": 0.09744630272243836, "mean_env_wait_ms": 0.16435024058452985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4419, "timesteps_this_iter": 32, "agent_timesteps_total": 8838, "timers": {"learn_time_ms": 6.376, "learn_throughput": 5018.949, "update_time_ms": 3.929}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4419, "num_agent_steps_sampled": 8838, "num_steps_trained": 5920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11840, "last_target_update_ts": 4419, "num_target_updates": 31}, "done": false, "episodes_total": 238, "training_iteration": 33, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-54", "timestamp": 1648815894, "time_this_iter_s": 0.3374955654144287, "time_total_s": 14.010466814041138, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "time_since_restore": 14.010466814041138, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 17.8, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.4, "episode_len_mean": 18.3, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.7, "policy1": -7.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, -40.0, 32.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0], "episode_lengths": [10, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, -20.0, 16.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569755280624835, "mean_inference_ms": 1.4142784380844398, "mean_action_processing_ms": 0.09735281561330006, "mean_env_wait_ms": 0.164236158372339, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4520, "timesteps_this_iter": 32, "agent_timesteps_total": 9040, "timers": {"learn_time_ms": 6.312, "learn_throughput": 5070.1, "update_time_ms": 3.974}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4520, "num_agent_steps_sampled": 9040, "num_steps_trained": 6112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12224, "last_target_update_ts": 4520, "num_target_updates": 32}, "done": false, "episodes_total": 244, "training_iteration": 34, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-54", "timestamp": 1648815894, "time_this_iter_s": 0.33884167671203613, "time_total_s": 14.349308490753174, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4faa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4faa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c55dcb0>"}, "time_since_restore": 14.349308490753174, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.4, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.7, "policy1": -7.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15684047702270518, "mean_inference_ms": 1.4126963039881282, "mean_action_processing_ms": 0.09726876117114922, "mean_env_wait_ms": 0.164138387273432, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4624, "timesteps_this_iter": 32, "agent_timesteps_total": 9248, "timers": {"learn_time_ms": 6.631, "learn_throughput": 4825.841, "update_time_ms": 3.992}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4624, "num_agent_steps_sampled": 9248, "num_steps_trained": 6304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12608, "last_target_update_ts": 4624, "num_target_updates": 33}, "done": false, "episodes_total": 250, "training_iteration": 35, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-54", "timestamp": 1648815894, "time_this_iter_s": 0.3487436771392822, "time_total_s": 14.698052167892456, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c577710>"}, "time_since_restore": 14.698052167892456, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.24, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.12, "policy1": -7.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15672809062465376, "mean_inference_ms": 1.4111796599213005, "mean_action_processing_ms": 0.09719122484948223, "mean_env_wait_ms": 0.16405983641204563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4731, "timesteps_this_iter": 32, "agent_timesteps_total": 9462, "timers": {"learn_time_ms": 6.75, "learn_throughput": 4740.917, "update_time_ms": 3.924}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4731, "num_agent_steps_sampled": 9462, "num_steps_trained": 6496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12992, "last_target_update_ts": 4731, "num_target_updates": 34}, "done": false, "episodes_total": 257, "training_iteration": 36, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-55", "timestamp": 1648815895, "time_this_iter_s": 0.3518979549407959, "time_total_s": 15.049950122833252, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c55d560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fa440>"}, "time_since_restore": 15.049950122833252, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.64, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.32, "policy1": -7.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15665242381099284, "mean_inference_ms": 1.4101900989706295, "mean_action_processing_ms": 0.0971372298504556, "mean_env_wait_ms": 0.16400393584068357, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4831, "timesteps_this_iter": 32, "agent_timesteps_total": 9662, "timers": {"learn_time_ms": 6.431, "learn_throughput": 4976.021, "update_time_ms": 3.763}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4831, "num_agent_steps_sampled": 9662, "num_steps_trained": 6656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13312, "last_target_update_ts": 4731, "num_target_updates": 34}, "done": false, "episodes_total": 262, "training_iteration": 37, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-55", "timestamp": 1648815895, "time_this_iter_s": 0.30950260162353516, "time_total_s": 15.359452724456787, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5777a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "time_since_restore": 15.359452724456787, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 18.3, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.44, "episode_len_mean": 18.02, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.22, "policy1": -7.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 24.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0], "episode_lengths": [20, 20, 8, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 12.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15655470006348746, "mean_inference_ms": 1.4088271964380699, "mean_action_processing_ms": 0.0970610880401502, "mean_env_wait_ms": 0.16392427589550848, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4941, "timesteps_this_iter": 32, "agent_timesteps_total": 9882, "timers": {"learn_time_ms": 6.316, "learn_throughput": 5066.751, "update_time_ms": 3.828}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 4941, "num_agent_steps_sampled": 9882, "num_steps_trained": 6848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13696, "last_target_update_ts": 4851, "num_target_updates": 35}, "done": false, "episodes_total": 268, "training_iteration": 38, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-55", "timestamp": 1648815895, "time_this_iter_s": 0.3496212959289551, "time_total_s": 15.709074020385742, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fa4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c528f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fa4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c528f80>"}, "time_since_restore": 15.709074020385742, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.28, "episode_len_mean": 18.14, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.64, "policy1": -7.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 12.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 6.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15646077667511488, "mean_inference_ms": 1.4077052947036037, "mean_action_processing_ms": 0.09699682647698157, "mean_env_wait_ms": 0.1638572825945153, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5041, "timesteps_this_iter": 32, "agent_timesteps_total": 10082, "timers": {"learn_time_ms": 6.229, "learn_throughput": 5137.56, "update_time_ms": 3.748}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5041, "num_agent_steps_sampled": 10082, "num_steps_trained": 7008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14016, "last_target_update_ts": 4961, "num_target_updates": 36}, "done": false, "episodes_total": 273, "training_iteration": 39, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-56", "timestamp": 1648815896, "time_this_iter_s": 0.3029661178588867, "time_total_s": 16.01204013824463, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 16.01204013824463, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 18.0, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.0, "episode_len_mean": 18.1, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.5, "policy1": -7.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15637361023762253, "mean_inference_ms": 1.4066482265939706, "mean_action_processing_ms": 0.09694139235112902, "mean_env_wait_ms": 0.16379853528535812, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5151, "timesteps_this_iter": 32, "agent_timesteps_total": 10302, "timers": {"learn_time_ms": 6.396, "learn_throughput": 5003.177, "update_time_ms": 3.737}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5151, "num_agent_steps_sampled": 10302, "num_steps_trained": 7200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14400, "last_target_update_ts": 5073, "num_target_updates": 37}, "done": false, "episodes_total": 279, "training_iteration": 40, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-56", "timestamp": 1648815896, "time_this_iter_s": 0.3536996841430664, "time_total_s": 16.365739822387695, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5287a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5287a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523d40>"}, "time_since_restore": 16.365739822387695, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.8, "episode_len_mean": 18.1, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.4, "policy1": -7.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 16.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 8.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15630321593516158, "mean_inference_ms": 1.4058077401823608, "mean_action_processing_ms": 0.09689564169187413, "mean_env_wait_ms": 0.16374932038158985, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5251, "timesteps_this_iter": 32, "agent_timesteps_total": 10502, "timers": {"learn_time_ms": 6.251, "learn_throughput": 5118.926, "update_time_ms": 3.608}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5251, "num_agent_steps_sampled": 10502, "num_steps_trained": 7360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14720, "last_target_update_ts": 5191, "num_target_updates": 38}, "done": false, "episodes_total": 284, "training_iteration": 41, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-56", "timestamp": 1648815896, "time_this_iter_s": 0.29062342643737793, "time_total_s": 16.656363248825073, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "time_since_restore": 16.656363248825073, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 18.2, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.56, "episode_len_mean": 18.28, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.78, "policy1": -7.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.156212289420618, "mean_inference_ms": 1.4048658120277708, "mean_action_processing_ms": 0.09684258976035708, "mean_env_wait_ms": 0.16368909117308017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5369, "timesteps_this_iter": 32, "agent_timesteps_total": 10738, "timers": {"learn_time_ms": 6.04, "learn_throughput": 5297.971, "update_time_ms": 3.547}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5369, "num_agent_steps_sampled": 10738, "num_steps_trained": 7552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15104, "last_target_update_ts": 5309, "num_target_updates": 39}, "done": false, "episodes_total": 290, "training_iteration": 42, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-57", "timestamp": 1648815897, "time_this_iter_s": 0.3455173969268799, "time_total_s": 17.001880645751953, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50b290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50b290>"}, "time_since_restore": 17.001880645751953, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.4, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.7, "policy1": -7.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 8.0, -20.0, -20.0, -40.0, -20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 16, 20, 20, 20, 20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 4.0, -10.0, -10.0, -20.0, -10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15612074819316113, "mean_inference_ms": 1.4039237588271873, "mean_action_processing_ms": 0.09679132287122524, "mean_env_wait_ms": 0.16362024452243115, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5481, "timesteps_this_iter": 32, "agent_timesteps_total": 10962, "timers": {"learn_time_ms": 6.211, "learn_throughput": 5152.233, "update_time_ms": 3.654}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5481, "num_agent_steps_sampled": 10962, "num_steps_trained": 7744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15488, "last_target_update_ts": 5421, "num_target_updates": 40}, "done": false, "episodes_total": 296, "training_iteration": 43, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-57", "timestamp": 1648815897, "time_this_iter_s": 0.3478562831878662, "time_total_s": 17.34973692893982, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 17.34973692893982, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 15.9, "ram_util_percent": 48.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.88, "episode_len_mean": 18.24, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.94, "policy1": -7.94}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 24.0, -20.0, -20.0, 26.0, 0.0, -40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 8, 20, 20, 7, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 12.0, -10.0, -10.0, 13.0, 0.0, -20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15604185095863818, "mean_inference_ms": 1.4031021280894425, "mean_action_processing_ms": 0.09674786039445711, "mean_env_wait_ms": 0.16355406445079992, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5581, "timesteps_this_iter": 32, "agent_timesteps_total": 11162, "timers": {"learn_time_ms": 6.117, "learn_throughput": 5231.457, "update_time_ms": 3.691}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5581, "num_agent_steps_sampled": 11162, "num_steps_trained": 7904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 15808, "last_target_update_ts": 5541, "num_target_updates": 41}, "done": false, "episodes_total": 301, "training_iteration": 44, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-57", "timestamp": 1648815897, "time_this_iter_s": 0.29393625259399414, "time_total_s": 17.643673181533813, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502710>"}, "time_since_restore": 17.643673181533813, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.34, "episode_len_mean": 18.37, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.17, "policy1": -8.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 0.0, -40.0, -20.0, 14.0, -40.0, -20.0, -40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0], "episode_lengths": [20, 20, 20, 20, 13, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16], "policy_policy0_reward": [-20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0], "policy_policy1_reward": [-20.0, 0.0, -20.0, -10.0, 7.0, -20.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15595624454647317, "mean_inference_ms": 1.4022335979956588, "mean_action_processing_ms": 0.09670535593383654, "mean_env_wait_ms": 0.16350029888094764, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5689, "timesteps_this_iter": 32, "agent_timesteps_total": 11378, "timers": {"learn_time_ms": 6.156, "learn_throughput": 5198.47, "update_time_ms": 3.715}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5689, "num_agent_steps_sampled": 11378, "num_steps_trained": 8096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16192, "last_target_update_ts": 5653, "num_target_updates": 42}, "done": false, "episodes_total": 307, "training_iteration": 45, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-58", "timestamp": 1648815898, "time_this_iter_s": 0.34905195236206055, "time_total_s": 17.992725133895874, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c502830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c502830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb00>"}, "time_since_restore": 17.992725133895874, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 15.3, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.16, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.58, "policy1": -7.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 8.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1558655286750904, "mean_inference_ms": 1.401132385847115, "mean_action_processing_ms": 0.09664847589842651, "mean_env_wait_ms": 0.16342026483024732, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5793, "timesteps_this_iter": 32, "agent_timesteps_total": 11586, "timers": {"learn_time_ms": 6.482, "learn_throughput": 4936.508, "update_time_ms": 4.077}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5793, "num_agent_steps_sampled": 11586, "num_steps_trained": 8288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16576, "last_target_update_ts": 5773, "num_target_updates": 43}, "done": false, "episodes_total": 314, "training_iteration": 46, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-58", "timestamp": 1648815898, "time_this_iter_s": 0.3463418483734131, "time_total_s": 18.339066982269287, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "time_since_restore": 18.339066982269287, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.8, "episode_len_mean": 17.8, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.9, "policy1": -6.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 0.0, -20.0, 34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0], "episode_lengths": [20, 20, 20, 20, 20, 3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18], "policy_policy0_reward": [-10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 0.0, -10.0, 17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15578439355990892, "mean_inference_ms": 1.4000611484411942, "mean_action_processing_ms": 0.09658559614359566, "mean_env_wait_ms": 0.1633313586418027, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5901, "timesteps_this_iter": 32, "agent_timesteps_total": 11802, "timers": {"learn_time_ms": 6.043, "learn_throughput": 5295.629, "update_time_ms": 3.687}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 5901, "num_agent_steps_sampled": 11802, "num_steps_trained": 8512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17024, "last_target_update_ts": 5883, "num_target_updates": 44}, "done": false, "episodes_total": 321, "training_iteration": 47, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-59", "timestamp": 1648815899, "time_this_iter_s": 0.35486674308776855, "time_total_s": 18.693933725357056, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "time_since_restore": 18.693933725357056, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 16.5, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.0, "episode_len_mean": 17.8, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.0, "policy1": -7.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, 4.0, 14.0, -20.0, -20.0, -40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [3, 18, 13, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [17.0, 2.0, 7.0, -10.0, -10.0, -20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1557175351328918, "mean_inference_ms": 1.399235646720082, "mean_action_processing_ms": 0.09653719684654934, "mean_env_wait_ms": 0.1632598655779508, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6001, "timesteps_this_iter": 32, "agent_timesteps_total": 12002, "timers": {"learn_time_ms": 5.992, "learn_throughput": 5340.575, "update_time_ms": 3.746}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6001, "num_agent_steps_sampled": 12002, "num_steps_trained": 8672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17344, "last_target_update_ts": 6001, "num_target_updates": 45}, "done": false, "episodes_total": 326, "training_iteration": 48, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-59", "timestamp": 1648815899, "time_this_iter_s": 0.29646944999694824, "time_total_s": 18.990403175354004, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502710>"}, "time_since_restore": 18.990403175354004, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.12, "episode_len_mean": 18.06, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.56, "policy1": -7.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 32.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 16.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15563270380036467, "mean_inference_ms": 1.3983217273710955, "mean_action_processing_ms": 0.09648000742063458, "mean_env_wait_ms": 0.1631725351924272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6101, "timesteps_this_iter": 32, "agent_timesteps_total": 12202, "timers": {"learn_time_ms": 5.97, "learn_throughput": 5360.39, "update_time_ms": 4.062}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6101, "num_agent_steps_sampled": 12202, "num_steps_trained": 8832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17664, "last_target_update_ts": 6001, "num_target_updates": 45}, "done": false, "episodes_total": 331, "training_iteration": 49, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-24-59", "timestamp": 1648815899, "time_this_iter_s": 0.2980029582977295, "time_total_s": 19.288406133651733, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb90>"}, "time_since_restore": 19.288406133651733, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.64, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.82, "policy1": -7.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15554430967804958, "mean_inference_ms": 1.3973751235022633, "mean_action_processing_ms": 0.09642062256401683, "mean_env_wait_ms": 0.16307932345795653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6201, "timesteps_this_iter": 32, "agent_timesteps_total": 12402, "timers": {"learn_time_ms": 5.943, "learn_throughput": 5384.864, "update_time_ms": 4.351}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6201, "num_agent_steps_sampled": 12402, "num_steps_trained": 8992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17984, "last_target_update_ts": 6121, "num_target_updates": 46}, "done": false, "episodes_total": 336, "training_iteration": 50, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-00", "timestamp": 1648815900, "time_this_iter_s": 0.2995336055755615, "time_total_s": 19.587939739227295, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "time_since_restore": 19.587939739227295, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.64, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.82, "policy1": -7.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, 10.0, -20.0, -20.0, 20.0, -20.0, -20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [6, 15, 20, 20, 10, 20, 20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [14.0, 5.0, -10.0, -10.0, 10.0, -10.0, -10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15544902257752494, "mean_inference_ms": 1.3964136661886375, "mean_action_processing_ms": 0.09635897839965579, "mean_env_wait_ms": 0.1629774750073921, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6301, "timesteps_this_iter": 32, "agent_timesteps_total": 12602, "timers": {"learn_time_ms": 6.152, "learn_throughput": 5201.854, "update_time_ms": 4.383}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6301, "num_agent_steps_sampled": 12602, "num_steps_trained": 9152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18304, "last_target_update_ts": 6241, "num_target_updates": 47}, "done": false, "episodes_total": 341, "training_iteration": 51, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-00", "timestamp": 1648815900, "time_this_iter_s": 0.3133060932159424, "time_total_s": 19.901245832443237, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56f440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 19.901245832443237, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 15.8, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.72, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.36, "policy1": -8.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 12.0, -20.0, -40.0, 8.0, 34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0], "episode_lengths": [20, 14, 20, 20, 16, 3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20], "policy_policy0_reward": [-10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0], "policy_policy1_reward": [-10.0, 6.0, -10.0, -20.0, 4.0, 17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15532024347877155, "mean_inference_ms": 1.3951326448235435, "mean_action_processing_ms": 0.09627501541894201, "mean_env_wait_ms": 0.16283395418735103, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6406, "timesteps_this_iter": 32, "agent_timesteps_total": 12812, "timers": {"learn_time_ms": 6.137, "learn_throughput": 5214.06, "update_time_ms": 3.887}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6406, "num_agent_steps_sampled": 12812, "num_steps_trained": 9344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18688, "last_target_update_ts": 6361, "num_target_updates": 48}, "done": false, "episodes_total": 347, "training_iteration": 52, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-00", "timestamp": 1648815900, "time_this_iter_s": 0.32079434394836426, "time_total_s": 20.2220401763916, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "time_since_restore": 20.2220401763916, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.12, "episode_len_mean": 18.46, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.56, "policy1": -8.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [3, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [17.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15520388127153584, "mean_inference_ms": 1.3940160237689696, "mean_action_processing_ms": 0.09620029316391608, "mean_env_wait_ms": 0.16270601718253946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6506, "timesteps_this_iter": 32, "agent_timesteps_total": 13012, "timers": {"learn_time_ms": 5.997, "learn_throughput": 5335.946, "update_time_ms": 3.54}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6506, "num_agent_steps_sampled": 13012, "num_steps_trained": 9504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19008, "last_target_update_ts": 6466, "num_target_updates": 49}, "done": false, "episodes_total": 352, "training_iteration": 53, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-01", "timestamp": 1648815901, "time_this_iter_s": 0.300412654876709, "time_total_s": 20.52245283126831, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502830>"}, "time_since_restore": 20.52245283126831, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 15.6, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.22, "episode_len_mean": 18.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.11, "policy1": -9.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15505541773585355, "mean_inference_ms": 1.3926230051520536, "mean_action_processing_ms": 0.09610531369281038, "mean_env_wait_ms": 0.16254701501880922, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6622, "timesteps_this_iter": 32, "agent_timesteps_total": 13244, "timers": {"learn_time_ms": 5.968, "learn_throughput": 5361.717, "update_time_ms": 3.664}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6622, "num_agent_steps_sampled": 13244, "num_steps_trained": 9696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19392, "last_target_update_ts": 6586, "num_target_updates": 50}, "done": false, "episodes_total": 358, "training_iteration": 54, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-01", "timestamp": 1648815901, "time_this_iter_s": 0.35296058654785156, "time_total_s": 20.875413417816162, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51aef0>"}, "time_since_restore": 20.875413417816162, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.58, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.79, "policy1": -8.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20], "policy_policy0_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0], "policy_policy1_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15491943256453206, "mean_inference_ms": 1.391325426085677, "mean_action_processing_ms": 0.09601655441359512, "mean_env_wait_ms": 0.16240005001785274, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6740, "timesteps_this_iter": 32, "agent_timesteps_total": 13480, "timers": {"learn_time_ms": 6.146, "learn_throughput": 5206.354, "update_time_ms": 3.908}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6740, "num_agent_steps_sampled": 13480, "num_steps_trained": 9888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19776, "last_target_update_ts": 6702, "num_target_updates": 51}, "done": false, "episodes_total": 364, "training_iteration": 55, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-01", "timestamp": 1648815901, "time_this_iter_s": 0.3779292106628418, "time_total_s": 21.253342628479004, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5235f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5235f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506b00>"}, "time_since_restore": 21.253342628479004, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 16.3, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.58, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.79, "policy1": -8.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -20.0, 16.0, 4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 12, 18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 8.0, 2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15481606119614874, "mean_inference_ms": 1.390390385845384, "mean_action_processing_ms": 0.09595371875119442, "mean_env_wait_ms": 0.16229939715486882, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6840, "timesteps_this_iter": 32, "agent_timesteps_total": 13680, "timers": {"learn_time_ms": 6.392, "learn_throughput": 5006.387, "update_time_ms": 4.018}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6840, "num_agent_steps_sampled": 13680, "num_steps_trained": 10048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20096, "last_target_update_ts": 6820, "num_target_updates": 52}, "done": false, "episodes_total": 369, "training_iteration": 56, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-02", "timestamp": 1648815902, "time_this_iter_s": 0.3333911895751953, "time_total_s": 21.5867338180542, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "time_since_restore": 21.5867338180542, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.18, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.59, "policy1": -8.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0], "episode_lengths": [18, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [2.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15469816210337492, "mean_inference_ms": 1.389316080816535, "mean_action_processing_ms": 0.09588325381519787, "mean_env_wait_ms": 0.16218458076521183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6952, "timesteps_this_iter": 32, "agent_timesteps_total": 13904, "timers": {"learn_time_ms": 6.488, "learn_throughput": 4932.354, "update_time_ms": 3.955}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 6952, "num_agent_steps_sampled": 13904, "num_steps_trained": 10240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20480, "last_target_update_ts": 6932, "num_target_updates": 53}, "done": false, "episodes_total": 375, "training_iteration": 57, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-02", "timestamp": 1648815902, "time_this_iter_s": 0.35799646377563477, "time_total_s": 21.944730281829834, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c56fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "time_since_restore": 21.944730281829834, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 16.4, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 4.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 2.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15458374227305696, "mean_inference_ms": 1.3882366854884092, "mean_action_processing_ms": 0.09581481199591008, "mean_env_wait_ms": 0.16207091771361598, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7062, "timesteps_this_iter": 32, "agent_timesteps_total": 14124, "timers": {"learn_time_ms": 6.283, "learn_throughput": 5093.304, "update_time_ms": 3.744}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7062, "num_agent_steps_sampled": 14124, "num_steps_trained": 10432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20864, "last_target_update_ts": 7042, "num_target_updates": 54}, "done": false, "episodes_total": 381, "training_iteration": 58, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-02", "timestamp": 1648815902, "time_this_iter_s": 0.3394126892089844, "time_total_s": 22.28414297103882, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51aef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51aef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "time_since_restore": 22.28414297103882, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.84, "episode_len_mean": 18.62, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.42, "policy1": -8.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0], "episode_lengths": [20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15448652673072594, "mean_inference_ms": 1.3872942306335059, "mean_action_processing_ms": 0.0957551639285839, "mean_env_wait_ms": 0.16197918206423037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7171, "timesteps_this_iter": 32, "agent_timesteps_total": 14342, "timers": {"learn_time_ms": 6.262, "learn_throughput": 5109.805, "update_time_ms": 3.725}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7171, "num_agent_steps_sampled": 14342, "num_steps_trained": 10624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21248, "last_target_update_ts": 7151, "num_target_updates": 55}, "done": false, "episodes_total": 387, "training_iteration": 59, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-03", "timestamp": 1648815903, "time_this_iter_s": 0.34029483795166016, "time_total_s": 22.62443780899048, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5235f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5235f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 22.62443780899048, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 15.4, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.12, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.06, "policy1": -8.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1543949553117437, "mean_inference_ms": 1.3863891459866813, "mean_action_processing_ms": 0.09569855807853166, "mean_env_wait_ms": 0.1618925812109795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7277, "timesteps_this_iter": 32, "agent_timesteps_total": 14554, "timers": {"learn_time_ms": 5.999, "learn_throughput": 5334.568, "update_time_ms": 3.586}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7277, "num_agent_steps_sampled": 14554, "num_steps_trained": 10816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 21632, "last_target_update_ts": 7257, "num_target_updates": 56}, "done": false, "episodes_total": 393, "training_iteration": 60, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-03", "timestamp": 1648815903, "time_this_iter_s": 0.3243367671966553, "time_total_s": 22.948774576187134, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "time_since_restore": 22.948774576187134, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 14.6, "ram_util_percent": 48.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.1, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.55, "policy1": -7.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 16.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0], "episode_lengths": [20, 12, 20, 20, 20, 20, 16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20], "policy_policy0_reward": [-10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, 8.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1543063571009609, "mean_inference_ms": 1.3854355971960564, "mean_action_processing_ms": 0.0956436210902317, "mean_env_wait_ms": 0.16180079276709514, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7396, "timesteps_this_iter": 32, "agent_timesteps_total": 14792, "timers": {"learn_time_ms": 6.175, "learn_throughput": 5182.392, "update_time_ms": 3.636}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7396, "num_agent_steps_sampled": 14792, "num_steps_trained": 11040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22080, "last_target_update_ts": 7376, "num_target_updates": 57}, "done": false, "episodes_total": 400, "training_iteration": 61, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-04", "timestamp": 1648815904, "time_this_iter_s": 0.3849363327026367, "time_total_s": 23.33371090888977, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c502830>"}, "time_since_restore": 23.33371090888977, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.18, "episode_len_mean": 18.29, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.59, "policy1": -7.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -40.0, 34.0, 30.0, 8.0, -20.0, -20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0], "episode_lengths": [16, 20, 3, 5, 16, 20, 20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9], "policy_policy0_reward": [4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0], "policy_policy1_reward": [4.0, -20.0, 17.0, 15.0, 4.0, -10.0, -10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15423855531452108, "mean_inference_ms": 1.384646643160158, "mean_action_processing_ms": 0.09559561863024882, "mean_env_wait_ms": 0.1617240063105321, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7502, "timesteps_this_iter": 32, "agent_timesteps_total": 15004, "timers": {"learn_time_ms": 6.377, "learn_throughput": 5018.01, "update_time_ms": 3.741}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7502, "num_agent_steps_sampled": 15004, "num_steps_trained": 11232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22464, "last_target_update_ts": 7493, "num_target_updates": 58}, "done": false, "episodes_total": 406, "training_iteration": 62, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-04", "timestamp": 1648815904, "time_this_iter_s": 0.3389873504638672, "time_total_s": 23.672698259353638, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "time_since_restore": 23.672698259353638, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 17.5, "ram_util_percent": 48.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.92, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.96, "policy1": -7.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 6.0, -20.0, 28.0, 26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 17, 20, 6, 7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 3.0, -10.0, 14.0, 13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15416820977806636, "mean_inference_ms": 1.3839502334663125, "mean_action_processing_ms": 0.09555430339796718, "mean_env_wait_ms": 0.16165941727826652, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7609, "timesteps_this_iter": 32, "agent_timesteps_total": 15218, "timers": {"learn_time_ms": 6.642, "learn_throughput": 4817.976, "update_time_ms": 3.899}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7609, "num_agent_steps_sampled": 15218, "num_steps_trained": 11424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22848, "last_target_update_ts": 7609, "num_target_updates": 59}, "done": false, "episodes_total": 412, "training_iteration": 63, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-04", "timestamp": 1648815904, "time_this_iter_s": 0.35498547554016113, "time_total_s": 24.0276837348938, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c523c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c56fb90>"}, "time_since_restore": 24.0276837348938, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.14, "episode_len_mean": 18.67, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.07, "policy1": -8.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, -40.0, 4.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0], "episode_lengths": [7, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20], "policy_policy0_reward": [13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0], "policy_policy1_reward": [13.0, -20.0, 2.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15409324823418374, "mean_inference_ms": 1.3832568422582865, "mean_action_processing_ms": 0.09551472809637268, "mean_env_wait_ms": 0.1616016385512296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7723, "timesteps_this_iter": 32, "agent_timesteps_total": 15446, "timers": {"learn_time_ms": 6.149, "learn_throughput": 5203.992, "update_time_ms": 3.611}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7723, "num_agent_steps_sampled": 15446, "num_steps_trained": 11616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23232, "last_target_update_ts": 7723, "num_target_updates": 60}, "done": false, "episodes_total": 418, "training_iteration": 64, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-05", "timestamp": 1648815905, "time_this_iter_s": 0.34356021881103516, "time_total_s": 24.371243953704834, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c523680>"}, "time_since_restore": 24.371243953704834, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 17.1, "ram_util_percent": 48.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.64, "episode_len_mean": 18.82, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.32, "policy1": -8.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15404700773826993, "mean_inference_ms": 1.3828726466226953, "mean_action_processing_ms": 0.09549783598136409, "mean_env_wait_ms": 0.1615817464663697, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7823, "timesteps_this_iter": 32, "agent_timesteps_total": 15646, "timers": {"learn_time_ms": 6.541, "learn_throughput": 4891.869, "update_time_ms": 3.914}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7823, "num_agent_steps_sampled": 15646, "num_steps_trained": 11776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23552, "last_target_update_ts": 7723, "num_target_updates": 60}, "done": false, "episodes_total": 423, "training_iteration": 65, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-05", "timestamp": 1648815905, "time_this_iter_s": 0.36266160011291504, "time_total_s": 24.73390555381775, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5027a0>"}, "time_since_restore": 24.73390555381775, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.76, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.88, "policy1": -7.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1540449671034554, "mean_inference_ms": 1.3828394226716296, "mean_action_processing_ms": 0.09551284035011146, "mean_env_wait_ms": 0.1616173824262289, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7939, "timesteps_this_iter": 32, "agent_timesteps_total": 15878, "timers": {"learn_time_ms": 7.366, "learn_throughput": 4344.052, "update_time_ms": 4.394}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 7939, "num_agent_steps_sampled": 15878, "num_steps_trained": 12000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24000, "last_target_update_ts": 7839, "num_target_updates": 61}, "done": false, "episodes_total": 430, "training_iteration": 66, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-06", "timestamp": 1648815906, "time_this_iter_s": 0.46124815940856934, "time_total_s": 25.19515371322632, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51a7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51add0>"}, "time_since_restore": 25.19515371322632, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 31.6, "ram_util_percent": 49.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.76, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.88, "policy1": -7.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15406347701917666, "mean_inference_ms": 1.3829662325981835, "mean_action_processing_ms": 0.09553510390599759, "mean_env_wait_ms": 0.1616662839943774, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8039, "timesteps_this_iter": 32, "agent_timesteps_total": 16078, "timers": {"learn_time_ms": 6.82, "learn_throughput": 4692.321, "update_time_ms": 4.217}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8039, "num_agent_steps_sampled": 16078, "num_steps_trained": 12160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24320, "last_target_update_ts": 7959, "num_target_updates": 62}, "done": false, "episodes_total": 435, "training_iteration": 67, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-06", "timestamp": 1648815906, "time_this_iter_s": 0.3301858901977539, "time_total_s": 25.525339603424072, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fee60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fee60>"}, "time_since_restore": 25.525339603424072, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.96, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.98, "policy1": -7.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15408051336817277, "mean_inference_ms": 1.3830990533976972, "mean_action_processing_ms": 0.09555692826836154, "mean_env_wait_ms": 0.16172104221415004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8139, "timesteps_this_iter": 32, "agent_timesteps_total": 16278, "timers": {"learn_time_ms": 6.481, "learn_throughput": 4937.561, "update_time_ms": 4.05}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8139, "num_agent_steps_sampled": 16278, "num_steps_trained": 12320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24640, "last_target_update_ts": 8079, "num_target_updates": 63}, "done": false, "episodes_total": 440, "training_iteration": 68, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-06", "timestamp": 1648815906, "time_this_iter_s": 0.3046884536743164, "time_total_s": 25.83002805709839, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 25.83002805709839, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 31.7, "ram_util_percent": 49.6}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.76, "episode_len_mean": 18.58, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.88, "policy1": -7.88}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15409735099749775, "mean_inference_ms": 1.3832625236417186, "mean_action_processing_ms": 0.09558098306117464, "mean_env_wait_ms": 0.16177771955316567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8239, "timesteps_this_iter": 32, "agent_timesteps_total": 16478, "timers": {"learn_time_ms": 6.325, "learn_throughput": 5059.512, "update_time_ms": 3.938}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8239, "num_agent_steps_sampled": 16478, "num_steps_trained": 12480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24960, "last_target_update_ts": 8199, "num_target_updates": 64}, "done": false, "episodes_total": 445, "training_iteration": 69, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-07", "timestamp": 1648815907, "time_this_iter_s": 0.3002948760986328, "time_total_s": 26.13032293319702, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506b00>"}, "time_since_restore": 26.13032293319702, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.66, "episode_len_mean": 18.73, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.33, "policy1": -8.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15411556860327358, "mean_inference_ms": 1.3834528805629065, "mean_action_processing_ms": 0.09560749299930435, "mean_env_wait_ms": 0.16183863229909945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8339, "timesteps_this_iter": 32, "agent_timesteps_total": 16678, "timers": {"learn_time_ms": 6.29, "learn_throughput": 5087.319, "update_time_ms": 4.104}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8339, "num_agent_steps_sampled": 16678, "num_steps_trained": 12640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25280, "last_target_update_ts": 8319, "num_target_updates": 65}, "done": false, "episodes_total": 450, "training_iteration": 70, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-07", "timestamp": 1648815907, "time_this_iter_s": 0.3115658760070801, "time_total_s": 26.4418888092041, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b9e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b9e0>"}, "time_since_restore": 26.4418888092041, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 26.3, "ram_util_percent": 50.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.3, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.15, "policy1": -8.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0], "episode_lengths": [16, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20], "policy_policy0_reward": [4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0], "policy_policy1_reward": [4.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15414003952947158, "mean_inference_ms": 1.3837049003620936, "mean_action_processing_ms": 0.09564177231441276, "mean_env_wait_ms": 0.1619133350512583, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8451, "timesteps_this_iter": 32, "agent_timesteps_total": 16902, "timers": {"learn_time_ms": 6.321, "learn_throughput": 5062.279, "update_time_ms": 3.995}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8451, "num_agent_steps_sampled": 16902, "num_steps_trained": 12832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25664, "last_target_update_ts": 8431, "num_target_updates": 66}, "done": false, "episodes_total": 456, "training_iteration": 71, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-07", "timestamp": 1648815907, "time_this_iter_s": 0.3479475975036621, "time_total_s": 26.789836406707764, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fedd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fedd0>"}, "time_since_restore": 26.789836406707764, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.78, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.39, "policy1": -8.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 4.0, -20.0, 0.0, -20.0, -20.0, 0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 18, 20, 20, 20, 20, 20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 2.0, -10.0, 0.0, -10.0, -10.0, 0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15415730478244083, "mean_inference_ms": 1.3839139169772898, "mean_action_processing_ms": 0.09567057258554361, "mean_env_wait_ms": 0.16197558081365476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8551, "timesteps_this_iter": 32, "agent_timesteps_total": 17102, "timers": {"learn_time_ms": 6.355, "learn_throughput": 5035.141, "update_time_ms": 3.834}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8551, "num_agent_steps_sampled": 17102, "num_steps_trained": 12992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25984, "last_target_update_ts": 8551, "num_target_updates": 67}, "done": false, "episodes_total": 461, "training_iteration": 72, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-08", "timestamp": 1648815908, "time_this_iter_s": 0.31380248069763184, "time_total_s": 27.103638887405396, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 27.103638887405396, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 24.7, "ram_util_percent": 50.4}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.14, "episode_len_mean": 18.67, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.57, "policy1": -8.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -40.0, 14.0, -40.0, 2.0, -20.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0], "episode_lengths": [20, 20, 13, 20, 19, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20], "policy_policy0_reward": [0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0], "policy_policy1_reward": [0.0, -20.0, 7.0, -20.0, 1.0, -10.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1541808499582817, "mean_inference_ms": 1.3841685238806993, "mean_action_processing_ms": 0.09570116752604718, "mean_env_wait_ms": 0.16204480364722046, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8667, "timesteps_this_iter": 32, "agent_timesteps_total": 17334, "timers": {"learn_time_ms": 6.765, "learn_throughput": 4730.04, "update_time_ms": 4.176}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8667, "num_agent_steps_sampled": 17334, "num_steps_trained": 13184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26368, "last_target_update_ts": 8667, "num_target_updates": 68}, "done": false, "episodes_total": 467, "training_iteration": 73, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-08", "timestamp": 1648815908, "time_this_iter_s": 0.38951730728149414, "time_total_s": 27.49315619468689, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fe680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fe680>"}, "time_since_restore": 27.49315619468689, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 25.1, "ram_util_percent": 50.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.5, "episode_len_mean": 18.55, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.25, "policy1": -8.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0], "episode_lengths": [20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15421403978989168, "mean_inference_ms": 1.384463520197525, "mean_action_processing_ms": 0.09573390786257722, "mean_env_wait_ms": 0.16212001934122205, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8767, "timesteps_this_iter": 32, "agent_timesteps_total": 17534, "timers": {"learn_time_ms": 7.047, "learn_throughput": 4540.657, "update_time_ms": 4.02}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8767, "num_agent_steps_sampled": 17534, "num_steps_trained": 13376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26752, "last_target_update_ts": 8667, "num_target_updates": 68}, "done": false, "episodes_total": 473, "training_iteration": 74, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-09", "timestamp": 1648815909, "time_this_iter_s": 0.3580448627471924, "time_total_s": 27.851201057434082, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b950>"}, "time_since_restore": 27.851201057434082, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.1, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.55, "policy1": -8.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, 8.0, -40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 16, 20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15425314095647, "mean_inference_ms": 1.3848446773815368, "mean_action_processing_ms": 0.09577157044783131, "mean_env_wait_ms": 0.16220415679940048, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8867, "timesteps_this_iter": 32, "agent_timesteps_total": 17734, "timers": {"learn_time_ms": 6.683, "learn_throughput": 4788.462, "update_time_ms": 4.025}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8867, "num_agent_steps_sampled": 17734, "num_steps_trained": 13536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27072, "last_target_update_ts": 8787, "num_target_updates": 69}, "done": false, "episodes_total": 478, "training_iteration": 75, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-09", "timestamp": 1648815909, "time_this_iter_s": 0.3453216552734375, "time_total_s": 28.19652271270752, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4fe170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 28.19652271270752, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 51.1}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.16, "episode_len_mean": 18.68, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.58, "policy1": -8.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 14.0, -40.0, 0.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 13, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20], "policy_policy0_reward": [-20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 7.0, -20.0, 0.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15430464908991512, "mean_inference_ms": 1.3853622630131213, "mean_action_processing_ms": 0.09582189701635606, "mean_env_wait_ms": 0.16231119690836923, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8986, "timesteps_this_iter": 32, "agent_timesteps_total": 17972, "timers": {"learn_time_ms": 6.583, "learn_throughput": 4860.971, "update_time_ms": 4.138}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 8986, "num_agent_steps_sampled": 17972, "num_steps_trained": 13728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27456, "last_target_update_ts": 8907, "num_target_updates": 70}, "done": false, "episodes_total": 484, "training_iteration": 76, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-09", "timestamp": 1648815909, "time_this_iter_s": 0.38133835792541504, "time_total_s": 28.577861070632935, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 28.577861070632935, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.5, "episode_len_mean": 18.75, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.75, "policy1": -8.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 6, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15436379530438518, "mean_inference_ms": 1.3859563056900708, "mean_action_processing_ms": 0.09587765220340362, "mean_env_wait_ms": 0.16242023858357477, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9086, "timesteps_this_iter": 32, "agent_timesteps_total": 18172, "timers": {"learn_time_ms": 6.933, "learn_throughput": 4615.91, "update_time_ms": 4.201}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9086, "num_agent_steps_sampled": 18172, "num_steps_trained": 13888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27776, "last_target_update_ts": 9026, "num_target_updates": 71}, "done": false, "episodes_total": 489, "training_iteration": 77, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-10", "timestamp": 1648815910, "time_this_iter_s": 0.3549764156341553, "time_total_s": 28.93283748626709, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5040e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5040e0>"}, "time_since_restore": 28.93283748626709, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 23.2, "ram_util_percent": 51.4}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.18, "episode_len_mean": 18.89, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.09, "policy1": -9.09}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 18.0, 24.0, -40.0, -20.0, -40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 11, 8, 20, 20, 20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 9.0, 12.0, -20.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15442556272224345, "mean_inference_ms": 1.386610345823685, "mean_action_processing_ms": 0.09593672339444297, "mean_env_wait_ms": 0.16253755337773754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9186, "timesteps_this_iter": 32, "agent_timesteps_total": 18372, "timers": {"learn_time_ms": 6.904, "learn_throughput": 4635.23, "update_time_ms": 4.184}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9186, "num_agent_steps_sampled": 18372, "num_steps_trained": 14048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28096, "last_target_update_ts": 9146, "num_target_updates": 72}, "done": false, "episodes_total": 494, "training_iteration": 78, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-10", "timestamp": 1648815910, "time_this_iter_s": 0.3160586357116699, "time_total_s": 29.24889612197876, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b950>"}, "time_since_restore": 29.24889612197876, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.28, "episode_len_mean": 18.94, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.14, "policy1": -9.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 6.0, -20.0, -40.0, 22.0, 16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0], "episode_lengths": [20, 20, 17, 20, 20, 9, 12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20], "policy_policy0_reward": [-20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 3.0, -10.0, -20.0, 11.0, 8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15449689102282516, "mean_inference_ms": 1.387387877889583, "mean_action_processing_ms": 0.09600463079268212, "mean_env_wait_ms": 0.1626792139746332, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9290, "timesteps_this_iter": 32, "agent_timesteps_total": 18580, "timers": {"learn_time_ms": 6.466, "learn_throughput": 4948.721, "update_time_ms": 3.813}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9290, "num_agent_steps_sampled": 18580, "num_steps_trained": 14240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28480, "last_target_update_ts": 9262, "num_target_updates": 73}, "done": false, "episodes_total": 500, "training_iteration": 79, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-10", "timestamp": 1648815910, "time_this_iter_s": 0.33730006217956543, "time_total_s": 29.586196184158325, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50a4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fed40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50a4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4fed40>"}, "time_since_restore": 29.586196184158325, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 51.9}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.94, "episode_len_mean": 19.07, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.47, "policy1": -9.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, 10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [12, 15, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [8.0, 5.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15456484697400197, "mean_inference_ms": 1.3882118828939098, "mean_action_processing_ms": 0.09607612917294471, "mean_env_wait_ms": 0.1628216133158572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9409, "timesteps_this_iter": 32, "agent_timesteps_total": 18818, "timers": {"learn_time_ms": 6.622, "learn_throughput": 4832.478, "update_time_ms": 3.782}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9409, "num_agent_steps_sampled": 18818, "num_steps_trained": 14432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28864, "last_target_update_ts": 9369, "num_target_updates": 74}, "done": false, "episodes_total": 506, "training_iteration": 80, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-11", "timestamp": 1648815911, "time_this_iter_s": 0.37929701805114746, "time_total_s": 29.965493202209473, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ba70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ba70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 29.965493202209473, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.46, "episode_len_mean": 19.03, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.73, "policy1": -9.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13], "policy_policy0_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15464204952636995, "mean_inference_ms": 1.3891197332355092, "mean_action_processing_ms": 0.09615641651897346, "mean_env_wait_ms": 0.1629765515546785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9512, "timesteps_this_iter": 32, "agent_timesteps_total": 19024, "timers": {"learn_time_ms": 6.737, "learn_throughput": 4749.91, "update_time_ms": 4.013}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9512, "num_agent_steps_sampled": 19024, "num_steps_trained": 14624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29248, "last_target_update_ts": 9479, "num_target_updates": 75}, "done": false, "episodes_total": 512, "training_iteration": 81, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-11", "timestamp": 1648815911, "time_this_iter_s": 0.3775801658630371, "time_total_s": 30.34307336807251, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "time_since_restore": 30.34307336807251, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 25.4, "ram_util_percent": 52.2}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.54, "episode_len_mean": 18.97, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.77, "policy1": -9.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 8.0, 24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 16, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 4.0, 12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15472423128716492, "mean_inference_ms": 1.3900861369877882, "mean_action_processing_ms": 0.09623918005211385, "mean_env_wait_ms": 0.16312818812324997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9620, "timesteps_this_iter": 32, "agent_timesteps_total": 19240, "timers": {"learn_time_ms": 6.402, "learn_throughput": 4998.109, "update_time_ms": 4.085}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9620, "num_agent_steps_sampled": 19240, "num_steps_trained": 14816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29632, "last_target_update_ts": 9582, "num_target_updates": 76}, "done": false, "episodes_total": 518, "training_iteration": 82, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-12", "timestamp": 1648815912, "time_this_iter_s": 0.3491382598876953, "time_total_s": 30.692211627960205, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "time_since_restore": 30.692211627960205, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.4, "episode_len_mean": 19.0, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.7, "policy1": -9.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 16.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20], "policy_policy0_reward": [12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, 8.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1547789379358255, "mean_inference_ms": 1.3907560168508046, "mean_action_processing_ms": 0.09629739584519072, "mean_env_wait_ms": 0.16323852816074716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9739, "timesteps_this_iter": 32, "agent_timesteps_total": 19478, "timers": {"learn_time_ms": 6.284, "learn_throughput": 5091.893, "update_time_ms": 3.92}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9739, "num_agent_steps_sampled": 19478, "num_steps_trained": 15008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30016, "last_target_update_ts": 9699, "num_target_updates": 77}, "done": false, "episodes_total": 524, "training_iteration": 83, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-12", "timestamp": 1648815912, "time_this_iter_s": 0.4972679615020752, "time_total_s": 31.18947958946228, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5047a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5047a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "time_since_restore": 31.18947958946228, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 27.0, "ram_util_percent": 52.7}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.2, "episode_len_mean": 19.2, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -10.1, "policy1": -10.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1548031793978925, "mean_inference_ms": 1.3911531910085262, "mean_action_processing_ms": 0.09633249172186069, "mean_env_wait_ms": 0.16331063511198926, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9839, "timesteps_this_iter": 32, "agent_timesteps_total": 19678, "timers": {"learn_time_ms": 6.415, "learn_throughput": 4988.301, "update_time_ms": 3.933}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9839, "num_agent_steps_sampled": 19678, "num_steps_trained": 15168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30336, "last_target_update_ts": 9819, "num_target_updates": 78}, "done": false, "episodes_total": 529, "training_iteration": 84, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-12", "timestamp": 1648815912, "time_this_iter_s": 0.33013463020324707, "time_total_s": 31.519614219665527, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ba70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ba70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 31.519614219665527, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 24.1, "ram_util_percent": 53.0}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.5, "episode_len_mean": 19.05, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.75, "policy1": -9.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1548292479856814, "mean_inference_ms": 1.3916075943501727, "mean_action_processing_ms": 0.09637192720650656, "mean_env_wait_ms": 0.1633926447217572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9944, "timesteps_this_iter": 32, "agent_timesteps_total": 19888, "timers": {"learn_time_ms": 6.524, "learn_throughput": 4904.776, "update_time_ms": 4.054}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 9944, "num_agent_steps_sampled": 19888, "num_steps_trained": 15360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30720, "last_target_update_ts": 9924, "num_target_updates": 79}, "done": false, "episodes_total": 535, "training_iteration": 85, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-13", "timestamp": 1648815913, "time_this_iter_s": 0.3576774597167969, "time_total_s": 31.877291679382324, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "time_since_restore": 31.877291679382324, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.4, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.2, "policy1": -9.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15487199423155698, "mean_inference_ms": 1.392176621976163, "mean_action_processing_ms": 0.09642414636990732, "mean_env_wait_ms": 0.16348466825760533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10059, "timesteps_this_iter": 32, "agent_timesteps_total": 20118, "timers": {"learn_time_ms": 6.43, "learn_throughput": 4976.926, "update_time_ms": 3.915}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10059, "num_agent_steps_sampled": 20118, "num_steps_trained": 15584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31168, "last_target_update_ts": 10039, "num_target_updates": 80}, "done": false, "episodes_total": 542, "training_iteration": 86, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-13", "timestamp": 1648815913, "time_this_iter_s": 0.38628244400024414, "time_total_s": 32.26357412338257, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "time_since_restore": 32.26357412338257, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 24.6, "ram_util_percent": 53.1}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.98, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -8.99, "policy1": -8.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1549154521457481, "mean_inference_ms": 1.3927100765329323, "mean_action_processing_ms": 0.0964719292319309, "mean_env_wait_ms": 0.16356546999108296, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10168, "timesteps_this_iter": 32, "agent_timesteps_total": 20336, "timers": {"learn_time_ms": 6.507, "learn_throughput": 4918.094, "update_time_ms": 3.841}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10168, "num_agent_steps_sampled": 20336, "num_steps_trained": 15776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31552, "last_target_update_ts": 10148, "num_target_updates": 81}, "done": false, "episodes_total": 548, "training_iteration": 87, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-14", "timestamp": 1648815914, "time_this_iter_s": 0.3569345474243164, "time_total_s": 32.620508670806885, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "time_since_restore": 32.620508670806885, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.62, "episode_len_mean": 18.71, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -8.81, "policy1": -8.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15497662520673494, "mean_inference_ms": 1.3934392697107791, "mean_action_processing_ms": 0.09653715950514438, "mean_env_wait_ms": 0.16366454301503627, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10282, "timesteps_this_iter": 32, "agent_timesteps_total": 20564, "timers": {"learn_time_ms": 6.708, "learn_throughput": 4770.659, "update_time_ms": 4.148}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10282, "num_agent_steps_sampled": 20564, "num_steps_trained": 15968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31936, "last_target_update_ts": 10262, "num_target_updates": 82}, "done": false, "episodes_total": 554, "training_iteration": 88, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-14", "timestamp": 1648815914, "time_this_iter_s": 0.40991783142089844, "time_total_s": 33.03042650222778, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 33.03042650222778, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 25.6, "ram_util_percent": 53.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.72, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.36, "policy1": -8.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 8.0, -20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 16, 20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 4.0, -10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15504935489547406, "mean_inference_ms": 1.3942274167311057, "mean_action_processing_ms": 0.09660707199657015, "mean_env_wait_ms": 0.1637666329165836, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10387, "timesteps_this_iter": 32, "agent_timesteps_total": 20774, "timers": {"learn_time_ms": 6.791, "learn_throughput": 4711.94, "update_time_ms": 4.304}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10387, "num_agent_steps_sampled": 20774, "num_steps_trained": 16160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32320, "last_target_update_ts": 10367, "num_target_updates": 83}, "done": false, "episodes_total": 560, "training_iteration": 89, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-14", "timestamp": 1648815914, "time_this_iter_s": 0.37410593032836914, "time_total_s": 33.40453243255615, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "time_since_restore": 33.40453243255615, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 24.8, "ram_util_percent": 53.3}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.3, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.15, "policy1": -8.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 0.0, -20.0, -20.0, 22.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 9, 11, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 0.0, -10.0, -10.0, 11.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15512793282662013, "mean_inference_ms": 1.3950512317177786, "mean_action_processing_ms": 0.09668068196177206, "mean_env_wait_ms": 0.16387535728160377, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10492, "timesteps_this_iter": 32, "agent_timesteps_total": 20984, "timers": {"learn_time_ms": 6.871, "learn_throughput": 4657.556, "update_time_ms": 4.029}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10492, "num_agent_steps_sampled": 20984, "num_steps_trained": 16352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32704, "last_target_update_ts": 10472, "num_target_updates": 84}, "done": false, "episodes_total": 566, "training_iteration": 90, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-15", "timestamp": 1648815915, "time_this_iter_s": 0.3775291442871094, "time_total_s": 33.78206157684326, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ba70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ba70>"}, "time_since_restore": 33.78206157684326, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.06, "episode_len_mean": 18.53, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.53, "policy1": -8.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1552042768640041, "mean_inference_ms": 1.3958914039237253, "mean_action_processing_ms": 0.09675279158602974, "mean_env_wait_ms": 0.1639850837140607, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10600, "timesteps_this_iter": 32, "agent_timesteps_total": 21200, "timers": {"learn_time_ms": 6.742, "learn_throughput": 4746.064, "update_time_ms": 4.213}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10600, "num_agent_steps_sampled": 21200, "num_steps_trained": 16544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33088, "last_target_update_ts": 10580, "num_target_updates": 85}, "done": false, "episodes_total": 572, "training_iteration": 91, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-15", "timestamp": 1648815915, "time_this_iter_s": 0.38706064224243164, "time_total_s": 34.16912221908569, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a4d0>"}, "time_since_restore": 34.16912221908569, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 25.1, "ram_util_percent": 53.5}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.46, "episode_len_mean": 18.53, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.73, "policy1": -8.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1552564018213597, "mean_inference_ms": 1.3964863345406833, "mean_action_processing_ms": 0.09680404224911353, "mean_env_wait_ms": 0.16405901373912815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10700, "timesteps_this_iter": 32, "agent_timesteps_total": 21400, "timers": {"learn_time_ms": 6.622, "learn_throughput": 4832.478, "update_time_ms": 4.358}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10700, "num_agent_steps_sampled": 21400, "num_steps_trained": 16704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33408, "last_target_update_ts": 10700, "num_target_updates": 86}, "done": false, "episodes_total": 577, "training_iteration": 92, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-16", "timestamp": 1648815916, "time_this_iter_s": 0.3100290298461914, "time_total_s": 34.479151248931885, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50a5f0>"}, "time_since_restore": 34.479151248931885, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.42, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.71, "policy1": -8.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15532106597401424, "mean_inference_ms": 1.3971809735268343, "mean_action_processing_ms": 0.09686263554831971, "mean_env_wait_ms": 0.1641463806218951, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10807, "timesteps_this_iter": 32, "agent_timesteps_total": 21614, "timers": {"learn_time_ms": 6.407, "learn_throughput": 4994.631, "update_time_ms": 3.869}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10807, "num_agent_steps_sampled": 21614, "num_steps_trained": 16896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33792, "last_target_update_ts": 10807, "num_target_updates": 87}, "done": false, "episodes_total": 583, "training_iteration": 93, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-16", "timestamp": 1648815916, "time_this_iter_s": 0.3543813228607178, "time_total_s": 34.8335325717926, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50ac20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51a7a0>"}, "time_since_restore": 34.8335325717926, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 26.3, "ram_util_percent": 53.6}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.5, "episode_len_mean": 18.25, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.25, "policy1": -8.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1553767932385162, "mean_inference_ms": 1.3977320481603925, "mean_action_processing_ms": 0.09691040416322821, "mean_env_wait_ms": 0.16421607169572083, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10911, "timesteps_this_iter": 32, "agent_timesteps_total": 21822, "timers": {"learn_time_ms": 6.267, "learn_throughput": 5105.801, "update_time_ms": 3.726}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 10911, "num_agent_steps_sampled": 21822, "num_steps_trained": 17088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34176, "last_target_update_ts": 10911, "num_target_updates": 88}, "done": false, "episodes_total": 589, "training_iteration": 94, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-16", "timestamp": 1648815916, "time_this_iter_s": 0.33498382568359375, "time_total_s": 35.168516397476196, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c505560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c505560>"}, "time_since_restore": 35.168516397476196, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.7, "episode_len_mean": 18.25, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.35, "policy1": -8.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 8.0, -40.0, 24.0, -20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 16, 20, 8, 20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 4.0, -20.0, 12.0, -10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15542347989093638, "mean_inference_ms": 1.398152868448709, "mean_action_processing_ms": 0.09694653790517195, "mean_env_wait_ms": 0.16426403895402988, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11011, "timesteps_this_iter": 32, "agent_timesteps_total": 22022, "timers": {"learn_time_ms": 6.452, "learn_throughput": 4959.363, "update_time_ms": 3.802}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11011, "num_agent_steps_sampled": 22022, "num_steps_trained": 17248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34496, "last_target_update_ts": 10911, "num_target_updates": 88}, "done": false, "episodes_total": 594, "training_iteration": 95, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-17", "timestamp": 1648815917, "time_this_iter_s": 0.3134775161743164, "time_total_s": 35.48199391365051, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "time_since_restore": 35.48199391365051, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 25.6, "ram_util_percent": 53.7}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.91, "policy1": -8.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 2.0, -40.0, -40.0, -40.0, -20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 19, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15546642990992487, "mean_inference_ms": 1.3985555851805975, "mean_action_processing_ms": 0.09698080479278602, "mean_env_wait_ms": 0.16431036557961654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11111, "timesteps_this_iter": 32, "agent_timesteps_total": 22222, "timers": {"learn_time_ms": 6.373, "learn_throughput": 5021.014, "update_time_ms": 3.85}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11111, "num_agent_steps_sampled": 22222, "num_steps_trained": 17408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 34816, "last_target_update_ts": 11031, "num_target_updates": 89}, "done": false, "episodes_total": 599, "training_iteration": 96, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-17", "timestamp": 1648815917, "time_this_iter_s": 0.30074453353881836, "time_total_s": 35.78273844718933, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "time_since_restore": 35.78273844718933, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.44, "episode_len_mean": 18.42, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.72, "policy1": -8.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 20.0, -20.0, -40.0, -40.0, 14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 10.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1555051909357947, "mean_inference_ms": 1.3989173254536356, "mean_action_processing_ms": 0.09701345571034274, "mean_env_wait_ms": 0.16435401694172028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11211, "timesteps_this_iter": 32, "agent_timesteps_total": 22422, "timers": {"learn_time_ms": 6.31, "learn_throughput": 5071.595, "update_time_ms": 3.81}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11211, "num_agent_steps_sampled": 22422, "num_steps_trained": 17568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35136, "last_target_update_ts": 11151, "num_target_updates": 90}, "done": false, "episodes_total": 604, "training_iteration": 97, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-17", "timestamp": 1648815917, "time_this_iter_s": 0.30387258529663086, "time_total_s": 36.08661103248596, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c504830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c504830>"}, "time_since_restore": 36.08661103248596, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 25.5, "ram_util_percent": 53.8}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.56, "episode_len_mean": 18.28, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.28, "policy1": -8.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -40.0, -40.0, -20.0, 20.0, 4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0], "episode_lengths": [13, 20, 20, 20, 10, 18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20], "policy_policy0_reward": [7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0], "policy_policy1_reward": [7.0, -20.0, -20.0, -10.0, 10.0, 2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15554722447584587, "mean_inference_ms": 1.3992725798632313, "mean_action_processing_ms": 0.09704695721616448, "mean_env_wait_ms": 0.16439257057563256, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11327, "timesteps_this_iter": 32, "agent_timesteps_total": 22654, "timers": {"learn_time_ms": 6.115, "learn_throughput": 5232.905, "update_time_ms": 3.846}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11327, "num_agent_steps_sampled": 22654, "num_steps_trained": 17792, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35584, "last_target_update_ts": 11259, "num_target_updates": 91}, "done": false, "episodes_total": 611, "training_iteration": 98, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-18", "timestamp": 1648815918, "time_this_iter_s": 0.3748469352722168, "time_total_s": 36.46145796775818, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c505560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c505560>"}, "time_since_restore": 36.46145796775818, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.3, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.65, "policy1": -8.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [18, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [2.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15557024516567758, "mean_inference_ms": 1.3994582353552927, "mean_action_processing_ms": 0.0970653991459594, "mean_env_wait_ms": 0.164414936427073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11427, "timesteps_this_iter": 32, "agent_timesteps_total": 22854, "timers": {"learn_time_ms": 6.047, "learn_throughput": 5291.579, "update_time_ms": 3.81}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11427, "num_agent_steps_sampled": 22854, "num_steps_trained": 17952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35904, "last_target_update_ts": 11367, "num_target_updates": 92}, "done": false, "episodes_total": 616, "training_iteration": 99, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-18", "timestamp": 1648815918, "time_this_iter_s": 0.2983384132385254, "time_total_s": 36.759796380996704, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "time_since_restore": 36.759796380996704, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 24.3, "ram_util_percent": 53.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.16, "episode_len_mean": 18.48, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.08, "policy1": -9.08}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15559602179725002, "mean_inference_ms": 1.3996895946740973, "mean_action_processing_ms": 0.09708819904938527, "mean_env_wait_ms": 0.1644454647585189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11527, "timesteps_this_iter": 32, "agent_timesteps_total": 23054, "timers": {"learn_time_ms": 6.145, "learn_throughput": 5207.526, "update_time_ms": 3.781}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11527, "num_agent_steps_sampled": 23054, "num_steps_trained": 18112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36224, "last_target_update_ts": 11487, "num_target_updates": 93}, "done": false, "episodes_total": 621, "training_iteration": 100, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-18", "timestamp": 1648815918, "time_this_iter_s": 0.31473708152770996, "time_total_s": 37.074533462524414, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b830>"}, "time_since_restore": 37.074533462524414, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.36, "episode_len_mean": 18.48, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.18, "policy1": -9.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 14.0, -40.0, -20.0, 16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 13, 20, 20, 12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 7.0, -20.0, -10.0, 8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15562404712659006, "mean_inference_ms": 1.399934021118259, "mean_action_processing_ms": 0.09711223580427292, "mean_env_wait_ms": 0.16447845540076267, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11627, "timesteps_this_iter": 32, "agent_timesteps_total": 23254, "timers": {"learn_time_ms": 6.366, "learn_throughput": 5026.392, "update_time_ms": 3.79}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11627, "num_agent_steps_sampled": 23254, "num_steps_trained": 18272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36544, "last_target_update_ts": 11607, "num_target_updates": 94}, "done": false, "episodes_total": 626, "training_iteration": 101, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-19", "timestamp": 1648815919, "time_this_iter_s": 0.3217477798461914, "time_total_s": 37.396281242370605, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5047a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5047a0>"}, "time_since_restore": 37.396281242370605, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 24.3, "ram_util_percent": 53.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.48, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.24, "policy1": -9.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, -20.0, 20.0, 24.0, -20.0, 6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0], "episode_lengths": [12, 20, 20, 10, 8, 20, 17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20], "policy_policy0_reward": [8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [8.0, -10.0, -10.0, 10.0, 12.0, -10.0, 3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15565472900001512, "mean_inference_ms": 1.4002405053681017, "mean_action_processing_ms": 0.0971426269090091, "mean_env_wait_ms": 0.16451420780366427, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11746, "timesteps_this_iter": 32, "agent_timesteps_total": 23492, "timers": {"learn_time_ms": 6.848, "learn_throughput": 4673.108, "update_time_ms": 4.162}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11746, "num_agent_steps_sampled": 23492, "num_steps_trained": 18464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36928, "last_target_update_ts": 11726, "num_target_updates": 95}, "done": false, "episodes_total": 632, "training_iteration": 102, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-19", "timestamp": 1648815919, "time_this_iter_s": 0.4041461944580078, "time_total_s": 37.80042743682861, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c507b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c507b90>"}, "time_since_restore": 37.80042743682861, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.72, "episode_len_mean": 18.76, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.86, "policy1": -9.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -20.0, -40.0, -20.0, 16.0, -40.0, -40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0], "episode_lengths": [17, 20, 20, 20, 12, 20, 20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20], "policy_policy0_reward": [3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [3.0, -10.0, -20.0, -10.0, 8.0, -20.0, -20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15568198679020892, "mean_inference_ms": 1.4005339283831932, "mean_action_processing_ms": 0.09717144252717168, "mean_env_wait_ms": 0.1645448811746215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11858, "timesteps_this_iter": 32, "agent_timesteps_total": 23716, "timers": {"learn_time_ms": 6.561, "learn_throughput": 4877.133, "update_time_ms": 4.091}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11858, "num_agent_steps_sampled": 23716, "num_steps_trained": 18656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37312, "last_target_update_ts": 11838, "num_target_updates": 96}, "done": false, "episodes_total": 638, "training_iteration": 103, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-20", "timestamp": 1648815920, "time_this_iter_s": 0.36463379859924316, "time_total_s": 38.165061235427856, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c510170>"}, "time_since_restore": 38.165061235427856, "timesteps_since_restore": 3296, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 25.8, "ram_util_percent": 53.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.24, "episode_len_mean": 18.82, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.12, "policy1": -10.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 6.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 17, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20], "policy_policy0_reward": [-20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, 3.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15572127930290797, "mean_inference_ms": 1.4009392444308835, "mean_action_processing_ms": 0.09720985189328152, "mean_env_wait_ms": 0.16459830895993224, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11973, "timesteps_this_iter": 32, "agent_timesteps_total": 23946, "timers": {"learn_time_ms": 6.588, "learn_throughput": 4857.259, "update_time_ms": 4.09}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 11973, "num_agent_steps_sampled": 23946, "num_steps_trained": 18848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37696, "last_target_update_ts": 11953, "num_target_updates": 97}, "done": false, "episodes_total": 644, "training_iteration": 104, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-20", "timestamp": 1648815920, "time_this_iter_s": 0.405684232711792, "time_total_s": 38.57074546813965, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 38.57074546813965, "timesteps_since_restore": 3328, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 26.3, "ram_util_percent": 54.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.8, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.9, "policy1": -9.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 12.0, -20.0, -20.0, -20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 14, 20, 20, 20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 6.0, -10.0, -10.0, -10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15576000881524557, "mean_inference_ms": 1.4013125179478059, "mean_action_processing_ms": 0.09724547966287453, "mean_env_wait_ms": 0.16464731751586872, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12088, "timesteps_this_iter": 32, "agent_timesteps_total": 24176, "timers": {"learn_time_ms": 6.427, "learn_throughput": 4979.326, "update_time_ms": 3.986}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12088, "num_agent_steps_sampled": 24176, "num_steps_trained": 19040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38080, "last_target_update_ts": 12068, "num_target_updates": 98}, "done": false, "episodes_total": 650, "training_iteration": 105, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-20", "timestamp": 1648815920, "time_this_iter_s": 0.37023186683654785, "time_total_s": 38.940977334976196, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "time_since_restore": 38.940977334976196, "timesteps_since_restore": 3360, "iterations_since_restore": 105, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.32, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.16, "policy1": -10.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 28.0, 2.0, -20.0, -20.0, -20.0, 30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 6, 19, 20, 20, 20, 5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 14.0, 1.0, -10.0, -10.0, -10.0, 15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15579103887843426, "mean_inference_ms": 1.4016142355135524, "mean_action_processing_ms": 0.09727349843367974, "mean_env_wait_ms": 0.16468682214061048, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12188, "timesteps_this_iter": 32, "agent_timesteps_total": 24376, "timers": {"learn_time_ms": 6.503, "learn_throughput": 4920.816, "update_time_ms": 4.337}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12188, "num_agent_steps_sampled": 24376, "num_steps_trained": 19200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38400, "last_target_update_ts": 12188, "num_target_updates": 99}, "done": false, "episodes_total": 655, "training_iteration": 106, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-21", "timestamp": 1648815921, "time_this_iter_s": 0.3515286445617676, "time_total_s": 39.292505979537964, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 39.292505979537964, "timesteps_since_restore": 3392, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 54.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.42, "episode_len_mean": 18.81, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -10.21, "policy1": -10.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0], "episode_lengths": [5, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14], "policy_policy0_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0], "policy_policy1_reward": [15.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15583126068825456, "mean_inference_ms": 1.401993546541845, "mean_action_processing_ms": 0.09731079154376548, "mean_env_wait_ms": 0.16473971115974934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12288, "timesteps_this_iter": 32, "agent_timesteps_total": 24576, "timers": {"learn_time_ms": 6.746, "learn_throughput": 4743.548, "update_time_ms": 4.511}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12288, "num_agent_steps_sampled": 24576, "num_steps_trained": 19392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38784, "last_target_update_ts": 12188, "num_target_updates": 99}, "done": false, "episodes_total": 661, "training_iteration": 107, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-21", "timestamp": 1648815921, "time_this_iter_s": 0.35942792892456055, "time_total_s": 39.651933908462524, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5085f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "time_since_restore": 39.651933908462524, "timesteps_since_restore": 3424, "iterations_since_restore": 107, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.7, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.85, "policy1": -9.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15588183376036263, "mean_inference_ms": 1.4023732039748682, "mean_action_processing_ms": 0.09735274274204266, "mean_env_wait_ms": 0.1647887506305197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12405, "timesteps_this_iter": 32, "agent_timesteps_total": 24810, "timers": {"learn_time_ms": 6.67, "learn_throughput": 4797.928, "update_time_ms": 3.966}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12405, "num_agent_steps_sampled": 24810, "num_steps_trained": 19616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39232, "last_target_update_ts": 12308, "num_target_updates": 100}, "done": false, "episodes_total": 669, "training_iteration": 108, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-22", "timestamp": 1648815922, "time_this_iter_s": 0.40790414810180664, "time_total_s": 40.05983805656433, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c504710>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c504710>"}, "time_since_restore": 40.05983805656433, "timesteps_since_restore": 3456, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 26.8, "ram_util_percent": 54.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.5, "episode_len_mean": 18.65, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.75, "policy1": -9.75}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, 26.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, 13.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15591296252273776, "mean_inference_ms": 1.4025972543007297, "mean_action_processing_ms": 0.09737809005216364, "mean_env_wait_ms": 0.16481808254097974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12505, "timesteps_this_iter": 32, "agent_timesteps_total": 25010, "timers": {"learn_time_ms": 6.867, "learn_throughput": 4660.273, "update_time_ms": 4.13}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12505, "num_agent_steps_sampled": 25010, "num_steps_trained": 19776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39552, "last_target_update_ts": 12425, "num_target_updates": 101}, "done": false, "episodes_total": 674, "training_iteration": 109, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-22", "timestamp": 1648815922, "time_this_iter_s": 0.33310389518737793, "time_total_s": 40.39294195175171, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508ef0>"}, "time_since_restore": 40.39294195175171, "timesteps_since_restore": 3488, "iterations_since_restore": 109, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.28, "episode_len_mean": 18.64, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.64, "policy1": -9.64}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15595506929234662, "mean_inference_ms": 1.4028915290497659, "mean_action_processing_ms": 0.09741067082783557, "mean_env_wait_ms": 0.1648556743305614, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12611, "timesteps_this_iter": 32, "agent_timesteps_total": 25222, "timers": {"learn_time_ms": 6.765, "learn_throughput": 4730.39, "update_time_ms": 3.993}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12611, "num_agent_steps_sampled": 25222, "num_steps_trained": 19968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39936, "last_target_update_ts": 12531, "num_target_updates": 102}, "done": false, "episodes_total": 680, "training_iteration": 110, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-22", "timestamp": 1648815922, "time_this_iter_s": 0.3607308864593506, "time_total_s": 40.75367283821106, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c504710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 40.75367283821106, "timesteps_since_restore": 3520, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 28.0, "ram_util_percent": 54.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.86, "episode_len_mean": 18.63, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.43, "policy1": -9.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15599682579664476, "mean_inference_ms": 1.4032167238844624, "mean_action_processing_ms": 0.09744698099591886, "mean_env_wait_ms": 0.16489332560359768, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12724, "timesteps_this_iter": 32, "agent_timesteps_total": 25448, "timers": {"learn_time_ms": 6.558, "learn_throughput": 4879.669, "update_time_ms": 4.117}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12724, "num_agent_steps_sampled": 25448, "num_steps_trained": 20160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40320, "last_target_update_ts": 12651, "num_target_updates": 103}, "done": false, "episodes_total": 686, "training_iteration": 111, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-23", "timestamp": 1648815923, "time_this_iter_s": 0.38063859939575195, "time_total_s": 41.13431143760681, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "time_since_restore": 41.13431143760681, "timesteps_since_restore": 3552, "iterations_since_restore": 111, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.48, "episode_len_mean": 18.64, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.24, "policy1": -9.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15604931452303583, "mean_inference_ms": 1.4036616443106846, "mean_action_processing_ms": 0.09749183016748322, "mean_env_wait_ms": 0.16494268541935825, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12835, "timesteps_this_iter": 32, "agent_timesteps_total": 25670, "timers": {"learn_time_ms": 6.669, "learn_throughput": 4798.1, "update_time_ms": 4.097}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12835, "num_agent_steps_sampled": 25670, "num_steps_trained": 20352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40704, "last_target_update_ts": 12763, "num_target_updates": 104}, "done": false, "episodes_total": 692, "training_iteration": 112, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-23", "timestamp": 1648815923, "time_this_iter_s": 0.39899206161499023, "time_total_s": 41.5333034992218, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 41.5333034992218, "timesteps_since_restore": 3584, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 28.5, "ram_util_percent": 54.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.98, "episode_len_mean": 18.59, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.99, "policy1": -8.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1561100686030693, "mean_inference_ms": 1.4041586359288956, "mean_action_processing_ms": 0.09754282735339732, "mean_env_wait_ms": 0.16500416276466395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12950, "timesteps_this_iter": 32, "agent_timesteps_total": 25900, "timers": {"learn_time_ms": 6.806, "learn_throughput": 4701.476, "update_time_ms": 4.146}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 12950, "num_agent_steps_sampled": 25900, "num_steps_trained": 20544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41088, "last_target_update_ts": 12875, "num_target_updates": 105}, "done": false, "episodes_total": 698, "training_iteration": 113, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-24", "timestamp": 1648815924, "time_this_iter_s": 0.38505053520202637, "time_total_s": 41.91835403442383, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5085f0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5085f0>"}, "time_since_restore": 41.91835403442383, "timesteps_since_restore": 3616, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 28.8, "ram_util_percent": 54.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.78, "episode_len_mean": 18.59, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.89, "policy1": -8.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 24.0, -20.0, 24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0], "episode_lengths": [20, 20, 20, 8, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 12.0, -10.0, 12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1561638784949176, "mean_inference_ms": 1.4045959771777796, "mean_action_processing_ms": 0.0975872542168263, "mean_env_wait_ms": 0.1650577886789738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13050, "timesteps_this_iter": 32, "agent_timesteps_total": 26100, "timers": {"learn_time_ms": 6.635, "learn_throughput": 4823.049, "update_time_ms": 4.109}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13050, "num_agent_steps_sampled": 26100, "num_steps_trained": 20704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41408, "last_target_update_ts": 12990, "num_target_updates": 106}, "done": false, "episodes_total": 703, "training_iteration": 114, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-24", "timestamp": 1648815924, "time_this_iter_s": 0.31221866607666016, "time_total_s": 42.23057270050049, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 42.23057270050049, "timesteps_since_restore": 3648, "iterations_since_restore": 114, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.22, "episode_len_mean": 18.71, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.11, "policy1": -9.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15622052618519805, "mean_inference_ms": 1.405091156822121, "mean_action_processing_ms": 0.09763557438823404, "mean_env_wait_ms": 0.16511834813163673, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13150, "timesteps_this_iter": 32, "agent_timesteps_total": 26300, "timers": {"learn_time_ms": 6.53, "learn_throughput": 4900.478, "update_time_ms": 4.151}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13150, "num_agent_steps_sampled": 26300, "num_steps_trained": 20864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41728, "last_target_update_ts": 13110, "num_target_updates": 107}, "done": false, "episodes_total": 708, "training_iteration": 115, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-24", "timestamp": 1648815924, "time_this_iter_s": 0.3291356563568115, "time_total_s": 42.5597083568573, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "time_since_restore": 42.5597083568573, "timesteps_since_restore": 3680, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 54.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.26, "episode_len_mean": 18.83, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.13, "policy1": -9.13}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15627858498153155, "mean_inference_ms": 1.405604970705418, "mean_action_processing_ms": 0.09768597594365072, "mean_env_wait_ms": 0.16518140346286964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13250, "timesteps_this_iter": 32, "agent_timesteps_total": 26500, "timers": {"learn_time_ms": 6.52, "learn_throughput": 4908.328, "update_time_ms": 4.252}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13250, "num_agent_steps_sampled": 26500, "num_steps_trained": 21024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42048, "last_target_update_ts": 13230, "num_target_updates": 108}, "done": false, "episodes_total": 713, "training_iteration": 116, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-25", "timestamp": 1648815925, "time_this_iter_s": 0.3175523281097412, "time_total_s": 42.87726068496704, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 42.87726068496704, "timesteps_since_restore": 3712, "iterations_since_restore": 116, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.18, "episode_len_mean": 18.69, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.59, "policy1": -8.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1563568139081167, "mean_inference_ms": 1.4062861244674116, "mean_action_processing_ms": 0.09775257613092926, "mean_env_wait_ms": 0.1652685919008931, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13356, "timesteps_this_iter": 32, "agent_timesteps_total": 26712, "timers": {"learn_time_ms": 6.614, "learn_throughput": 4838.105, "update_time_ms": 4.083}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13356, "num_agent_steps_sampled": 26712, "num_steps_trained": 21216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42432, "last_target_update_ts": 13336, "num_target_updates": 109}, "done": false, "episodes_total": 719, "training_iteration": 117, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-25", "timestamp": 1648815925, "time_this_iter_s": 0.36092567443847656, "time_total_s": 43.23818635940552, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508d40>"}, "time_since_restore": 43.23818635940552, "timesteps_since_restore": 3744, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 26.2, "ram_util_percent": 54.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.38, "episode_len_mean": 18.59, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.19, "policy1": -8.19}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 2.0, -20.0, -20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 19, 20, 20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 1.0, -10.0, -10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15644341182151641, "mean_inference_ms": 1.407027426156717, "mean_action_processing_ms": 0.09782388025244605, "mean_env_wait_ms": 0.16536485607961776, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13466, "timesteps_this_iter": 32, "agent_timesteps_total": 26932, "timers": {"learn_time_ms": 6.86, "learn_throughput": 4664.97, "update_time_ms": 3.998}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13466, "num_agent_steps_sampled": 26932, "num_steps_trained": 21408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42816, "last_target_update_ts": 13446, "num_target_updates": 110}, "done": false, "episodes_total": 725, "training_iteration": 118, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-26", "timestamp": 1648815926, "time_this_iter_s": 0.3884003162384033, "time_total_s": 43.62658667564392, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5199e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 43.62658667564392, "timesteps_since_restore": 3776, "iterations_since_restore": 118, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.6, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.3, "policy1": -8.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 6.0, -20.0, 10.0, -40.0, -40.0, -40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 17, 20, 15, 20, 20, 20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 3.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1565153043765098, "mean_inference_ms": 1.407622870662867, "mean_action_processing_ms": 0.09788192019140457, "mean_env_wait_ms": 0.16544457495723272, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13566, "timesteps_this_iter": 32, "agent_timesteps_total": 27132, "timers": {"learn_time_ms": 6.735, "learn_throughput": 4751.457, "update_time_ms": 4.051}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13566, "num_agent_steps_sampled": 27132, "num_steps_trained": 21568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43136, "last_target_update_ts": 13566, "num_target_updates": 111}, "done": false, "episodes_total": 730, "training_iteration": 119, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-26", "timestamp": 1648815926, "time_this_iter_s": 0.330047607421875, "time_total_s": 43.956634283065796, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "time_since_restore": 43.956634283065796, "timesteps_since_restore": 3808, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 27.0, "ram_util_percent": 54.2}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.92, "episode_len_mean": 18.46, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.96, "policy1": -7.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 10.0, -40.0, -40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 15, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15661543021094854, "mean_inference_ms": 1.4084193582990145, "mean_action_processing_ms": 0.0979598617525631, "mean_env_wait_ms": 0.16555255008693062, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13684, "timesteps_this_iter": 32, "agent_timesteps_total": 27368, "timers": {"learn_time_ms": 6.507, "learn_throughput": 4917.499, "update_time_ms": 4.063}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13684, "num_agent_steps_sampled": 27368, "num_steps_trained": 21792, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43584, "last_target_update_ts": 13684, "num_target_updates": 112}, "done": false, "episodes_total": 737, "training_iteration": 120, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-26", "timestamp": 1648815926, "time_this_iter_s": 0.39110589027404785, "time_total_s": 44.347740173339844, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518290>"}, "time_since_restore": 44.347740173339844, "timesteps_since_restore": 3840, "iterations_since_restore": 120, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.02, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.01, "policy1": -8.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 10.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, 5.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1566741054351894, "mean_inference_ms": 1.408894515423404, "mean_action_processing_ms": 0.09800662469679267, "mean_env_wait_ms": 0.16561187285927625, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13784, "timesteps_this_iter": 32, "agent_timesteps_total": 27568, "timers": {"learn_time_ms": 6.585, "learn_throughput": 4859.897, "update_time_ms": 4.081}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13784, "num_agent_steps_sampled": 27568, "num_steps_trained": 21952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43904, "last_target_update_ts": 13684, "num_target_updates": 112}, "done": false, "episodes_total": 742, "training_iteration": 121, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-27", "timestamp": 1648815927, "time_this_iter_s": 0.3101654052734375, "time_total_s": 44.65790557861328, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "time_since_restore": 44.65790557861328, "timesteps_since_restore": 3872, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 28.2, "ram_util_percent": 54.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.12, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.06, "policy1": -8.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15672819074250458, "mean_inference_ms": 1.4093077702607228, "mean_action_processing_ms": 0.09804876676332838, "mean_env_wait_ms": 0.1656638492851167, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13884, "timesteps_this_iter": 32, "agent_timesteps_total": 27768, "timers": {"learn_time_ms": 6.575, "learn_throughput": 4866.823, "update_time_ms": 3.923}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13884, "num_agent_steps_sampled": 27768, "num_steps_trained": 22112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44224, "last_target_update_ts": 13804, "num_target_updates": 113}, "done": false, "episodes_total": 747, "training_iteration": 122, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-27", "timestamp": 1648815927, "time_this_iter_s": 0.30531930923461914, "time_total_s": 44.9632248878479, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5188c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5188c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 44.9632248878479, "timesteps_since_restore": 3904, "iterations_since_restore": 122, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.32, "episode_len_mean": 18.56, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.16, "policy1": -8.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 6, 20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15677855776932187, "mean_inference_ms": 1.4096483200962535, "mean_action_processing_ms": 0.09808646258275537, "mean_env_wait_ms": 0.1657103188140095, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13984, "timesteps_this_iter": 32, "agent_timesteps_total": 27968, "timers": {"learn_time_ms": 6.228, "learn_throughput": 5138.012, "update_time_ms": 3.685}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 13984, "num_agent_steps_sampled": 27968, "num_steps_trained": 22272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44544, "last_target_update_ts": 13924, "num_target_updates": 114}, "done": false, "episodes_total": 752, "training_iteration": 123, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-27", "timestamp": 1648815927, "time_this_iter_s": 0.30522584915161133, "time_total_s": 45.26845073699951, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "time_since_restore": 45.26845073699951, "timesteps_since_restore": 3936, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 54.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.6, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.3, "policy1": -8.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -20.0, 10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 14, 20, 20, 20, 15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -10.0, 5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1568190746634056, "mean_inference_ms": 1.4099003657110183, "mean_action_processing_ms": 0.09811634961841355, "mean_env_wait_ms": 0.16574967412562214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14084, "timesteps_this_iter": 32, "agent_timesteps_total": 28168, "timers": {"learn_time_ms": 6.198, "learn_throughput": 5163.074, "update_time_ms": 3.706}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14084, "num_agent_steps_sampled": 28168, "num_steps_trained": 22432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44864, "last_target_update_ts": 14044, "num_target_updates": 115}, "done": false, "episodes_total": 757, "training_iteration": 124, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-28", "timestamp": 1648815928, "time_this_iter_s": 0.31066441535949707, "time_total_s": 45.57911515235901, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5189e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5189e0>"}, "time_since_restore": 45.57911515235901, "timesteps_since_restore": 3968, "iterations_since_restore": 124, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.84, "episode_len_mean": 18.52, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.92, "policy1": -7.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, 14.0, 28.0, 34.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0], "episode_lengths": [15, 13, 6, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20], "policy_policy0_reward": [5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0], "policy_policy1_reward": [5.0, 7.0, 14.0, 17.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15686177672195362, "mean_inference_ms": 1.4101643146626497, "mean_action_processing_ms": 0.09814895283351227, "mean_env_wait_ms": 0.16579237635812852, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14200, "timesteps_this_iter": 32, "agent_timesteps_total": 28400, "timers": {"learn_time_ms": 6.292, "learn_throughput": 5085.796, "update_time_ms": 3.736}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14200, "num_agent_steps_sampled": 28400, "num_steps_trained": 22656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45312, "last_target_update_ts": 14150, "num_target_updates": 116}, "done": false, "episodes_total": 764, "training_iteration": 125, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-28", "timestamp": 1648815928, "time_this_iter_s": 0.38515210151672363, "time_total_s": 45.96426725387573, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "time_since_restore": 45.96426725387573, "timesteps_since_restore": 4000, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 27.1, "ram_util_percent": 54.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.46, "episode_len_mean": 18.83, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.73, "policy1": -8.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1568897386846723, "mean_inference_ms": 1.4103345810967534, "mean_action_processing_ms": 0.09817322088305515, "mean_env_wait_ms": 0.16582619774763505, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14308, "timesteps_this_iter": 32, "agent_timesteps_total": 28616, "timers": {"learn_time_ms": 6.221, "learn_throughput": 5144.097, "update_time_ms": 3.748}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14308, "num_agent_steps_sampled": 28616, "num_steps_trained": 22848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45696, "last_target_update_ts": 14268, "num_target_updates": 117}, "done": false, "episodes_total": 770, "training_iteration": 126, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-28", "timestamp": 1648815928, "time_this_iter_s": 0.34351563453674316, "time_total_s": 46.307782888412476, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5188c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5188c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 46.307782888412476, "timesteps_since_restore": 4032, "iterations_since_restore": 126, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.82, "episode_len_mean": 18.81, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.91, "policy1": -8.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15692174313270604, "mean_inference_ms": 1.4104809584456854, "mean_action_processing_ms": 0.09819638656447005, "mean_env_wait_ms": 0.16585553649206142, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14412, "timesteps_this_iter": 32, "agent_timesteps_total": 28824, "timers": {"learn_time_ms": 6.395, "learn_throughput": 5003.569, "update_time_ms": 3.898}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14412, "num_agent_steps_sampled": 28824, "num_steps_trained": 23040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46080, "last_target_update_ts": 14372, "num_target_updates": 118}, "done": false, "episodes_total": 776, "training_iteration": 127, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-29", "timestamp": 1648815929, "time_this_iter_s": 0.36763691902160645, "time_total_s": 46.67541980743408, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508680>"}, "time_since_restore": 46.67541980743408, "timesteps_since_restore": 4064, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 54.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.56, "episode_len_mean": 18.78, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.78, "policy1": -8.78}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0], "episode_lengths": [13, 20, 20, 20, 19, 20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20], "policy_policy0_reward": [7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0], "policy_policy1_reward": [7.0, -10.0, -10.0, -10.0, 1.0, -10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15694653181274978, "mean_inference_ms": 1.4105732480735103, "mean_action_processing_ms": 0.09821511452490203, "mean_env_wait_ms": 0.16587587661980546, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14529, "timesteps_this_iter": 32, "agent_timesteps_total": 29058, "timers": {"learn_time_ms": 6.543, "learn_throughput": 4890.532, "update_time_ms": 4.76}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14529, "num_agent_steps_sampled": 29058, "num_steps_trained": 23232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46464, "last_target_update_ts": 14489, "num_target_updates": 119}, "done": false, "episodes_total": 782, "training_iteration": 128, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-29", "timestamp": 1648815929, "time_this_iter_s": 0.36980652809143066, "time_total_s": 47.04522633552551, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c505b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518290>"}, "time_since_restore": 47.04522633552551, "timesteps_since_restore": 4096, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 28.5, "ram_util_percent": 54.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.32, "episode_len_mean": 18.86, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.16, "policy1": -9.16}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 16.0, -40.0, -20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 12, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 8.0, -20.0, -10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569600414374922, "mean_inference_ms": 1.4105975164166624, "mean_action_processing_ms": 0.09822606173233722, "mean_env_wait_ms": 0.1658876325301351, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14629, "timesteps_this_iter": 32, "agent_timesteps_total": 29258, "timers": {"learn_time_ms": 6.435, "learn_throughput": 4972.556, "update_time_ms": 4.954}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14629, "num_agent_steps_sampled": 29258, "num_steps_trained": 23392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46784, "last_target_update_ts": 14609, "num_target_updates": 120}, "done": false, "episodes_total": 787, "training_iteration": 129, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-30", "timestamp": 1648815930, "time_this_iter_s": 0.3106238842010498, "time_total_s": 47.35585021972656, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "time_since_restore": 47.35585021972656, "timesteps_since_restore": 4128, "iterations_since_restore": 129, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.68, "episode_len_mean": 18.94, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.34, "policy1": -9.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 10.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15696163374840644, "mean_inference_ms": 1.4105314594240803, "mean_action_processing_ms": 0.09823080682424085, "mean_env_wait_ms": 0.16588892614755235, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14729, "timesteps_this_iter": 32, "agent_timesteps_total": 29458, "timers": {"learn_time_ms": 6.334, "learn_throughput": 5051.762, "update_time_ms": 4.578}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14729, "num_agent_steps_sampled": 29458, "num_steps_trained": 23552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47104, "last_target_update_ts": 14729, "num_target_updates": 121}, "done": false, "episodes_total": 792, "training_iteration": 130, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-30", "timestamp": 1648815930, "time_this_iter_s": 0.31128573417663574, "time_total_s": 47.6671359539032, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 47.6671359539032, "timesteps_since_restore": 4160, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 54.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.58, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.29, "policy1": -9.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569616373416793, "mean_inference_ms": 1.4104276472031512, "mean_action_processing_ms": 0.0982325656086473, "mean_env_wait_ms": 0.16588134734403018, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14829, "timesteps_this_iter": 32, "agent_timesteps_total": 29658, "timers": {"learn_time_ms": 6.164, "learn_throughput": 5191.512, "update_time_ms": 4.438}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14829, "num_agent_steps_sampled": 29658, "num_steps_trained": 23744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47488, "last_target_update_ts": 14729, "num_target_updates": 121}, "done": false, "episodes_total": 798, "training_iteration": 131, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-30", "timestamp": 1648815930, "time_this_iter_s": 0.33039045333862305, "time_total_s": 47.99752640724182, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "time_since_restore": 47.99752640724182, "timesteps_since_restore": 4192, "iterations_since_restore": 131, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.78, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.39, "policy1": -9.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15696283460033394, "mean_inference_ms": 1.4103395216403056, "mean_action_processing_ms": 0.09823345217303726, "mean_env_wait_ms": 0.16587384438103198, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14929, "timesteps_this_iter": 32, "agent_timesteps_total": 29858, "timers": {"learn_time_ms": 6.186, "learn_throughput": 5172.685, "update_time_ms": 4.053}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 14929, "num_agent_steps_sampled": 29858, "num_steps_trained": 23904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47808, "last_target_update_ts": 14849, "num_target_updates": 122}, "done": false, "episodes_total": 803, "training_iteration": 132, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-31", "timestamp": 1648815931, "time_this_iter_s": 0.30957484245300293, "time_total_s": 48.307101249694824, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52a680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52a680>"}, "time_since_restore": 48.307101249694824, "timesteps_since_restore": 4224, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 28.2, "ram_util_percent": 54.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.64, "episode_len_mean": 18.62, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.32, "policy1": -9.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 24.0, -20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 18, 20, 8, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 2.0, -10.0, 12.0, -10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569629513936616, "mean_inference_ms": 1.4101869568731182, "mean_action_processing_ms": 0.09823104979315396, "mean_env_wait_ms": 0.16585886811185482, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15032, "timesteps_this_iter": 32, "agent_timesteps_total": 30064, "timers": {"learn_time_ms": 6.24, "learn_throughput": 5128.608, "update_time_ms": 3.811}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15032, "num_agent_steps_sampled": 30064, "num_steps_trained": 24064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48128, "last_target_update_ts": 14952, "num_target_updates": 123}, "done": false, "episodes_total": 809, "training_iteration": 133, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-31", "timestamp": 1648815931, "time_this_iter_s": 0.31624269485473633, "time_total_s": 48.62334394454956, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52a710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500a70>"}, "time_since_restore": 48.62334394454956, "timesteps_since_restore": 4256, "iterations_since_restore": 133, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.84, "episode_len_mean": 18.52, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.42, "policy1": -9.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15696135043384982, "mean_inference_ms": 1.4099807543640617, "mean_action_processing_ms": 0.09822405744325372, "mean_env_wait_ms": 0.16583564967684214, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15148, "timesteps_this_iter": 32, "agent_timesteps_total": 30296, "timers": {"learn_time_ms": 6.16, "learn_throughput": 5194.868, "update_time_ms": 3.747}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15148, "num_agent_steps_sampled": 30296, "num_steps_trained": 24288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48576, "last_target_update_ts": 15072, "num_target_updates": 124}, "done": false, "episodes_total": 816, "training_iteration": 134, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-31", "timestamp": 1648815931, "time_this_iter_s": 0.38121891021728516, "time_total_s": 49.004562854766846, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5278c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5278c0>"}, "time_since_restore": 49.004562854766846, "timesteps_since_restore": 4288, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 26.8, "ram_util_percent": 54.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.0, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.5, "policy1": -9.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15695393251725015, "mean_inference_ms": 1.4097461418424524, "mean_action_processing_ms": 0.09821245777373282, "mean_env_wait_ms": 0.16580603310879416, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15256, "timesteps_this_iter": 32, "agent_timesteps_total": 30512, "timers": {"learn_time_ms": 6.243, "learn_throughput": 5126.042, "update_time_ms": 3.849}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15256, "num_agent_steps_sampled": 30512, "num_steps_trained": 24480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48960, "last_target_update_ts": 15188, "num_target_updates": 125}, "done": false, "episodes_total": 822, "training_iteration": 135, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-32", "timestamp": 1648815932, "time_this_iter_s": 0.35219550132751465, "time_total_s": 49.35675835609436, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c508c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 49.35675835609436, "timesteps_since_restore": 4320, "iterations_since_restore": 135, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.08, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.54, "policy1": -9.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 26.0, -20.0, 8.0, -40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0], "episode_lengths": [20, 20, 7, 20, 16, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20], "policy_policy0_reward": [-10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, 13.0, -10.0, 4.0, -20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15693863990391282, "mean_inference_ms": 1.409441098390834, "mean_action_processing_ms": 0.09819523137825371, "mean_env_wait_ms": 0.16576711182608028, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15370, "timesteps_this_iter": 32, "agent_timesteps_total": 30740, "timers": {"learn_time_ms": 6.229, "learn_throughput": 5137.481, "update_time_ms": 3.894}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15370, "num_agent_steps_sampled": 30740, "num_steps_trained": 24672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49344, "last_target_update_ts": 15296, "num_target_updates": 126}, "done": false, "episodes_total": 828, "training_iteration": 136, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-32", "timestamp": 1648815932, "time_this_iter_s": 0.3569977283477783, "time_total_s": 49.71375608444214, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50e8c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c50e8c0>"}, "time_since_restore": 49.71375608444214, "timesteps_since_restore": 4352, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 26.0, "ram_util_percent": 54.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.62, "episode_len_mean": 18.61, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.81, "policy1": -9.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15692286868250513, "mean_inference_ms": 1.4091612460314513, "mean_action_processing_ms": 0.09817877952003556, "mean_env_wait_ms": 0.16573239266448386, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15470, "timesteps_this_iter": 32, "agent_timesteps_total": 30940, "timers": {"learn_time_ms": 6.239, "learn_throughput": 5129.353, "update_time_ms": 3.728}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15470, "num_agent_steps_sampled": 30940, "num_steps_trained": 24832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49664, "last_target_update_ts": 15410, "num_target_updates": 127}, "done": false, "episodes_total": 833, "training_iteration": 137, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-32", "timestamp": 1648815932, "time_this_iter_s": 0.3076817989349365, "time_total_s": 50.021437883377075, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5180e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5180e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "time_since_restore": 50.021437883377075, "timesteps_since_restore": 4384, "iterations_since_restore": 137, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.86, "episode_len_mean": 18.33, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.43, "policy1": -9.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15691289270901335, "mean_inference_ms": 1.4088606369290642, "mean_action_processing_ms": 0.09816397788652907, "mean_env_wait_ms": 0.16569464570456116, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15577, "timesteps_this_iter": 32, "agent_timesteps_total": 31154, "timers": {"learn_time_ms": 6.642, "learn_throughput": 4817.941, "update_time_ms": 4.29}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15577, "num_agent_steps_sampled": 31154, "num_steps_trained": 25056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50112, "last_target_update_ts": 15522, "num_target_updates": 128}, "done": false, "episodes_total": 840, "training_iteration": 138, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-33", "timestamp": 1648815933, "time_this_iter_s": 0.40618419647216797, "time_total_s": 50.42762207984924, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5278c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5278c0>"}, "time_since_restore": 50.42762207984924, "timesteps_since_restore": 4416, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 27.4, "ram_util_percent": 54.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.04, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.02, "policy1": -9.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569117582079377, "mean_inference_ms": 1.4086203124760375, "mean_action_processing_ms": 0.09815388163124243, "mean_env_wait_ms": 0.16566774575255938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15696, "timesteps_this_iter": 32, "agent_timesteps_total": 31392, "timers": {"learn_time_ms": 6.584, "learn_throughput": 4860.196, "update_time_ms": 4.059}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15696, "num_agent_steps_sampled": 31392, "num_steps_trained": 25280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50560, "last_target_update_ts": 15636, "num_target_updates": 129}, "done": false, "episodes_total": 847, "training_iteration": 139, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-33", "timestamp": 1648815933, "time_this_iter_s": 0.4084174633026123, "time_total_s": 50.836039543151855, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518a70>"}, "time_since_restore": 50.836039543151855, "timesteps_since_restore": 4448, "iterations_since_restore": 139, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.92, "episode_len_mean": 17.86, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.46, "policy1": -8.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 4.0, -40.0, 0.0, 24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 18, 20, 20, 8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 2.0, -20.0, 0.0, 12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1569160899793099, "mean_inference_ms": 1.4084462644226898, "mean_action_processing_ms": 0.09814831000574842, "mean_env_wait_ms": 0.16564515720125222, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15810, "timesteps_this_iter": 32, "agent_timesteps_total": 31620, "timers": {"learn_time_ms": 6.397, "learn_throughput": 5002.636, "update_time_ms": 3.921}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15810, "num_agent_steps_sampled": 31620, "num_steps_trained": 25504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51008, "last_target_update_ts": 15754, "num_target_updates": 130}, "done": false, "episodes_total": 854, "training_iteration": 140, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-34", "timestamp": 1648815934, "time_this_iter_s": 0.38772130012512207, "time_total_s": 51.22376084327698, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5278c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5278c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 51.22376084327698, "timesteps_since_restore": 4480, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 26.6, "ram_util_percent": 54.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.36, "episode_len_mean": 17.78, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.18, "policy1": -8.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, 20.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0], "episode_lengths": [8, 10, 20, 20, 20, 20, 8, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20], "policy_policy0_reward": [12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0], "policy_policy1_reward": [12.0, 10.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15692791549736754, "mean_inference_ms": 1.408360696320985, "mean_action_processing_ms": 0.09815027166631823, "mean_env_wait_ms": 0.1656310224806792, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15920, "timesteps_this_iter": 32, "agent_timesteps_total": 31840, "timers": {"learn_time_ms": 6.561, "learn_throughput": 4877.062, "update_time_ms": 3.78}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 15920, "num_agent_steps_sampled": 31840, "num_steps_trained": 25696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51392, "last_target_update_ts": 15867, "num_target_updates": 131}, "done": false, "episodes_total": 860, "training_iteration": 141, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-34", "timestamp": 1648815934, "time_this_iter_s": 0.3776383399963379, "time_total_s": 51.601399183273315, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c518a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c518a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "time_since_restore": 51.601399183273315, "timesteps_since_restore": 4512, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 54.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.28, "episode_len_mean": 17.84, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.14, "policy1": -8.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, 32.0, -40.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, 16.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15695187277190167, "mean_inference_ms": 1.4083368573943722, "mean_action_processing_ms": 0.09815685597517432, "mean_env_wait_ms": 0.16562348898435647, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16032, "timesteps_this_iter": 32, "agent_timesteps_total": 32064, "timers": {"learn_time_ms": 6.615, "learn_throughput": 4837.32, "update_time_ms": 3.955}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16032, "num_agent_steps_sampled": 32064, "num_steps_trained": 25920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51840, "last_target_update_ts": 15968, "num_target_updates": 132}, "done": false, "episodes_total": 867, "training_iteration": 142, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-35", "timestamp": 1648815935, "time_this_iter_s": 0.40263962745666504, "time_total_s": 52.00403881072998, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c50e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c506290>"}, "time_since_restore": 52.00403881072998, "timesteps_since_restore": 4544, "iterations_since_restore": 142, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.6, "episode_len_mean": 18.0, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.3, "policy1": -8.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15696870443020944, "mean_inference_ms": 1.4083472721108166, "mean_action_processing_ms": 0.0981627121862022, "mean_env_wait_ms": 0.1656213729757569, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16132, "timesteps_this_iter": 32, "agent_timesteps_total": 32264, "timers": {"learn_time_ms": 6.491, "learn_throughput": 4929.944, "update_time_ms": 4.058}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16132, "num_agent_steps_sampled": 32264, "num_steps_trained": 26080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52160, "last_target_update_ts": 16072, "num_target_updates": 133}, "done": false, "episodes_total": 872, "training_iteration": 143, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-35", "timestamp": 1648815935, "time_this_iter_s": 0.3272883892059326, "time_total_s": 52.33132719993591, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c508c20>"}, "time_since_restore": 52.33132719993591, "timesteps_since_restore": 4576, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 25.9, "ram_util_percent": 54.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.04, "episode_len_mean": 17.82, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.02, "policy1": -8.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 6.0, 0.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0], "episode_lengths": [20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8], "policy_policy0_reward": [-20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0], "policy_policy1_reward": [-20.0, 3.0, 0.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15698873352777898, "mean_inference_ms": 1.408372306012212, "mean_action_processing_ms": 0.09817192163005037, "mean_env_wait_ms": 0.16562111194764717, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16234, "timesteps_this_iter": 32, "agent_timesteps_total": 32468, "timers": {"learn_time_ms": 6.29, "learn_throughput": 5087.069, "update_time_ms": 4.201}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16234, "num_agent_steps_sampled": 32468, "num_steps_trained": 26272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52544, "last_target_update_ts": 16186, "num_target_updates": 134}, "done": false, "episodes_total": 878, "training_iteration": 144, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-35", "timestamp": 1648815935, "time_this_iter_s": 0.3556087017059326, "time_total_s": 52.686935901641846, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52a560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52a560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52b7a0>"}, "time_since_restore": 52.686935901641846, "timesteps_since_restore": 4608, "iterations_since_restore": 144, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.18, "episode_len_mean": 17.59, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.59, "policy1": -7.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15702004079980433, "mean_inference_ms": 1.4084525258650116, "mean_action_processing_ms": 0.09818679767185298, "mean_env_wait_ms": 0.1656284802226516, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16348, "timesteps_this_iter": 32, "agent_timesteps_total": 32696, "timers": {"learn_time_ms": 6.282, "learn_throughput": 5093.613, "update_time_ms": 4.396}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16348, "num_agent_steps_sampled": 32696, "num_steps_trained": 26464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52928, "last_target_update_ts": 16288, "num_target_updates": 135}, "done": false, "episodes_total": 885, "training_iteration": 145, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-36", "timestamp": 1648815936, "time_this_iter_s": 0.3755378723144531, "time_total_s": 53.0624737739563, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c518a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c518a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c500b90>"}, "time_since_restore": 53.0624737739563, "timesteps_since_restore": 4640, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 27.1, "ram_util_percent": 54.5}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.18, "episode_len_mean": 17.59, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.59, "policy1": -7.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 16.0, -40.0, -40.0, 24.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 12, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 8.0, -20.0, -20.0, 12.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15704954922129905, "mean_inference_ms": 1.4085676846178226, "mean_action_processing_ms": 0.0982024016384857, "mean_env_wait_ms": 0.1656423546649646, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16448, "timesteps_this_iter": 32, "agent_timesteps_total": 32896, "timers": {"learn_time_ms": 6.521, "learn_throughput": 4907.556, "update_time_ms": 4.355}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16448, "num_agent_steps_sampled": 32896, "num_steps_trained": 26624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53248, "last_target_update_ts": 16408, "num_target_updates": 136}, "done": false, "episodes_total": 890, "training_iteration": 146, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-36", "timestamp": 1648815936, "time_this_iter_s": 0.3340334892272949, "time_total_s": 53.396507263183594, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52a680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52a680>"}, "time_since_restore": 53.396507263183594, "timesteps_since_restore": 4672, "iterations_since_restore": 146, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.26, "episode_len_mean": 17.73, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.63, "policy1": -7.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15708495424691876, "mean_inference_ms": 1.4087092264814067, "mean_action_processing_ms": 0.0982210312404928, "mean_env_wait_ms": 0.16566235106753704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16562, "timesteps_this_iter": 32, "agent_timesteps_total": 33124, "timers": {"learn_time_ms": 6.339, "learn_throughput": 5048.303, "update_time_ms": 3.864}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16562, "num_agent_steps_sampled": 33124, "num_steps_trained": 26816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53632, "last_target_update_ts": 16522, "num_target_updates": 137}, "done": false, "episodes_total": 896, "training_iteration": 147, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-36", "timestamp": 1648815936, "time_this_iter_s": 0.36221885681152344, "time_total_s": 53.75872611999512, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "time_since_restore": 53.75872611999512, "timesteps_since_restore": 4704, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 29.4, "ram_util_percent": 54.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.42, "episode_len_mean": 17.61, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.21, "policy1": -7.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 34.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 3, 20, 20, 20, 20, 20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 17.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15712049716949408, "mean_inference_ms": 1.4088716424412897, "mean_action_processing_ms": 0.09824220746698441, "mean_env_wait_ms": 0.16568484838633932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16670, "timesteps_this_iter": 32, "agent_timesteps_total": 33340, "timers": {"learn_time_ms": 6.5, "learn_throughput": 4923.253, "update_time_ms": 3.869}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16670, "num_agent_steps_sampled": 33340, "num_steps_trained": 27008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54016, "last_target_update_ts": 16630, "num_target_updates": 138}, "done": false, "episodes_total": 902, "training_iteration": 148, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-37", "timestamp": 1648815937, "time_this_iter_s": 0.3625969886779785, "time_total_s": 54.121323108673096, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c535ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c527830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c535ef0>"}, "time_since_restore": 54.121323108673096, "timesteps_since_restore": 4736, "iterations_since_restore": 148, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.4, "episode_len_mean": 17.7, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.2, "policy1": -7.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 28.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 6, 20, 10, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 14.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15715743623466305, "mean_inference_ms": 1.4090790650773948, "mean_action_processing_ms": 0.09826613369897604, "mean_env_wait_ms": 0.1657120346649972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16782, "timesteps_this_iter": 32, "agent_timesteps_total": 33564, "timers": {"learn_time_ms": 6.724, "learn_throughput": 4758.853, "update_time_ms": 3.946}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16782, "num_agent_steps_sampled": 33564, "num_steps_trained": 27200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54400, "last_target_update_ts": 16742, "num_target_updates": 139}, "done": false, "episodes_total": 908, "training_iteration": 149, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-37", "timestamp": 1648815937, "time_this_iter_s": 0.3697781562805176, "time_total_s": 54.49110126495361, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e8c0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e8c0>"}, "time_since_restore": 54.49110126495361, "timesteps_since_restore": 4768, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 29.3, "ram_util_percent": 54.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.74, "episode_len_mean": 17.77, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.37, "policy1": -7.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15719760582548797, "mean_inference_ms": 1.4093312700990834, "mean_action_processing_ms": 0.09829366094471143, "mean_env_wait_ms": 0.16574492106724997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16885, "timesteps_this_iter": 32, "agent_timesteps_total": 33770, "timers": {"learn_time_ms": 6.531, "learn_throughput": 4899.781, "update_time_ms": 4.037}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 16885, "num_agent_steps_sampled": 33770, "num_steps_trained": 27360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54720, "last_target_update_ts": 16845, "num_target_updates": 140}, "done": false, "episodes_total": 914, "training_iteration": 150, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-38", "timestamp": 1648815938, "time_this_iter_s": 0.34154605865478516, "time_total_s": 54.8326473236084, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c506290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b90>"}, "time_since_restore": 54.8326473236084, "timesteps_since_restore": 4800, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 54.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.08, "episode_len_mean": 17.84, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.54, "policy1": -7.54}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -40.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15724104038415748, "mean_inference_ms": 1.4096237964632743, "mean_action_processing_ms": 0.09832600365047145, "mean_env_wait_ms": 0.1657830117604846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17000, "timesteps_this_iter": 32, "agent_timesteps_total": 34000, "timers": {"learn_time_ms": 6.33, "learn_throughput": 5055.358, "update_time_ms": 4.082}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17000, "num_agent_steps_sampled": 34000, "num_steps_trained": 27552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55104, "last_target_update_ts": 16960, "num_target_updates": 141}, "done": false, "episodes_total": 920, "training_iteration": 151, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-38", "timestamp": 1648815938, "time_this_iter_s": 0.38548803329467773, "time_total_s": 55.218135356903076, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "time_since_restore": 55.218135356903076, "timesteps_since_restore": 4832, "iterations_since_restore": 151, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.88, "episode_len_mean": 17.84, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.44, "policy1": -7.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 14, 20, 20, 20, 20, 20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15727856947473967, "mean_inference_ms": 1.409874922207996, "mean_action_processing_ms": 0.09835387941697454, "mean_env_wait_ms": 0.1658165524120035, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17100, "timesteps_this_iter": 32, "agent_timesteps_total": 34200, "timers": {"learn_time_ms": 6.327, "learn_throughput": 5057.453, "update_time_ms": 3.971}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17100, "num_agent_steps_sampled": 34200, "num_steps_trained": 27712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55424, "last_target_update_ts": 17080, "num_target_updates": 142}, "done": false, "episodes_total": 925, "training_iteration": 152, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-38", "timestamp": 1648815938, "time_this_iter_s": 0.32224416732788086, "time_total_s": 55.54037952423096, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c521b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c521b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 55.54037952423096, "timesteps_since_restore": 4864, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 54.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.6, "episode_len_mean": 17.8, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.3, "policy1": -7.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 16.0, -20.0, -40.0, 26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 12, 20, 20, 7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 8.0, -10.0, -20.0, 13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15732744988525865, "mean_inference_ms": 1.4102127596263199, "mean_action_processing_ms": 0.09839009374255206, "mean_env_wait_ms": 0.16586074337308326, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17210, "timesteps_this_iter": 32, "agent_timesteps_total": 34420, "timers": {"learn_time_ms": 6.477, "learn_throughput": 4940.869, "update_time_ms": 4.161}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17210, "num_agent_steps_sampled": 34420, "num_steps_trained": 27904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55808, "last_target_update_ts": 17190, "num_target_updates": 143}, "done": false, "episodes_total": 931, "training_iteration": 153, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-39", "timestamp": 1648815939, "time_this_iter_s": 0.36763548851013184, "time_total_s": 55.90801501274109, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "time_since_restore": 55.90801501274109, "timesteps_since_restore": 4896, "iterations_since_restore": 153, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.16, "episode_len_mean": 17.88, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.58, "policy1": -7.58}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, -40.0, 24.0, -40.0, 30.0, -20.0, 12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [7, 20, 8, 20, 5, 20, 14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [13.0, -20.0, 12.0, -20.0, 15.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.157366143630051, "mean_inference_ms": 1.410494315712848, "mean_action_processing_ms": 0.09842007673004857, "mean_env_wait_ms": 0.16589679923105882, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17310, "timesteps_this_iter": 32, "agent_timesteps_total": 34620, "timers": {"learn_time_ms": 6.675, "learn_throughput": 4793.935, "update_time_ms": 4.172}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17310, "num_agent_steps_sampled": 34620, "num_steps_trained": 28064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56128, "last_target_update_ts": 17310, "num_target_updates": 144}, "done": false, "episodes_total": 936, "training_iteration": 154, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-39", "timestamp": 1648815939, "time_this_iter_s": 0.338132381439209, "time_total_s": 56.2461473941803, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c500a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521440>"}, "time_since_restore": 56.2461473941803, "timesteps_since_restore": 4928, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 29.0, "ram_util_percent": 54.6}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.46, "episode_len_mean": 18.23, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.23, "policy1": -8.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0], "episode_lengths": [14, 20, 20, 20, 20, 20, 20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20], "policy_policy0_reward": [6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0], "policy_policy1_reward": [6.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15741053242357772, "mean_inference_ms": 1.4108349615489635, "mean_action_processing_ms": 0.09845669756005798, "mean_env_wait_ms": 0.16593930413385533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17425, "timesteps_this_iter": 32, "agent_timesteps_total": 34850, "timers": {"learn_time_ms": 6.787, "learn_throughput": 4714.572, "update_time_ms": 4.036}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17425, "num_agent_steps_sampled": 34850, "num_steps_trained": 28256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56512, "last_target_update_ts": 17425, "num_target_updates": 145}, "done": false, "episodes_total": 942, "training_iteration": 155, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-40", "timestamp": 1648815940, "time_this_iter_s": 0.3854820728302002, "time_total_s": 56.6316294670105, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "time_since_restore": 56.6316294670105, "timesteps_since_restore": 4960, "iterations_since_restore": 155, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.02, "episode_len_mean": 18.21, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.01, "policy1": -8.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 4.0, 28.0, 20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0], "episode_lengths": [20, 18, 6, 10, 20, 20, 20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0], "policy_policy1_reward": [-10.0, 2.0, 14.0, 10.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15745410875551594, "mean_inference_ms": 1.4112066418791005, "mean_action_processing_ms": 0.0984955019470133, "mean_env_wait_ms": 0.1659839659170217, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17537, "timesteps_this_iter": 32, "agent_timesteps_total": 35074, "timers": {"learn_time_ms": 6.944, "learn_throughput": 4608.524, "update_time_ms": 4.133}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17537, "num_agent_steps_sampled": 35074, "num_steps_trained": 28448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 56896, "last_target_update_ts": 17537, "num_target_updates": 146}, "done": false, "episodes_total": 948, "training_iteration": 156, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-40", "timestamp": 1648815940, "time_this_iter_s": 0.38602709770202637, "time_total_s": 57.017656564712524, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5217a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5217a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 57.017656564712524, "timesteps_since_restore": 4992, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.78, "episode_len_mean": 18.29, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.39, "policy1": -8.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 6.0, -40.0, 14.0, 0.0, -20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 17, 20, 13, 20, 20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 3.0, -20.0, 7.0, 0.0, -10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15749321750262926, "mean_inference_ms": 1.4115509123206926, "mean_action_processing_ms": 0.09853094564661136, "mean_env_wait_ms": 0.16602672821220785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17639, "timesteps_this_iter": 32, "agent_timesteps_total": 35278, "timers": {"learn_time_ms": 6.601, "learn_throughput": 4847.47, "update_time_ms": 4.067}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17639, "num_agent_steps_sampled": 35278, "num_steps_trained": 28640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57280, "last_target_update_ts": 17639, "num_target_updates": 147}, "done": false, "episodes_total": 954, "training_iteration": 157, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-40", "timestamp": 1648815940, "time_this_iter_s": 0.3308384418487549, "time_total_s": 57.34849500656128, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "time_since_restore": 57.34849500656128, "timesteps_since_restore": 5024, "iterations_since_restore": 157, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.22, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.61, "policy1": -8.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 24.0, 10.0, 22.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0], "episode_lengths": [20, 20, 8, 15, 9, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 12.0, 5.0, 11.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15752990835386804, "mean_inference_ms": 1.4118896128172989, "mean_action_processing_ms": 0.09856543112255674, "mean_env_wait_ms": 0.1660718518713707, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17751, "timesteps_this_iter": 32, "agent_timesteps_total": 35502, "timers": {"learn_time_ms": 6.541, "learn_throughput": 4892.369, "update_time_ms": 4.263}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17751, "num_agent_steps_sampled": 35502, "num_steps_trained": 28832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57664, "last_target_update_ts": 17751, "num_target_updates": 148}, "done": false, "episodes_total": 960, "training_iteration": 158, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-41", "timestamp": 1648815941, "time_this_iter_s": 0.387249231338501, "time_total_s": 57.73574423789978, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ecb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ecb0>"}, "time_since_restore": 57.73574423789978, "timesteps_since_restore": 5056, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 27.3, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.9, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.95, "policy1": -8.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, 12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15756827718189664, "mean_inference_ms": 1.4122926339386552, "mean_action_processing_ms": 0.09860640634127352, "mean_env_wait_ms": 0.16612171284830476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17867, "timesteps_this_iter": 32, "agent_timesteps_total": 35734, "timers": {"learn_time_ms": 6.66, "learn_throughput": 4804.541, "update_time_ms": 4.393}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17867, "num_agent_steps_sampled": 35734, "num_steps_trained": 29056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58112, "last_target_update_ts": 17867, "num_target_updates": 149}, "done": false, "episodes_total": 967, "training_iteration": 159, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-41", "timestamp": 1648815941, "time_this_iter_s": 0.422013521194458, "time_total_s": 58.15775775909424, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ea70>"}, "time_since_restore": 58.15775775909424, "timesteps_since_restore": 5088, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.3, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.65, "policy1": -8.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, -40.0, -40.0, -20.0, 24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0], "episode_lengths": [14, 20, 20, 20, 20, 8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0], "policy_policy1_reward": [6.0, -20.0, -20.0, -20.0, -10.0, 12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15759726944420943, "mean_inference_ms": 1.4126106307991164, "mean_action_processing_ms": 0.0986376662267717, "mean_env_wait_ms": 0.16615833463550522, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17967, "timesteps_this_iter": 32, "agent_timesteps_total": 35934, "timers": {"learn_time_ms": 6.771, "learn_throughput": 4726.243, "update_time_ms": 4.496}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 17967, "num_agent_steps_sampled": 35934, "num_steps_trained": 29216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58432, "last_target_update_ts": 17867, "num_target_updates": 149}, "done": false, "episodes_total": 972, "training_iteration": 160, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-42", "timestamp": 1648815942, "time_this_iter_s": 0.3482518196105957, "time_total_s": 58.506009578704834, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ecb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52ecb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 58.506009578704834, "timesteps_since_restore": 5120, "iterations_since_restore": 160, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -40.0, -20.0, 34.0, 18.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 20, 20, 3, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -20.0, -10.0, 17.0, 9.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576258821916401, "mean_inference_ms": 1.4129519102956873, "mean_action_processing_ms": 0.09866878286931874, "mean_env_wait_ms": 0.166198284590451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18067, "timesteps_this_iter": 32, "agent_timesteps_total": 36134, "timers": {"learn_time_ms": 7.494, "learn_throughput": 4269.854, "update_time_ms": 4.498}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18067, "num_agent_steps_sampled": 36134, "num_steps_trained": 29376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58752, "last_target_update_ts": 17987, "num_target_updates": 150}, "done": false, "episodes_total": 977, "training_iteration": 161, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-42", "timestamp": 1648815942, "time_this_iter_s": 0.3504664897918701, "time_total_s": 58.856476068496704, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5214d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c5214d0>"}, "time_since_restore": 58.856476068496704, "timesteps_since_restore": 5152, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.58, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.29, "policy1": -9.29}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15765541640295594, "mean_inference_ms": 1.4133149788507569, "mean_action_processing_ms": 0.09870208460293933, "mean_env_wait_ms": 0.16624159746798553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18167, "timesteps_this_iter": 32, "agent_timesteps_total": 36334, "timers": {"learn_time_ms": 7.404, "learn_throughput": 4322.006, "update_time_ms": 4.213}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18167, "num_agent_steps_sampled": 36334, "num_steps_trained": 29536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59072, "last_target_update_ts": 18107, "num_target_updates": 151}, "done": false, "episodes_total": 982, "training_iteration": 162, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-42", "timestamp": 1648815942, "time_this_iter_s": 0.33634042739868164, "time_total_s": 59.192816495895386, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52eb90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52eb90>"}, "time_since_restore": 59.192816495895386, "timesteps_since_restore": 5184, "iterations_since_restore": 162, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.38, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.69, "policy1": -9.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15768757152395402, "mean_inference_ms": 1.4137024757721033, "mean_action_processing_ms": 0.098737195802846, "mean_env_wait_ms": 0.16628775691799322, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18267, "timesteps_this_iter": 32, "agent_timesteps_total": 36534, "timers": {"learn_time_ms": 6.685, "learn_throughput": 4786.686, "update_time_ms": 3.986}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18267, "num_agent_steps_sampled": 36534, "num_steps_trained": 29696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59392, "last_target_update_ts": 18227, "num_target_updates": 152}, "done": false, "episodes_total": 987, "training_iteration": 163, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-43", "timestamp": 1648815943, "time_this_iter_s": 0.34152746200561523, "time_total_s": 59.534343957901, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5214d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5214d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e320>"}, "time_since_restore": 59.534343957901, "timesteps_since_restore": 5216, "iterations_since_restore": 163, "perf": {"cpu_util_percent": 27.0, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.58, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -9.79, "policy1": -9.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 12.0, -40.0, -20.0, -20.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 14, 20, 20, 20, 8, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 6.0, -20.0, -10.0, -10.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15772290553894686, "mean_inference_ms": 1.414104607116962, "mean_action_processing_ms": 0.09877441749580422, "mean_env_wait_ms": 0.16633471378965756, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18367, "timesteps_this_iter": 32, "agent_timesteps_total": 36734, "timers": {"learn_time_ms": 6.687, "learn_throughput": 4785.714, "update_time_ms": 3.885}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18367, "num_agent_steps_sampled": 36734, "num_steps_trained": 29856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59712, "last_target_update_ts": 18347, "num_target_updates": 153}, "done": false, "episodes_total": 992, "training_iteration": 164, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-43", "timestamp": 1648815943, "time_this_iter_s": 0.3379981517791748, "time_total_s": 59.872342109680176, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 59.872342109680176, "timesteps_since_restore": 5248, "iterations_since_restore": 164, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.02, "episode_len_mean": 18.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.01, "policy1": -10.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15777032349631184, "mean_inference_ms": 1.414645330010452, "mean_action_processing_ms": 0.0988232070990947, "mean_env_wait_ms": 0.16639740025135052, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18481, "timesteps_this_iter": 32, "agent_timesteps_total": 36962, "timers": {"learn_time_ms": 6.745, "learn_throughput": 4744.151, "update_time_ms": 4.074}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18481, "num_agent_steps_sampled": 36962, "num_steps_trained": 30048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60096, "last_target_update_ts": 18461, "num_target_updates": 154}, "done": false, "episodes_total": 998, "training_iteration": 165, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-43", "timestamp": 1648815943, "time_this_iter_s": 0.3980400562286377, "time_total_s": 60.27038216590881, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b00>"}, "time_since_restore": 60.27038216590881, "timesteps_since_restore": 5280, "iterations_since_restore": 165, "perf": {"cpu_util_percent": 27.1, "ram_util_percent": 54.7}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.62, "episode_len_mean": 18.91, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.31, "policy1": -10.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, -40.0, -20.0, -20.0, -20.0, 34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [12, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [8.0, -10.0, -20.0, -10.0, -10.0, -10.0, 17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15780780945555178, "mean_inference_ms": 1.4150781500248188, "mean_action_processing_ms": 0.09886202606315068, "mean_env_wait_ms": 0.1664479233292803, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18581, "timesteps_this_iter": 32, "agent_timesteps_total": 37162, "timers": {"learn_time_ms": 6.854, "learn_throughput": 4668.638, "update_time_ms": 4.187}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18581, "num_agent_steps_sampled": 37162, "num_steps_trained": 30208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60416, "last_target_update_ts": 18581, "num_target_updates": 155}, "done": false, "episodes_total": 1003, "training_iteration": 166, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-44", "timestamp": 1648815944, "time_this_iter_s": 0.3178138732910156, "time_total_s": 60.58819603919983, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ec20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52ec20>"}, "time_since_restore": 60.58819603919983, "timesteps_since_restore": 5312, "iterations_since_restore": 166, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.96, "episode_len_mean": 18.88, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -10.48, "policy1": -10.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [34.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0], "episode_lengths": [3, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20], "policy_policy0_reward": [17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0], "policy_policy1_reward": [17.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15785635212509588, "mean_inference_ms": 1.4156082556778802, "mean_action_processing_ms": 0.09890952665961227, "mean_env_wait_ms": 0.16651018254968034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18690, "timesteps_this_iter": 32, "agent_timesteps_total": 37380, "timers": {"learn_time_ms": 6.797, "learn_throughput": 4707.726, "update_time_ms": 4.055}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18690, "num_agent_steps_sampled": 37380, "num_steps_trained": 30400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60800, "last_target_update_ts": 18690, "num_target_updates": 156}, "done": false, "episodes_total": 1009, "training_iteration": 167, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-44", "timestamp": 1648815944, "time_this_iter_s": 0.3813660144805908, "time_total_s": 60.96956205368042, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5214d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e3b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5214d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e3b0>"}, "time_since_restore": 60.96956205368042, "timesteps_since_restore": 5344, "iterations_since_restore": 167, "perf": {"cpu_util_percent": 27.8, "ram_util_percent": 54.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.62, "episode_len_mean": 19.01, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.81, "policy1": -10.81}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20], "policy_policy0_reward": [5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [5.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15790262430649246, "mean_inference_ms": 1.41612847851423, "mean_action_processing_ms": 0.09895671368078883, "mean_env_wait_ms": 0.16657438849493045, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18806, "timesteps_this_iter": 32, "agent_timesteps_total": 37612, "timers": {"learn_time_ms": 6.491, "learn_throughput": 4930.089, "update_time_ms": 3.966}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18806, "num_agent_steps_sampled": 37612, "num_steps_trained": 30592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61184, "last_target_update_ts": 18806, "num_target_updates": 157}, "done": false, "episodes_total": 1015, "training_iteration": 168, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-45", "timestamp": 1648815945, "time_this_iter_s": 0.3845076560974121, "time_total_s": 61.35406970977783, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 61.35406970977783, "timesteps_since_restore": 5376, "iterations_since_restore": 168, "perf": {"cpu_util_percent": 28.0, "ram_util_percent": 54.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.9, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.45, "policy1": -10.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -40.0, 0.0, 20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, 0.0, 10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15795407120072347, "mean_inference_ms": 1.4166843365449202, "mean_action_processing_ms": 0.09900593008512346, "mean_env_wait_ms": 0.16664065844046866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18925, "timesteps_this_iter": 32, "agent_timesteps_total": 37850, "timers": {"learn_time_ms": 6.419, "learn_throughput": 4985.374, "update_time_ms": 4.014}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 18925, "num_agent_steps_sampled": 37850, "num_steps_trained": 30816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61632, "last_target_update_ts": 18925, "num_target_updates": 158}, "done": false, "episodes_total": 1022, "training_iteration": 169, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-45", "timestamp": 1648815945, "time_this_iter_s": 0.3925209045410156, "time_total_s": 61.74659061431885, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52e9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521b00>"}, "time_since_restore": 61.74659061431885, "timesteps_since_restore": 5408, "iterations_since_restore": 169, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.9, "episode_len_mean": 18.85, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.45, "policy1": -10.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15798725656385654, "mean_inference_ms": 1.4170508011241838, "mean_action_processing_ms": 0.09903865290092959, "mean_env_wait_ms": 0.1666820717726242, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19025, "timesteps_this_iter": 32, "agent_timesteps_total": 38050, "timers": {"learn_time_ms": 6.32, "learn_throughput": 5063.081, "update_time_ms": 3.948}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19025, "num_agent_steps_sampled": 38050, "num_steps_trained": 30976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61952, "last_target_update_ts": 18925, "num_target_updates": 158}, "done": false, "episodes_total": 1027, "training_iteration": 170, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-45", "timestamp": 1648815945, "time_this_iter_s": 0.3067784309387207, "time_total_s": 62.05336904525757, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c535170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c535170>"}, "time_since_restore": 62.05336904525757, "timesteps_since_restore": 5440, "iterations_since_restore": 170, "perf": {"cpu_util_percent": 29.0, "ram_util_percent": 54.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.78, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.39, "policy1": -10.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1580238576791751, "mean_inference_ms": 1.4174415722573475, "mean_action_processing_ms": 0.09907395549744066, "mean_env_wait_ms": 0.16672608426449542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19129, "timesteps_this_iter": 32, "agent_timesteps_total": 38258, "timers": {"learn_time_ms": 6.401, "learn_throughput": 4998.854, "update_time_ms": 4.035}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19129, "num_agent_steps_sampled": 38258, "num_steps_trained": 31168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62336, "last_target_update_ts": 19045, "num_target_updates": 159}, "done": false, "episodes_total": 1033, "training_iteration": 171, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-46", "timestamp": 1648815946, "time_this_iter_s": 0.3385477066040039, "time_total_s": 62.39191675186157, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c521b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e3b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c521b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e3b0>"}, "time_since_restore": 62.39191675186157, "timesteps_since_restore": 5472, "iterations_since_restore": 171, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.12, "episode_len_mean": 18.76, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.06, "policy1": -10.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 10.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0], "episode_lengths": [20, 15, 20, 20, 20, 20, 20, 12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0], "policy_policy1_reward": [-20.0, 5.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1580560063647382, "mean_inference_ms": 1.4177871068822936, "mean_action_processing_ms": 0.09910460030158436, "mean_env_wait_ms": 0.16676617425682164, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19246, "timesteps_this_iter": 32, "agent_timesteps_total": 38492, "timers": {"learn_time_ms": 6.298, "learn_throughput": 5081.349, "update_time_ms": 3.914}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19246, "num_agent_steps_sampled": 38492, "num_steps_trained": 31360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62720, "last_target_update_ts": 19146, "num_target_updates": 160}, "done": false, "episodes_total": 1039, "training_iteration": 172, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-46", "timestamp": 1648815946, "time_this_iter_s": 0.3670651912689209, "time_total_s": 62.75898194313049, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c535170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 62.75898194313049, "timesteps_since_restore": 5504, "iterations_since_restore": 172, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 54.8}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.4, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.7, "policy1": -9.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, -40.0, 28.0, 8.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0], "episode_lengths": [12, 20, 20, 6, 16, 20, 20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20], "policy_policy0_reward": [8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [8.0, -10.0, -20.0, 14.0, 4.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15809391485562838, "mean_inference_ms": 1.4181460157229417, "mean_action_processing_ms": 0.09913768133701704, "mean_env_wait_ms": 0.16680973782502373, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19365, "timesteps_this_iter": 32, "agent_timesteps_total": 38730, "timers": {"learn_time_ms": 6.17, "learn_throughput": 5186.297, "update_time_ms": 3.911}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19365, "num_agent_steps_sampled": 38730, "num_steps_trained": 31584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63168, "last_target_update_ts": 19266, "num_target_updates": 161}, "done": false, "episodes_total": 1046, "training_iteration": 173, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-47", "timestamp": 1648815947, "time_this_iter_s": 0.3957505226135254, "time_total_s": 63.15473246574402, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b90>"}, "time_since_restore": 63.15473246574402, "timesteps_since_restore": 5536, "iterations_since_restore": 173, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.78, "episode_len_mean": 18.79, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.89, "policy1": -9.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, 16.0, -20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 12, 20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, 8.0, -10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15812614944432357, "mean_inference_ms": 1.4184431823483736, "mean_action_processing_ms": 0.0991644023963561, "mean_env_wait_ms": 0.1668459281613059, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19478, "timesteps_this_iter": 32, "agent_timesteps_total": 38956, "timers": {"learn_time_ms": 6.344, "learn_throughput": 5043.769, "update_time_ms": 3.847}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19478, "num_agent_steps_sampled": 38956, "num_steps_trained": 31776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63552, "last_target_update_ts": 19385, "num_target_updates": 162}, "done": false, "episodes_total": 1052, "training_iteration": 174, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-47", "timestamp": 1648815947, "time_this_iter_s": 0.35866475105285645, "time_total_s": 63.513397216796875, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52d4d0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52d4d0>"}, "time_since_restore": 63.513397216796875, "timesteps_since_restore": 5568, "iterations_since_restore": 174, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 54.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.94, "episode_len_mean": 18.77, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.97, "policy1": -9.97}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 28.0, 20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 6, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 14.0, 10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15815561863997263, "mean_inference_ms": 1.4187124209397377, "mean_action_processing_ms": 0.09918753826839294, "mean_env_wait_ms": 0.1668774522894533, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19588, "timesteps_this_iter": 32, "agent_timesteps_total": 39176, "timers": {"learn_time_ms": 6.205, "learn_throughput": 5157.519, "update_time_ms": 3.787}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19588, "num_agent_steps_sampled": 39176, "num_steps_trained": 31968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63936, "last_target_update_ts": 19488, "num_target_updates": 163}, "done": false, "episodes_total": 1058, "training_iteration": 175, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-48", "timestamp": 1648815948, "time_this_iter_s": 0.6008987426757812, "time_total_s": 64.11429595947266, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "time_since_restore": 64.11429595947266, "timesteps_since_restore": 5600, "iterations_since_restore": 175, "perf": {"cpu_util_percent": 32.1, "ram_util_percent": 54.9}}
{"episode_reward_max": 22.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.42, "episode_len_mean": 18.91, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 11.0, "policy1": 11.0}, "policy_reward_mean": {"policy0": -10.21, "policy1": -10.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1581742837211358, "mean_inference_ms": 1.418874207935007, "mean_action_processing_ms": 0.0992019236771927, "mean_env_wait_ms": 0.16689776754535124, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19688, "timesteps_this_iter": 32, "agent_timesteps_total": 39376, "timers": {"learn_time_ms": 6.369, "learn_throughput": 5024.209, "update_time_ms": 3.79}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19688, "num_agent_steps_sampled": 39376, "num_steps_trained": 32128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64256, "last_target_update_ts": 19608, "num_target_updates": 164}, "done": false, "episodes_total": 1063, "training_iteration": 176, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-48", "timestamp": 1648815948, "time_this_iter_s": 0.3043057918548584, "time_total_s": 64.41860175132751, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 64.41860175132751, "timesteps_since_restore": 5632, "iterations_since_restore": 176, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.74, "episode_len_mean": 18.87, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.37, "policy1": -10.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20], "policy_policy0_reward": [-10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15819342936502762, "mean_inference_ms": 1.419013104936393, "mean_action_processing_ms": 0.09921554607236693, "mean_env_wait_ms": 0.16691704078783726, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19794, "timesteps_this_iter": 32, "agent_timesteps_total": 39588, "timers": {"learn_time_ms": 6.434, "learn_throughput": 4973.587, "update_time_ms": 3.744}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19794, "num_agent_steps_sampled": 39588, "num_steps_trained": 32320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64640, "last_target_update_ts": 19728, "num_target_updates": 165}, "done": false, "episodes_total": 1069, "training_iteration": 177, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-48", "timestamp": 1648815948, "time_this_iter_s": 0.3408169746398926, "time_total_s": 64.75941872596741, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd7a0>"}, "time_since_restore": 64.75941872596741, "timesteps_since_restore": 5664, "iterations_since_restore": 177, "perf": {"cpu_util_percent": 29.1, "ram_util_percent": 54.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.94, "episode_len_mean": 18.87, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.47, "policy1": -10.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15820438405705425, "mean_inference_ms": 1.4190716436726698, "mean_action_processing_ms": 0.09922344669605561, "mean_env_wait_ms": 0.1669269919446103, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19894, "timesteps_this_iter": 32, "agent_timesteps_total": 39788, "timers": {"learn_time_ms": 6.354, "learn_throughput": 5035.859, "update_time_ms": 3.86}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 19894, "num_agent_steps_sampled": 39788, "num_steps_trained": 32480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64960, "last_target_update_ts": 19834, "num_target_updates": 166}, "done": false, "episodes_total": 1074, "training_iteration": 178, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-49", "timestamp": 1648815949, "time_this_iter_s": 0.31104063987731934, "time_total_s": 65.07045936584473, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db00>"}, "time_since_restore": 65.07045936584473, "timesteps_since_restore": 5696, "iterations_since_restore": 178, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.3, "episode_len_mean": 18.75, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -10.15, "policy1": -10.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15821206201674534, "mean_inference_ms": 1.419088026645159, "mean_action_processing_ms": 0.09922822991151406, "mean_env_wait_ms": 0.16693106146508063, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20002, "timesteps_this_iter": 32, "agent_timesteps_total": 40004, "timers": {"learn_time_ms": 6.233, "learn_throughput": 5134.376, "update_time_ms": 3.856}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20002, "num_agent_steps_sampled": 40004, "num_steps_trained": 32672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65344, "last_target_update_ts": 19954, "num_target_updates": 167}, "done": false, "episodes_total": 1080, "training_iteration": 179, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-49", "timestamp": 1648815949, "time_this_iter_s": 0.3463566303253174, "time_total_s": 65.41681599617004, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "time_since_restore": 65.41681599617004, "timesteps_since_restore": 5728, "iterations_since_restore": 179, "perf": {"cpu_util_percent": 28.7, "ram_util_percent": 54.9}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.0, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.5, "policy1": -9.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15821468598276042, "mean_inference_ms": 1.4190304396411328, "mean_action_processing_ms": 0.09922715432627692, "mean_env_wait_ms": 0.16692506287971887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20107, "timesteps_this_iter": 32, "agent_timesteps_total": 40214, "timers": {"learn_time_ms": 6.222, "learn_throughput": 5143.447, "update_time_ms": 3.987}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20107, "num_agent_steps_sampled": 40214, "num_steps_trained": 32864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65728, "last_target_update_ts": 20055, "num_target_updates": 168}, "done": false, "episodes_total": 1086, "training_iteration": 180, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-49", "timestamp": 1648815949, "time_this_iter_s": 0.34285497665405273, "time_total_s": 65.7596709728241, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52dcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c527830>"}, "time_since_restore": 65.7596709728241, "timesteps_since_restore": 5760, "iterations_since_restore": 180, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.6, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -9.3, "policy1": -9.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, 12.0, -20.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, 6.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1582092158138872, "mean_inference_ms": 1.4189270269295, "mean_action_processing_ms": 0.09922059396011747, "mean_env_wait_ms": 0.16691185707718667, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20207, "timesteps_this_iter": 32, "agent_timesteps_total": 40414, "timers": {"learn_time_ms": 6.209, "learn_throughput": 5153.657, "update_time_ms": 4.178}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20207, "num_agent_steps_sampled": 40414, "num_steps_trained": 33024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66048, "last_target_update_ts": 20167, "num_target_updates": 169}, "done": false, "episodes_total": 1091, "training_iteration": 181, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-50", "timestamp": 1648815950, "time_this_iter_s": 0.31044554710388184, "time_total_s": 66.07011651992798, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd830>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bd7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd830>"}, "time_since_restore": 66.07011651992798, "timesteps_since_restore": 5792, "iterations_since_restore": 181, "perf": {"cpu_util_percent": 27.4, "ram_util_percent": 54.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.42, "episode_len_mean": 18.51, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.21, "policy1": -9.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15819714741597543, "mean_inference_ms": 1.4187228290367893, "mean_action_processing_ms": 0.09920701799832096, "mean_env_wait_ms": 0.1668865392427616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20312, "timesteps_this_iter": 32, "agent_timesteps_total": 40624, "timers": {"learn_time_ms": 6.229, "learn_throughput": 5137.501, "update_time_ms": 3.981}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20312, "num_agent_steps_sampled": 40624, "num_steps_trained": 33216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66432, "last_target_update_ts": 20272, "num_target_updates": 170}, "done": false, "episodes_total": 1097, "training_iteration": 182, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-50", "timestamp": 1648815950, "time_this_iter_s": 0.33205246925354004, "time_total_s": 66.40216898918152, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5357a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db00>"}, "time_since_restore": 66.40216898918152, "timesteps_since_restore": 5824, "iterations_since_restore": 182, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.9, "episode_len_mean": 18.15, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.95, "policy1": -7.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, 22.0, -40.0, -40.0, 8.0, -40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0], "episode_lengths": [20, 20, 20, 9, 20, 20, 16, 20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8], "policy_policy0_reward": [-10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, 11.0, -20.0, -20.0, 4.0, -20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15818564156979267, "mean_inference_ms": 1.4184545572026999, "mean_action_processing_ms": 0.09919000727294777, "mean_env_wait_ms": 0.16685486325930438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20416, "timesteps_this_iter": 32, "agent_timesteps_total": 40832, "timers": {"learn_time_ms": 6.036, "learn_throughput": 5301.779, "update_time_ms": 3.738}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20416, "num_agent_steps_sampled": 40832, "num_steps_trained": 33440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66880, "last_target_update_ts": 20381, "num_target_updates": 171}, "done": false, "episodes_total": 1104, "training_iteration": 183, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-50", "timestamp": 1648815950, "time_this_iter_s": 0.35564398765563965, "time_total_s": 66.75781297683716, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bde60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bde60>"}, "time_since_restore": 66.75781297683716, "timesteps_since_restore": 5856, "iterations_since_restore": 183, "perf": {"cpu_util_percent": 26.9, "ram_util_percent": 54.9}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.36, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.68, "policy1": -7.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -20.0, 22.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0], "episode_lengths": [20, 20, 20, 20, 9, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, 11.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15817008609714528, "mean_inference_ms": 1.4181335125101902, "mean_action_processing_ms": 0.09916821835195051, "mean_env_wait_ms": 0.16681788646175127, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20534, "timesteps_this_iter": 32, "agent_timesteps_total": 41068, "timers": {"learn_time_ms": 6.212, "learn_throughput": 5151.699, "update_time_ms": 3.755}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20534, "num_agent_steps_sampled": 41068, "num_steps_trained": 33664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67328, "last_target_update_ts": 20486, "num_target_updates": 172}, "done": false, "episodes_total": 1111, "training_iteration": 184, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-51", "timestamp": 1648815951, "time_this_iter_s": 0.3892629146575928, "time_total_s": 67.14707589149475, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c24d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c24d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db90>"}, "time_since_restore": 67.14707589149475, "timesteps_since_restore": 5888, "iterations_since_restore": 184, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.92, "episode_len_mean": 18.06, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.46, "policy1": -7.46}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20], "policy_policy0_reward": [-10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15815858489859277, "mean_inference_ms": 1.4178986387276384, "mean_action_processing_ms": 0.09915029997794747, "mean_env_wait_ms": 0.16678442463593462, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20641, "timesteps_this_iter": 32, "agent_timesteps_total": 41282, "timers": {"learn_time_ms": 6.697, "learn_throughput": 4778.234, "update_time_ms": 3.875}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20641, "num_agent_steps_sampled": 41282, "num_steps_trained": 33856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67712, "last_target_update_ts": 20601, "num_target_updates": 173}, "done": false, "episodes_total": 1117, "training_iteration": 185, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-51", "timestamp": 1648815951, "time_this_iter_s": 0.37813735008239746, "time_total_s": 67.52521324157715, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bddd0>"}, "time_since_restore": 67.52521324157715, "timesteps_since_restore": 5920, "iterations_since_restore": 185, "perf": {"cpu_util_percent": 29.1, "ram_util_percent": 55.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.7, "episode_len_mean": 17.85, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -6.85, "policy1": -6.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, 12.0, -20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0], "episode_lengths": [20, 20, 20, 20, 14, 20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.158146272680878, "mean_inference_ms": 1.417627160464135, "mean_action_processing_ms": 0.0991305542465105, "mean_env_wait_ms": 0.1667509633669747, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20750, "timesteps_this_iter": 32, "agent_timesteps_total": 41500, "timers": {"learn_time_ms": 6.484, "learn_throughput": 4934.983, "update_time_ms": 3.896}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20750, "num_agent_steps_sampled": 41500, "num_steps_trained": 34080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68160, "last_target_update_ts": 20718, "num_target_updates": 174}, "done": false, "episodes_total": 1124, "training_iteration": 186, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-52", "timestamp": 1648815952, "time_this_iter_s": 0.3755371570587158, "time_total_s": 67.90075039863586, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52db00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c52db00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 67.90075039863586, "timesteps_since_restore": 5952, "iterations_since_restore": 186, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 55.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.82, "episode_len_mean": 17.91, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -6.91, "policy1": -6.91}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 20.0, -20.0, 6.0, -20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 10, 20, 17, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 10.0, -10.0, 3.0, -10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15813780776625536, "mean_inference_ms": 1.417446450962255, "mean_action_processing_ms": 0.09911688672236689, "mean_env_wait_ms": 0.16672881852472032, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20850, "timesteps_this_iter": 32, "agent_timesteps_total": 41700, "timers": {"learn_time_ms": 6.175, "learn_throughput": 5182.292, "update_time_ms": 3.891}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20850, "num_agent_steps_sampled": 41700, "num_steps_trained": 34240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68480, "last_target_update_ts": 20830, "num_target_updates": 175}, "done": false, "episodes_total": 1129, "training_iteration": 187, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-52", "timestamp": 1648815952, "time_this_iter_s": 0.30475711822509766, "time_total_s": 68.20550751686096, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4b9680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4b9680>"}, "time_since_restore": 68.20550751686096, "timesteps_since_restore": 5984, "iterations_since_restore": 187, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.68, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.34, "policy1": -7.34}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -40.0, 0.0, -20.0, -40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -20.0, 0.0, -10.0, -20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1581287539799914, "mean_inference_ms": 1.4172684388095376, "mean_action_processing_ms": 0.09910378812298408, "mean_env_wait_ms": 0.16670852475442974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20950, "timesteps_this_iter": 32, "agent_timesteps_total": 41900, "timers": {"learn_time_ms": 6.135, "learn_throughput": 5216.086, "update_time_ms": 3.873}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 20950, "num_agent_steps_sampled": 41900, "num_steps_trained": 34400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68800, "last_target_update_ts": 20950, "num_target_updates": 176}, "done": false, "episodes_total": 1134, "training_iteration": 188, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-52", "timestamp": 1648815952, "time_this_iter_s": 0.30605602264404297, "time_total_s": 68.511563539505, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52db90>"}, "time_since_restore": 68.511563539505, "timesteps_since_restore": 6016, "iterations_since_restore": 188, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.3, "episode_len_mean": 17.95, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.15, "policy1": -7.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 22.0, -20.0, 20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0], "episode_lengths": [20, 20, 9, 20, 10, 20, 20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 11.0, -10.0, 10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15811683047014996, "mean_inference_ms": 1.417047221610639, "mean_action_processing_ms": 0.09908803343072282, "mean_env_wait_ms": 0.16668286560310402, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21061, "timesteps_this_iter": 32, "agent_timesteps_total": 42122, "timers": {"learn_time_ms": 6.329, "learn_throughput": 5056.158, "update_time_ms": 3.878}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21061, "num_agent_steps_sampled": 42122, "num_steps_trained": 34592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69184, "last_target_update_ts": 21061, "num_target_updates": 177}, "done": false, "episodes_total": 1140, "training_iteration": 189, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-53", "timestamp": 1648815953, "time_this_iter_s": 0.350766658782959, "time_total_s": 68.86233019828796, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "time_since_restore": 68.86233019828796, "timesteps_since_restore": 6048, "iterations_since_restore": 189, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 55.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.48, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.24, "policy1": -7.24}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 14.0, -20.0, -20.0, -20.0, 20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0], "episode_lengths": [20, 20, 13, 20, 20, 20, 10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20], "policy_policy0_reward": [-10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 7.0, -10.0, -10.0, -10.0, 10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15810354993887013, "mean_inference_ms": 1.416834174755989, "mean_action_processing_ms": 0.09907166341279136, "mean_env_wait_ms": 0.16665989355944968, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21169, "timesteps_this_iter": 32, "agent_timesteps_total": 42338, "timers": {"learn_time_ms": 6.37, "learn_throughput": 5023.664, "update_time_ms": 3.883}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21169, "num_agent_steps_sampled": 42338, "num_steps_trained": 34784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69568, "last_target_update_ts": 21169, "num_target_updates": 178}, "done": false, "episodes_total": 1146, "training_iteration": 190, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-53", "timestamp": 1648815953, "time_this_iter_s": 0.354938268661499, "time_total_s": 69.21726846694946, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 69.21726846694946, "timesteps_since_restore": 6080, "iterations_since_restore": 190, "perf": {"cpu_util_percent": 28.6, "ram_util_percent": 55.0}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.22, "episode_len_mean": 17.91, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -7.11, "policy1": -7.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, 0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0], "episode_lengths": [10, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10], "policy_policy0_reward": [10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0], "policy_policy1_reward": [10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15809057755032632, "mean_inference_ms": 1.4166175727878172, "mean_action_processing_ms": 0.09905549691506783, "mean_env_wait_ms": 0.16663643905748265, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21269, "timesteps_this_iter": 32, "agent_timesteps_total": 42538, "timers": {"learn_time_ms": 6.351, "learn_throughput": 5038.26, "update_time_ms": 3.915}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21269, "num_agent_steps_sampled": 42538, "num_steps_trained": 34976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69952, "last_target_update_ts": 21169, "num_target_updates": 178}, "done": false, "episodes_total": 1152, "training_iteration": 191, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-53", "timestamp": 1648815953, "time_this_iter_s": 0.32647061347961426, "time_total_s": 69.54373908042908, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bde60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bde60>"}, "time_since_restore": 69.54373908042908, "timesteps_since_restore": 6112, "iterations_since_restore": 191, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.48, "episode_len_mean": 17.74, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.74, "policy1": -6.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, 28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20], "policy_policy0_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0], "policy_policy1_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, 14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1580789941682744, "mean_inference_ms": 1.416362813700652, "mean_action_processing_ms": 0.09903678319119362, "mean_env_wait_ms": 0.166607939368055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21382, "timesteps_this_iter": 32, "agent_timesteps_total": 42764, "timers": {"learn_time_ms": 6.347, "learn_throughput": 5041.553, "update_time_ms": 3.819}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21382, "num_agent_steps_sampled": 42764, "num_steps_trained": 35200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70400, "last_target_update_ts": 21382, "num_target_updates": 180}, "done": false, "episodes_total": 1159, "training_iteration": 192, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-54", "timestamp": 1648815954, "time_this_iter_s": 0.37659263610839844, "time_total_s": 69.92033171653748, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "time_since_restore": 69.92033171653748, "timesteps_since_restore": 6144, "iterations_since_restore": 192, "perf": {"cpu_util_percent": 27.4, "ram_util_percent": 55.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.06, "episode_len_mean": 17.43, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -6.03, "policy1": -6.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0], "episode_lengths": [6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20], "policy_policy0_reward": [14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0], "policy_policy1_reward": [14.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15807335547919513, "mean_inference_ms": 1.4161471089590578, "mean_action_processing_ms": 0.09902115687249502, "mean_env_wait_ms": 0.16658278569409016, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21491, "timesteps_this_iter": 32, "agent_timesteps_total": 42982, "timers": {"learn_time_ms": 6.171, "learn_throughput": 5185.275, "update_time_ms": 3.825}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21491, "num_agent_steps_sampled": 42982, "num_steps_trained": 35424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70848, "last_target_update_ts": 21491, "num_target_updates": 181}, "done": false, "episodes_total": 1166, "training_iteration": 193, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-54", "timestamp": 1648815954, "time_this_iter_s": 0.37369227409362793, "time_total_s": 70.2940239906311, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bde60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "time_since_restore": 70.2940239906311, "timesteps_since_restore": 6176, "iterations_since_restore": 193, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.42, "episode_len_mean": 17.31, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.71, "policy1": -5.71}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 24.0, -40.0, -20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -20.0, -10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.158071153327351, "mean_inference_ms": 1.4159559029362112, "mean_action_processing_ms": 0.09900685074874657, "mean_env_wait_ms": 0.16656042727827775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21605, "timesteps_this_iter": 32, "agent_timesteps_total": 43210, "timers": {"learn_time_ms": 6.109, "learn_throughput": 5237.929, "update_time_ms": 3.874}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21605, "num_agent_steps_sampled": 43210, "num_steps_trained": 35648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71296, "last_target_update_ts": 21605, "num_target_updates": 182}, "done": false, "episodes_total": 1173, "training_iteration": 194, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-55", "timestamp": 1648815955, "time_this_iter_s": 0.3825507164001465, "time_total_s": 70.67657470703125, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4cecb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4cecb0>"}, "time_since_restore": 70.67657470703125, "timesteps_since_restore": 6208, "iterations_since_restore": 194, "perf": {"cpu_util_percent": 26.6, "ram_util_percent": 55.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.34, "episode_len_mean": 17.27, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.67, "policy1": -5.67}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 14.0, -20.0, -40.0, 16.0, -20.0, 0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 13, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 7.0, -10.0, -20.0, 8.0, -10.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15806959111172594, "mean_inference_ms": 1.41577854716196, "mean_action_processing_ms": 0.09899394338790718, "mean_env_wait_ms": 0.16654049227700785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21709, "timesteps_this_iter": 32, "agent_timesteps_total": 43418, "timers": {"learn_time_ms": 6.257, "learn_throughput": 5114.147, "update_time_ms": 4.048}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21709, "num_agent_steps_sampled": 43418, "num_steps_trained": 35840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71680, "last_target_update_ts": 21709, "num_target_updates": 183}, "done": false, "episodes_total": 1179, "training_iteration": 195, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-55", "timestamp": 1648815955, "time_this_iter_s": 0.33254170417785645, "time_total_s": 71.0091164112091, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bdd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "time_since_restore": 71.0091164112091, "timesteps_since_restore": 6240, "iterations_since_restore": 195, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.72, "episode_len_mean": 17.26, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.86, "policy1": -5.86}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, -20.0, -20.0, -20.0, -20.0, -20.0, 30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20], "policy_policy0_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0], "policy_policy1_reward": [0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15806640489675086, "mean_inference_ms": 1.4156068824398815, "mean_action_processing_ms": 0.09898068185506943, "mean_env_wait_ms": 0.16652246574530472, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21813, "timesteps_this_iter": 32, "agent_timesteps_total": 43626, "timers": {"learn_time_ms": 6.262, "learn_throughput": 5110.253, "update_time_ms": 3.94}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21813, "num_agent_steps_sampled": 43626, "num_steps_trained": 36032, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72064, "last_target_update_ts": 21813, "num_target_updates": 184}, "done": false, "episodes_total": 1185, "training_iteration": 196, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-55", "timestamp": 1648815955, "time_this_iter_s": 0.33942294120788574, "time_total_s": 71.34853935241699, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4ceef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4ceef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 71.34853935241699, "timesteps_since_restore": 6272, "iterations_since_restore": 196, "perf": {"cpu_util_percent": 28.3, "ram_util_percent": 55.0}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.58, "episode_len_mean": 17.09, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -5.79, "policy1": -5.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [5, 20, 20, 20, 20, 20, 20, 20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20], "policy_policy0_reward": [15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [15.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.158066498565979, "mean_inference_ms": 1.4154502023482598, "mean_action_processing_ms": 0.09896839128796024, "mean_env_wait_ms": 0.1665077138627494, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21916, "timesteps_this_iter": 32, "agent_timesteps_total": 43832, "timers": {"learn_time_ms": 6.24, "learn_throughput": 5128.216, "update_time_ms": 3.647}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 21916, "num_agent_steps_sampled": 43832, "num_steps_trained": 36224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72448, "last_target_update_ts": 21916, "num_target_updates": 185}, "done": false, "episodes_total": 1191, "training_iteration": 197, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-56", "timestamp": 1648815956, "time_this_iter_s": 0.33646297454833984, "time_total_s": 71.68500232696533, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "time_since_restore": 71.68500232696533, "timesteps_since_restore": 6304, "iterations_since_restore": 197, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.32, "episode_len_mean": 16.96, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -5.66, "policy1": -5.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 8.0, 14.0, 22.0, 4.0, 24.0, -20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 16, 13, 9, 18, 8, 20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 4.0, 7.0, 11.0, 2.0, 12.0, -10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15806783084355794, "mean_inference_ms": 1.4152995561707382, "mean_action_processing_ms": 0.09895541088412804, "mean_env_wait_ms": 0.16649431283847593, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22028, "timesteps_this_iter": 32, "agent_timesteps_total": 44056, "timers": {"learn_time_ms": 6.298, "learn_throughput": 5081.214, "update_time_ms": 3.874}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22028, "num_agent_steps_sampled": 44056, "num_steps_trained": 36416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72832, "last_target_update_ts": 22028, "num_target_updates": 186}, "done": false, "episodes_total": 1198, "training_iteration": 198, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-56", "timestamp": 1648815956, "time_this_iter_s": 0.3601663112640381, "time_total_s": 72.04516863822937, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce680>"}, "time_since_restore": 72.04516863822937, "timesteps_since_restore": 6336, "iterations_since_restore": 198, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 55.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.98, "episode_len_mean": 17.29, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.49, "policy1": -6.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 20.0, -20.0, -20.0, 24.0, -40.0, -20.0, -20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 10, 20, 20, 8, 20, 20, 20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 10.0, -10.0, -10.0, 12.0, -20.0, -10.0, -10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1580642114766637, "mean_inference_ms": 1.415162638136414, "mean_action_processing_ms": 0.09894239822803337, "mean_env_wait_ms": 0.16648041063601082, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22145, "timesteps_this_iter": 32, "agent_timesteps_total": 44290, "timers": {"learn_time_ms": 6.386, "learn_throughput": 5011.153, "update_time_ms": 4.106}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22145, "num_agent_steps_sampled": 44290, "num_steps_trained": 36608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73216, "last_target_update_ts": 22145, "num_target_updates": 187}, "done": false, "episodes_total": 1204, "training_iteration": 199, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-57", "timestamp": 1648815957, "time_this_iter_s": 0.36063599586486816, "time_total_s": 72.40580463409424, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "time_since_restore": 72.40580463409424, "timesteps_since_restore": 6368, "iterations_since_restore": 199, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.34, "episode_len_mean": 17.07, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.17, "policy1": -6.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 26.0, -20.0, -20.0, -20.0, 4.0, 26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0], "episode_lengths": [20, 7, 20, 20, 20, 18, 7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20], "policy_policy0_reward": [-10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0], "policy_policy1_reward": [-10.0, 13.0, -10.0, -10.0, -10.0, 2.0, 13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15805772525762127, "mean_inference_ms": 1.414970196268228, "mean_action_processing_ms": 0.09892454178680321, "mean_env_wait_ms": 0.16645801774401012, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22261, "timesteps_this_iter": 32, "agent_timesteps_total": 44522, "timers": {"learn_time_ms": 6.196, "learn_throughput": 5164.207, "update_time_ms": 3.922}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22261, "num_agent_steps_sampled": 44522, "num_steps_trained": 36832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73664, "last_target_update_ts": 22261, "num_target_updates": 188}, "done": false, "episodes_total": 1212, "training_iteration": 200, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-57", "timestamp": 1648815957, "time_this_iter_s": 0.3871157169342041, "time_total_s": 72.79292035102844, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 72.79292035102844, "timesteps_since_restore": 6400, "iterations_since_restore": 200, "perf": {"cpu_util_percent": 27.4, "ram_util_percent": 55.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.86, "episode_len_mean": 17.03, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.43, "policy1": -6.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [26.0, 16.0, -40.0, -20.0, 16.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0], "episode_lengths": [7, 12, 20, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20], "policy_policy0_reward": [13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0], "policy_policy1_reward": [13.0, 8.0, -20.0, -10.0, 8.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15805070632652538, "mean_inference_ms": 1.4147645477462105, "mean_action_processing_ms": 0.09890802315173002, "mean_env_wait_ms": 0.16643713717213085, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22362, "timesteps_this_iter": 32, "agent_timesteps_total": 44724, "timers": {"learn_time_ms": 6.247, "learn_throughput": 5122.56, "update_time_ms": 3.773}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22362, "num_agent_steps_sampled": 44724, "num_steps_trained": 37024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74048, "last_target_update_ts": 22362, "num_target_updates": 189}, "done": false, "episodes_total": 1218, "training_iteration": 201, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-57", "timestamp": 1648815957, "time_this_iter_s": 0.3262615203857422, "time_total_s": 73.11918187141418, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb290>"}, "time_since_restore": 73.11918187141418, "timesteps_since_restore": 6432, "iterations_since_restore": 201, "perf": {"cpu_util_percent": 28.1, "ram_util_percent": 55.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.24, "episode_len_mean": 17.32, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.12, "policy1": -7.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15804120356866613, "mean_inference_ms": 1.4145908448720572, "mean_action_processing_ms": 0.09889355768903833, "mean_env_wait_ms": 0.16641684064499512, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22462, "timesteps_this_iter": 32, "agent_timesteps_total": 44924, "timers": {"learn_time_ms": 6.236, "learn_throughput": 5131.863, "update_time_ms": 3.88}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22462, "num_agent_steps_sampled": 44924, "num_steps_trained": 37184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74368, "last_target_update_ts": 22362, "num_target_updates": 189}, "done": false, "episodes_total": 1223, "training_iteration": 202, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-58", "timestamp": 1648815958, "time_this_iter_s": 0.3046109676361084, "time_total_s": 73.4237928390503, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4cecb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4cecb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b00>"}, "time_since_restore": 73.4237928390503, "timesteps_since_restore": 6464, "iterations_since_restore": 202, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.66, "episode_len_mean": 17.03, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.33, "policy1": -6.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15803031371693277, "mean_inference_ms": 1.4143349204734905, "mean_action_processing_ms": 0.09887346166711909, "mean_env_wait_ms": 0.1663886960217637, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22573, "timesteps_this_iter": 32, "agent_timesteps_total": 45146, "timers": {"learn_time_ms": 6.307, "learn_throughput": 5073.857, "update_time_ms": 3.988}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22573, "num_agent_steps_sampled": 45146, "num_steps_trained": 37408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74816, "last_target_update_ts": 22573, "num_target_updates": 191}, "done": false, "episodes_total": 1230, "training_iteration": 203, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-58", "timestamp": 1648815958, "time_this_iter_s": 0.36607885360717773, "time_total_s": 73.78987169265747, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "time_since_restore": 73.78987169265747, "timesteps_since_restore": 6496, "iterations_since_restore": 203, "perf": {"cpu_util_percent": 30.1, "ram_util_percent": 55.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.66, "episode_len_mean": 17.03, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.33, "policy1": -6.33}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 18.0, -20.0, -20.0, -20.0, -20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 11, 20, 20, 20, 20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 9.0, -10.0, -10.0, -10.0, -10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15802399254095043, "mean_inference_ms": 1.4141581145281614, "mean_action_processing_ms": 0.0988590979461571, "mean_env_wait_ms": 0.1663691294240251, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22673, "timesteps_this_iter": 32, "agent_timesteps_total": 45346, "timers": {"learn_time_ms": 6.308, "learn_throughput": 5072.879, "update_time_ms": 3.8}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22673, "num_agent_steps_sampled": 45346, "num_steps_trained": 37568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75136, "last_target_update_ts": 22573, "num_target_updates": 191}, "done": false, "episodes_total": 1235, "training_iteration": 204, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-58", "timestamp": 1648815958, "time_this_iter_s": 0.30310940742492676, "time_total_s": 74.0929811000824, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d1950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 74.0929811000824, "timesteps_since_restore": 6528, "iterations_since_restore": 204, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -11.92, "episode_len_mean": 16.96, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -5.96, "policy1": -5.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 2.0, -40.0, 22.0, -20.0, -20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0], "episode_lengths": [20, 19, 20, 9, 20, 20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20], "policy_policy0_reward": [-10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 1.0, -20.0, 11.0, -10.0, -10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15801672865477326, "mean_inference_ms": 1.4139434130260489, "mean_action_processing_ms": 0.09884150174789726, "mean_env_wait_ms": 0.16634592173184504, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22777, "timesteps_this_iter": 32, "agent_timesteps_total": 45554, "timers": {"learn_time_ms": 6.232, "learn_throughput": 5134.808, "update_time_ms": 3.618}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22777, "num_agent_steps_sampled": 45554, "num_steps_trained": 37760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75520, "last_target_update_ts": 22685, "num_target_updates": 192}, "done": false, "episodes_total": 1241, "training_iteration": 205, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-59", "timestamp": 1648815959, "time_this_iter_s": 0.3346693515777588, "time_total_s": 74.42765045166016, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c521c20>"}, "time_since_restore": 74.42765045166016, "timesteps_since_restore": 6560, "iterations_since_restore": 205, "perf": {"cpu_util_percent": 24.9, "ram_util_percent": 55.0}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.56, "episode_len_mean": 17.08, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.28, "policy1": -6.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 20.0, -20.0, -20.0, -40.0, 20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 10, 20, 20, 20, 10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 10.0, -10.0, -10.0, -20.0, 10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15800740744651243, "mean_inference_ms": 1.4137481926279685, "mean_action_processing_ms": 0.09882457894031126, "mean_env_wait_ms": 0.16632133046929443, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22877, "timesteps_this_iter": 32, "agent_timesteps_total": 45754, "timers": {"learn_time_ms": 6.275, "learn_throughput": 5099.71, "update_time_ms": 3.594}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22877, "num_agent_steps_sampled": 45754, "num_steps_trained": 37920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75840, "last_target_update_ts": 22797, "num_target_updates": 193}, "done": false, "episodes_total": 1246, "training_iteration": 206, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-59", "timestamp": 1648815959, "time_this_iter_s": 0.30367469787597656, "time_total_s": 74.73132514953613, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4ce680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4ce680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1b00>"}, "time_since_restore": 74.73132514953613, "timesteps_since_restore": 6592, "iterations_since_restore": 206, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -12.76, "episode_len_mean": 17.18, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.38, "policy1": -6.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 22.0, -20.0, -20.0, -40.0, 32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [10, 9, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [10.0, 11.0, -10.0, -10.0, -20.0, 16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15799799143150234, "mean_inference_ms": 1.4135636334149047, "mean_action_processing_ms": 0.09880877714131579, "mean_env_wait_ms": 0.16629854511378483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22977, "timesteps_this_iter": 32, "agent_timesteps_total": 45954, "timers": {"learn_time_ms": 6.284, "learn_throughput": 5092.666, "update_time_ms": 3.696}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 22977, "num_agent_steps_sampled": 45954, "num_steps_trained": 38080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76160, "last_target_update_ts": 22917, "num_target_updates": 194}, "done": false, "episodes_total": 1251, "training_iteration": 207, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-25-59", "timestamp": 1648815959, "time_this_iter_s": 0.31368350982666016, "time_total_s": 75.0450086593628, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c3cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4ce0e0>"}, "time_since_restore": 75.0450086593628, "timesteps_since_restore": 6624, "iterations_since_restore": 207, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 55.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.98, "episode_len_mean": 17.39, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.99, "policy1": -6.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [32.0, -20.0, -40.0, -20.0, -20.0, 24.0, -20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0], "episode_lengths": [4, 20, 20, 20, 20, 8, 20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [16.0, -10.0, -20.0, -10.0, -10.0, 12.0, -10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15798566571873834, "mean_inference_ms": 1.4133823131985808, "mean_action_processing_ms": 0.09879386942457181, "mean_env_wait_ms": 0.16627617454764007, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23077, "timesteps_this_iter": 32, "agent_timesteps_total": 46154, "timers": {"learn_time_ms": 6.252, "learn_throughput": 5118.594, "update_time_ms": 4.316}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23077, "num_agent_steps_sampled": 46154, "num_steps_trained": 38240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76480, "last_target_update_ts": 23037, "num_target_updates": 195}, "done": false, "episodes_total": 1256, "training_iteration": 208, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-00", "timestamp": 1648815960, "time_this_iter_s": 0.31188035011291504, "time_total_s": 75.35688900947571, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4be560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4be560>"}, "time_since_restore": 75.35688900947571, "timesteps_since_restore": 6656, "iterations_since_restore": 208, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.7, "episode_len_mean": 17.55, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.35, "policy1": -7.35}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 24.0, 14.0, -20.0, -40.0, 28.0, -20.0, -20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0], "episode_lengths": [20, 8, 13, 20, 20, 6, 20, 20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20], "policy_policy0_reward": [-10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0], "policy_policy1_reward": [-10.0, 12.0, 7.0, -10.0, -20.0, 14.0, -10.0, -10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15796940346507274, "mean_inference_ms": 1.4131514250312998, "mean_action_processing_ms": 0.09877553018562385, "mean_env_wait_ms": 0.16624710504381315, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23185, "timesteps_this_iter": 32, "agent_timesteps_total": 46370, "timers": {"learn_time_ms": 6.168, "learn_throughput": 5188.281, "update_time_ms": 4.64}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23185, "num_agent_steps_sampled": 46370, "num_steps_trained": 38432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76864, "last_target_update_ts": 23157, "num_target_updates": 196}, "done": false, "episodes_total": 1262, "training_iteration": 209, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-00", "timestamp": 1648815960, "time_this_iter_s": 0.3485682010650635, "time_total_s": 75.70545721054077, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb7a0>"}, "time_since_restore": 75.70545721054077, "timesteps_since_restore": 6688, "iterations_since_restore": 209, "perf": {"cpu_util_percent": 29.4, "ram_util_percent": 55.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.8, "episode_len_mean": 17.6, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.4, "policy1": -7.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 24.0, -20.0, -20.0, 32.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0], "episode_lengths": [20, 8, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20], "policy_policy0_reward": [-10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, 12.0, -10.0, -10.0, 16.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1579477451894715, "mean_inference_ms": 1.4128581503221977, "mean_action_processing_ms": 0.09875240155818292, "mean_env_wait_ms": 0.16620938346725594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23297, "timesteps_this_iter": 32, "agent_timesteps_total": 46594, "timers": {"learn_time_ms": 6.38, "learn_throughput": 5015.891, "update_time_ms": 4.341}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23297, "num_agent_steps_sampled": 46594, "num_steps_trained": 38656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77312, "last_target_update_ts": 23277, "num_target_updates": 197}, "done": false, "episodes_total": 1269, "training_iteration": 210, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-01", "timestamp": 1648815961, "time_this_iter_s": 0.37340521812438965, "time_total_s": 76.07886242866516, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c533d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c533d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "time_since_restore": 76.07886242866516, "timesteps_since_restore": 6720, "iterations_since_restore": 210, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.36, "episode_len_mean": 17.88, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.18, "policy1": -8.18}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15792949477048762, "mean_inference_ms": 1.4126371080108382, "mean_action_processing_ms": 0.09873483711591906, "mean_env_wait_ms": 0.166179168859347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23397, "timesteps_this_iter": 32, "agent_timesteps_total": 46794, "timers": {"learn_time_ms": 6.512, "learn_throughput": 4914.312, "update_time_ms": 4.057}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23397, "num_agent_steps_sampled": 46794, "num_steps_trained": 38816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77632, "last_target_update_ts": 23397, "num_target_updates": 198}, "done": false, "episodes_total": 1274, "training_iteration": 211, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-01", "timestamp": 1648815961, "time_this_iter_s": 0.3046116828918457, "time_total_s": 76.383474111557, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1320>"}, "time_since_restore": 76.383474111557, "timesteps_since_restore": 6752, "iterations_since_restore": 211, "perf": {"cpu_util_percent": 27.3, "ram_util_percent": 55.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.56, "episode_len_mean": 17.88, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.28, "policy1": -8.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 20.0, 12.0, -40.0, -40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 10, 14, 20, 20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, 10.0, 6.0, -20.0, -20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15791221890691426, "mean_inference_ms": 1.4124285202182154, "mean_action_processing_ms": 0.09871831126508017, "mean_env_wait_ms": 0.16614866714116347, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23497, "timesteps_this_iter": 32, "agent_timesteps_total": 46994, "timers": {"learn_time_ms": 6.21, "learn_throughput": 5153.004, "update_time_ms": 3.955}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23497, "num_agent_steps_sampled": 46994, "num_steps_trained": 38976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77952, "last_target_update_ts": 23397, "num_target_updates": 198}, "done": false, "episodes_total": 1279, "training_iteration": 212, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-01", "timestamp": 1648815961, "time_this_iter_s": 0.3232102394104004, "time_total_s": 76.70668435096741, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4be560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4be560>"}, "time_since_restore": 76.70668435096741, "timesteps_since_restore": 6784, "iterations_since_restore": 212, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.88, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.44, "policy1": -8.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 22.0, 12.0, -20.0, -40.0, -20.0, -40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 9, 14, 20, 20, 20, 20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 11.0, 6.0, -10.0, -20.0, -10.0, -20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15789514048452052, "mean_inference_ms": 1.4122224106886796, "mean_action_processing_ms": 0.0987029105579277, "mean_env_wait_ms": 0.16611830895995192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23597, "timesteps_this_iter": 32, "agent_timesteps_total": 47194, "timers": {"learn_time_ms": 6.208, "learn_throughput": 5154.39, "update_time_ms": 3.787}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23597, "num_agent_steps_sampled": 47194, "num_steps_trained": 39136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78272, "last_target_update_ts": 23517, "num_target_updates": 199}, "done": false, "episodes_total": 1284, "training_iteration": 213, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-02", "timestamp": 1648815962, "time_this_iter_s": 0.3061504364013672, "time_total_s": 77.01283478736877, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bb7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bb7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1170>"}, "time_since_restore": 77.01283478736877, "timesteps_since_restore": 6816, "iterations_since_restore": 213, "perf": {"cpu_util_percent": 28.7, "ram_util_percent": 55.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.12, "episode_len_mean": 18.16, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.56, "policy1": -8.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 22.0, -40.0, 34.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 9, 20, 3, 20, 20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 11.0, -20.0, 17.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15787193214166753, "mean_inference_ms": 1.4119627902840477, "mean_action_processing_ms": 0.09868379226530813, "mean_env_wait_ms": 0.16607925007081228, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23712, "timesteps_this_iter": 32, "agent_timesteps_total": 47424, "timers": {"learn_time_ms": 6.205, "learn_throughput": 5157.222, "update_time_ms": 3.785}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23712, "num_agent_steps_sampled": 47424, "num_steps_trained": 39328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78656, "last_target_update_ts": 23632, "num_target_updates": 200}, "done": false, "episodes_total": 1290, "training_iteration": 214, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-02", "timestamp": 1648815962, "time_this_iter_s": 0.35516905784606934, "time_total_s": 77.36800384521484, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e53b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e53b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "time_since_restore": 77.36800384521484, "timesteps_since_restore": 6848, "iterations_since_restore": 214, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.68, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.84, "policy1": -8.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 17, 20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, 3.0, -10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15785144946192972, "mean_inference_ms": 1.4117439487248873, "mean_action_processing_ms": 0.09866850596889626, "mean_env_wait_ms": 0.16604747552963114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23812, "timesteps_this_iter": 32, "agent_timesteps_total": 47624, "timers": {"learn_time_ms": 6.202, "learn_throughput": 5159.998, "update_time_ms": 3.712}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23812, "num_agent_steps_sampled": 47624, "num_steps_trained": 39488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78976, "last_target_update_ts": 23752, "num_target_updates": 201}, "done": false, "episodes_total": 1295, "training_iteration": 215, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-02", "timestamp": 1648815962, "time_this_iter_s": 0.30852365493774414, "time_total_s": 77.67652750015259, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4b9f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1320>"}, "time_since_restore": 77.67652750015259, "timesteps_since_restore": 6880, "iterations_since_restore": 215, "perf": {"cpu_util_percent": 27.4, "ram_util_percent": 55.1}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.32, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.66, "policy1": -8.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -40.0, -20.0, 30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, 15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15782702409288757, "mean_inference_ms": 1.4114913049838425, "mean_action_processing_ms": 0.09865142716463084, "mean_env_wait_ms": 0.1660106328391829, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23921, "timesteps_this_iter": 32, "agent_timesteps_total": 47842, "timers": {"learn_time_ms": 6.301, "learn_throughput": 5078.33, "update_time_ms": 3.656}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 23921, "num_agent_steps_sampled": 47842, "num_steps_trained": 39680, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79360, "last_target_update_ts": 23861, "num_target_updates": 202}, "done": false, "episodes_total": 1301, "training_iteration": 216, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-03", "timestamp": 1648815963, "time_this_iter_s": 0.350766658782959, "time_total_s": 78.02729415893555, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c533d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bc7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c533d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bc7a0>"}, "time_since_restore": 78.02729415893555, "timesteps_since_restore": 6912, "iterations_since_restore": 216, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.32, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.66, "policy1": -8.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -20.0, -20.0, 24.0, 34.0, -20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [5, 20, 20, 8, 3, 20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [15.0, -10.0, -10.0, 12.0, 17.0, -10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1578058298121452, "mean_inference_ms": 1.4112835350386024, "mean_action_processing_ms": 0.09863800423886972, "mean_env_wait_ms": 0.16598066828758892, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24021, "timesteps_this_iter": 32, "agent_timesteps_total": 48042, "timers": {"learn_time_ms": 6.444, "learn_throughput": 4965.987, "update_time_ms": 3.763}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24021, "num_agent_steps_sampled": 48042, "num_steps_trained": 39840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79680, "last_target_update_ts": 23981, "num_target_updates": 203}, "done": false, "episodes_total": 1306, "training_iteration": 217, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-03", "timestamp": 1648815963, "time_this_iter_s": 0.3084077835083008, "time_total_s": 78.33570194244385, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb7a0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bb7a0>"}, "time_since_restore": 78.33570194244385, "timesteps_since_restore": 6944, "iterations_since_restore": 217, "perf": {"cpu_util_percent": 29.2, "ram_util_percent": 55.1}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.8, "episode_len_mean": 18.8, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.4, "policy1": -9.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, 32.0, -40.0, -20.0, 6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 4, 20, 20, 17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, 16.0, -20.0, -10.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15778231104556453, "mean_inference_ms": 1.4110618036158495, "mean_action_processing_ms": 0.0986235857404278, "mean_env_wait_ms": 0.16594935945220934, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24121, "timesteps_this_iter": 32, "agent_timesteps_total": 48242, "timers": {"learn_time_ms": 6.507, "learn_throughput": 4917.427, "update_time_ms": 3.877}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24121, "num_agent_steps_sampled": 48242, "num_steps_trained": 40000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80000, "last_target_update_ts": 24101, "num_target_updates": 204}, "done": false, "episodes_total": 1311, "training_iteration": 218, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-03", "timestamp": 1648815963, "time_this_iter_s": 0.30159687995910645, "time_total_s": 78.63729882240295, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d1950>"}, "time_since_restore": 78.63729882240295, "timesteps_since_restore": 6976, "iterations_since_restore": 218, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.12, "episode_len_mean": 18.96, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.56, "policy1": -9.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [6.0, -40.0, -20.0, -40.0, -20.0, -40.0, -20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [17, 20, 20, 20, 20, 20, 20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15775608335204847, "mean_inference_ms": 1.4108345807261302, "mean_action_processing_ms": 0.09860811657907068, "mean_env_wait_ms": 0.16591634137667197, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24221, "timesteps_this_iter": 32, "agent_timesteps_total": 48442, "timers": {"learn_time_ms": 6.456, "learn_throughput": 4956.744, "update_time_ms": 3.777}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24221, "num_agent_steps_sampled": 48442, "num_steps_trained": 40160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80320, "last_target_update_ts": 24221, "num_target_updates": 205}, "done": false, "episodes_total": 1316, "training_iteration": 219, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-04", "timestamp": 1648815964, "time_this_iter_s": 0.30411362648010254, "time_total_s": 78.94141244888306, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f70e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f70e0>"}, "time_since_restore": 78.94141244888306, "timesteps_since_restore": 7008, "iterations_since_restore": 219, "perf": {"cpu_util_percent": 27.5, "ram_util_percent": 55.1}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.76, "episode_len_mean": 18.98, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.38, "policy1": -9.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 24.0, -20.0, 12.0, 12.0, 10.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0], "episode_lengths": [20, 8, 20, 14, 14, 15, 20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0], "policy_policy1_reward": [-10.0, 12.0, -10.0, 6.0, 6.0, 5.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15772746528472428, "mean_inference_ms": 1.4105895052920503, "mean_action_processing_ms": 0.09859282073471316, "mean_env_wait_ms": 0.16587926415994553, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24340, "timesteps_this_iter": 32, "agent_timesteps_total": 48680, "timers": {"learn_time_ms": 6.486, "learn_throughput": 4933.786, "update_time_ms": 3.917}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24340, "num_agent_steps_sampled": 48680, "num_steps_trained": 40352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80704, "last_target_update_ts": 24340, "num_target_updates": 206}, "done": false, "episodes_total": 1322, "training_iteration": 220, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-04", "timestamp": 1648815964, "time_this_iter_s": 0.38953447341918945, "time_total_s": 79.33094692230225, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1a70>"}, "time_since_restore": 79.33094692230225, "timesteps_since_restore": 7040, "iterations_since_restore": 220, "perf": {}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.8, "episode_len_mean": 19.2, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -9.9, "policy1": -9.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15770303129120677, "mean_inference_ms": 1.4104140844930237, "mean_action_processing_ms": 0.09858182178303586, "mean_env_wait_ms": 0.16585021005464515, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24453, "timesteps_this_iter": 32, "agent_timesteps_total": 48906, "timers": {"learn_time_ms": 6.772, "learn_throughput": 4725.361, "update_time_ms": 4.034}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24453, "num_agent_steps_sampled": 48906, "num_steps_trained": 40544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81088, "last_target_update_ts": 24453, "num_target_updates": 207}, "done": false, "episodes_total": 1328, "training_iteration": 221, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-05", "timestamp": 1648815965, "time_this_iter_s": 0.3924245834350586, "time_total_s": 79.7233715057373, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bce60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bce60>"}, "time_since_restore": 79.7233715057373, "timesteps_since_restore": 7072, "iterations_since_restore": 221, "perf": {"cpu_util_percent": 29.2, "ram_util_percent": 55.1}}
{"episode_reward_max": 24.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.0, "episode_len_mean": 19.2, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 12.0}, "policy_reward_mean": {"policy0": -10.0, "policy1": -10.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 16.0, -20.0, 8.0, 8.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0], "episode_lengths": [20, 20, 12, 20, 16, 16, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 8.0, -10.0, 4.0, 4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15768312479424995, "mean_inference_ms": 1.4102757789749085, "mean_action_processing_ms": 0.09857340208605776, "mean_env_wait_ms": 0.16582748288574908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24553, "timesteps_this_iter": 32, "agent_timesteps_total": 49106, "timers": {"learn_time_ms": 6.607, "learn_throughput": 4843.097, "update_time_ms": 4.071}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24553, "num_agent_steps_sampled": 49106, "num_steps_trained": 40704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81408, "last_target_update_ts": 24453, "num_target_updates": 207}, "done": false, "episodes_total": 1333, "training_iteration": 222, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-05", "timestamp": 1648815965, "time_this_iter_s": 0.3121335506439209, "time_total_s": 80.03550505638123, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4e1b90>"}, "time_since_restore": 80.03550505638123, "timesteps_since_restore": 7104, "iterations_since_restore": 222, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.96, "episode_len_mean": 18.98, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.98, "policy1": -9.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576605333136396, "mean_inference_ms": 1.4101189477615237, "mean_action_processing_ms": 0.098563689287321, "mean_env_wait_ms": 0.1657989783491761, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24655, "timesteps_this_iter": 32, "agent_timesteps_total": 49310, "timers": {"learn_time_ms": 6.625, "learn_throughput": 4830.391, "update_time_ms": 4.363}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24655, "num_agent_steps_sampled": 49310, "num_steps_trained": 40928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81856, "last_target_update_ts": 24573, "num_target_updates": 208}, "done": false, "episodes_total": 1340, "training_iteration": 223, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-05", "timestamp": 1648815965, "time_this_iter_s": 0.37608933448791504, "time_total_s": 80.41159439086914, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7050>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7050>"}, "time_since_restore": 80.41159439086914, "timesteps_since_restore": 7136, "iterations_since_restore": 223, "perf": {"cpu_util_percent": 27.8, "ram_util_percent": 55.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.92, "episode_len_mean": 18.96, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -9.96, "policy1": -9.96}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576433492966066, "mean_inference_ms": 1.4099904246237076, "mean_action_processing_ms": 0.09855725483178478, "mean_env_wait_ms": 0.16577896899183706, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24773, "timesteps_this_iter": 32, "agent_timesteps_total": 49546, "timers": {"learn_time_ms": 6.832, "learn_throughput": 4683.593, "update_time_ms": 4.085}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24773, "num_agent_steps_sampled": 49546, "num_steps_trained": 41120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82240, "last_target_update_ts": 24675, "num_target_updates": 209}, "done": false, "episodes_total": 1346, "training_iteration": 224, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-06", "timestamp": 1648815966, "time_this_iter_s": 0.3703920841217041, "time_total_s": 80.78198647499084, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 80.78198647499084, "timesteps_since_restore": 7168, "iterations_since_restore": 224, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.8, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 8, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.9, "policy1": -8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -20.0, -40.0, 24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, 12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576310855149289, "mean_inference_ms": 1.4098710454591747, "mean_action_processing_ms": 0.09855279237576715, "mean_env_wait_ms": 0.1657571865865946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24887, "timesteps_this_iter": 32, "agent_timesteps_total": 49774, "timers": {"learn_time_ms": 6.822, "learn_throughput": 4690.468, "update_time_ms": 4.098}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24887, "num_agent_steps_sampled": 49774, "num_steps_trained": 41376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82752, "last_target_update_ts": 24887, "num_target_updates": 211}, "done": false, "episodes_total": 1354, "training_iteration": 225, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-06", "timestamp": 1648815966, "time_this_iter_s": 0.43500375747680664, "time_total_s": 81.21699023246765, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bce60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bce60>"}, "time_since_restore": 81.21699023246765, "timesteps_since_restore": 7200, "iterations_since_restore": 225, "perf": {"cpu_util_percent": 26.4, "ram_util_percent": 55.1}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.72, "episode_len_mean": 18.36, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.36, "policy1": -8.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, 12.0, -20.0, -20.0, 22.0, 22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [8, 20, 14, 20, 20, 9, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20], "policy_policy0_reward": [12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [12.0, -10.0, 6.0, -10.0, -10.0, 11.0, 11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15762438541580487, "mean_inference_ms": 1.4098182195810622, "mean_action_processing_ms": 0.09855168510443894, "mean_env_wait_ms": 0.16574582018760062, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24993, "timesteps_this_iter": 32, "agent_timesteps_total": 49986, "timers": {"learn_time_ms": 6.836, "learn_throughput": 4680.996, "update_time_ms": 4.113}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 24993, "num_agent_steps_sampled": 49986, "num_steps_trained": 41568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83136, "last_target_update_ts": 24993, "num_target_updates": 212}, "done": false, "episodes_total": 1360, "training_iteration": 226, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-07", "timestamp": 1648815967, "time_this_iter_s": 0.36907076835632324, "time_total_s": 81.58606100082397, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "time_since_restore": 81.58606100082397, "timesteps_since_restore": 7232, "iterations_since_restore": 226, "perf": {"cpu_util_percent": 29.2, "ram_util_percent": 55.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.48, "episode_len_mean": 18.54, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.74, "policy1": -8.74}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, -20.0, -40.0, -20.0, -40.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0], "episode_lengths": [9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20], "policy_policy0_reward": [11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [11.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15762049743824993, "mean_inference_ms": 1.4097926929678348, "mean_action_processing_ms": 0.09855271892842986, "mean_env_wait_ms": 0.16573902219903527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25102, "timesteps_this_iter": 32, "agent_timesteps_total": 50204, "timers": {"learn_time_ms": 6.618, "learn_throughput": 4835.473, "update_time_ms": 4.07}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25102, "num_agent_steps_sampled": 50204, "num_steps_trained": 41760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83520, "last_target_update_ts": 25102, "num_target_updates": 213}, "done": false, "episodes_total": 1366, "training_iteration": 227, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-07", "timestamp": 1648815967, "time_this_iter_s": 0.36482882499694824, "time_total_s": 81.95088982582092, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bcef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7290>"}, "time_since_restore": 81.95088982582092, "timesteps_since_restore": 7264, "iterations_since_restore": 227, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.46, "episode_len_mean": 18.63, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.73, "policy1": -8.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761799419139524, "mean_inference_ms": 1.409773789597445, "mean_action_processing_ms": 0.09855434941117103, "mean_env_wait_ms": 0.16573414013494792, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25220, "timesteps_this_iter": 32, "agent_timesteps_total": 50440, "timers": {"learn_time_ms": 6.441, "learn_throughput": 4968.046, "update_time_ms": 3.821}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25220, "num_agent_steps_sampled": 50440, "num_steps_trained": 41952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83904, "last_target_update_ts": 25220, "num_target_updates": 214}, "done": false, "episodes_total": 1372, "training_iteration": 228, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-07", "timestamp": 1648815967, "time_this_iter_s": 0.36764097213745117, "time_total_s": 82.31853079795837, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 82.31853079795837, "timesteps_since_restore": 7296, "iterations_since_restore": 228, "perf": {"cpu_util_percent": 28.8, "ram_util_percent": 55.2}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.02, "episode_len_mean": 18.61, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.51, "policy1": -8.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761602900316865, "mean_inference_ms": 1.4097485758129398, "mean_action_processing_ms": 0.09855504036001082, "mean_env_wait_ms": 0.16572970036704024, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25338, "timesteps_this_iter": 32, "agent_timesteps_total": 50676, "timers": {"learn_time_ms": 6.238, "learn_throughput": 5129.471, "update_time_ms": 3.724}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25338, "num_agent_steps_sampled": 50676, "num_steps_trained": 42144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84288, "last_target_update_ts": 25338, "num_target_updates": 215}, "done": false, "episodes_total": 1378, "training_iteration": 229, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-08", "timestamp": 1648815968, "time_this_iter_s": 0.3614518642425537, "time_total_s": 82.67998266220093, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9a70>"}, "time_since_restore": 82.67998266220093, "timesteps_since_restore": 7328, "iterations_since_restore": 229, "perf": {}}
{"episode_reward_max": 30.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.74, "episode_len_mean": 18.47, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 15.0, "policy1": 15.0}, "policy_reward_mean": {"policy0": -8.37, "policy1": -8.37}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 10.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 5.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761426124305922, "mean_inference_ms": 1.4097187232289656, "mean_action_processing_ms": 0.09855561736581554, "mean_env_wait_ms": 0.16572519917970943, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25444, "timesteps_this_iter": 32, "agent_timesteps_total": 50888, "timers": {"learn_time_ms": 6.343, "learn_throughput": 5045.172, "update_time_ms": 3.712}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25444, "num_agent_steps_sampled": 50888, "num_steps_trained": 42336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84672, "last_target_update_ts": 25444, "num_target_updates": 216}, "done": false, "episodes_total": 1384, "training_iteration": 230, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-08", "timestamp": 1648815968, "time_this_iter_s": 0.3380138874053955, "time_total_s": 83.01799654960632, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "time_since_restore": 83.01799654960632, "timesteps_since_restore": 7360, "iterations_since_restore": 230, "perf": {"cpu_util_percent": 26.5, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.8, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.9, "policy1": -7.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761518316991058, "mean_inference_ms": 1.4097015284162284, "mean_action_processing_ms": 0.0985566625560433, "mean_env_wait_ms": 0.16572105805278078, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25552, "timesteps_this_iter": 32, "agent_timesteps_total": 51104, "timers": {"learn_time_ms": 6.335, "learn_throughput": 5051.438, "update_time_ms": 3.763}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25552, "num_agent_steps_sampled": 51104, "num_steps_trained": 42560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85120, "last_target_update_ts": 25552, "num_target_updates": 217}, "done": false, "episodes_total": 1391, "training_iteration": 231, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-08", "timestamp": 1648815968, "time_this_iter_s": 0.3656141757965088, "time_total_s": 83.38361072540283, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7290>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7290>"}, "time_since_restore": 83.38361072540283, "timesteps_since_restore": 7392, "iterations_since_restore": 231, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.54, "episode_len_mean": 18.17, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.77, "policy1": -7.77}, "custom_metrics": {}, "hist_stats": {"episode_reward": [22.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20], "policy_policy0_reward": [11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [11.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576144658541796, "mean_inference_ms": 1.4096814828892759, "mean_action_processing_ms": 0.09855672340956904, "mean_env_wait_ms": 0.16571695669161915, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25669, "timesteps_this_iter": 32, "agent_timesteps_total": 51338, "timers": {"learn_time_ms": 6.444, "learn_throughput": 4966.098, "update_time_ms": 4.129}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25669, "num_agent_steps_sampled": 51338, "num_steps_trained": 42752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85504, "last_target_update_ts": 25669, "num_target_updates": 218}, "done": false, "episodes_total": 1397, "training_iteration": 232, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-09", "timestamp": 1648815969, "time_this_iter_s": 0.3662593364715576, "time_total_s": 83.74987006187439, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 83.74987006187439, "timesteps_since_restore": 7424, "iterations_since_restore": 232, "perf": {"cpu_util_percent": 28.9, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.52, "episode_len_mean": 18.16, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.76, "policy1": -7.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761570560074734, "mean_inference_ms": 1.4096602243347198, "mean_action_processing_ms": 0.0985565324535332, "mean_env_wait_ms": 0.1657129610536539, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25777, "timesteps_this_iter": 32, "agent_timesteps_total": 51554, "timers": {"learn_time_ms": 6.436, "learn_throughput": 4972.335, "update_time_ms": 3.988}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25777, "num_agent_steps_sampled": 51554, "num_steps_trained": 42944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85888, "last_target_update_ts": 25777, "num_target_updates": 219}, "done": false, "episodes_total": 1403, "training_iteration": 233, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-09", "timestamp": 1648815969, "time_this_iter_s": 0.3553447723388672, "time_total_s": 84.10521483421326, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bce60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9a70>"}, "time_since_restore": 84.10521483421326, "timesteps_since_restore": 7456, "iterations_since_restore": 233, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.52, "episode_len_mean": 18.16, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.76, "policy1": -7.76}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15761718311773942, "mean_inference_ms": 1.4096459809955835, "mean_action_processing_ms": 0.09855673133107881, "mean_env_wait_ms": 0.16571045502081064, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25877, "timesteps_this_iter": 32, "agent_timesteps_total": 51754, "timers": {"learn_time_ms": 6.285, "learn_throughput": 5091.584, "update_time_ms": 3.822}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25877, "num_agent_steps_sampled": 51754, "num_steps_trained": 43104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86208, "last_target_update_ts": 25777, "num_target_updates": 219}, "done": false, "episodes_total": 1408, "training_iteration": 234, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-10", "timestamp": 1648815970, "time_this_iter_s": 0.30438733100891113, "time_total_s": 84.40960216522217, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c1e60>"}, "time_since_restore": 84.40960216522217, "timesteps_since_restore": 7488, "iterations_since_restore": 234, "perf": {"cpu_util_percent": 26.2, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.44, "episode_len_mean": 18.02, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.72, "policy1": -7.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 2.0, -20.0, -40.0, -40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0], "episode_lengths": [20, 20, 19, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 1.0, -10.0, -20.0, -20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15762165695304692, "mean_inference_ms": 1.4096387553302105, "mean_action_processing_ms": 0.09855783915898102, "mean_env_wait_ms": 0.1657096220381809, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25983, "timesteps_this_iter": 32, "agent_timesteps_total": 51966, "timers": {"learn_time_ms": 6.235, "learn_throughput": 5132.334, "update_time_ms": 3.869}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 25983, "num_agent_steps_sampled": 51966, "num_steps_trained": 43296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86592, "last_target_update_ts": 25897, "num_target_updates": 220}, "done": false, "episodes_total": 1414, "training_iteration": 235, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-10", "timestamp": 1648815970, "time_this_iter_s": 0.3446626663208008, "time_total_s": 84.75426483154297, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d9a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d9a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5950>"}, "time_since_restore": 84.75426483154297, "timesteps_since_restore": 7520, "iterations_since_restore": 235, "perf": {"cpu_util_percent": 27.9, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.46, "episode_len_mean": 18.03, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.73, "policy1": -7.73}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 0.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, 0.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.157624654022708, "mean_inference_ms": 1.409619368388571, "mean_action_processing_ms": 0.098557785670398, "mean_env_wait_ms": 0.16570843627693513, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26083, "timesteps_this_iter": 32, "agent_timesteps_total": 52166, "timers": {"learn_time_ms": 6.308, "learn_throughput": 5072.611, "update_time_ms": 3.964}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26083, "num_agent_steps_sampled": 52166, "num_steps_trained": 43456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86912, "last_target_update_ts": 26003, "num_target_updates": 221}, "done": false, "episodes_total": 1419, "training_iteration": 236, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-10", "timestamp": 1648815970, "time_this_iter_s": 0.30469512939453125, "time_total_s": 85.0589599609375, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4bc8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "time_since_restore": 85.0589599609375, "timesteps_since_restore": 7552, "iterations_since_restore": 236, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.96, "episode_len_mean": 18.08, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.98, "policy1": -7.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15762618819992058, "mean_inference_ms": 1.4095582839495933, "mean_action_processing_ms": 0.09855494990882809, "mean_env_wait_ms": 0.16570318967058814, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26201, "timesteps_this_iter": 32, "agent_timesteps_total": 52402, "timers": {"learn_time_ms": 6.292, "learn_throughput": 5085.546, "update_time_ms": 3.76}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26201, "num_agent_steps_sampled": 52402, "num_steps_trained": 43648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87296, "last_target_update_ts": 26121, "num_target_updates": 222}, "done": false, "episodes_total": 1425, "training_iteration": 237, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-11", "timestamp": 1648815971, "time_this_iter_s": 0.36676478385925293, "time_total_s": 85.42572474479675, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bcef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bcef0>"}, "time_since_restore": 85.42572474479675, "timesteps_since_restore": 7584, "iterations_since_restore": 237, "perf": {"cpu_util_percent": 29.1, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.24, "episode_len_mean": 17.92, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.62, "policy1": -7.62}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -40.0, -20.0, -40.0, 30.0, 16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 5, 12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, 15.0, 8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576259824458863, "mean_inference_ms": 1.4094644563185466, "mean_action_processing_ms": 0.09854974471112082, "mean_env_wait_ms": 0.16569319870458682, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26305, "timesteps_this_iter": 32, "agent_timesteps_total": 52610, "timers": {"learn_time_ms": 6.535, "learn_throughput": 4896.652, "update_time_ms": 3.826}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26305, "num_agent_steps_sampled": 52610, "num_steps_trained": 43840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87680, "last_target_update_ts": 26227, "num_target_updates": 223}, "done": false, "episodes_total": 1431, "training_iteration": 238, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-11", "timestamp": 1648815971, "time_this_iter_s": 0.3371162414550781, "time_total_s": 85.76284098625183, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7f80>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4e1170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7f80>"}, "time_since_restore": 85.76284098625183, "timesteps_since_restore": 7616, "iterations_since_restore": 238, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.82, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.41, "policy1": -7.41}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -20.0, 30.0, -20.0, -40.0, 4.0, -20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0], "episode_lengths": [12, 20, 5, 20, 20, 18, 20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20], "policy_policy0_reward": [8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0], "policy_policy1_reward": [8.0, -10.0, 15.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576223381648155, "mean_inference_ms": 1.4093515491721815, "mean_action_processing_ms": 0.09854373009399041, "mean_env_wait_ms": 0.16568005142203177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26419, "timesteps_this_iter": 32, "agent_timesteps_total": 52838, "timers": {"learn_time_ms": 6.541, "learn_throughput": 4892.315, "update_time_ms": 3.942}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26419, "num_agent_steps_sampled": 52838, "num_steps_trained": 44032, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88064, "last_target_update_ts": 26345, "num_target_updates": 224}, "done": false, "episodes_total": 1437, "training_iteration": 239, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-11", "timestamp": 1648815971, "time_this_iter_s": 0.3563690185546875, "time_total_s": 86.11921000480652, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9b90>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9b90>"}, "time_since_restore": 86.11921000480652, "timesteps_since_restore": 7648, "iterations_since_restore": 239, "perf": {"cpu_util_percent": 27.3, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.38, "episode_len_mean": 18.19, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.69, "policy1": -7.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, 18.0, -20.0, -40.0, 20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0], "episode_lengths": [20, 20, 20, 11, 20, 20, 10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, 9.0, -10.0, -20.0, 10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576148984913079, "mean_inference_ms": 1.4092176447567168, "mean_action_processing_ms": 0.09853605692209644, "mean_env_wait_ms": 0.1656618030946362, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26532, "timesteps_this_iter": 32, "agent_timesteps_total": 53064, "timers": {"learn_time_ms": 6.506, "learn_throughput": 4918.815, "update_time_ms": 3.925}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26532, "num_agent_steps_sampled": 53064, "num_steps_trained": 44224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88448, "last_target_update_ts": 26459, "num_target_updates": 225}, "done": false, "episodes_total": 1443, "training_iteration": 240, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-12", "timestamp": 1648815972, "time_this_iter_s": 0.3512105941772461, "time_total_s": 86.47042059898376, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "time_since_restore": 86.47042059898376, "timesteps_since_restore": 7680, "iterations_since_restore": 240, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.86, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.43, "policy1": -7.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, 20.0, 20.0, 14.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0], "episode_lengths": [10, 10, 10, 13, 20, 6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8], "policy_policy0_reward": [10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0], "policy_policy1_reward": [10.0, 10.0, 10.0, 7.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1576038845882327, "mean_inference_ms": 1.4090588515839408, "mean_action_processing_ms": 0.09852544681742735, "mean_env_wait_ms": 0.165639192957252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26637, "timesteps_this_iter": 32, "agent_timesteps_total": 53274, "timers": {"learn_time_ms": 6.497, "learn_throughput": 4925.457, "update_time_ms": 3.94}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26637, "num_agent_steps_sampled": 53274, "num_steps_trained": 44416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88832, "last_target_update_ts": 26572, "num_target_updates": 226}, "done": false, "episodes_total": 1449, "training_iteration": 241, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-12", "timestamp": 1648815972, "time_this_iter_s": 0.33646345138549805, "time_total_s": 86.80688405036926, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d9b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d9b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7dd0>"}, "time_since_restore": 86.80688405036926, "timesteps_since_restore": 7712, "iterations_since_restore": 241, "perf": {"cpu_util_percent": 27.3, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.4, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.2, "policy1": -8.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [6, 20, 20, 20, 20, 20, 11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20], "policy_policy0_reward": [14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [14.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15759079123894384, "mean_inference_ms": 1.4089034990135167, "mean_action_processing_ms": 0.09851488190479285, "mean_env_wait_ms": 0.16561700951706118, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26737, "timesteps_this_iter": 32, "agent_timesteps_total": 53474, "timers": {"learn_time_ms": 6.323, "learn_throughput": 5060.962, "update_time_ms": 3.998}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26737, "num_agent_steps_sampled": 53474, "num_steps_trained": 44576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89152, "last_target_update_ts": 26677, "num_target_updates": 227}, "done": false, "episodes_total": 1454, "training_iteration": 242, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-12", "timestamp": 1648815972, "time_this_iter_s": 0.30841779708862305, "time_total_s": 87.11530184745789, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51f320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51f320>"}, "time_since_restore": 87.11530184745789, "timesteps_since_restore": 7744, "iterations_since_restore": 242, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.08, "episode_len_mean": 18.44, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.04, "policy1": -8.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [18.0, -40.0, 4.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0], "episode_lengths": [11, 20, 18, 20, 20, 20, 20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20], "policy_policy0_reward": [9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0], "policy_policy1_reward": [9.0, -20.0, 2.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15757367908842784, "mean_inference_ms": 1.4086918454114894, "mean_action_processing_ms": 0.09850076471589725, "mean_env_wait_ms": 0.16558758711715058, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26837, "timesteps_this_iter": 32, "agent_timesteps_total": 53674, "timers": {"learn_time_ms": 6.332, "learn_throughput": 5053.93, "update_time_ms": 3.986}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26837, "num_agent_steps_sampled": 53674, "num_steps_trained": 44768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89536, "last_target_update_ts": 26784, "num_target_updates": 228}, "done": false, "episodes_total": 1460, "training_iteration": 243, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-13", "timestamp": 1648815973, "time_this_iter_s": 0.3306560516357422, "time_total_s": 87.44595789909363, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 87.44595789909363, "timesteps_since_restore": 7776, "iterations_since_restore": 243, "perf": {"cpu_util_percent": 28.4, "ram_util_percent": 55.2}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.4, "episode_len_mean": 18.5, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.2, "policy1": -8.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 4.0, -20.0, -40.0, -20.0, 4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0], "episode_lengths": [20, 20, 18, 20, 20, 20, 18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20], "policy_policy0_reward": [-10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 2.0, -10.0, -20.0, -10.0, 2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1575557600934069, "mean_inference_ms": 1.4084659372617248, "mean_action_processing_ms": 0.09848597954995601, "mean_env_wait_ms": 0.16555819356901527, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26952, "timesteps_this_iter": 32, "agent_timesteps_total": 53904, "timers": {"learn_time_ms": 6.272, "learn_throughput": 5102.191, "update_time_ms": 3.807}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 26952, "num_agent_steps_sampled": 53904, "num_steps_trained": 44960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89920, "last_target_update_ts": 26897, "num_target_updates": 229}, "done": false, "episodes_total": 1466, "training_iteration": 244, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-13", "timestamp": 1648815973, "time_this_iter_s": 0.36110854148864746, "time_total_s": 87.80706644058228, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "time_since_restore": 87.80706644058228, "timesteps_since_restore": 7808, "iterations_since_restore": 244, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.98, "episode_len_mean": 18.39, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -7.99, "policy1": -7.99}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, -20.0, -40.0, -20.0, -40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0], "episode_lengths": [18, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0], "policy_policy1_reward": [2.0, -10.0, -10.0, -20.0, -10.0, -20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15753742987807148, "mean_inference_ms": 1.4082312701508999, "mean_action_processing_ms": 0.09847054317426351, "mean_env_wait_ms": 0.16552684976059723, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27059, "timesteps_this_iter": 32, "agent_timesteps_total": 54118, "timers": {"learn_time_ms": 6.371, "learn_throughput": 5023.062, "update_time_ms": 3.796}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27059, "num_agent_steps_sampled": 54118, "num_steps_trained": 45152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90304, "last_target_update_ts": 26999, "num_target_updates": 230}, "done": false, "episodes_total": 1472, "training_iteration": 245, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-14", "timestamp": 1648815974, "time_this_iter_s": 0.33808445930480957, "time_total_s": 88.14515089988708, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7dd0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f7dd0>"}, "time_since_restore": 88.14515089988708, "timesteps_since_restore": 7840, "iterations_since_restore": 245, "perf": {"cpu_util_percent": 25.5, "ram_util_percent": 55.3}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.42, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.21, "policy1": -8.21}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 28.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [20, 6, 20, 20, 20, 20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, 14.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15752107763238252, "mean_inference_ms": 1.4080359646727785, "mean_action_processing_ms": 0.09845789035503383, "mean_env_wait_ms": 0.16550041663748594, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27159, "timesteps_this_iter": 32, "agent_timesteps_total": 54318, "timers": {"learn_time_ms": 6.479, "learn_throughput": 4938.797, "update_time_ms": 3.903}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27159, "num_agent_steps_sampled": 54318, "num_steps_trained": 45312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90624, "last_target_update_ts": 27119, "num_target_updates": 231}, "done": false, "episodes_total": 1477, "training_iteration": 246, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-14", "timestamp": 1648815974, "time_this_iter_s": 0.3002665042877197, "time_total_s": 88.4454174041748, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51f320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f70e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c51f320>"}, "time_since_restore": 88.4454174041748, "timesteps_since_restore": 7872, "iterations_since_restore": 246, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.5, "episode_len_mean": 18.55, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -8.25, "policy1": -8.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 12.0, 32.0, -20.0, 20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 14, 4, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 6.0, 16.0, -10.0, 10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15750512564667424, "mean_inference_ms": 1.4078457725855003, "mean_action_processing_ms": 0.0984450640403767, "mean_env_wait_ms": 0.1654739385461748, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27259, "timesteps_this_iter": 32, "agent_timesteps_total": 54518, "timers": {"learn_time_ms": 6.424, "learn_throughput": 4981.636, "update_time_ms": 3.894}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27259, "num_agent_steps_sampled": 54518, "num_steps_trained": 45472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90944, "last_target_update_ts": 27239, "num_target_updates": 232}, "done": false, "episodes_total": 1482, "training_iteration": 247, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-14", "timestamp": 1648815974, "time_this_iter_s": 0.30797433853149414, "time_total_s": 88.7533917427063, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519950>"}, "time_since_restore": 88.7533917427063, "timesteps_since_restore": 7904, "iterations_since_restore": 247, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 55.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.86, "episode_len_mean": 18.63, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.43, "policy1": -8.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [20.0, -40.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0], "episode_lengths": [10, 20, 20, 20, 17, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19], "policy_policy0_reward": [10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0], "policy_policy1_reward": [10.0, -20.0, -10.0, -10.0, 3.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15748565709111087, "mean_inference_ms": 1.4076145176806443, "mean_action_processing_ms": 0.09843010097988834, "mean_env_wait_ms": 0.1654432260738451, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27365, "timesteps_this_iter": 32, "agent_timesteps_total": 54730, "timers": {"learn_time_ms": 6.338, "learn_throughput": 5048.816, "update_time_ms": 3.879}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27365, "num_agent_steps_sampled": 54730, "num_steps_trained": 45664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91328, "last_target_update_ts": 27346, "num_target_updates": 233}, "done": false, "episodes_total": 1488, "training_iteration": 248, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-15", "timestamp": 1648815975, "time_this_iter_s": 0.3420073986053467, "time_total_s": 89.09539914131165, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d53b0>"}, "time_since_restore": 89.09539914131165, "timesteps_since_restore": 7936, "iterations_since_restore": 248, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.32, "episode_len_mean": 18.76, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.66, "policy1": -8.66}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 24.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1574692238762273, "mean_inference_ms": 1.4074287088122799, "mean_action_processing_ms": 0.09841807016962707, "mean_env_wait_ms": 0.16541788586778167, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27465, "timesteps_this_iter": 32, "agent_timesteps_total": 54930, "timers": {"learn_time_ms": 6.35, "learn_throughput": 5039.414, "update_time_ms": 3.957}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27465, "num_agent_steps_sampled": 54930, "num_steps_trained": 45824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91648, "last_target_update_ts": 27465, "num_target_updates": 234}, "done": false, "episodes_total": 1493, "training_iteration": 249, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-15", "timestamp": 1648815975, "time_this_iter_s": 0.3129563331604004, "time_total_s": 89.40835547447205, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9680>"}, "time_since_restore": 89.40835547447205, "timesteps_since_restore": 7968, "iterations_since_restore": 249, "perf": {"cpu_util_percent": 26.4, "ram_util_percent": 55.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.8, "episode_len_mean": 18.7, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.4, "policy1": -8.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15744978197962733, "mean_inference_ms": 1.40720063338053, "mean_action_processing_ms": 0.09840316862730734, "mean_env_wait_ms": 0.16538594611439145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27567, "timesteps_this_iter": 32, "agent_timesteps_total": 55134, "timers": {"learn_time_ms": 6.419, "learn_throughput": 4985.3, "update_time_ms": 3.876}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27567, "num_agent_steps_sampled": 55134, "num_steps_trained": 46016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92032, "last_target_update_ts": 27567, "num_target_updates": 235}, "done": false, "episodes_total": 1499, "training_iteration": 250, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-15", "timestamp": 1648815975, "time_this_iter_s": 0.327545166015625, "time_total_s": 89.73590064048767, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "time_since_restore": 89.73590064048767, "timesteps_since_restore": 8000, "iterations_since_restore": 250, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.2, "episode_len_mean": 18.6, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -8.1, "policy1": -8.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -40.0, -40.0, -20.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -20.0, -20.0, -10.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15742946655897788, "mean_inference_ms": 1.4069742562237002, "mean_action_processing_ms": 0.09838871310538984, "mean_env_wait_ms": 0.16535577464774348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27677, "timesteps_this_iter": 32, "agent_timesteps_total": 55354, "timers": {"learn_time_ms": 6.35, "learn_throughput": 5039.395, "update_time_ms": 3.801}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27677, "num_agent_steps_sampled": 55354, "num_steps_trained": 46208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92416, "last_target_update_ts": 27677, "num_target_updates": 236}, "done": false, "episodes_total": 1505, "training_iteration": 251, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-16", "timestamp": 1648815976, "time_this_iter_s": 0.34838318824768066, "time_total_s": 90.08428382873535, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c95f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c95f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d9b00>"}, "time_since_restore": 90.08428382873535, "timesteps_since_restore": 8032, "iterations_since_restore": 251, "perf": {"cpu_util_percent": 26.7, "ram_util_percent": 55.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.78, "episode_len_mean": 18.49, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.89, "policy1": -7.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0], "episode_lengths": [6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20], "policy_policy0_reward": [14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15741073928016688, "mean_inference_ms": 1.406757485783321, "mean_action_processing_ms": 0.09837509915814018, "mean_env_wait_ms": 0.16532723300370786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27786, "timesteps_this_iter": 32, "agent_timesteps_total": 55572, "timers": {"learn_time_ms": 6.184, "learn_throughput": 5174.24, "update_time_ms": 3.752}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27786, "num_agent_steps_sampled": 55572, "num_steps_trained": 46400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92800, "last_target_update_ts": 27786, "num_target_updates": 237}, "done": false, "episodes_total": 1511, "training_iteration": 252, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-16", "timestamp": 1648815976, "time_this_iter_s": 0.3457164764404297, "time_total_s": 90.43000030517578, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519320>"}, "time_since_restore": 90.43000030517578, "timesteps_since_restore": 8064, "iterations_since_restore": 252, "perf": {}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.94, "episode_len_mean": 18.37, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.47, "policy1": -7.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, 4.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 18, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20], "policy_policy0_reward": [-10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15739028945139708, "mean_inference_ms": 1.4065010573038603, "mean_action_processing_ms": 0.09835885570966486, "mean_env_wait_ms": 0.16529270843431232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27900, "timesteps_this_iter": 32, "agent_timesteps_total": 55800, "timers": {"learn_time_ms": 6.159, "learn_throughput": 5195.733, "update_time_ms": 4.074}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 27900, "num_agent_steps_sampled": 55800, "num_steps_trained": 46624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93248, "last_target_update_ts": 27900, "num_target_updates": 238}, "done": false, "episodes_total": 1518, "training_iteration": 253, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-16", "timestamp": 1648815976, "time_this_iter_s": 0.3745865821838379, "time_total_s": 90.80458688735962, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d93b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9cb0>"}, "time_since_restore": 90.80458688735962, "timesteps_since_restore": 8096, "iterations_since_restore": 253, "perf": {"cpu_util_percent": 28.8, "ram_util_percent": 55.3}}
{"episode_reward_max": 28.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.78, "episode_len_mean": 18.39, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 14.0}, "policy_reward_mean": {"policy0": -7.39, "policy1": -7.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 28.0, -20.0, 4.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 14.0, -10.0, 2.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15737480461524064, "mean_inference_ms": 1.4063214547816505, "mean_action_processing_ms": 0.0983466964943134, "mean_env_wait_ms": 0.1652677700819185, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28000, "timesteps_this_iter": 32, "agent_timesteps_total": 56000, "timers": {"learn_time_ms": 6.481, "learn_throughput": 4937.38, "update_time_ms": 4.193}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28000, "num_agent_steps_sampled": 56000, "num_steps_trained": 46784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93568, "last_target_update_ts": 27900, "num_target_updates": 238}, "done": false, "episodes_total": 1523, "training_iteration": 254, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-17", "timestamp": 1648815977, "time_this_iter_s": 0.3152296543121338, "time_total_s": 91.11981654167175, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5193b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c5193b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "time_since_restore": 91.11981654167175, "timesteps_since_restore": 8128, "iterations_since_restore": 254, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.72, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.36, "policy1": -7.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, -20.0, -20.0, 12.0, -20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -10.0, -10.0, 6.0, -10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15735461755309857, "mean_inference_ms": 1.4060777706880327, "mean_action_processing_ms": 0.09833005278517253, "mean_env_wait_ms": 0.16523627621219877, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28111, "timesteps_this_iter": 32, "agent_timesteps_total": 56222, "timers": {"learn_time_ms": 6.57, "learn_throughput": 4870.691, "update_time_ms": 3.883}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28111, "num_agent_steps_sampled": 56222, "num_steps_trained": 46976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93952, "last_target_update_ts": 28020, "num_target_updates": 239}, "done": false, "episodes_total": 1530, "training_iteration": 255, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-17", "timestamp": 1648815977, "time_this_iter_s": 0.35361719131469727, "time_total_s": 91.47343373298645, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9050>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9050>"}, "time_since_restore": 91.47343373298645, "timesteps_since_restore": 8160, "iterations_since_restore": 255, "perf": {"cpu_util_percent": 26.4, "ram_util_percent": 55.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.12, "episode_len_mean": 18.26, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.06, "policy1": -7.06}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 14.0, -20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 7.0, -10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.157337207173759, "mean_inference_ms": 1.4058695737431148, "mean_action_processing_ms": 0.09831547374480626, "mean_env_wait_ms": 0.16520908681450897, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28225, "timesteps_this_iter": 32, "agent_timesteps_total": 56450, "timers": {"learn_time_ms": 6.417, "learn_throughput": 4986.689, "update_time_ms": 3.873}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28225, "num_agent_steps_sampled": 56450, "num_steps_trained": 47168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94336, "last_target_update_ts": 28131, "num_target_updates": 240}, "done": false, "episodes_total": 1536, "training_iteration": 256, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-18", "timestamp": 1648815978, "time_this_iter_s": 0.3580927848815918, "time_total_s": 91.83152651786804, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519440>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519440>"}, "time_since_restore": 91.83152651786804, "timesteps_since_restore": 8192, "iterations_since_restore": 256, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.34, "episode_len_mean": 18.27, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.17, "policy1": -7.17}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, 6.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 17, 20, 8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, 3.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15732083795307486, "mean_inference_ms": 1.405672446982448, "mean_action_processing_ms": 0.09830065241482265, "mean_env_wait_ms": 0.16518347534378008, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28339, "timesteps_this_iter": 32, "agent_timesteps_total": 56678, "timers": {"learn_time_ms": 6.453, "learn_throughput": 4958.942, "update_time_ms": 3.829}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28339, "num_agent_steps_sampled": 56678, "num_steps_trained": 47360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94720, "last_target_update_ts": 28245, "num_target_updates": 241}, "done": false, "episodes_total": 1542, "training_iteration": 257, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-18", "timestamp": 1648815978, "time_this_iter_s": 0.35685157775878906, "time_total_s": 92.18837809562683, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 92.18837809562683, "timesteps_since_restore": 8224, "iterations_since_restore": 257, "perf": {"cpu_util_percent": 26.6, "ram_util_percent": 55.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.8, "episode_len_mean": 18.1, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.9, "policy1": -6.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0], "episode_lengths": [8, 20, 20, 20, 20, 20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16], "policy_policy0_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0], "policy_policy1_reward": [12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15730658624613889, "mean_inference_ms": 1.4054826166629883, "mean_action_processing_ms": 0.09828753495829468, "mean_env_wait_ms": 0.16515965204022276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28439, "timesteps_this_iter": 32, "agent_timesteps_total": 56878, "timers": {"learn_time_ms": 6.186, "learn_throughput": 5173.084, "update_time_ms": 3.856}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28439, "num_agent_steps_sampled": 56878, "num_steps_trained": 47552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95104, "last_target_update_ts": 28359, "num_target_updates": 242}, "done": false, "episodes_total": 1548, "training_iteration": 258, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-18", "timestamp": 1648815978, "time_this_iter_s": 0.327268123626709, "time_total_s": 92.51564621925354, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "time_since_restore": 92.51564621925354, "timesteps_since_restore": 8256, "iterations_since_restore": 258, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.44, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.22, "policy1": -7.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, 26.0, -20.0, 14.0, -20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 7, 20, 13, 20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, 13.0, -10.0, 7.0, -10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1572945463763748, "mean_inference_ms": 1.4053231571783424, "mean_action_processing_ms": 0.09827663264864171, "mean_env_wait_ms": 0.1651404782342684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28539, "timesteps_this_iter": 32, "agent_timesteps_total": 57078, "timers": {"learn_time_ms": 6.313, "learn_throughput": 5069.047, "update_time_ms": 3.975}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28539, "num_agent_steps_sampled": 57078, "num_steps_trained": 47712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95424, "last_target_update_ts": 28479, "num_target_updates": 243}, "done": false, "episodes_total": 1553, "training_iteration": 259, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-19", "timestamp": 1648815979, "time_this_iter_s": 0.3066670894622803, "time_total_s": 92.82231330871582, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9cb0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9cb0>"}, "time_since_restore": 92.82231330871582, "timesteps_since_restore": 8288, "iterations_since_restore": 259, "perf": {"cpu_util_percent": 27.8, "ram_util_percent": 55.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.96, "episode_len_mean": 18.28, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.48, "policy1": -7.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, 10.0, -20.0, -40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 15, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15728017452668477, "mean_inference_ms": 1.405132573647892, "mean_action_processing_ms": 0.09826265214909456, "mean_env_wait_ms": 0.16511580875077186, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28645, "timesteps_this_iter": 32, "agent_timesteps_total": 57290, "timers": {"learn_time_ms": 6.308, "learn_throughput": 5072.783, "update_time_ms": 3.917}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28645, "num_agent_steps_sampled": 57290, "num_steps_trained": 47904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95808, "last_target_update_ts": 28599, "num_target_updates": 244}, "done": false, "episodes_total": 1559, "training_iteration": 260, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-19", "timestamp": 1648815979, "time_this_iter_s": 0.3385345935821533, "time_total_s": 93.16084790229797, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c519320>"}, "time_since_restore": 93.16084790229797, "timesteps_since_restore": 8320, "iterations_since_restore": 260, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.64, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.32, "policy1": -7.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, 26.0, 0.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0], "episode_lengths": [20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, 13.0, 0.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15726110072108754, "mean_inference_ms": 1.4049067137943139, "mean_action_processing_ms": 0.09824513137790623, "mean_env_wait_ms": 0.16508324771696384, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28764, "timesteps_this_iter": 32, "agent_timesteps_total": 57528, "timers": {"learn_time_ms": 6.211, "learn_throughput": 5152.055, "update_time_ms": 3.988}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28764, "num_agent_steps_sampled": 57528, "num_steps_trained": 48128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96256, "last_target_update_ts": 28705, "num_target_updates": 245}, "done": false, "episodes_total": 1566, "training_iteration": 261, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-19", "timestamp": 1648815979, "time_this_iter_s": 0.38494181632995605, "time_total_s": 93.54578971862793, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f0ef0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4f0ef0>"}, "time_since_restore": 93.54578971862793, "timesteps_since_restore": 8352, "iterations_since_restore": 261, "perf": {"cpu_util_percent": 25.8, "ram_util_percent": 55.3}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -15.1, "episode_len_mean": 18.25, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.55, "policy1": -7.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1572468231072, "mean_inference_ms": 1.4047518407501849, "mean_action_processing_ms": 0.09823267152067477, "mean_env_wait_ms": 0.1650600104163419, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28864, "timesteps_this_iter": 32, "agent_timesteps_total": 57728, "timers": {"learn_time_ms": 6.233, "learn_throughput": 5133.591, "update_time_ms": 3.88}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28864, "num_agent_steps_sampled": 57728, "num_steps_trained": 48288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96576, "last_target_update_ts": 28824, "num_target_updates": 246}, "done": false, "episodes_total": 1571, "training_iteration": 262, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-20", "timestamp": 1648815980, "time_this_iter_s": 0.3081092834472656, "time_total_s": 93.8538990020752, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c519320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c518170>"}, "time_since_restore": 93.8538990020752, "timesteps_since_restore": 8384, "iterations_since_restore": 262, "perf": {"cpu_util_percent": 27.8, "ram_util_percent": 55.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.0, "episode_len_mean": 18.1, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.0, "policy1": -7.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1572320300096504, "mean_inference_ms": 1.4045817420440796, "mean_action_processing_ms": 0.09821909929076089, "mean_env_wait_ms": 0.16503536881072228, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28969, "timesteps_this_iter": 32, "agent_timesteps_total": 57938, "timers": {"learn_time_ms": 6.356, "learn_throughput": 5034.348, "update_time_ms": 3.934}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 28969, "num_agent_steps_sampled": 57938, "num_steps_trained": 48480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96960, "last_target_update_ts": 28930, "num_target_updates": 247}, "done": false, "episodes_total": 1577, "training_iteration": 263, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-20", "timestamp": 1648815980, "time_this_iter_s": 0.34587669372558594, "time_total_s": 94.19977569580078, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d59e0>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d59e0>"}, "time_since_restore": 94.19977569580078, "timesteps_since_restore": 8416, "iterations_since_restore": 263, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -13.78, "episode_len_mean": 17.99, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -6.89, "policy1": -6.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -20.0, -20.0, 26.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0], "episode_lengths": [20, 20, 20, 7, 19, 20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, 13.0, 1.0, -10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15721673425876162, "mean_inference_ms": 1.4044021703367284, "mean_action_processing_ms": 0.09820528240748036, "mean_env_wait_ms": 0.16500959129995987, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29078, "timesteps_this_iter": 32, "agent_timesteps_total": 58156, "timers": {"learn_time_ms": 6.474, "learn_throughput": 4942.743, "update_time_ms": 3.895}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29078, "num_agent_steps_sampled": 58156, "num_steps_trained": 48672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97344, "last_target_update_ts": 29049, "num_target_updates": 248}, "done": false, "episodes_total": 1583, "training_iteration": 264, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-21", "timestamp": 1648815981, "time_this_iter_s": 0.34113287925720215, "time_total_s": 94.54090857505798, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5320>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c516c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5320>"}, "time_since_restore": 94.54090857505798, "timesteps_since_restore": 8448, "iterations_since_restore": 264, "perf": {"cpu_util_percent": 26.5, "ram_util_percent": 55.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.46, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.23, "policy1": -7.23}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, 8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, 4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15720369757000455, "mean_inference_ms": 1.4042532551574431, "mean_action_processing_ms": 0.09819362159658311, "mean_env_wait_ms": 0.16498778519286653, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29178, "timesteps_this_iter": 32, "agent_timesteps_total": 58356, "timers": {"learn_time_ms": 6.327, "learn_throughput": 5057.358, "update_time_ms": 3.814}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29178, "num_agent_steps_sampled": 58356, "num_steps_trained": 48832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97664, "last_target_update_ts": 29158, "num_target_updates": 249}, "done": false, "episodes_total": 1588, "training_iteration": 265, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-21", "timestamp": 1648815981, "time_this_iter_s": 0.30900049209594727, "time_total_s": 94.84990906715393, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 94.84990906715393, "timesteps_since_restore": 8480, "iterations_since_restore": 265, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -14.86, "episode_len_mean": 18.13, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -7.43, "policy1": -7.43}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, -20.0, 8.0, -20.0, 20.0, -20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0], "episode_lengths": [16, 20, 16, 20, 10, 20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [4.0, -10.0, 4.0, -10.0, 10.0, -10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1571914347806153, "mean_inference_ms": 1.4041008084623419, "mean_action_processing_ms": 0.09818235495056485, "mean_env_wait_ms": 0.16496628458972623, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29278, "timesteps_this_iter": 32, "agent_timesteps_total": 58556, "timers": {"learn_time_ms": 6.434, "learn_throughput": 4973.864, "update_time_ms": 3.737}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29278, "num_agent_steps_sampled": 58556, "num_steps_trained": 48992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97984, "last_target_update_ts": 29278, "num_target_updates": 250}, "done": false, "episodes_total": 1593, "training_iteration": 266, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-21", "timestamp": 1648815981, "time_this_iter_s": 0.31354308128356934, "time_total_s": 95.1634521484375, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd170>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd170>"}, "time_since_restore": 95.1634521484375, "timesteps_since_restore": 8512, "iterations_since_restore": 266, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 55.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.22, "episode_len_mean": 18.31, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.11, "policy1": -8.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 16.0, -40.0, 4.0, -20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0], "episode_lengths": [20, 20, 12, 20, 18, 20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, 8.0, -20.0, 2.0, -10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15717793333078262, "mean_inference_ms": 1.4039510577443863, "mean_action_processing_ms": 0.09817112260627449, "mean_env_wait_ms": 0.16494493121590661, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29378, "timesteps_this_iter": 32, "agent_timesteps_total": 58756, "timers": {"learn_time_ms": 6.492, "learn_throughput": 4929.383, "update_time_ms": 3.851}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29378, "num_agent_steps_sampled": 58756, "num_steps_trained": 49152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 98304, "last_target_update_ts": 29278, "num_target_updates": 250}, "done": false, "episodes_total": 1598, "training_iteration": 267, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-22", "timestamp": 1648815982, "time_this_iter_s": 0.30556297302246094, "time_total_s": 95.46901512145996, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5b00>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f0e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d5b00>"}, "time_since_restore": 95.46901512145996, "timesteps_since_restore": 8544, "iterations_since_restore": 267, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.62, "episode_len_mean": 18.41, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.31, "policy1": -8.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -40.0, -40.0, -20.0, 22.0, -40.0, -20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 20, 9, 20, 20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, 11.0, -20.0, -10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15716468325875976, "mean_inference_ms": 1.4038035836333362, "mean_action_processing_ms": 0.0981594396960297, "mean_env_wait_ms": 0.16492279468551616, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29478, "timesteps_this_iter": 32, "agent_timesteps_total": 58956, "timers": {"learn_time_ms": 6.329, "learn_throughput": 5055.72, "update_time_ms": 3.915}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29478, "num_agent_steps_sampled": 58956, "num_steps_trained": 49312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 98624, "last_target_update_ts": 29398, "num_target_updates": 251}, "done": false, "episodes_total": 1603, "training_iteration": 268, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-22", "timestamp": 1648815982, "time_this_iter_s": 0.30954432487487793, "time_total_s": 95.77855944633484, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51f320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e200>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c51f320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c52e200>"}, "time_since_restore": 95.77855944633484, "timesteps_since_restore": 8576, "iterations_since_restore": 268, "perf": {"cpu_util_percent": 29.3, "ram_util_percent": 55.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.2, "episode_len_mean": 18.4, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.1, "policy1": -8.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 12.0, -20.0, 24.0, 16.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 14, 20, 8, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 6.0, -10.0, 12.0, 8.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15714839408655082, "mean_inference_ms": 1.4036222500149387, "mean_action_processing_ms": 0.09814462601323483, "mean_env_wait_ms": 0.16489455821470345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29586, "timesteps_this_iter": 32, "agent_timesteps_total": 59172, "timers": {"learn_time_ms": 6.246, "learn_throughput": 5123.577, "update_time_ms": 3.816}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29586, "num_agent_steps_sampled": 59172, "num_steps_trained": 49504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99008, "last_target_update_ts": 29506, "num_target_updates": 252}, "done": false, "episodes_total": 1609, "training_iteration": 269, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-22", "timestamp": 1648815982, "time_this_iter_s": 0.34078288078308105, "time_total_s": 96.11934232711792, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d59e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d59e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c533d40>"}, "time_since_restore": 96.11934232711792, "timesteps_since_restore": 8608, "iterations_since_restore": 269, "perf": {}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -16.9, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 7, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.45, "policy1": -8.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 11, 8, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15712794092889534, "mean_inference_ms": 1.4034131912875367, "mean_action_processing_ms": 0.09812727095633647, "mean_env_wait_ms": 0.16486289935814089, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29705, "timesteps_this_iter": 32, "agent_timesteps_total": 59410, "timers": {"learn_time_ms": 6.229, "learn_throughput": 5137.639, "update_time_ms": 3.779}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29705, "num_agent_steps_sampled": 59410, "num_steps_trained": 49728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99456, "last_target_update_ts": 29626, "num_target_updates": 253}, "done": false, "episodes_total": 1616, "training_iteration": 270, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-23", "timestamp": 1648815983, "time_this_iter_s": 0.3826107978820801, "time_total_s": 96.501953125, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd680>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4bd680>"}, "time_since_restore": 96.501953125, "timesteps_since_restore": 8640, "iterations_since_restore": 270, "perf": {"cpu_util_percent": 27.0, "ram_util_percent": 55.4}}
{"episode_reward_max": 34.0, "episode_reward_min": -40.0, "episode_reward_mean": -17.3, "episode_len_mean": 18.45, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 17.0, "policy1": 17.0}, "policy_reward_mean": {"policy0": -8.65, "policy1": -8.65}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-20.0, -20.0, 0.0, 8.0, -40.0, 34.0, 16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0], "episode_lengths": [20, 20, 20, 16, 20, 3, 12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, 0.0, 4.0, -20.0, 17.0, 8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15711335780245497, "mean_inference_ms": 1.4032731509863015, "mean_action_processing_ms": 0.0981159613447533, "mean_env_wait_ms": 0.16484191257100542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29805, "timesteps_this_iter": 32, "agent_timesteps_total": 59610, "timers": {"learn_time_ms": 6.326, "learn_throughput": 5058.12, "update_time_ms": 3.996}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29805, "num_agent_steps_sampled": 59610, "num_steps_trained": 49888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 99776, "last_target_update_ts": 29745, "num_target_updates": 254}, "done": false, "episodes_total": 1621, "training_iteration": 271, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-23", "timestamp": 1648815983, "time_this_iter_s": 0.3153817653656006, "time_total_s": 96.8173348903656, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9560>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4d5170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4c9560>"}, "time_since_restore": 96.8173348903656, "timesteps_since_restore": 8672, "iterations_since_restore": 271, "perf": {}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.28, "episode_len_mean": 18.64, "episode_media": {}, "episodes_this_iter": 6, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.14, "policy1": -9.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [16.0, -40.0, -40.0, -20.0, 4.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -20.0, -40.0], "episode_lengths": [12, 20, 20, 20, 18, 18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20], "policy_policy0_reward": [8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [8.0, -20.0, -20.0, -10.0, 2.0, 2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.1570952820355158, "mean_inference_ms": 1.4031021459327575, "mean_action_processing_ms": 0.09810256865974651, "mean_env_wait_ms": 0.16481566953232762, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29923, "timesteps_this_iter": 32, "agent_timesteps_total": 59846, "timers": {"learn_time_ms": 6.313, "learn_throughput": 5068.875, "update_time_ms": 3.925}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 29923, "num_agent_steps_sampled": 59846, "num_steps_trained": 50080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100160, "last_target_update_ts": 29863, "num_target_updates": 255}, "done": false, "episodes_total": 1627, "training_iteration": 272, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-23", "timestamp": 1648815983, "time_this_iter_s": 0.36345338821411133, "time_total_s": 97.18078827857971, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d4a70>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4f7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d4a70>"}, "time_since_restore": 97.18078827857971, "timesteps_since_restore": 8704, "iterations_since_restore": 272, "perf": {"cpu_util_percent": 27.7, "ram_util_percent": 55.4}}
{"episode_reward_max": 32.0, "episode_reward_min": -40.0, "episode_reward_mean": -18.88, "episode_len_mean": 18.74, "episode_media": {}, "episodes_this_iter": 5, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 16.0, "policy1": 16.0}, "policy_reward_mean": {"policy0": -9.44, "policy1": -9.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -20.0, 4.0, -20.0, -20.0, -20.0, -20.0, 12.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 32.0, 8.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, 28.0, -20.0, -20.0, -20.0, -20.0, -40.0, 14.0, 28.0, -20.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 28.0, -20.0, -20.0, 2.0, -40.0, -20.0, -20.0, -20.0, 22.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -20.0, -20.0, -40.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -20.0, -20.0, -20.0, -20.0, -40.0, 24.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 18.0, 24.0, -40.0, -40.0, -40.0, -40.0, -20.0, -20.0, -20.0, -40.0, 4.0, -20.0, -20.0, -20.0, -40.0, -40.0, -20.0, -40.0, -20.0, -20.0], "episode_lengths": [18, 20, 18, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 4, 16, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 13, 6, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 19, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 11, 8, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [2.0, -10.0, 2.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 16.0, 4.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, 14.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 14.0, -10.0, -10.0, 1.0, -20.0, -10.0, -10.0, -10.0, 11.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, 9.0, 12.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.15707908812976595, "mean_inference_ms": 1.402959911483317, "mean_action_processing_ms": 0.09809146467871856, "mean_env_wait_ms": 0.1647930029092496, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30023, "timesteps_this_iter": 32, "agent_timesteps_total": 60046, "timers": {"learn_time_ms": 6.274, "learn_throughput": 5100.814, "update_time_ms": 3.748}, "info": {"learner": {"policy1": {"learner_stats": {}}, "policy0": {"learner_stats": {}}}, "num_steps_sampled": 30023, "num_agent_steps_sampled": 60046, "num_steps_trained": 50240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 100480, "last_target_update_ts": 29983, "num_target_updates": 256}, "done": true, "episodes_total": 1632, "training_iteration": 273, "trial_id": "abe87_00000", "experiment_id": "3f2913d09030466cb46ae0deeaf9fb6e", "date": "2022-04-01_05-26-24", "timestamp": 1648815984, "time_this_iter_s": 0.3076918125152588, "time_total_s": 97.48848009109497, "pid": 26901, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "coop", "trainer": "maddpg"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "epsilon_timesteps": 25000, "final_epsilon": 0.0}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d4e60>"}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": null, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": null, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.contrib.maddpg.maddpg_policy.MADDPGTFPolicy'>", "Box([0. 0. 0. 0. 0. 0. 0. 0.], [ 6.  9.  6.  9.  7. 10.  7. 10.], (8,), float32)", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f7c6c4c9c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "lockstep", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": -1, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 0, "collect_metrics_timeout": -1, "agent_id": null, "use_local_critic": false, "use_state_preprocessor": false, "actor_hiddens": [256, 256], "actor_hidden_activation": "tanh", "critic_hiddens": [256, 256], "critic_hidden_activation": "tanh", "n_step": 1, "good_policy": "maddpg", "adv_policy": "maddpg", "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 1000000}, "training_intensity": null, "critic_lr": 0.01, "actor_lr": 0.01, "target_network_update_freq": 100, "tau": 0.01, "actor_feature_reg": 0.001, "grad_norm_clipping": 0.5, "learning_starts": 1000, "before_learn_on_batch": "<function MADDPGTrainer.validate_config.<locals>.f at 0x7f7c6c4d4e60>"}, "time_since_restore": 97.48848009109497, "timesteps_since_restore": 8736, "iterations_since_restore": 273, "perf": {}}
