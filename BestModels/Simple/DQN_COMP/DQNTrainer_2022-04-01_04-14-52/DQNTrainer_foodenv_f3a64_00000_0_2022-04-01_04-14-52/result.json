{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.275862068965516, "episode_len_mean": 17.56896551724138, "episode_media": {}, "episodes_this_iter": 58, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.327586206896552, "policy1": -13.948275862068966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -8.0, 0.0, -30.0, 14.0, -40.0, -40.0, -6.0, -30.0, -30.0, -30.0, 8.0, 8.0, -40.0, -10.0, -40.0, -30.0, -40.0, -8.0, -30.0, -30.0, -2.0, -30.0, -6.0, -30.0, -30.0, -18.0, 4.0, -30.0, -6.0, -30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 10, 20, 3, 20, 20, 13, 20, 20, 20, 6, 6, 20, 15, 20, 20, 20, 14, 20, 20, 11, 20, 13, 20, 20, 19, 8, 20, 13, 20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -3.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -14.0, 0.0, -10.0, 7.0, -20.0, -20.0, -3.0, -20.0, -10.0, -20.0, 14.0, 4.0, -20.0, -15.0, -20.0, -10.0, -20.0, -4.0, -10.0, -10.0, -1.0, -10.0, 7.0, -10.0, -10.0, -9.0, 12.0, -20.0, -13.0, -10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 6.0, 0.0, -20.0, 7.0, -20.0, -20.0, -3.0, -10.0, -20.0, -10.0, -6.0, 4.0, -20.0, 5.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -20.0, -13.0, -20.0, -20.0, -9.0, -8.0, -10.0, 7.0, -20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3382505155077168, "mean_inference_ms": 1.992952589895211, "mean_action_processing_ms": 0.13389119914933745, "mean_env_wait_ms": 0.08011495365816004, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1019, "timesteps_this_iter": 32, "agent_timesteps_total": 2038, "timers": {"load_time_ms": 0.391, "load_throughput": 81790.206, "learn_time_ms": 381.816, "learn_throughput": 83.81, "update_time_ms": 6.48}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": 0.06474529951810837, "min_q": -0.5340701937675476, "max_q": 0.6649793982505798, "mean_td_error": 0.7047158479690552, "model": {}}, "td_error": [1.0407304763793945, 1.7569246292114258, 2.4864189624786377, 2.121119737625122, 2.077812671661377, 0.9304206967353821, 1.3943556547164917, 2.363179922103882, -8.617629051208496, 0.9559100866317749, -7.877291679382324, 1.0501161813735962, 1.309735894203186, 1.74990713596344, 1.6455446481704712, 1.8755619525909424, 1.8323277235031128, 2.121119737625122, 1.7277536392211914, 2.14385724067688, -8.40459156036377, 1.2789502143859863, 1.6617405414581299, 2.086656093597412, 1.847369909286499, 1.3019031286239624, 1.0506703853607178, 1.822333812713623, 1.8114181756973267, 1.280498743057251, 1.4380931854248047, 1.2879873514175415], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -0.2282947450876236, "min_q": -0.9416021704673767, "max_q": 0.28372201323509216, "mean_td_error": 0.6768286228179932, "model": {}}, "td_error": [1.0295138359069824, 0.8170213103294373, 0.416683554649353, 0.42153939604759216, 0.6190270185470581, 0.20554423332214355, 0.7445655465126038, 1.0844581127166748, 0.9018027782440186, -0.15134745836257935, 0.201668381690979, 0.39682766795158386, 0.6972134709358215, 0.6388363838195801, 0.7104793787002563, 0.07440754771232605, 0.6532926559448242, 0.994727373123169, 0.7843175530433655, 0.4632169008255005, 0.14565527439117432, 0.6149972677230835, 1.1373193264007568, 0.6168556809425354, 0.986014723777771, 1.166850209236145, 0.8486711978912354, 0.697024941444397, 0.7396522760391235, 1.030390977859497, 1.4532266855239868, 0.5180611610412598], "custom_metrics": {}}}, "num_steps_sampled": 1019, "num_agent_steps_sampled": 2038, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64, "last_target_update_ts": 1019, "num_target_updates": 1}, "done": false, "episodes_total": 58, "training_iteration": 1, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-09", "timestamp": 1648811709, "time_this_iter_s": 3.5881972312927246, "time_total_s": 3.5881972312927246, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3.5881972312927246, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 39.31666666666667, "ram_util_percent": 64.35000000000001}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.04, "episode_len_mean": 17.786666666666665, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.853333333333333, "policy1": -14.186666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -8.0, 0.0, -30.0, 14.0, -40.0, -40.0, -6.0, -30.0, -30.0, -30.0, 8.0, 8.0, -40.0, -10.0, -40.0, -30.0, -40.0, -8.0, -30.0, -30.0, -2.0, -30.0, -6.0, -30.0, -30.0, -18.0, 4.0, -30.0, -6.0, -30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -16.0, -40.0, -40.0, -30.0, -30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 10, 20, 3, 20, 20, 13, 20, 20, 20, 6, 6, 20, 15, 20, 20, 20, 14, 20, 20, 11, 20, 13, 20, 20, 19, 8, 20, 13, 20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -3.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -14.0, 0.0, -10.0, 7.0, -20.0, -20.0, -3.0, -20.0, -10.0, -20.0, 14.0, 4.0, -20.0, -15.0, -20.0, -10.0, -20.0, -4.0, -10.0, -10.0, -1.0, -10.0, 7.0, -10.0, -10.0, -9.0, 12.0, -20.0, -13.0, -10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, 4.0, -20.0, -8.0, -20.0, -20.0, -20.0, -10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 6.0, 0.0, -20.0, 7.0, -20.0, -20.0, -3.0, -10.0, -20.0, -10.0, -6.0, 4.0, -20.0, 5.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -20.0, -13.0, -20.0, -20.0, -9.0, -8.0, -10.0, 7.0, -20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 4.0, -10.0, -8.0, -20.0, -20.0, -10.0, -20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.33688083440535926, "mean_inference_ms": 1.9804129906230146, "mean_action_processing_ms": 0.13330132360543115, "mean_env_wait_ms": 0.07977320309768052, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1334, "timesteps_this_iter": 32, "agent_timesteps_total": 2668, "timers": {"load_time_ms": 0.429, "load_throughput": 74557.12, "learn_time_ms": 7.613, "learn_throughput": 4203.368, "update_time_ms": 6.683}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -8.51982593536377, "min_q": -12.640963554382324, "max_q": -4.1804327964782715, "mean_td_error": -0.3585882782936096, "model": {}}, "td_error": [-0.5358905792236328, 1.363511085510254, -0.32181644439697266, -1.1407890319824219, -3.1447601318359375, -0.9622087478637695, 2.072627067565918, -1.4281373023986816, 0.34711408615112305, -1.9326410293579102, -0.8493361473083496, -0.6182050704956055, 1.2043142318725586, -1.481367588043213, 1.9379868507385254, -0.6209278106689453, 0.13074588775634766, -0.27648448944091797, 1.7886266708374023, -1.7310047149658203, 0.40453243255615234, -0.4713764190673828, 2.5601959228515625, -2.1804962158203125, -1.307802677154541, -0.3824772834777832, -1.0079007148742676, 2.148649215698242, -7.560665130615234, 0.8971881866455078, -2.048290252685547, 3.6722617149353027], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.809699058532715, "min_q": -13.188980102539062, "max_q": -7.744482517242432, "mean_td_error": -0.06917330622673035, "model": {}}, "td_error": [1.6761126518249512, 0.02028179168701172, 0.6801576614379883, 1.1563835144042969, -0.7634868621826172, 0.798701286315918, 0.2903575897216797, 0.18520641326904297, -0.22775650024414062, -4.04353666305542, -0.09621810913085938, 0.28804779052734375, 0.058014869689941406, -0.13474750518798828, -2.0577220916748047, 0.8307294845581055, 1.0302810668945312, -0.0052661895751953125, -0.21332263946533203, -0.3501119613647461, -0.757624626159668, -1.2678050994873047, -0.3842954635620117, -9.957698822021484, -0.058788299560546875, 1.3819332122802734, 0.8785400390625, 0.6353244781494141, 1.9007387161254883, 1.9683990478515625, 2.3162879943847656, 2.0093374252319336], "custom_metrics": {}}}, "num_steps_sampled": 1334, "num_agent_steps_sampled": 2668, "num_steps_trained": 576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 1152, "last_target_update_ts": 1234, "num_target_updates": 3}, "done": false, "episodes_total": 75, "training_iteration": 2, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-11", "timestamp": 1648811711, "time_this_iter_s": 1.272122859954834, "time_total_s": 4.860320091247559, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020124f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020124f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4.860320091247559, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 37.8, "ram_util_percent": 61.349999999999994}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.9247311827957, "episode_len_mean": 17.78494623655914, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.580645161290322, "policy1": -14.344086021505376}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -8.0, 0.0, -30.0, 14.0, -40.0, -40.0, -6.0, -30.0, -30.0, -30.0, 8.0, 8.0, -40.0, -10.0, -40.0, -30.0, -40.0, -8.0, -30.0, -30.0, -2.0, -30.0, -6.0, -30.0, -30.0, -18.0, 4.0, -30.0, -6.0, -30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -16.0, -40.0, -40.0, -30.0, -30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, -8.0, -12.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 10, 20, 3, 20, 20, 13, 20, 20, 20, 6, 6, 20, 15, 20, 20, 20, 14, 20, 20, 11, 20, 13, 20, 20, 19, 8, 20, 13, 20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 16, 20, 20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -3.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -14.0, 0.0, -10.0, 7.0, -20.0, -20.0, -3.0, -20.0, -10.0, -20.0, 14.0, 4.0, -20.0, -15.0, -20.0, -10.0, -20.0, -4.0, -10.0, -10.0, -1.0, -10.0, 7.0, -10.0, -10.0, -9.0, 12.0, -20.0, -13.0, -10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, 4.0, -20.0, -8.0, -20.0, -20.0, -20.0, -10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, -4.0, 4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 6.0, 0.0, -20.0, 7.0, -20.0, -20.0, -3.0, -10.0, -20.0, -10.0, -6.0, 4.0, -20.0, 5.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -20.0, -13.0, -20.0, -20.0, -9.0, -8.0, -10.0, 7.0, -20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 4.0, -10.0, -8.0, -20.0, -20.0, -10.0, -20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -4.0, -16.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3342624185972441, "mean_inference_ms": 1.9579937743842672, "mean_action_processing_ms": 0.13205168909663176, "mean_env_wait_ms": 0.07917112179069692, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1654, "timesteps_this_iter": 32, "agent_timesteps_total": 3308, "timers": {"load_time_ms": 0.475, "load_throughput": 67320.925, "learn_time_ms": 7.534, "learn_throughput": 4247.464, "update_time_ms": 4.689}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -9.441211700439453, "min_q": -10.437664985656738, "max_q": -7.520127773284912, "mean_td_error": 1.1285344362258911, "model": {}}, "td_error": [2.2294530868530273, 2.1293210983276367, 1.9000635147094727, 1.8596220016479492, 1.238734245300293, 1.6103391647338867, 1.943242073059082, 1.529916763305664, 1.7963132858276367, 2.5837669372558594, 1.7011537551879883, 1.7712593078613281, 1.9978227615356445, 1.2384538650512695, -9.263386726379395, 2.9787216186523438, 1.42132568359375, 2.895479202270508, 1.8915958404541016, 1.1192636489868164, -9.226299285888672, 1.1110081672668457, 1.112410545349121, 2.091008186340332, 1.927067756652832, 1.673874855041504, 2.816070556640625, 0.2589387893676758, 1.1368484497070312, 2.509611129760742, 1.6944818496704102, 2.4356212615966797], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.325594902038574, "min_q": -15.23532485961914, "max_q": -10.89980697631836, "mean_td_error": 1.0588297843933105, "model": {}}, "td_error": [0.6874866485595703, 1.5403118133544922, 1.9858436584472656, 1.5342702865600586, 0.6085748672485352, 0.785675048828125, 1.4096641540527344, 1.191929817199707, 1.2733402252197266, 1.0775175094604492, 1.143794059753418, 0.35671138763427734, 0.8331794738769531, 1.3038253784179688, -0.41190147399902344, 0.37094974517822266, 0.2346048355102539, 1.3578071594238281, 1.434931755065918, 2.059414863586426, 0.7235298156738281, 1.0527887344360352, 1.4655752182006836, 1.0308027267456055, 1.7380609512329102, 1.2166509628295898, 0.7234296798706055, 0.9602203369140625, 0.9472684860229492, 1.737874984741211, 0.4033651351928711, 1.1050539016723633], "custom_metrics": {}}}, "num_steps_sampled": 1654, "num_agent_steps_sampled": 3308, "num_steps_trained": 1152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 2304, "last_target_update_ts": 1570, "num_target_updates": 6}, "done": false, "episodes_total": 93, "training_iteration": 3, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-12", "timestamp": 1648811712, "time_this_iter_s": 1.1810283660888672, "time_total_s": 6.041348457336426, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6.041348457336426, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 58.1}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.62, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -11.01, "policy1": -14.61}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -8.0, 0.0, -30.0, 14.0, -40.0, -40.0, -6.0, -30.0, -30.0, -30.0, 8.0, 8.0, -40.0, -10.0, -40.0, -30.0, -40.0, -8.0, -30.0, -30.0, -2.0, -30.0, -6.0, -30.0, -30.0, -18.0, 4.0, -30.0, -6.0, -30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -16.0, -40.0, -40.0, -30.0, -30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, -8.0, -12.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -20.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 14, 10, 20, 3, 20, 20, 13, 20, 20, 20, 6, 6, 20, 15, 20, 20, 20, 14, 20, 20, 11, 20, 13, 20, 20, 19, 8, 20, 13, 20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 16, 20, 20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -14.0, 0.0, -10.0, 7.0, -20.0, -20.0, -3.0, -20.0, -10.0, -20.0, 14.0, 4.0, -20.0, -15.0, -20.0, -10.0, -20.0, -4.0, -10.0, -10.0, -1.0, -10.0, 7.0, -10.0, -10.0, -9.0, 12.0, -20.0, -13.0, -10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, 4.0, -20.0, -8.0, -20.0, -20.0, -20.0, -10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, -4.0, 4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 6.0, 0.0, -20.0, 7.0, -20.0, -20.0, -3.0, -10.0, -20.0, -10.0, -6.0, 4.0, -20.0, 5.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -20.0, -13.0, -20.0, -20.0, -9.0, -8.0, -10.0, 7.0, -20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 4.0, -10.0, -8.0, -20.0, -20.0, -10.0, -20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -4.0, -16.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3315307367819603, "mean_inference_ms": 1.93416194140565, "mean_action_processing_ms": 0.13077027293038504, "mean_env_wait_ms": 0.07855885410231965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 1954, "timesteps_this_iter": 32, "agent_timesteps_total": 3908, "timers": {"load_time_ms": 0.46, "load_throughput": 69496.053, "learn_time_ms": 7.293, "learn_throughput": 4387.935, "update_time_ms": 4.72}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.593351364135742, "min_q": -12.56407642364502, "max_q": -10.554155349731445, "mean_td_error": -1.0669565200805664, "model": {}}, "td_error": [-0.33745765686035156, -0.24330711364746094, -0.009152412414550781, -0.08797931671142578, -0.13343524932861328, -0.6056642532348633, 0.3088216781616211, -10.766863822937012, -0.11897087097167969, 0.008821487426757812, -0.17874908447265625, -0.49333858489990234, -0.77667236328125, 0.18495845794677734, -10.8562650680542, -0.3478050231933594, -0.1101980209350586, 0.13405895233154297, 0.26854419708251953, -0.18921852111816406, -0.0065288543701171875, -0.006920814514160156, 0.17597293853759766, 0.20006275177001953, -0.062046051025390625, -0.24733924865722656, 0.16756439208984375, 0.16007232666015625, -0.4658470153808594, -0.38027286529541016, -9.280468940734863, -0.04698657989501953], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -19.317081451416016, "min_q": -20.583206176757812, "max_q": -15.140704154968262, "mean_td_error": -2.419281005859375, "model": {}}, "td_error": [-1.4609241485595703, -5.912153244018555, -1.5078468322753906, -1.48077392578125, -11.990942001342773, -1.0920934677124023, -1.4965686798095703, -1.5505599975585938, -1.7188396453857422, -0.7174301147460938, -1.6047077178955078, -18.760332107543945, -0.9425926208496094, -1.1255302429199219, -1.7117195129394531, -2.3287153244018555, -2.2809810638427734, -1.9281625747680664, -1.023956298828125, -1.2911338806152344, -0.8286352157592773, -1.442972183227539, -1.1672868728637695, -1.0518302917480469, -0.5916461944580078, -1.6790390014648438, -1.289297103881836, -1.5260562896728516, -1.5978832244873047, -1.5181236267089844, -1.2944526672363281, -1.503805160522461], "custom_metrics": {}}}, "num_steps_sampled": 1954, "num_agent_steps_sampled": 3908, "num_steps_trained": 1632, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 3264, "last_target_update_ts": 1914, "num_target_updates": 9}, "done": false, "episodes_total": 108, "training_iteration": 4, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-13", "timestamp": 1648811713, "time_this_iter_s": 1.0588529109954834, "time_total_s": 7.100201368331909, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 7.100201368331909, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 30.85, "ram_util_percent": 58.1}}
{"episode_reward_max": 8.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.9, "episode_len_mean": 18.2, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.7, "policy1": -15.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 8.0, -40.0, -10.0, -40.0, -30.0, -40.0, -8.0, -30.0, -30.0, -2.0, -30.0, -6.0, -30.0, -30.0, -18.0, 4.0, -30.0, -6.0, -30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -16.0, -40.0, -40.0, -30.0, -30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, -8.0, -12.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -20.0, -30.0, -30.0, -16.0, -40.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, -30.0, -40.0, -10.0, -30.0], "episode_lengths": [6, 6, 20, 15, 20, 20, 20, 14, 20, 20, 11, 20, 13, 20, 20, 19, 8, 20, 13, 20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 16, 20, 20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 20, 20, 18, 20, 20, 20, 20, 20, 15, 20], "policy_policy0_reward": [14.0, 4.0, -20.0, -15.0, -20.0, -10.0, -20.0, -4.0, -10.0, -10.0, -1.0, -10.0, 7.0, -10.0, -10.0, -9.0, 12.0, -20.0, -13.0, -10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, 4.0, -20.0, -8.0, -20.0, -20.0, -20.0, -10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, -4.0, 4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -8.0, -20.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -8.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -10.0], "policy_policy1_reward": [-6.0, 4.0, -20.0, 5.0, -20.0, -20.0, -20.0, -4.0, -20.0, -20.0, -1.0, -20.0, -13.0, -20.0, -20.0, -9.0, -8.0, -10.0, 7.0, -20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 4.0, -10.0, -8.0, -20.0, -20.0, -10.0, -20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -4.0, -16.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, -10.0, -8.0, -20.0, -10.0, -20.0, -20.0, -20.0, -15.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32694391570855075, "mean_inference_ms": 1.895742822237524, "mean_action_processing_ms": 0.12865441139755643, "mean_env_wait_ms": 0.077576296192445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2293, "timesteps_this_iter": 32, "agent_timesteps_total": 4586, "timers": {"load_time_ms": 0.428, "load_throughput": 74698.201, "learn_time_ms": 7.215, "learn_throughput": 4435.439, "update_time_ms": 4.597}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -10.963822364807129, "min_q": -11.6363525390625, "max_q": -10.15982437133789, "mean_td_error": -0.08980560302734375, "model": {}}, "td_error": [0.5406904220581055, 0.9146738052368164, 0.21853065490722656, 0.6409769058227539, 0.46574974060058594, 0.43923473358154297, 0.1808176040649414, -9.21114444732666, 0.627772331237793, 0.90106201171875, 1.001424789428711, 0.3951387405395508, 0.25275135040283203, 1.1246623992919922, 0.9234724044799805, 0.2391376495361328, 1.109349250793457, 0.7209739685058594, 0.46880340576171875, 0.5987739562988281, 0.6247224807739258, 0.4632396697998047, 0.47049903869628906, 0.47393035888671875, 0.43327903747558594, 0.5818386077880859, 0.506688117980957, 0.37157726287841797, -10.593518257141113, 0.6644792556762695, 0.2806406021118164, 0.2959928512573242], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -19.21686553955078, "min_q": -20.575441360473633, "max_q": -17.077133178710938, "mean_td_error": -2.938371419906616, "model": {}}, "td_error": [-1.0671672821044922, -0.4349479675292969, -0.6152439117431641, 0.20132827758789062, -0.7689838409423828, -0.9239425659179688, -0.0044040679931640625, -0.6896839141845703, -19.20987319946289, -18.45582389831543, -18.29339599609375, -0.48592185974121094, -0.4258003234863281, -1.6409797668457031, -0.1895294189453125, -18.712221145629883, -0.5378856658935547, -1.2253532409667969, -0.8330249786376953, -0.5114841461181641, -0.9662933349609375, -0.6092777252197266, -1.2474918365478516, -0.29752349853515625, -0.8799648284912109, -1.1724929809570312, -0.6223030090332031, -1.14239501953125, -0.4543037414550781, -0.2960643768310547, -0.4635143280029297, -1.0519237518310547], "custom_metrics": {}}}, "num_steps_sampled": 2293, "num_agent_steps_sampled": 4586, "num_steps_trained": 2208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 4416, "last_target_update_ts": 2258, "num_target_updates": 12}, "done": false, "episodes_total": 126, "training_iteration": 5, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-14", "timestamp": 1648811714, "time_this_iter_s": 1.2147252559661865, "time_total_s": 8.314926624298096, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8704f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8704f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.314926624298096, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 58.150000000000006}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.8, "episode_len_mean": 18.3, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -11.1, "policy1": -15.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 6.0, -30.0, -8.0, -40.0, -30.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -16.0, -40.0, -40.0, -30.0, -30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, -8.0, -12.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -20.0, -30.0, -30.0, -16.0, -40.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, -30.0, -40.0, -10.0, -30.0, 10.0, 2.0, -2.0, -30.0, -30.0, -40.0, -40.0, -30.0, 12.0, -40.0, -30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 7, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 6, 20, 18, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 16, 20, 20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 20, 20, 18, 20, 20, 20, 20, 20, 15, 20, 5, 9, 11, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 3.0, -10.0, 6.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, 4.0, -20.0, -8.0, -20.0, -20.0, -20.0, -10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, -4.0, 4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -8.0, -20.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -8.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -10.0, 5.0, 1.0, -11.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, 3.0, -20.0, -14.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 4.0, -10.0, -8.0, -20.0, -20.0, -10.0, -20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -4.0, -16.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, -10.0, -8.0, -20.0, -10.0, -20.0, -20.0, -20.0, -15.0, -20.0, 5.0, 1.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.32184299062330884, "mean_inference_ms": 1.8522550148399455, "mean_action_processing_ms": 0.12615124786391635, "mean_env_wait_ms": 0.07651685214444205, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2608, "timesteps_this_iter": 32, "agent_timesteps_total": 5216, "timers": {"load_time_ms": 0.434, "load_throughput": 73721.701, "learn_time_ms": 7.348, "learn_throughput": 4355.004, "update_time_ms": 4.922}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -11.952216148376465, "min_q": -12.53102970123291, "max_q": -10.824976921081543, "mean_td_error": 0.15570113062858582, "model": {}}, "td_error": [1.1191015243530273, 1.0873136520385742, 0.6142587661743164, 0.8652582168579102, 0.9700965881347656, 0.7548952102661133, 0.7548952102661133, 0.8159418106079102, 0.7146711349487305, 0.5946483612060547, -9.064878463745117, 1.031336784362793, 0.9700965881347656, 0.7486820220947266, 0.5764188766479492, 1.0455150604248047, -9.274691581726074, 0.22556304931640625, 0.996312141418457, 0.9158535003662109, 0.6725358963012695, 0.9119606018066406, 0.6392793655395508, 0.49342823028564453, 0.8069877624511719, 1.0486478805541992, 0.5643110275268555, 0.894622802734375, 0.5048923492431641, 0.7782316207885742, 0.5399541854858398, 0.6662960052490234], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -20.851694107055664, "min_q": -22.508487701416016, "max_q": -16.189739227294922, "mean_td_error": 0.64900141954422, "model": {}}, "td_error": [0.9597949981689453, 0.45792579650878906, -0.3435554504394531, 0.6316471099853516, -0.319580078125, 0.7462120056152344, 0.7419471740722656, 0.8687305450439453, 0.9696121215820312, 0.6059589385986328, 0.6949043273925781, 0.2746601104736328, 0.6944904327392578, 0.1997356414794922, 0.5642871856689453, 1.0054206848144531, 0.7364864349365234, 0.8053913116455078, 0.42272186279296875, 0.5239009857177734, 0.7917919158935547, 0.7496681213378906, 1.4078407287597656, 0.9849987030029297, 0.7086086273193359, 0.2161579132080078, -0.15982818603515625, 0.8542423248291016, 1.021728515625, 0.8536205291748047, 0.6796875, 1.4188365936279297], "custom_metrics": {}}}, "num_steps_sampled": 2608, "num_agent_steps_sampled": 5216, "num_steps_trained": 2816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 5632, "last_target_update_ts": 2588, "num_target_updates": 15}, "done": false, "episodes_total": 145, "training_iteration": 6, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-16", "timestamp": 1648811716, "time_this_iter_s": 1.34916090965271, "time_total_s": 9.664087533950806, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020124e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020124e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 9.664087533950806, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 58.2}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.88, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -10.44, "policy1": -15.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -2.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -20.0, -30.0, -30.0, -30.0, -40.0, -8.0, -12.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -20.0, -30.0, -30.0, -16.0, -40.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, -30.0, -40.0, -10.0, -30.0, 10.0, 2.0, -2.0, -30.0, -30.0, -40.0, -40.0, -30.0, 12.0, -40.0, -30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -16.0, -40.0, -30.0, 2.0, -30.0, -8.0, -30.0, -30.0, -30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0], "episode_lengths": [20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 14, 16, 20, 20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 20, 20, 18, 20, 20, 20, 20, 20, 15, 20, 5, 9, 11, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 14, 20, 20, 20, 10, 20, 10, 5, 20, 20, 13, 20], "policy_policy0_reward": [-10.0, -1.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, 0.0, -10.0, -20.0, -10.0, -20.0, -4.0, 4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -8.0, -20.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -8.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -10.0, 5.0, 1.0, -11.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 1.0, -10.0, -4.0, -10.0, -10.0, -10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0], "policy_policy1_reward": [-20.0, -1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -4.0, -16.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, -10.0, -8.0, -20.0, -10.0, -20.0, -20.0, -20.0, -15.0, -20.0, 5.0, 1.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 1.0, -20.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31680265240272804, "mean_inference_ms": 1.8084207659913902, "mean_action_processing_ms": 0.12357429826754572, "mean_env_wait_ms": 0.07543536801581965, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 2927, "timesteps_this_iter": 32, "agent_timesteps_total": 5854, "timers": {"load_time_ms": 0.459, "load_throughput": 69665.591, "learn_time_ms": 7.407, "learn_throughput": 4320.1, "update_time_ms": 4.608}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.138327598571777, "min_q": -14.187443733215332, "max_q": -11.643865585327148, "mean_td_error": -1.3511165380477905, "model": {}}, "td_error": [-8.977344512939453, 0.09174537658691406, -0.24846363067626953, -12.949599266052246, 0.3392477035522461, 0.1856698989868164, -0.3846015930175781, -0.22066974639892578, 0.17222023010253906, -0.128082275390625, 0.3885154724121094, -0.07890605926513672, -0.12199974060058594, 0.2680482864379883, 0.13158321380615234, -12.181946754455566, -0.1146554946899414, -0.11742019653320312, 0.26267337799072266, -0.46137332916259766, -0.1608428955078125, -0.24846363067626953, -0.6762104034423828, -0.011201858520507812, 0.13324451446533203, -8.865735054016113, 0.12034797668457031, 0.4104423522949219, -0.24863338470458984, -0.09743309020996094, 0.3633079528808594, 0.19080543518066406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -23.68520164489746, "min_q": -24.619888305664062, "max_q": -19.834434509277344, "mean_td_error": -2.0422654151916504, "model": {}}, "td_error": [-0.4696922302246094, -0.3954734802246094, -19.51149559020996, -0.33811378479003906, -0.9345951080322266, -0.6196212768554688, -0.5497226715087891, -1.2109184265136719, -0.57623291015625, -0.5991611480712891, -0.6872787475585938, -0.22687530517578125, -0.8799037933349609, -0.9422264099121094, -0.2539806365966797, -1.0013370513916016, -0.8910388946533203, -0.3015270233154297, -23.30947494506836, -1.0185375213623047, -0.9985179901123047, -1.3968086242675781, -0.878570556640625, -0.6780757904052734, -1.0562915802001953, -0.6866168975830078, -0.4575080871582031, -0.8598136901855469, -0.7279052734375, -1.3327808380126953, -0.9164924621582031, -0.6459026336669922], "custom_metrics": {}}}, "num_steps_sampled": 2927, "num_agent_steps_sampled": 5854, "num_steps_trained": 3424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6848, "last_target_update_ts": 2927, "num_target_updates": 18}, "done": false, "episodes_total": 164, "training_iteration": 7, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-17", "timestamp": 1648811717, "time_this_iter_s": 1.212594747543335, "time_total_s": 10.87668228149414, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 10.87668228149414, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 29.75, "ram_util_percent": 58.25}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.74, "episode_len_mean": 17.92, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -10.22, "policy1": -15.52}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -30.0, -30.0, 8.0, -30.0, 0.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -20.0, -30.0, -30.0, -16.0, -40.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, -30.0, -40.0, -10.0, -30.0, 10.0, 2.0, -2.0, -30.0, -30.0, -40.0, -40.0, -30.0, 12.0, -40.0, -30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -16.0, -40.0, -30.0, 2.0, -30.0, -8.0, -30.0, -30.0, -30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0, 8.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 6, 20, 10, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 20, 20, 18, 20, 20, 20, 20, 20, 15, 20, 5, 9, 11, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 14, 20, 20, 20, 10, 20, 10, 5, 20, 20, 13, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, 14.0, -10.0, 0.0, -4.0, -10.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -8.0, -20.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -8.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -10.0, 5.0, 1.0, -11.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 1.0, -10.0, -4.0, -10.0, -10.0, -10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0, 14.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -6.0, -20.0, 0.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, -10.0, -8.0, -20.0, -10.0, -20.0, -20.0, -20.0, -15.0, -20.0, 5.0, 1.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 1.0, -20.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0, -6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31314190478575976, "mean_inference_ms": 1.7770232685993212, "mean_action_processing_ms": 0.12167182096186764, "mean_env_wait_ms": 0.07472359932138692, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3256, "timesteps_this_iter": 32, "agent_timesteps_total": 6512, "timers": {"load_time_ms": 0.459, "load_throughput": 69680.058, "learn_time_ms": 7.512, "learn_throughput": 4259.717, "update_time_ms": 4.66}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -13.736648559570312, "min_q": -14.35919189453125, "max_q": -12.651775360107422, "mean_td_error": -1.3798694610595703, "model": {}}, "td_error": [0.0561676025390625, -0.019280433654785156, -0.1564931869506836, -0.9461002349853516, -1.052083969116211, 0.20105361938476562, 0.3903846740722656, -1.0657987594604492, 0.32779788970947266, -0.028090476989746094, 1.0567197799682617, 0.1311960220336914, -0.00963592529296875, -0.09970664978027344, 0.7172279357910156, -9.548968315124512, -0.10904407501220703, 0.7574043273925781, 0.1821308135986328, 0.8447847366333008, 0.9506807327270508, -9.535223960876465, 0.1311960220336914, 0.10262393951416016, -13.086981773376465, 0.18421649932861328, -2.0319929122924805, 0.0229949951171875, -13.303074836730957, 0.09488773345947266, 0.09427356719970703, 0.590911865234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -24.323408126831055, "min_q": -25.554365158081055, "max_q": -20.65949058532715, "mean_td_error": -1.8806490898132324, "model": {}}, "td_error": [0.38332557678222656, 1.8714237213134766, 0.6321601867675781, 0.5401649475097656, 1.2685127258300781, 0.5746955871582031, 1.2493515014648438, 1.3122997283935547, 1.6055240631103516, 0.9044685363769531, 1.3686790466308594, -20.032793045043945, 1.4705791473388672, 1.3362617492675781, 1.3398323059082031, -24.135019302368164, 1.6397972106933594, -19.775798797607422, 1.1661643981933594, 0.5894241333007812, -23.642040252685547, 0.7836494445800781, 0.4786872863769531, 0.45383453369140625, -0.0002689361572265625, 0.8131732940673828, 0.7645034790039062, 1.3090038299560547, 1.2747001647949219, 0.2969226837158203, 0.5234184265136719, 1.4545955657958984], "custom_metrics": {}}}, "num_steps_sampled": 3256, "num_agent_steps_sampled": 6512, "num_steps_trained": 4000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 8000, "last_target_update_ts": 3256, "num_target_updates": 21}, "done": false, "episodes_total": 182, "training_iteration": 8, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-18", "timestamp": 1648811718, "time_this_iter_s": 1.241063117980957, "time_total_s": 12.117745399475098, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 12.117745399475098, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 58.3}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.76, "episode_len_mean": 17.53, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -10.13, "policy1": -14.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -20.0, -30.0, -30.0, -16.0, -40.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, -30.0, -40.0, -10.0, -30.0, 10.0, 2.0, -2.0, -30.0, -30.0, -40.0, -40.0, -30.0, 12.0, -40.0, -30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -16.0, -40.0, -30.0, 2.0, -30.0, -8.0, -30.0, -30.0, -30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0, 8.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -2.0, -30.0, -30.0, -40.0, 4.0, -18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 18, 20, 20, 20, 20, 20, 8, 20, 20, 20, 18, 20, 20, 20, 20, 20, 15, 20, 5, 9, 11, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 14, 20, 20, 20, 10, 20, 10, 5, 20, 20, 13, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 8, 19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -8.0, -20.0, -10.0, -10.0, -10.0, -20.0, 12.0, -10.0, -10.0, -20.0, -8.0, -10.0, -20.0, -10.0, -10.0, -20.0, 5.0, -10.0, 5.0, 1.0, -11.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 1.0, -10.0, -4.0, -10.0, -10.0, -10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0, 14.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -1.0, -10.0, -10.0, -20.0, 12.0, -19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, -20.0, -10.0, -8.0, -20.0, -10.0, -20.0, -20.0, -20.0, -15.0, -20.0, 5.0, 1.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 1.0, -20.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0, -6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, -8.0, 1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.31066338650349, "mean_inference_ms": 1.7546047272854448, "mean_action_processing_ms": 0.12034064252963501, "mean_env_wait_ms": 0.07428209566813487, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3587, "timesteps_this_iter": 32, "agent_timesteps_total": 7174, "timers": {"load_time_ms": 0.444, "load_throughput": 72074.819, "learn_time_ms": 7.571, "learn_throughput": 4226.571, "update_time_ms": 4.764}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -14.05045223236084, "min_q": -14.929969787597656, "max_q": -10.752155303955078, "mean_td_error": -1.113201379776001, "model": {}}, "td_error": [0.6009807586669922, -0.14417171478271484, -0.3193674087524414, -13.883956909179688, 0.2622537612915039, 0.5733718872070312, 0.5391998291015625, 0.6161565780639648, 0.7944364547729492, 0.6095285415649414, -13.006314277648926, 1.493962287902832, 0.27025699615478516, 0.7958316802978516, 0.567774772644043, -6.012564659118652, 0.5063867568969727, -13.40040397644043, 0.6426715850830078, 0.9394216537475586, 0.4523601531982422, 0.38936614990234375, -0.16448688507080078, 1.0686759948730469, 0.567774772644043, 0.43515682220458984, 0.6749391555786133, -0.15845298767089844, 0.8656702041625977, 0.5107316970825195, -3.5149049758911133, 0.8052711486816406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -27.148639678955078, "min_q": -27.922414779663086, "max_q": -24.387916564941406, "mean_td_error": -0.8472228050231934, "model": {}}, "td_error": [1.2324848175048828, 1.6093292236328125, 1.6787796020507812, 1.2193660736083984, 1.067953109741211, 0.9715805053710938, -26.12757682800293, -26.734647750854492, 1.2357349395751953, 1.5797977447509766, 1.2667083740234375, 1.7335681915283203, 1.5374946594238281, 1.0777816772460938, 1.6873188018798828, 1.3556652069091797, 1.9101066589355469, -12.135696411132812, 1.3092231750488281, 1.1993350982666016, 0.8341712951660156, 1.493051528930664, 1.5011959075927734, 0.88995361328125, 1.3208580017089844, 1.6892757415771484, 0.7581653594970703, 0.9379062652587891, 1.4212074279785156, 1.2360763549804688, 1.2501029968261719, 0.882598876953125], "custom_metrics": {}}}, "num_steps_sampled": 3587, "num_agent_steps_sampled": 7174, "num_steps_trained": 4640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 9280, "last_target_update_ts": 3587, "num_target_updates": 24}, "done": false, "episodes_total": 202, "training_iteration": 9, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-20", "timestamp": 1648811720, "time_this_iter_s": 1.3240866661071777, "time_total_s": 13.441832065582275, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020126a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 13.441832065582275, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 32.349999999999994, "ram_util_percent": 58.3}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.24, "episode_len_mean": 17.37, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -9.67, "policy1": -14.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -40.0, -10.0, -30.0, 10.0, 2.0, -2.0, -30.0, -30.0, -40.0, -40.0, -30.0, 12.0, -40.0, -30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -16.0, -40.0, -30.0, 2.0, -30.0, -8.0, -30.0, -30.0, -30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0, 8.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -2.0, -30.0, -30.0, -40.0, 4.0, -18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 15, 20, 5, 9, 11, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 14, 20, 20, 20, 10, 20, 10, 5, 20, 20, 13, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 8, 19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -20.0, 5.0, -10.0, 5.0, 1.0, -11.0, -10.0, -10.0, -20.0, -20.0, -10.0, 6.0, -20.0, -10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 1.0, -10.0, -4.0, -10.0, -10.0, -10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0, 14.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -1.0, -10.0, -10.0, -20.0, 12.0, -19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -15.0, -20.0, 5.0, 1.0, 9.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 1.0, -20.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0, -6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, -8.0, 1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30931797589241206, "mean_inference_ms": 1.7418326520064285, "mean_action_processing_ms": 0.11948489538430394, "mean_env_wait_ms": 0.07403760458412079, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 3915, "timesteps_this_iter": 32, "agent_timesteps_total": 7830, "timers": {"load_time_ms": 0.43, "load_throughput": 74441.336, "learn_time_ms": 7.844, "learn_throughput": 4079.492, "update_time_ms": 4.712}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -15.26637077331543, "min_q": -16.97015953063965, "max_q": -7.777599334716797, "mean_td_error": -0.06331312656402588, "model": {}}, "td_error": [1.3578014373779297, 0.44939613342285156, 0.4143810272216797, 0.5985050201416016, 0.1995105743408203, -4.723553657531738, 0.44110679626464844, 0.01125335693359375, 0.2763099670410156, 0.17108440399169922, 1.2573623657226562, 0.4281597137451172, 1.7544078826904297, 0.3039436340332031, 1.2847509384155273, -14.34310245513916, 1.9346332550048828, 0.44060707092285156, 1.6240234375, 1.1190605163574219, 0.5087337493896484, 0.7909622192382812, 0.9764194488525391, -0.2902350425720215, 0.9636831283569336, 1.4307079315185547, 1.3805742263793945, -4.044145584106445, 0.5247249603271484, 1.0222845077514648, 0.39019298553466797, -0.6795654296875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -29.44297218322754, "min_q": -30.8150691986084, "max_q": -26.82979965209961, "mean_td_error": -0.02535015344619751, "model": {}}, "td_error": [0.44991493225097656, 0.8143463134765625, 1.0226726531982422, 1.4483509063720703, 1.4963512420654297, 0.6337394714355469, 0.2685890197753906, 0.5863914489746094, 0.8565177917480469, 1.1898918151855469, 0.9783515930175781, 1.3263168334960938, 1.4254264831542969, 0.4992256164550781, 0.6887092590332031, 0.9335536956787109, 0.1862945556640625, 1.2072811126708984, 1.3117408752441406, 1.1700115203857422, 1.0971012115478516, 1.0769386291503906, 0.8998737335205078, 1.7108726501464844, 0.15192604064941406, 1.329092025756836, 1.303323745727539, -0.11161231994628906, -29.384803771972656, 1.225198745727539, 1.0779304504394531, 0.3192768096923828], "custom_metrics": {}}}, "num_steps_sampled": 3915, "num_agent_steps_sampled": 7830, "num_steps_trained": 5216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 10432, "last_target_update_ts": 3815, "num_target_updates": 26}, "done": false, "episodes_total": 220, "training_iteration": 10, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-21", "timestamp": 1648811721, "time_this_iter_s": 1.2327139377593994, "time_total_s": 14.674546003341675, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 14.674546003341675, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 29.85, "ram_util_percent": 58.3}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.76, "episode_len_mean": 17.88, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.28, "policy1": -15.48}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, 8.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -16.0, -40.0, -30.0, 2.0, -30.0, -8.0, -30.0, -30.0, -30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0, 8.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -2.0, -30.0, -30.0, -40.0, 4.0, -18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 9, 20, 14, 20, 20, 20, 10, 20, 10, 5, 20, 20, 13, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 8, 19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, 14.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -10.0, 1.0, -10.0, -4.0, -10.0, -10.0, -10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0, 14.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -1.0, -10.0, -10.0, -20.0, 12.0, -19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 1.0, -20.0, -4.0, -20.0, -20.0, -20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0, -6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, -8.0, 1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3083355420376661, "mean_inference_ms": 1.7326228004086182, "mean_action_processing_ms": 0.11887064854969802, "mean_env_wait_ms": 0.07384193422214766, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4230, "timesteps_this_iter": 32, "agent_timesteps_total": 8460, "timers": {"load_time_ms": 0.423, "load_throughput": 75730.818, "learn_time_ms": 7.502, "learn_throughput": 4265.525, "update_time_ms": 4.643}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -17.361412048339844, "min_q": -18.696195602416992, "max_q": -15.368496894836426, "mean_td_error": -2.8791723251342773, "model": {}}, "td_error": [0.008417129516601562, -1.3105106353759766, -1.7992706298828125, -0.8070030212402344, -10.041157722473145, 0.5698089599609375, -17.56468963623047, -0.9801349639892578, -0.6557159423828125, -3.253129005432129, -16.424091339111328, -0.6737346649169922, -10.593023300170898, -9.617471694946289, -0.83685302734375, -0.13067245483398438, -0.7254104614257812, -1.2928314208984375, -0.4901161193847656, -10.209789276123047, -0.1673717498779297, 0.0067615509033203125, -0.27443885803222656, -0.9011249542236328, -0.8614234924316406, -0.45635986328125, -0.4822731018066406, -0.11873817443847656, -0.38100433349609375, -0.4758014678955078, -0.5999870300292969, -0.5943756103515625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -33.77965545654297, "min_q": -35.56350326538086, "max_q": -20.797636032104492, "mean_td_error": -2.086925983428955, "model": {}}, "td_error": [-0.6396713256835938, -0.8146629333496094, -0.76568603515625, -0.4266014099121094, -0.37850189208984375, -1.0684318542480469, 0.026941299438476562, -0.6151084899902344, -0.2759819030761719, -0.22135543823242188, -0.16996383666992188, -0.230743408203125, 0.04032325744628906, -0.4264678955078125, 0.06766128540039062, -0.40775299072265625, -0.4683990478515625, -0.7402267456054688, -0.5118827819824219, -0.2020893096923828, -0.7943840026855469, -0.211029052734375, -0.6014900207519531, -0.7281455993652344, -0.8689613342285156, -33.998573303222656, -0.19559860229492188, -1.3888664245605469, -0.91473388671875, 1.3329200744628906, -0.3865318298339844, -19.797636032104492], "custom_metrics": {}}}, "num_steps_sampled": 4230, "num_agent_steps_sampled": 8460, "num_steps_trained": 5728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 11456, "last_target_update_ts": 4170, "num_target_updates": 29}, "done": false, "episodes_total": 236, "training_iteration": 11, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-22", "timestamp": 1648811722, "time_this_iter_s": 1.129084825515747, "time_total_s": 15.803630828857422, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 15.803630828857422, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 30.85, "ram_util_percent": 58.4}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -24.98, "episode_len_mean": 17.64, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -9.84, "policy1": -15.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 0.0, -40.0, 0.0, 10.0, -30.0, -40.0, -6.0, -30.0, 8.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -2.0, -30.0, -30.0, -40.0, 4.0, -18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, 0.0, -30.0, -18.0, -40.0, -40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0], "episode_lengths": [20, 10, 20, 10, 5, 20, 20, 13, 20, 6, 20, 20, 20, 20, 20, 20, 20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 8, 19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 19, 20, 20, 4, 20, 13, 6, 15, 20, 20, 16], "policy_policy0_reward": [-10.0, 10.0, -20.0, 0.0, 5.0, -10.0, -20.0, -13.0, -10.0, 14.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -1.0, -10.0, -10.0, -20.0, 12.0, -19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, 1.0, -20.0, -20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 0.0, 5.0, -20.0, -20.0, 7.0, -20.0, -6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, -8.0, 1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -19.0, -20.0, -20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30747331168626385, "mean_inference_ms": 1.7246803822661634, "mean_action_processing_ms": 0.1183777434613158, "mean_env_wait_ms": 0.07366252585194319, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4553, "timesteps_this_iter": 32, "agent_timesteps_total": 9106, "timers": {"load_time_ms": 0.485, "load_throughput": 65980.596, "learn_time_ms": 8.388, "learn_throughput": 3815.095, "update_time_ms": 5.399}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -19.378677368164062, "min_q": -20.23640251159668, "max_q": -18.560791015625, "mean_td_error": -1.9123406410217285, "model": {}}, "td_error": [0.052600860595703125, -0.08352851867675781, -9.094402313232422, -0.28100013732910156, 0.08383369445800781, -0.36403656005859375, -0.3369312286376953, -0.2901172637939453, -0.15938186645507812, -0.31983375549316406, 0.06297111511230469, -0.2410602569580078, -28.66282081604004, -0.1988983154296875, -9.735668182373047, -0.22183799743652344, -0.16522789001464844, -0.21617507934570312, 0.4947624206542969, -0.19696807861328125, 0.32120323181152344, -0.03588676452636719, -0.03295326232910156, -0.09452438354492188, -9.803365707397461, -0.1988983154296875, -0.1338787078857422, -0.4726123809814453, -0.23093032836914062, -0.21274566650390625, -0.3302783966064453, -0.09631538391113281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -35.03015899658203, "min_q": -38.407310485839844, "max_q": -30.536754608154297, "mean_td_error": -2.5280404090881348, "model": {}}, "td_error": [0.7574501037597656, 1.124765396118164, 0.33605194091796875, 0.7689132690429688, 1.2936744689941406, 1.0313339233398438, 0.9866561889648438, 0.348419189453125, 0.6853141784667969, 1.5885772705078125, -2.7582855224609375, -29.536754608154297, 1.0713653564453125, 1.0372123718261719, 1.0713653564453125, 3.4560089111328125, 1.5229568481445312, 0.343505859375, 0.8483524322509766, 1.3415145874023438, 1.0021820068359375, 0.8371543884277344, -37.407310485839844, 1.3126907348632812, -41.029579162597656, 1.5974102020263672, 0.8580131530761719, 0.7779693603515625, 0.9004859924316406, 1.2822990417480469, 1.184377670288086, 0.4686164855957031], "custom_metrics": {}}}, "num_steps_sampled": 4553, "num_agent_steps_sampled": 9106, "num_steps_trained": 6336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12672, "last_target_update_ts": 4517, "num_target_updates": 32}, "done": false, "episodes_total": 255, "training_iteration": 12, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-23", "timestamp": 1648811723, "time_this_iter_s": 1.3107647895812988, "time_total_s": 17.11439561843872, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 17.11439561843872, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 31.85, "ram_util_percent": 58.4}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.48, "episode_len_mean": 18.04, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.64, "policy1": -15.84}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -16.0, -30.0, -40.0, 10.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -2.0, -30.0, -30.0, -40.0, 4.0, -18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, 0.0, -30.0, -18.0, -40.0, -40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0, -12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 18, 20, 20, 5, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 8, 19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 19, 20, 20, 4, 20, 13, 6, 15, 20, 20, 16, 16, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 2.0, -10.0, -20.0, 5.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -1.0, -10.0, -10.0, -20.0, 12.0, -19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, 1.0, -20.0, -20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0, -6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -18.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -1.0, -20.0, -20.0, -20.0, -8.0, 1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -19.0, -20.0, -20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30679835288036217, "mean_inference_ms": 1.718871516976239, "mean_action_processing_ms": 0.11798848307819357, "mean_env_wait_ms": 0.07351906377299279, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 4857, "timesteps_this_iter": 32, "agent_timesteps_total": 9714, "timers": {"load_time_ms": 0.438, "load_throughput": 73039.687, "learn_time_ms": 7.539, "learn_throughput": 4244.616, "update_time_ms": 5.243}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -20.42661476135254, "min_q": -21.27653694152832, "max_q": -19.757307052612305, "mean_td_error": -0.18339353799819946, "model": {}}, "td_error": [0.47633934020996094, 0.5171546936035156, 0.8294200897216797, 0.45226287841796875, 0.3620128631591797, 0.6459503173828125, 0.20916366577148438, 0.6738071441650391, -9.13902473449707, 0.45067405700683594, 0.5507946014404297, -0.3902759552001953, -0.075592041015625, 0.8623065948486328, 0.042263031005859375, 0.45067405700683594, 0.6808128356933594, 0.5579967498779297, -0.2490386962890625, 0.47281455993652344, 0.5470447540283203, 0.08895111083984375, -0.07829856872558594, 0.4361248016357422, 0.6019287109375, 0.8942909240722656, -0.11138343811035156, 0.9875907897949219, -8.933361053466797, 0.45067405700683594, 0.7100067138671875, 0.15732192993164062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -36.35572052001953, "min_q": -38.34718322753906, "max_q": -33.21708297729492, "mean_td_error": -5.850898742675781, "model": {}}, "td_error": [-0.8306007385253906, -0.19126510620117188, 0.7142372131347656, -0.5479774475097656, -0.294708251953125, 0.24053573608398438, -0.13625335693359375, -33.483341217041016, 0.1305084228515625, 0.01544952392578125, -37.343284606933594, -0.3869438171386719, -0.42345428466796875, -3.2464218139648438, -0.08523178100585938, -2.881805419921875, -0.4487152099609375, -37.22739028930664, 0.6217308044433594, -0.28963470458984375, -36.73164749145508, -32.657283782958984, 0.046661376953125, 0.5102195739746094, 0.055095672607421875, -0.10954666137695312, -0.329864501953125, -0.18083572387695312, -0.7325096130371094, -0.271484375, -0.4842185974121094, -0.24877548217773438], "custom_metrics": {}}}, "num_steps_sampled": 4857, "num_agent_steps_sampled": 9714, "num_steps_trained": 6848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 13696, "last_target_update_ts": 4857, "num_target_updates": 35}, "done": false, "episodes_total": 271, "training_iteration": 13, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-25", "timestamp": 1648811725, "time_this_iter_s": 1.1190643310546875, "time_total_s": 18.233459949493408, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 18.233459949493408, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 29.8, "ram_util_percent": 58.4}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.24, "episode_len_mean": 18.12, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -11.32, "policy1": -14.92}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-18.0, -30.0, -40.0, -30.0, -40.0, 8.0, -30.0, -20.0, -30.0, -4.0, 8.0, 2.0, -40.0, -40.0, -20.0, -30.0, -30.0, -30.0, -30.0, -30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, 0.0, -30.0, -18.0, -40.0, -40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0, -12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -12.0, -30.0, -30.0, -30.0, 0.0, -30.0, 0.0, -40.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [19, 20, 20, 20, 20, 6, 20, 20, 20, 12, 6, 9, 20, 20, 20, 20, 20, 20, 20, 20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 19, 20, 20, 4, 20, 13, 6, 15, 20, 20, 16, 16, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 10, 20, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-19.0, -10.0, -20.0, -10.0, -20.0, 14.0, -20.0, -20.0, -10.0, -2.0, 4.0, 1.0, -20.0, -20.0, 0.0, -10.0, -10.0, -10.0, -10.0, -10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, 1.0, -20.0, -20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0, -6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -20.0, -4.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [1.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, 0.0, -20.0, -2.0, 4.0, 1.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -19.0, -20.0, -20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -6.0, -20.0, -10.0, -20.0, 0.0, -20.0, 10.0, -20.0, -4.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30610995821830644, "mean_inference_ms": 1.7129793305713235, "mean_action_processing_ms": 0.11758762313191383, "mean_env_wait_ms": 0.07334089101710883, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5167, "timesteps_this_iter": 32, "agent_timesteps_total": 10334, "timers": {"load_time_ms": 0.438, "load_throughput": 73003.931, "learn_time_ms": 7.741, "learn_throughput": 4133.821, "update_time_ms": 4.745}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -22.543594360351562, "min_q": -23.85529136657715, "max_q": -20.046672821044922, "mean_td_error": 0.5138038396835327, "model": {}}, "td_error": [1.6831207275390625, 1.1959724426269531, 1.4504222869873047, 1.5045661926269531, 0.34725189208984375, 1.2939071655273438, 1.1959724426269531, 1.5703067779541016, 0.5483436584472656, 0.34012794494628906, 1.2976703643798828, 1.7379589080810547, 1.3514842987060547, 1.70343017578125, -21.515541076660156, 2.230531692504883, 1.3764533996582031, 1.5967178344726562, 1.0482826232910156, 0.7670345306396484, 2.617950439453125, 1.533823013305664, 0.49393653869628906, 0.2475147247314453, 1.7742061614990234, 1.1328277587890625, 1.4841594696044922, 0.4260234832763672, 0.2525672912597656, 1.1975135803222656, 1.4718799591064453, 1.085306167602539], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -38.70151138305664, "min_q": -39.958648681640625, "max_q": -35.335025787353516, "mean_td_error": -0.16133570671081543, "model": {}}, "td_error": [-0.00569915771484375, -0.001567840576171875, -0.728790283203125, -0.1684722900390625, -0.019550323486328125, 0.090118408203125, 0.5945014953613281, 0.16055679321289062, -0.0341949462890625, -0.03000640869140625, -0.3018646240234375, -0.0158538818359375, -0.4034080505371094, -0.09636688232421875, -0.23366928100585938, -0.020053863525390625, -0.14251327514648438, -0.07632064819335938, -0.12762069702148438, -0.2105255126953125, -0.38182830810546875, -0.26981353759765625, 0.14578628540039062, -0.12061691284179688, -0.025691986083984375, -0.40969085693359375, -1.1240081787109375, -0.5757331848144531, -0.3921012878417969, 0.08417510986328125, 0.07946395874023438, -0.4013824462890625], "custom_metrics": {}}}, "num_steps_sampled": 5167, "num_agent_steps_sampled": 10334, "num_steps_trained": 7392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 14784, "last_target_update_ts": 5067, "num_target_updates": 37}, "done": false, "episodes_total": 288, "training_iteration": 14, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-26", "timestamp": 1648811726, "time_this_iter_s": 1.1616740226745605, "time_total_s": 19.39513397216797, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010add0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010add0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 19.39513397216797, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 29.45, "ram_util_percent": 58.5}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.42, "episode_len_mean": 18.11, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -12.11, "policy1": -14.31}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 4.0, -30.0, -6.0, -30.0, -10.0, -40.0, -4.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, 0.0, -30.0, -18.0, -40.0, -40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0, -12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -12.0, -30.0, -30.0, -30.0, 0.0, -30.0, 0.0, -40.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -12.0, -40.0, 10.0, 8.0, -30.0, -40.0, 0.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 8, 20, 13, 20, 15, 20, 12, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 19, 20, 20, 4, 20, 13, 6, 15, 20, 20, 16, 16, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 10, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 20, 5, 6, 20, 20, 10, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, 12.0, -10.0, -13.0, -10.0, -5.0, -20.0, 8.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, 1.0, -20.0, -20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0, -6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -20.0, -4.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, 5.0, 4.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -8.0, -20.0, 7.0, -20.0, -5.0, -20.0, -12.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -19.0, -20.0, -20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -6.0, -20.0, -10.0, -20.0, 0.0, -20.0, 10.0, -20.0, -4.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -6.0, -20.0, 5.0, 4.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.305307353965393, "mean_inference_ms": 1.7066920220650292, "mean_action_processing_ms": 0.11711017185870742, "mean_env_wait_ms": 0.07310721307872203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5498, "timesteps_this_iter": 32, "agent_timesteps_total": 10996, "timers": {"load_time_ms": 0.431, "load_throughput": 74260.113, "learn_time_ms": 7.682, "learn_throughput": 4165.73, "update_time_ms": 4.787}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -25.36679458618164, "min_q": -26.608016967773438, "max_q": -24.400650024414062, "mean_td_error": -0.6194554567337036, "model": {}}, "td_error": [1.2937183380126953, 1.1435909271240234, -23.56553077697754, 0.8293952941894531, 0.3928050994873047, 0.5535430908203125, 0.7357120513916016, 1.158987045288086, 0.6201019287109375, 0.9122543334960938, 0.7165679931640625, 0.6201019287109375, 0.8808059692382812, 0.58367919921875, 1.4886627197265625, 1.6402759552001953, 0.6748237609863281, 1.0614395141601562, 1.0523853302001953, 1.338388442993164, -23.888874053955078, 1.2618179321289062, 1.1584587097167969, 0.5089855194091797, 0.8211174011230469, 0.7722911834716797, 0.39933204650878906, 0.8049373626708984, 1.7282428741455078, 1.1145782470703125, 0.47756004333496094, 0.8872699737548828], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -38.84788513183594, "min_q": -40.631168365478516, "max_q": -34.755409240722656, "mean_td_error": -2.139754295349121, "model": {}}, "td_error": [0.6298637390136719, 0.36234283447265625, 0.39117431640625, 0.8243980407714844, -9.431900024414062, 0.13673019409179688, 0.4318199157714844, 0.13844680786132812, 0.1134033203125, 0.3106880187988281, 0.264801025390625, 0.3404884338378906, 0.5232505798339844, 0.2926063537597656, -34.97145080566406, 0.4458122253417969, 0.31285858154296875, 0.6676101684570312, 0.2885704040527344, -0.06823348999023438, 0.4894599914550781, 0.30843353271484375, 0.5669174194335938, 0.48278045654296875, 0.3986320495605469, 0.1330718994140625, 1.1767692565917969, 0.32614898681640625, -35.24887466430664, 0.1883697509765625, 0.24571609497070312, 0.4571533203125], "custom_metrics": {}}}, "num_steps_sampled": 5498, "num_agent_steps_sampled": 10996, "num_steps_trained": 8000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 16000, "last_target_update_ts": 5398, "num_target_updates": 40}, "done": false, "episodes_total": 307, "training_iteration": 15, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-27", "timestamp": 1648811727, "time_this_iter_s": 1.2721467018127441, "time_total_s": 20.667280673980713, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 20.667280673980713, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 31.05, "ram_util_percent": 58.55}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.28, "episode_len_mean": 17.64, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -12.14, "policy1": -13.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -30.0, -10.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, 0.0, -30.0, -18.0, -40.0, -40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0, -12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -12.0, -30.0, -30.0, -30.0, 0.0, -30.0, 0.0, -40.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -12.0, -40.0, 10.0, 8.0, -30.0, -40.0, 0.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -10.0, -40.0, -30.0, -30.0, 0.0, -30.0, -6.0, -40.0, -30.0, 8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0], "episode_lengths": [20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 10, 20, 19, 20, 20, 4, 20, 13, 6, 15, 20, 20, 16, 16, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 10, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 20, 5, 6, 20, 20, 10, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 10, 20, 13, 20, 20, 6, 3, 20, 20, 8, 20, 6, 20], "policy_policy0_reward": [-20.0, -10.0, -10.0, -10.0, -5.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 10.0, -10.0, 1.0, -20.0, -20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0, -6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -20.0, -4.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, 5.0, 4.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, 0.0, -20.0, -3.0, -20.0, -20.0, 4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -19.0, -20.0, -20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -6.0, -20.0, -10.0, -20.0, 0.0, -20.0, 10.0, -20.0, -4.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -6.0, -20.0, 5.0, 4.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -10.0, -10.0, 0.0, -10.0, -3.0, -20.0, -10.0, 4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30502373057188614, "mean_inference_ms": 1.7037909217690514, "mean_action_processing_ms": 0.11693393082403102, "mean_env_wait_ms": 0.0729980719246114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 5819, "timesteps_this_iter": 32, "agent_timesteps_total": 11638, "timers": {"load_time_ms": 0.448, "load_throughput": 71498.896, "learn_time_ms": 7.663, "learn_throughput": 4176.164, "update_time_ms": 4.698}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -27.268779754638672, "min_q": -29.12432289123535, "max_q": -26.50482177734375, "mean_td_error": -3.65682053565979, "model": {}}, "td_error": [-0.46852684020996094, 0.6028900146484375, 1.0092525482177734, 1.3080425262451172, 0.6925773620605469, 0.6423664093017578, 1.2643280029296875, -9.361604690551758, 0.7787055969238281, 0.8639316558837891, 1.0469493865966797, 1.2065143585205078, 0.0569915771484375, -7.669212341308594, -26.398353576660156, 0.9752559661865234, 0.5837650299072266, -28.12432289123535, 0.588104248046875, -9.781978607177734, 0.9325046539306641, -26.335853576660156, 0.7640438079833984, 0.3342018127441406, -0.17673301696777344, 0.3375720977783203, 0.6900844573974609, 0.6553688049316406, 0.8883991241455078, 0.4469013214111328, -25.970300674438477, 0.5998878479003906], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -41.39258575439453, "min_q": -42.568119049072266, "max_q": -37.310333251953125, "mean_td_error": -2.0884830951690674, "model": {}}, "td_error": [-0.4000663757324219, -1.218902587890625, -0.4601936340332031, -0.6397438049316406, -0.6397438049316406, -0.9729728698730469, 0.6182708740234375, -0.4519844055175781, -0.39829254150390625, 1.1306381225585938, -0.6414909362792969, -0.3913917541503906, -0.5583076477050781, -0.3451080322265625, -1.4325408935546875, -0.3528480529785156, -1.084075927734375, -0.6679840087890625, -0.78167724609375, -0.17982101440429688, -9.811912536621094, -0.44789886474609375, -0.664398193359375, -0.5425987243652344, -0.6838264465332031, -0.7201881408691406, -0.9005279541015625, -41.116615295410156, -0.6071434020996094, -0.1285858154296875, -0.6715431213378906, -0.6679840087890625], "custom_metrics": {}}}, "num_steps_sampled": 5819, "num_agent_steps_sampled": 11638, "num_steps_trained": 8608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 17216, "last_target_update_ts": 5745, "num_target_updates": 43}, "done": false, "episodes_total": 327, "training_iteration": 16, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-29", "timestamp": 1648811729, "time_this_iter_s": 1.3519117832183838, "time_total_s": 22.019192457199097, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 22.019192457199097, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 31.05, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.86, "episode_len_mean": 17.33, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -12.03, "policy1": -11.83}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, 12.0, -30.0, -6.0, 8.0, -10.0, -30.0, -30.0, -12.0, -12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -12.0, -30.0, -30.0, -30.0, 0.0, -30.0, 0.0, -40.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -12.0, -40.0, 10.0, 8.0, -30.0, -40.0, 0.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -10.0, -40.0, -30.0, -30.0, 0.0, -30.0, -6.0, -40.0, -30.0, 8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -4.0, -8.0, -16.0, 12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 4, 20, 13, 6, 15, 20, 20, 16, 16, 20, 20, 20, 20, 8, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 10, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 20, 5, 6, 20, 20, 10, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 10, 20, 13, 20, 20, 6, 3, 20, 20, 8, 20, 6, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 14, 18, 4, 20, 20, 20, 11, 20, 20, 20], "policy_policy0_reward": [-20.0, 6.0, -10.0, -3.0, 14.0, 5.0, -10.0, -10.0, -6.0, -6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -20.0, -4.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, 5.0, 4.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, 0.0, -20.0, -3.0, -20.0, -20.0, 4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0, -4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -4.0, -8.0, 6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, 6.0, -20.0, -3.0, -6.0, -15.0, -20.0, -20.0, -6.0, -6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -6.0, -20.0, -10.0, -20.0, 0.0, -20.0, 10.0, -20.0, -4.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -6.0, -20.0, 5.0, 4.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -10.0, -10.0, 0.0, -10.0, -3.0, -20.0, -10.0, 4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0, -4.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -2.0, -4.0, -8.0, 6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30493729033628375, "mean_inference_ms": 1.7027756389218425, "mean_action_processing_ms": 0.11690747546549782, "mean_env_wait_ms": 0.0729711728011767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6152, "timesteps_this_iter": 32, "agent_timesteps_total": 12304, "timers": {"load_time_ms": 0.428, "load_throughput": 74768.942, "learn_time_ms": 7.851, "learn_throughput": 4076.023, "update_time_ms": 4.944}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -31.165847778320312, "min_q": -31.5831356048584, "max_q": -30.70460319519043, "mean_td_error": -2.0245516300201416, "model": {}}, "td_error": [-0.7787570953369141, 0.12002754211425781, -0.4085578918457031, -0.8574695587158203, -0.1621837615966797, 0.350799560546875, -0.2456188201904297, -0.019796371459960938, -30.1517276763916, 0.30258750915527344, -0.03577613830566406, -0.39630889892578125, -0.031198501586914062, 0.24856185913085938, 0.022207260131835938, 0.12255477905273438, -0.17123794555664062, -0.42047119140625, -0.1277790069580078, -0.2890510559082031, -0.18740463256835938, 0.18641281127929688, -0.04224205017089844, -29.910799026489258, -0.42136573791503906, -0.16910934448242188, 0.10281562805175781, -0.7975845336914062, -0.1045379638671875, -0.5412082672119141, -0.06531906127929688, 0.09388542175292969], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -43.91793441772461, "min_q": -47.89607620239258, "max_q": -38.07552719116211, "mean_td_error": -2.2886579036712646, "model": {}}, "td_error": [-0.18508148193359375, -0.9514122009277344, -1.4510154724121094, -0.8335304260253906, -1.2178421020507812, -1.3501701354980469, -0.9508438110351562, -0.524444580078125, -0.5628128051757812, -0.5018882751464844, -0.7090110778808594, -0.6054000854492188, -0.9662322998046875, -0.8909873962402344, -1.0278129577636719, -48.708953857421875, -1.1190452575683594, -1.055145263671875, -0.4648628234863281, -0.5628128051757812, -0.14997482299804688, -0.7339248657226562, 0.3982353210449219, -0.8104248046875, -0.8319892883300781, -0.6871261596679688, -0.9983596801757812, -1.2090492248535156, -1.1451416015625, -0.9122657775878906, -0.7779083251953125, -0.7398185729980469], "custom_metrics": {}}}, "num_steps_sampled": 6152, "num_agent_steps_sampled": 12304, "num_steps_trained": 9216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18432, "last_target_update_ts": 6081, "num_target_updates": 46}, "done": false, "episodes_total": 346, "training_iteration": 17, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-30", "timestamp": 1648811730, "time_this_iter_s": 1.3418045043945312, "time_total_s": 23.360996961593628, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 23.360996961593628, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 30.450000000000003, "ram_util_percent": 58.6}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.62, "episode_len_mean": 17.31, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -12.51, "policy1": -11.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -12.0, -30.0, -30.0, -30.0, 0.0, -30.0, 0.0, -40.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -12.0, -40.0, 10.0, 8.0, -30.0, -40.0, 0.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -10.0, -40.0, -30.0, -30.0, 0.0, -30.0, -6.0, -40.0, -30.0, 8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -4.0, -8.0, -16.0, 12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0, 10.0, 12.0, -30.0, -10.0, -30.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 20, 10, 20, 10, 20, 14, 20, 20, 20, 20, 20, 20, 20, 16, 20, 5, 6, 20, 20, 10, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 10, 20, 13, 20, 20, 6, 3, 20, 20, 8, 20, 6, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 14, 18, 4, 20, 20, 20, 11, 20, 20, 20, 5, 4, 20, 15, 20, 20, 20, 20, 20, 7, 20, 15, 20, 20, 10, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -6.0, -10.0, -20.0, -10.0, 0.0, -10.0, -10.0, -20.0, -4.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -6.0, -20.0, 5.0, 4.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, 0.0, -20.0, -3.0, -20.0, -20.0, 4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0, -4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -4.0, -8.0, 6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -5.0, -10.0, -20.0, -20.0, -20.0, -20.0, 3.0, -10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -6.0, -20.0, -10.0, -20.0, 0.0, -20.0, 10.0, -20.0, -4.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -6.0, -20.0, 5.0, 4.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -10.0, -10.0, 0.0, -10.0, -3.0, -20.0, -10.0, 4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0, -4.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -2.0, -4.0, -8.0, 6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0, 5.0, 6.0, -20.0, -5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30508672653422275, "mean_inference_ms": 1.7030958957922482, "mean_action_processing_ms": 0.11699965206287154, "mean_env_wait_ms": 0.07300731058701554, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6468, "timesteps_this_iter": 32, "agent_timesteps_total": 12936, "timers": {"load_time_ms": 0.469, "load_throughput": 68161.966, "learn_time_ms": 7.82, "learn_throughput": 4092.091, "update_time_ms": 4.799}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -34.14488983154297, "min_q": -34.660240173339844, "max_q": -33.52769088745117, "mean_td_error": -1.7171967029571533, "model": {}}, "td_error": [-1.1513214111328125, -0.5814132690429688, -0.7398147583007812, -0.042812347412109375, -0.6551780700683594, -0.48871612548828125, -0.2876434326171875, -0.5332870483398438, -1.0038337707519531, -0.6284713745117188, -0.7730674743652344, -1.0038337707519531, -0.25305938720703125, -0.3717536926269531, -33.13297653198242, -0.7510490417480469, -0.6968498229980469, -0.7414360046386719, -1.0750312805175781, -0.8141365051269531, -1.3313713073730469, -0.6527099609375, -0.5525474548339844, -0.9403343200683594, -0.8547630310058594, -0.6802101135253906, -0.2790069580078125, -0.6335716247558594, -1.0971794128417969, -0.5564918518066406, -0.4689216613769531, -1.1775016784667969], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -45.46515655517578, "min_q": -49.705726623535156, "max_q": -39.28450393676758, "mean_td_error": -3.0806803703308105, "model": {}}, "td_error": [-0.7634658813476562, 0.3405914306640625, -1.0494956970214844, -48.036949157714844, -0.06843948364257812, -1.0512237548828125, -1.8158798217773438, -0.06287765502929688, -39.38786315917969, 0.057430267333984375, 0.3286590576171875, 0.8762016296386719, -0.6683502197265625, -0.4466285705566406, -0.598419189453125, -0.03112030029296875, 0.3749504089355469, -0.09488296508789062, 0.07631683349609375, -1.6955833435058594, -0.42700958251953125, 0.20763778686523438, -1.0512237548828125, -0.12496566772460938, -0.9858551025390625, -0.8664932250976562, -0.2668418884277344, -0.8554267883300781, -1.0465011596679688, -0.08936691284179688, -1.0701446533203125, 1.7114524841308594], "custom_metrics": {}}}, "num_steps_sampled": 6468, "num_agent_steps_sampled": 12936, "num_steps_trained": 9824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 19648, "last_target_update_ts": 6408, "num_target_updates": 49}, "done": false, "episodes_total": 365, "training_iteration": 18, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-31", "timestamp": 1648811731, "time_this_iter_s": 1.3101603984832764, "time_total_s": 24.671157360076904, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 24.671157360076904, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 31.65, "ram_util_percent": 58.650000000000006}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.84, "episode_len_mean": 16.72, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 10.0}, "policy_reward_mean": {"policy0": -11.82, "policy1": -10.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -12.0, -40.0, 10.0, 8.0, -30.0, -40.0, 0.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -10.0, -40.0, -30.0, -30.0, 0.0, -30.0, -6.0, -40.0, -30.0, 8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -4.0, -8.0, -16.0, 12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0, 10.0, 12.0, -30.0, -10.0, -30.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -2.0, -4.0, -30.0, -30.0, -2.0, 4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0], "episode_lengths": [20, 20, 16, 20, 5, 6, 20, 20, 10, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 10, 20, 13, 20, 20, 6, 3, 20, 20, 8, 20, 6, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 14, 18, 4, 20, 20, 20, 11, 20, 20, 20, 5, 4, 20, 15, 20, 20, 20, 20, 20, 7, 20, 15, 20, 20, 10, 20, 20, 20, 20, 7, 20, 20, 11, 12, 20, 20, 11, 8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -6.0, -20.0, 5.0, 4.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, 0.0, -20.0, -3.0, -20.0, -20.0, 4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0, -4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -4.0, -8.0, 6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -5.0, -10.0, -20.0, -20.0, -20.0, -20.0, 3.0, -10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0, 3.0, -20.0, -20.0, -1.0, -12.0, -10.0, -20.0, -1.0, 2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0], "policy_policy1_reward": [-10.0, -10.0, -6.0, -20.0, 5.0, 4.0, -10.0, -20.0, 10.0, -10.0, -10.0, -10.0, -10.0, 6.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -10.0, -10.0, 0.0, -10.0, -3.0, -20.0, -10.0, 4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0, -4.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -2.0, -4.0, -8.0, 6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0, 5.0, 6.0, -20.0, -5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -1.0, 8.0, -20.0, -10.0, -1.0, 2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3054787016808981, "mean_inference_ms": 1.704901569800908, "mean_action_processing_ms": 0.11717254865221928, "mean_env_wait_ms": 0.07310211800062925, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 6799, "timesteps_this_iter": 32, "agent_timesteps_total": 13598, "timers": {"load_time_ms": 0.447, "load_throughput": 71548.445, "learn_time_ms": 7.827, "learn_throughput": 4088.564, "update_time_ms": 5.034}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -36.36309814453125, "min_q": -37.02524185180664, "max_q": -35.30793762207031, "mean_td_error": -2.5804555416107178, "model": {}}, "td_error": [-0.111236572265625, -0.5400886535644531, 0.38048553466796875, 0.39666748046875, 0.24942398071289062, -0.12961196899414062, -0.3407859802246094, -0.1884307861328125, 0.10164642333984375, 0.21698379516601562, -0.5404472351074219, -0.5437202453613281, 0.13698196411132812, -0.3875007629394531, 0.3604621887207031, -0.3213462829589844, -34.82188034057617, 0.3326911926269531, -0.07429122924804688, -0.5185279846191406, 0.03522491455078125, 0.16021347045898438, -10.542991638183594, -0.13846969604492188, -0.2631492614746094, 0.034881591796875, 0.029994964599609375, 0.26194000244140625, -0.5821380615234375, -0.18795394897460938, -35.241336822509766, 0.20173263549804688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -45.79728698730469, "min_q": -48.50951385498047, "max_q": -40.47690200805664, "mean_td_error": -2.30707049369812, "model": {}}, "td_error": [0.5489044189453125, -46.851226806640625, 1.0889167785644531, 1.5861167907714844, 1.28643798828125, 1.3823394775390625, 1.2139129638671875, 2.0492401123046875, 1.4087905883789062, 1.3056983947753906, -3.4678916931152344, 0.7102470397949219, 0.9619216918945312, 1.3649749755859375, 1.3546104431152344, 1.7344741821289062, 0.4510536193847656, 0.9364013671875, 0.3949127197265625, 1.3908119201660156, 0.7076072692871094, 0.9469337463378906, -39.47690200805664, 1.3446540832519531, 1.0974655151367188, 0.8665885925292969, 0.5603065490722656, 1.4178428649902344, 1.0594558715820312, -14.529243469238281, 0.5574874877929688, 0.7709007263183594], "custom_metrics": {}}}, "num_steps_sampled": 6799, "num_agent_steps_sampled": 13598, "num_steps_trained": 10496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 20992, "last_target_update_ts": 6729, "num_target_updates": 52}, "done": false, "episodes_total": 386, "training_iteration": 19, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-33", "timestamp": 1648811733, "time_this_iter_s": 1.3737313747406006, "time_total_s": 26.044888734817505, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010a8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 26.044888734817505, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 58.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -22.26, "episode_len_mean": 16.78, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 8.0}, "policy_reward_mean": {"policy0": -11.28, "policy1": -10.98}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -10.0, -40.0, -30.0, -30.0, 0.0, -30.0, -6.0, -40.0, -30.0, 8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -4.0, -8.0, -16.0, 12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0, 10.0, 12.0, -30.0, -10.0, -30.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -2.0, -4.0, -30.0, -30.0, -2.0, 4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0, -30.0, 10.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 10, 20, 13, 20, 20, 6, 3, 20, 20, 8, 20, 6, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 14, 18, 4, 20, 20, 20, 11, 20, 20, 20, 5, 4, 20, 15, 20, 20, 20, 20, 20, 7, 20, 15, 20, 20, 10, 20, 20, 20, 20, 7, 20, 20, 11, 12, 20, 20, 11, 8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20, 20, 5, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -5.0, -20.0, -20.0, -20.0, 0.0, -20.0, -3.0, -20.0, -20.0, 4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0, -4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -4.0, -8.0, 6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -5.0, -10.0, -20.0, -20.0, -20.0, -20.0, 3.0, -10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0, 3.0, -20.0, -20.0, -1.0, -12.0, -10.0, -20.0, -1.0, 2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -5.0, -20.0, -10.0, -10.0, 0.0, -10.0, -3.0, -20.0, -10.0, 4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0, -4.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -2.0, -4.0, -8.0, 6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0, 5.0, 6.0, -20.0, -5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -1.0, 8.0, -20.0, -10.0, -1.0, 2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3060162311229495, "mean_inference_ms": 1.7077907442813751, "mean_action_processing_ms": 0.1174303521490158, "mean_env_wait_ms": 0.07325675292975871, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7116, "timesteps_this_iter": 32, "agent_timesteps_total": 14232, "timers": {"load_time_ms": 0.421, "load_throughput": 76026.809, "learn_time_ms": 7.883, "learn_throughput": 4059.589, "update_time_ms": 5.224}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -38.14035415649414, "min_q": -38.44124984741211, "max_q": -37.68973922729492, "mean_td_error": -2.562995672225952, "model": {}}, "td_error": [-0.24517822265625, -0.3451995849609375, -37.385643005371094, 0.045337677001953125, -0.3456993103027344, -0.280059814453125, -0.24517822265625, -0.08550643920898438, -0.3683357238769531, -0.38201904296875, -0.2449798583984375, -0.3548583984375, -0.21230697631835938, -0.21263885498046875, 0.020488739013671875, -0.2402801513671875, -37.408878326416016, -0.19900894165039062, -0.24517822265625, -0.26436614990234375, -0.37151336669921875, -0.32340240478515625, 0.3270606994628906, -0.3452033996582031, -0.09650039672851562, -0.3830986022949219, -0.25601959228515625, -0.3829460144042969, -0.48616790771484375, -0.25601959228515625, -0.24058914184570312, -0.20197296142578125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.48305130004883, "min_q": -52.22319030761719, "max_q": -41.3572883605957, "mean_td_error": -3.2823848724365234, "model": {}}, "td_error": [-1.7342338562011719, -3.3467559814453125, -1.6696815490722656, -1.9951095581054688, -1.6505775451660156, -1.5651741027832031, -0.9829216003417969, -1.75653076171875, -1.7598457336425781, -0.9031639099121094, -1.9361305236816406, -1.3074150085449219, -1.1537513732910156, -1.4003219604492188, -1.6335945129394531, -1.4852104187011719, -2.1652145385742188, -46.74643325805664, -1.1050910949707031, -1.8130607604980469, -1.6699981689453125, -1.9649200439453125, -6.935905456542969, -3.1553001403808594, -1.6787490844726562, -2.7374191284179688, 0.3668708801269531, -1.6674346923828125, -1.2279930114746094, -2.5929641723632812, -1.8985137939453125, -1.7637786865234375], "custom_metrics": {}}}, "num_steps_sampled": 7116, "num_agent_steps_sampled": 14232, "num_steps_trained": 11072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 22144, "last_target_update_ts": 7076, "num_target_updates": 55}, "done": false, "episodes_total": 404, "training_iteration": 20, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-34", "timestamp": 1648811734, "time_this_iter_s": 1.293731451034546, "time_total_s": 27.33862018585205, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 27.33862018585205, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 32.0, "ram_util_percent": 58.7}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -19.64, "episode_len_mean": 16.12, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 12.0, "policy1": 8.0}, "policy_reward_mean": {"policy0": -9.42, "policy1": -10.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [8.0, 14.0, -30.0, -30.0, 4.0, -30.0, 8.0, -30.0, -8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -4.0, -8.0, -16.0, 12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0, 10.0, 12.0, -30.0, -10.0, -30.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -2.0, -4.0, -30.0, -30.0, -2.0, 4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0, -30.0, 10.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -4.0, -30.0, -16.0, -10.0, 2.0, -12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0], "episode_lengths": [6, 3, 20, 20, 8, 20, 6, 20, 14, 20, 20, 20, 20, 20, 20, 20, 12, 14, 18, 4, 20, 20, 20, 11, 20, 20, 20, 5, 4, 20, 15, 20, 20, 20, 20, 20, 7, 20, 15, 20, 20, 10, 20, 20, 20, 20, 7, 20, 20, 11, 12, 20, 20, 11, 8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20, 20, 5, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 15, 9, 16, 20, 7, 20, 16, 4, 14, 7, 14], "policy_policy0_reward": [4.0, 7.0, -20.0, -20.0, 12.0, -10.0, 4.0, -20.0, -4.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -4.0, -8.0, 6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -5.0, -10.0, -20.0, -20.0, -20.0, -20.0, 3.0, -10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0, 3.0, -20.0, -20.0, -1.0, -12.0, -10.0, -20.0, -1.0, 2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -10.0, -8.0, -15.0, 1.0, -6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0], "policy_policy1_reward": [4.0, 7.0, -10.0, -10.0, -8.0, -20.0, 4.0, -10.0, -4.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -2.0, -4.0, -8.0, 6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0, 5.0, 6.0, -20.0, -5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -1.0, 8.0, -20.0, -10.0, -1.0, 2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -2.0, -20.0, -8.0, 5.0, 1.0, -6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30642217050406156, "mean_inference_ms": 1.7100040946116914, "mean_action_processing_ms": 0.11761394808868454, "mean_env_wait_ms": 0.07336780407186785, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7328, "timesteps_this_iter": 32, "agent_timesteps_total": 14656, "timers": {"load_time_ms": 0.458, "load_throughput": 69828.692, "learn_time_ms": 8.054, "learn_throughput": 3973.102, "update_time_ms": 4.962}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -38.98513412475586, "min_q": -39.37281799316406, "max_q": -38.3628044128418, "mean_td_error": -2.0455660820007324, "model": {}}, "td_error": [-0.3253326416015625, -0.718719482421875, -0.7882270812988281, -1.1379432678222656, -0.5797500610351562, -38.105201721191406, -0.3628730773925781, -0.949920654296875, -0.23215103149414062, -0.6792068481445312, -0.6789131164550781, -0.41471099853515625, -0.7447586059570312, -0.5521965026855469, -0.7402534484863281, -0.2657814025878906, -0.4665985107421875, -0.7393302917480469, 0.11673736572265625, -0.6956138610839844, -0.7336692810058594, -10.191596984863281, -0.5426521301269531, -0.6888427734375, -0.5475997924804688, -0.5168113708496094, -0.5553321838378906, -0.4590644836425781, -0.748291015625, -0.505950927734375, -0.4826927185058594, -0.4248695373535156], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.15651321411133, "min_q": -50.453060150146484, "max_q": -43.55662536621094, "mean_td_error": -1.0365686416625977, "model": {}}, "td_error": [-0.4705352783203125, -1.8625717163085938, -0.7708663940429688, -0.9668045043945312, 0.11290359497070312, -1.730316162109375, -1.8055191040039062, -0.2697181701660156, -1.543701171875, -1.4108772277832031, -0.4829444885253906, -1.7610549926757812, -2.3420028686523438, 0.1780242919921875, -0.79852294921875, -1.7098312377929688, -0.8204803466796875, -1.0371208190917969, -0.6633758544921875, -0.8094749450683594, 0.14414596557617188, -1.4516830444335938, -0.7303237915039062, -1.9957618713378906, -0.3247489929199219, 0.01956939697265625, -1.730316162109375, -1.26483154296875, -1.2147941589355469, -1.5913047790527344, -1.5058212280273438, -0.5595359802246094], "custom_metrics": {}}}, "num_steps_sampled": 7328, "num_agent_steps_sampled": 14656, "num_steps_trained": 11552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 23104, "last_target_update_ts": 7289, "num_target_updates": 57}, "done": false, "episodes_total": 419, "training_iteration": 21, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-35", "timestamp": 1648811735, "time_this_iter_s": 0.975334644317627, "time_total_s": 28.313954830169678, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 28.313954830169678, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 30.0, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -20.94, "episode_len_mean": 16.37, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 8.0}, "policy_reward_mean": {"policy0": -9.87, "policy1": -11.07}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -40.0, -30.0, -30.0, -2.0, -40.0, -30.0, -30.0, 10.0, 12.0, -30.0, -10.0, -30.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -2.0, -4.0, -30.0, -30.0, -2.0, 4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0, -30.0, 10.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -4.0, -30.0, -16.0, -10.0, 2.0, -12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0, -16.0, -30.0, -40.0, -30.0, -40.0, 14.0, 12.0, -30.0, -40.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0], "episode_lengths": [4, 20, 20, 20, 11, 20, 20, 20, 5, 4, 20, 15, 20, 20, 20, 20, 20, 7, 20, 15, 20, 20, 10, 20, 20, 20, 20, 7, 20, 20, 11, 12, 20, 20, 11, 8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20, 20, 5, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 15, 9, 16, 20, 7, 20, 16, 4, 14, 7, 14, 18, 20, 20, 20, 20, 3, 4, 20, 20, 20, 20, 18, 20, 20, 20, 3, 20, 20, 20], "policy_policy0_reward": [6.0, -20.0, -20.0, -10.0, -1.0, -20.0, -20.0, -10.0, 5.0, 6.0, -10.0, -5.0, -10.0, -20.0, -20.0, -20.0, -20.0, 3.0, -10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0, 3.0, -20.0, -20.0, -1.0, -12.0, -10.0, -20.0, -1.0, 2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -10.0, -8.0, -15.0, 1.0, -6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0, -8.0, -20.0, -20.0, -10.0, -20.0, 7.0, 6.0, -10.0, -20.0, -10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [6.0, -20.0, -10.0, -20.0, -1.0, -20.0, -10.0, -20.0, 5.0, 6.0, -20.0, -5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 3.0, -20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -1.0, 8.0, -20.0, -10.0, -1.0, 2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -2.0, -20.0, -8.0, 5.0, 1.0, -6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0, -8.0, -10.0, -20.0, -20.0, -20.0, 7.0, 6.0, -20.0, -20.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30675994434049625, "mean_inference_ms": 1.7114860901685445, "mean_action_processing_ms": 0.11774743054208966, "mean_env_wait_ms": 0.07343722449707754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7654, "timesteps_this_iter": 32, "agent_timesteps_total": 15308, "timers": {"load_time_ms": 0.454, "load_throughput": 70470.297, "learn_time_ms": 7.654, "learn_throughput": 4180.639, "update_time_ms": 4.729}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -42.45830535888672, "min_q": -43.064186096191406, "max_q": -41.985992431640625, "mean_td_error": -4.425806522369385, "model": {}}, "td_error": [-1.5250778198242188, -1.1753959655761719, -0.990936279296875, -41.52902603149414, -41.339107513427734, -1.4806365966796875, -0.747222900390625, -1.4799919128417969, -1.7579269409179688, -1.1872291564941406, -1.1974678039550781, -1.169158935546875, -11.133995056152344, -1.423126220703125, -1.2970848083496094, -1.245574951171875, -1.3696823120117188, -1.3730850219726562, -1.3694190979003906, -1.407501220703125, -0.9294281005859375, -1.0374336242675781, -1.3948554992675781, -1.3228034973144531, -1.4243125915527344, -1.4378395080566406, -1.1669769287109375, -10.848876953125, -1.4246711730957031, -1.3370246887207031, -1.4653396606445312, -1.6375923156738281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -47.785316467285156, "min_q": -50.37889099121094, "max_q": -43.06502151489258, "mean_td_error": -1.1693202257156372, "model": {}}, "td_error": [-0.8409843444824219, -0.4995079040527344, -1.3094749450683594, -1.0421676635742188, -1.4719200134277344, -1.1965904235839844, -1.1022415161132812, -0.7168807983398438, -0.8741188049316406, -0.9530563354492188, -1.1019210815429688, -1.0572280883789062, -0.9551124572753906, -0.2843894958496094, -0.9481697082519531, -0.3775596618652344, -1.0031623840332031, -1.4577903747558594, -5.167991638183594, -1.273468017578125, -0.3438835144042969, -0.9406471252441406, -0.9358558654785156, 0.05158233642578125, -5.6790771484375, -1.1385536193847656, -0.5606613159179688, -0.7277107238769531, -1.0951995849609375, -1.1255722045898438, -0.7497634887695312, -0.5391693115234375], "custom_metrics": {}}}, "num_steps_sampled": 7654, "num_agent_steps_sampled": 15308, "num_steps_trained": 12096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24192, "last_target_update_ts": 7614, "num_target_updates": 60}, "done": false, "episodes_total": 438, "training_iteration": 22, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-36", "timestamp": 1648811736, "time_this_iter_s": 1.2144417762756348, "time_total_s": 29.528396606445312, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 29.528396606445312, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 32.1, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -21.76, "episode_len_mean": 16.73, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 8.0}, "policy_reward_mean": {"policy0": -10.13, "policy1": -11.63}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -10.0, -30.0, -30.0, 0.0, -30.0, -30.0, -30.0, -30.0, 6.0, -40.0, -30.0, -2.0, -4.0, -30.0, -30.0, -2.0, 4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0, -30.0, 10.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -4.0, -30.0, -16.0, -10.0, 2.0, -12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0, -16.0, -30.0, -40.0, -30.0, -40.0, 14.0, 12.0, -30.0, -40.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0, -30.0, -30.0, 4.0, -30.0, -8.0, -30.0, -30.0, 4.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0], "episode_lengths": [20, 15, 20, 20, 10, 20, 20, 20, 20, 7, 20, 20, 11, 12, 20, 20, 11, 8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20, 20, 5, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 15, 9, 16, 20, 7, 20, 16, 4, 14, 7, 14, 18, 20, 20, 20, 20, 3, 4, 20, 20, 20, 20, 18, 20, 20, 20, 3, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 8, 20, 20, 20, 20, 20, 20, 18, 14, 20, 20], "policy_policy0_reward": [-10.0, -5.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, -10.0, 3.0, -20.0, -20.0, -1.0, -12.0, -10.0, -20.0, -1.0, 2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -10.0, -8.0, -15.0, 1.0, -6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0, -8.0, -20.0, -20.0, -10.0, -20.0, 7.0, 6.0, -10.0, -20.0, -10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -10.0, 6.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -5.0, -10.0, -20.0, 0.0, -10.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -1.0, 8.0, -20.0, -10.0, -1.0, 2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -2.0, -20.0, -8.0, 5.0, 1.0, -6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0, -8.0, -10.0, -20.0, -20.0, -20.0, 7.0, 6.0, -20.0, -20.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -20.0, -14.0, -20.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3070970636871319, "mean_inference_ms": 1.7131662260305691, "mean_action_processing_ms": 0.11788229159021366, "mean_env_wait_ms": 0.07349423744419191, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 7976, "timesteps_this_iter": 32, "agent_timesteps_total": 15952, "timers": {"load_time_ms": 0.452, "load_throughput": 70827.297, "learn_time_ms": 8.131, "learn_throughput": 3935.392, "update_time_ms": 4.955}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -44.66306686401367, "min_q": -46.06056213378906, "max_q": -42.6901969909668, "mean_td_error": -5.379543781280518, "model": {}}, "td_error": [0.22397994995117188, 0.5646934509277344, -0.3327789306640625, -0.620513916015625, -0.3621978759765625, 0.5623207092285156, -0.24502182006835938, -44.39485549926758, -0.3277130126953125, -0.3383216857910156, 1.0039253234863281, 0.07370376586914062, -0.6860618591308594, -44.230159759521484, 0.6489944458007812, -42.309532165527344, -0.3615760803222656, 0.7703361511230469, 0.0069427490234375, -0.3325920104980469, 0.22035598754882812, -0.0678863525390625, 0.076141357421875, -41.93252182006836, -0.19614028930664062, -0.2920112609863281, 0.3991584777832031, 0.32636260986328125, -0.119720458984375, 0.20044708251953125, -0.1630401611328125, 0.08989715576171875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.2598991394043, "min_q": -51.98493957519531, "max_q": -39.86189651489258, "mean_td_error": -1.1373740434646606, "model": {}}, "td_error": [-46.34169387817383, -0.3104591369628906, 0.15424346923828125, -0.3431587219238281, 0.7583847045898438, 1.012176513671875, -0.6601943969726562, -0.9134712219238281, 0.7710075378417969, 0.881134033203125, -0.342559814453125, -0.7769126892089844, 0.31048583984375, 0.2742652893066406, 0.9930534362792969, -1.2377357482910156, -0.3072357177734375, 2.1510467529296875, -0.7116889953613281, 1.0912361145019531, 0.20953369140625, 0.5410385131835938, 0.06424713134765625, 0.7512702941894531, -0.6177215576171875, 3.4557647705078125, -0.3863563537597656, 0.126953125, 4.0825653076171875, -0.20387649536132812, -0.516357421875, -0.3549537658691406], "custom_metrics": {}}}, "num_steps_sampled": 7976, "num_agent_steps_sampled": 15952, "num_steps_trained": 12672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 25344, "last_target_update_ts": 7936, "num_target_updates": 63}, "done": false, "episodes_total": 456, "training_iteration": 23, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-38", "timestamp": 1648811738, "time_this_iter_s": 1.326737403869629, "time_total_s": 30.85513401031494, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 30.85513401031494, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 58.8}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.14, "episode_len_mean": 17.07, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.67, "policy1": -12.47}, "custom_metrics": {}, "hist_stats": {"episode_reward": [4.0, -40.0, -30.0, 6.0, 10.0, -40.0, -30.0, -30.0, -30.0, -30.0, 0.0, -40.0, -30.0, -30.0, 10.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -4.0, -30.0, -16.0, -10.0, 2.0, -12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0, -16.0, -30.0, -40.0, -30.0, -40.0, 14.0, 12.0, -30.0, -40.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0, -30.0, -30.0, 4.0, -30.0, -8.0, -30.0, -30.0, 4.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0], "episode_lengths": [8, 20, 20, 7, 5, 20, 20, 20, 20, 20, 10, 20, 20, 20, 5, 20, 20, 20, 7, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 15, 9, 16, 20, 7, 20, 16, 4, 14, 7, 14, 18, 20, 20, 20, 20, 3, 4, 20, 20, 20, 20, 18, 20, 20, 20, 3, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 8, 20, 20, 20, 20, 20, 20, 18, 14, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20], "policy_policy0_reward": [2.0, -20.0, -20.0, 3.0, 5.0, -20.0, -20.0, -20.0, -20.0, -10.0, 0.0, -20.0, -10.0, -10.0, 5.0, -10.0, -20.0, -10.0, 3.0, -10.0, -10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -10.0, -8.0, -15.0, 1.0, -6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0, -8.0, -20.0, -20.0, -10.0, -20.0, 7.0, 6.0, -10.0, -20.0, -10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -10.0, 6.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [2.0, -20.0, -10.0, 3.0, 5.0, -20.0, -10.0, -10.0, -10.0, -20.0, 0.0, -20.0, -20.0, -20.0, 5.0, -20.0, -10.0, -20.0, 3.0, -20.0, -20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -2.0, -20.0, -8.0, 5.0, 1.0, -6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0, -8.0, -10.0, -20.0, -20.0, -20.0, 7.0, 6.0, -20.0, -20.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -20.0, -14.0, -20.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 4.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30732813232649475, "mean_inference_ms": 1.7148396787366715, "mean_action_processing_ms": 0.11800052604747449, "mean_env_wait_ms": 0.07352963012487794, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8296, "timesteps_this_iter": 32, "agent_timesteps_total": 16592, "timers": {"load_time_ms": 0.42, "load_throughput": 76143.262, "learn_time_ms": 7.876, "learn_throughput": 4062.932, "update_time_ms": 4.921}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -46.30604934692383, "min_q": -46.934993743896484, "max_q": -44.87223434448242, "mean_td_error": -3.8240671157836914, "model": {}}, "td_error": [-0.07199478149414062, 0.42844390869140625, 0.25707244873046875, 0.6181831359863281, -45.732662200927734, 0.35797119140625, 0.6289215087890625, 0.3931083679199219, 0.5014266967773438, 0.7694740295410156, 0.21757888793945312, 0.6365318298339844, -0.055950164794921875, 0.3405303955078125, 0.6158561706542969, 0.49710845947265625, -43.87223434448242, 0.3160972595214844, 0.3131675720214844, 1.0911178588867188, 0.3964805603027344, 0.21884536743164062, 0.3949127197265625, 0.21254348754882812, 0.41735076904296875, 0.3746376037597656, -44.31497573852539, 0.4898872375488281, 0.1846160888671875, 0.26087188720703125, 0.64288330078125, 0.10205841064453125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.58177185058594, "min_q": -52.26432800292969, "max_q": -44.38330841064453, "mean_td_error": -10.105253219604492, "model": {}}, "td_error": [0.0664520263671875, 0.14107894897460938, -4.267402648925781, -4.2966461181640625, -50.70470428466797, -0.5851402282714844, -0.08539581298828125, 0.2728996276855469, 0.12597274780273438, 0.4513206481933594, -50.9132080078125, 0.3133659362792969, 0.10659408569335938, -7.573768615722656, -0.02187347412109375, -0.13344192504882812, -54.40999984741211, 0.3106727600097656, 0.6617050170898438, -60.874481201171875, 0.13549423217773438, 0.22251510620117188, -0.18080520629882812, 0.5618171691894531, -3.104564666748047, 0.18342208862304688, 0.5424537658691406, -0.21855926513671875, -44.660762786865234, -1.0574226379394531, 0.16342544555664062, -44.53912353515625], "custom_metrics": {}}}, "num_steps_sampled": 8296, "num_agent_steps_sampled": 16592, "num_steps_trained": 13216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 26432, "last_target_update_ts": 8276, "num_target_updates": 66}, "done": false, "episodes_total": 473, "training_iteration": 24, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-39", "timestamp": 1648811739, "time_this_iter_s": 1.2600302696228027, "time_total_s": 32.115164279937744, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87158c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87158c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 32.115164279937744, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 32.1, "ram_util_percent": 58.849999999999994}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.16, "episode_len_mean": 17.08, "episode_media": {}, "episodes_this_iter": 20, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -10.78, "policy1": -12.38}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 10.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -4.0, -30.0, -16.0, -10.0, 2.0, -12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0, -16.0, -30.0, -40.0, -30.0, -40.0, 14.0, 12.0, -30.0, -40.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0, -30.0, -30.0, 4.0, -30.0, -8.0, -30.0, -30.0, 4.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, 6.0, -30.0, -18.0, -40.0, -30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0], "episode_lengths": [20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 12, 20, 18, 15, 9, 16, 20, 7, 20, 16, 4, 14, 7, 14, 18, 20, 20, 20, 20, 3, 4, 20, 20, 20, 20, 18, 20, 20, 20, 3, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 8, 20, 20, 20, 20, 20, 20, 18, 14, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 7, 20, 19, 20, 20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20], "policy_policy0_reward": [-10.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -2.0, -10.0, -8.0, -15.0, 1.0, -6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0, -8.0, -20.0, -20.0, -10.0, -20.0, 7.0, 6.0, -10.0, -20.0, -10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -10.0, 6.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -20.0, -9.0, -20.0, -10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0], "policy_policy1_reward": [-20.0, 5.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -2.0, -20.0, -8.0, 5.0, 1.0, -6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0, -8.0, -10.0, -20.0, -20.0, -20.0, 7.0, 6.0, -20.0, -20.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -20.0, -14.0, -20.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 4.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 3.0, -10.0, -9.0, -20.0, -20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3074901391433815, "mean_inference_ms": 1.71609500945399, "mean_action_processing_ms": 0.11810595891977861, "mean_env_wait_ms": 0.0735433260473944, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8619, "timesteps_this_iter": 32, "agent_timesteps_total": 17238, "timers": {"load_time_ms": 0.468, "load_throughput": 68304.187, "learn_time_ms": 7.63, "learn_throughput": 4193.767, "update_time_ms": 4.536}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.603515625, "min_q": -50.42580795288086, "max_q": -48.615081787109375, "mean_td_error": -4.753414630889893, "model": {}}, "td_error": [0.68115234375, 0.17264175415039062, 0.6093368530273438, 0.042499542236328125, 0.5387344360351562, 0.09788131713867188, 0.455047607421875, 0.20169448852539062, 0.2628669738769531, 0.7685585021972656, 0.9139595031738281, 0.2528533935546875, 0.705963134765625, 0.11479568481445312, 0.4861869812011719, 0.1944427490234375, -59.008583068847656, 0.6381263732910156, 0.3651390075683594, 0.433197021484375, -0.043701171875, 0.5543632507324219, 0.7984085083007812, 0.7671699523925781, -48.45037078857422, -57.615081787109375, 0.4202842712402344, 0.7142486572265625, 0.30875396728515625, 0.8045310974121094, 0.30304718017578125, 0.402587890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.8802490234375, "min_q": -52.84659194946289, "max_q": -44.91166687011719, "mean_td_error": -0.030709505081176758, "model": {}}, "td_error": [0.62872314453125, 0.7726593017578125, -0.28623199462890625, -0.8339729309082031, 0.13378524780273438, -0.2633323669433594, 0.13638687133789062, -1.314971923828125, 0.62872314453125, 0.8708534240722656, 0.0886383056640625, 0.05461883544921875, -8.156627655029297, 0.49859619140625, 1.1472663879394531, 0.297576904296875, 0.04518890380859375, 0.3521728515625, 0.4138832092285156, 0.31739044189453125, 0.5132827758789062, -0.18196487426757812, 0.4619941711425781, 0.09700775146484375, 1.0309982299804688, -0.15458297729492188, 0.3965110778808594, -0.11067581176757812, 0.03688812255859375, 0.3689994812011719, 0.8998527526855469, 0.12765884399414062], "custom_metrics": {}}}, "num_steps_sampled": 8619, "num_agent_steps_sampled": 17238, "num_steps_trained": 13824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 27648, "last_target_update_ts": 8599, "num_target_updates": 69}, "done": false, "episodes_total": 493, "training_iteration": 25, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-40", "timestamp": 1648811740, "time_this_iter_s": 1.2598628997802734, "time_total_s": 33.37502717971802, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 33.37502717971802, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 58.9}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -23.48, "episode_len_mean": 17.14, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -11.04, "policy1": -12.44}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-12.0, -40.0, 6.0, -30.0, -12.0, 12.0, -8.0, 6.0, -8.0, -16.0, -30.0, -40.0, -30.0, -40.0, 14.0, 12.0, -30.0, -40.0, -30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0, -30.0, -30.0, 4.0, -30.0, -8.0, -30.0, -30.0, 4.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, 6.0, -30.0, -18.0, -40.0, -30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0], "episode_lengths": [16, 20, 7, 20, 16, 4, 14, 7, 14, 18, 20, 20, 20, 20, 3, 4, 20, 20, 20, 20, 18, 20, 20, 20, 3, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 8, 20, 20, 20, 20, 20, 20, 18, 14, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 7, 20, 19, 20, 20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20], "policy_policy0_reward": [-6.0, -20.0, 3.0, -10.0, 4.0, 6.0, 6.0, 3.0, 6.0, -8.0, -20.0, -20.0, -10.0, -20.0, 7.0, 6.0, -10.0, -20.0, -10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -10.0, 6.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -20.0, -9.0, -20.0, -10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-6.0, -20.0, 3.0, -20.0, -16.0, 6.0, -14.0, 3.0, -14.0, -8.0, -10.0, -20.0, -20.0, -20.0, 7.0, 6.0, -20.0, -20.0, -20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -20.0, -14.0, -20.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 4.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 3.0, -10.0, -9.0, -20.0, -20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30741413640455945, "mean_inference_ms": 1.7157968657811662, "mean_action_processing_ms": 0.11809722481090126, "mean_env_wait_ms": 0.07350325191857024, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 8924, "timesteps_this_iter": 32, "agent_timesteps_total": 17848, "timers": {"load_time_ms": 0.419, "load_throughput": 76446.846, "learn_time_ms": 7.234, "learn_throughput": 4423.803, "update_time_ms": 4.693}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -52.78697204589844, "min_q": -53.51789093017578, "max_q": -52.135902404785156, "mean_td_error": -4.7931036949157715, "model": {}}, "td_error": [-0.5786590576171875, -1.5648880004882812, -1.271484375, -1.0477294921875, -1.4695014953613281, -1.6332817077636719, -1.4889602661132812, -1.426177978515625, -1.5492362976074219, -1.3550148010253906, -10.6068115234375, -0.438751220703125, -1.7506904602050781, -1.6939888000488281, -0.8460731506347656, -1.2600631713867188, -1.0074005126953125, -1.7303314208984375, -2.3581581115722656, -1.0275306701660156, -0.6110572814941406, -0.9463768005371094, -0.8179512023925781, -1.6676445007324219, -1.143096923828125, -51.367156982421875, -2.1800918579101562, -2.179912567138672, -2.108348846435547, -1.2011604309082031, -51.92424774169922, -1.1275520324707031], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -48.00139236450195, "min_q": -50.87716293334961, "max_q": -44.4415397644043, "mean_td_error": -5.396033763885498, "model": {}}, "td_error": [2.3232460021972656, -0.06642532348632812, 1.0588722229003906, 2.056396484375, 0.7067337036132812, 0.3089599609375, 0.3333091735839844, 2.36285400390625, 1.2935104370117188, 2.1941757202148438, -49.192501068115234, -49.54425048828125, -49.62465286254883, 0.2799797058105469, 1.4839897155761719, 0.038784027099609375, 2.07073974609375, 2.0362510681152344, 2.2657737731933594, 0.11429595947265625, -47.95879364013672, -3.7522735595703125, 1.0817604064941406, -0.011554718017578125, 0.11142730712890625, 2.0391387939453125, 1.2949409484863281, 1.7725334167480469, 0.2557373046875, 0.7067337036132812, 0.00574493408203125, -0.7185173034667969], "custom_metrics": {}}}, "num_steps_sampled": 8924, "num_agent_steps_sampled": 17848, "num_steps_trained": 14368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 28736, "last_target_update_ts": 8924, "num_target_updates": 72}, "done": false, "episodes_total": 510, "training_iteration": 26, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-42", "timestamp": 1648811742, "time_this_iter_s": 1.1328229904174805, "time_total_s": 34.5078501701355, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8729560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 34.5078501701355, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 58.9}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.08, "episode_len_mean": 17.69, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -12.19, "policy1": -12.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -16.0, -30.0, -30.0, -30.0, 14.0, -40.0, -40.0, -30.0, -30.0, -30.0, 4.0, -30.0, -8.0, -30.0, -30.0, 4.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, 6.0, -30.0, -18.0, -40.0, -30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0], "episode_lengths": [20, 20, 18, 20, 20, 20, 3, 20, 20, 20, 20, 20, 8, 20, 14, 20, 20, 8, 20, 20, 20, 20, 20, 20, 18, 14, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 7, 20, 19, 20, 20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12], "policy_policy0_reward": [-10.0, -20.0, -8.0, -10.0, -10.0, -10.0, 7.0, -20.0, -20.0, -10.0, -10.0, -20.0, 2.0, -10.0, 6.0, -10.0, -10.0, 2.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -20.0, -9.0, -20.0, -10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0], "policy_policy1_reward": [-20.0, -10.0, -8.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -10.0, 2.0, -20.0, -14.0, -20.0, -20.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 4.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 3.0, -10.0, -9.0, -20.0, -20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30729309999808924, "mean_inference_ms": 1.715324817677009, "mean_action_processing_ms": 0.1180912886269694, "mean_env_wait_ms": 0.07347088134938827, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9242, "timesteps_this_iter": 32, "agent_timesteps_total": 18484, "timers": {"load_time_ms": 0.471, "load_throughput": 68006.55, "learn_time_ms": 8.258, "learn_throughput": 3874.948, "update_time_ms": 4.812}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.72016143798828, "min_q": -54.571537017822266, "max_q": -52.877140045166016, "mean_td_error": -2.418001890182495, "model": {}}, "td_error": [0.036006927490234375, -0.23481369018554688, 0.9946098327636719, 0.07114028930664062, -9.174995422363281, -0.47945404052734375, 1.42645263671875, -0.5676383972167969, -9.4267578125, -0.4753456115722656, 0.5123558044433594, 0.2702751159667969, -53.1571159362793, 0.22906112670898438, 0.9578666687011719, -0.3477783203125, -0.3221015930175781, 0.09702301025390625, 0.4785270690917969, 0.146331787109375, 0.6633872985839844, 0.12984085083007812, 0.38593292236328125, 0.5107612609863281, -0.11361312866210938, -0.09075164794921875, -0.5797309875488281, 1.1257553100585938, -0.01345062255859375, -0.7630081176757812, -9.4267578125, -0.23807525634765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -49.1434211730957, "min_q": -54.03697204589844, "max_q": -45.133018493652344, "mean_td_error": 0.6992886066436768, "model": {}}, "td_error": [0.5142822265625, 0.7763786315917969, 0.6636810302734375, 1.8366661071777344, 0.6980438232421875, -0.3438835144042969, 0.7557563781738281, 0.6100845336914062, 0.6272125244140625, 0.1875762939453125, 0.9461669921875, 0.7086563110351562, 0.5268821716308594, 1.0399589538574219, 1.1738052368164062, -0.08582305908203125, -0.18853759765625, 1.7315711975097656, 0.42739105224609375, 0.441192626953125, 0.4981575012207031, 0.3122367858886719, -0.36093902587890625, -0.04703521728515625, 1.1981735229492188, 2.942523956298828, 0.1150970458984375, 2.3193626403808594, 0.7380561828613281, 0.4561271667480469, 0.6579742431640625, 0.5004386901855469], "custom_metrics": {}}}, "num_steps_sampled": 9242, "num_agent_steps_sampled": 18484, "num_steps_trained": 14944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 29888, "last_target_update_ts": 9242, "num_target_updates": 75}, "done": false, "episodes_total": 528, "training_iteration": 27, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-43", "timestamp": 1648811743, "time_this_iter_s": 1.264892816543579, "time_total_s": 35.77274298667908, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010ad40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02010ad40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 35.77274298667908, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 32.5, "ram_util_percent": 59.0}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -25.84, "episode_len_mean": 17.92, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.52, "policy1": -12.32}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -16.0, -8.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, 6.0, -30.0, -18.0, -40.0, -30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0, -2.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 18, 14, 20, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 7, 20, 19, 20, 20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -18.0, -14.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 4.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -20.0, -9.0, -20.0, -10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0, -1.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 2.0, 6.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, 4.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 3.0, -10.0, -9.0, -20.0, -20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0, -1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30720288276662266, "mean_inference_ms": 1.7151782403272842, "mean_action_processing_ms": 0.11811672135653364, "mean_env_wait_ms": 0.07346172140208952, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9576, "timesteps_this_iter": 32, "agent_timesteps_total": 19152, "timers": {"load_time_ms": 0.452, "load_throughput": 70838.512, "learn_time_ms": 7.939, "learn_throughput": 4030.683, "update_time_ms": 4.883}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.35243606567383, "min_q": -53.974613189697266, "max_q": -52.422088623046875, "mean_td_error": -1.166745901107788, "model": {}}, "td_error": [0.06627273559570312, -52.529441833496094, -0.3815269470214844, 0.7202682495117188, 0.9614601135253906, 0.2719459533691406, 0.1077728271484375, 1.134613037109375, 0.5914573669433594, 0.9181327819824219, 1.234100341796875, 0.4039115905761719, 0.4672737121582031, 0.9579544067382812, 0.4063148498535156, 0.5517539978027344, 0.10500335693359375, 0.3444633483886719, 0.13763809204101562, 0.04929351806640625, 0.7012290954589844, 0.7915115356445312, 0.4262809753417969, 0.6079559326171875, 0.9186668395996094, 0.00658416748046875, 0.4890594482421875, 0.5604782104492188, 0.6175117492675781, 0.3598136901855469, -0.1963348388671875, 0.8627128601074219], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -53.740196228027344, "min_q": -57.035221099853516, "max_q": -46.46300506591797, "mean_td_error": 0.9128866195678711, "model": {}}, "td_error": [1.6798820495605469, -0.650360107421875, 1.6855201721191406, -1.0872039794921875, 1.9220924377441406, 1.6793937683105469, 1.929718017578125, 1.6611557006835938, -0.38809967041015625, -0.6683311462402344, 2.461090087890625, 1.6245803833007812, -0.7228660583496094, 1.7106704711914062, 1.0658378601074219, 1.8820877075195312, 1.0658378601074219, 2.024311065673828, 1.3946266174316406, 3.470081329345703, 0.7079238891601562, 1.7482566833496094, -0.6452484130859375, -0.6800994873046875, -0.19015121459960938, -0.6996955871582031, 1.3520088195800781, -0.19737625122070312, 1.8837394714355469, 1.9258575439453125, -0.5617866516113281, 0.82891845703125], "custom_metrics": {}}}, "num_steps_sampled": 9576, "num_agent_steps_sampled": 19152, "num_steps_trained": 15520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 31040, "last_target_update_ts": 9576, "num_target_updates": 78}, "done": false, "episodes_total": 546, "training_iteration": 28, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-44", "timestamp": 1648811744, "time_this_iter_s": 1.3362715244293213, "time_total_s": 37.1090145111084, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 37.1090145111084, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.0}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.42, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.41, "policy1": -13.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -8.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, 6.0, -30.0, -18.0, -40.0, -30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0, -2.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 7, 20, 19, 20, 20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -20.0, -4.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -20.0, -9.0, -20.0, -10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0, -1.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -10.0, -4.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, 3.0, -10.0, -9.0, -20.0, -20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0, -1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3070930457279909, "mean_inference_ms": 1.7147860165758066, "mean_action_processing_ms": 0.11814385004227107, "mean_env_wait_ms": 0.07346297657731816, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 9903, "timesteps_this_iter": 32, "agent_timesteps_total": 19806, "timers": {"load_time_ms": 0.432, "load_throughput": 74112.495, "learn_time_ms": 7.909, "learn_throughput": 4046.237, "update_time_ms": 5.085}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -57.21056365966797, "min_q": -57.97312545776367, "max_q": -56.37733459472656, "mean_td_error": -1.6916937828063965, "model": {}}, "td_error": [3.3216400146484375, -8.957374572753906, 2.3498268127441406, 2.676715850830078, 3.541065216064453, 2.3080215454101562, 1.4872398376464844, 3.3216400146484375, -6.971523284912109, 2.5351104736328125, 1.9216499328613281, 4.389869689941406, 3.3595962524414062, 3.352123260498047, -56.693180084228516, 1.9049224853515625, 2.9949913024902344, 3.3374061584472656, 3.80340576171875, 1.448028564453125, 2.8105430603027344, 1.7473106384277344, 1.6062393188476562, 3.153675079345703, 2.7629547119140625, 3.905731201171875, 1.3320960998535156, 2.681842803955078, 1.4109420776367188, -55.98304748535156, 3.7268753051757812, 1.2794609069824219], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -57.26008605957031, "min_q": -63.05967712402344, "max_q": -50.59001922607422, "mean_td_error": -4.298103332519531, "model": {}}, "td_error": [-0.4440422058105469, -1.3213577270507812, -0.23702239990234375, 0.15747451782226562, 0.3264312744140625, -0.13159561157226562, 3.676513671875, 0.22794723510742188, -0.4902610778808594, 0.0860137939453125, -60.51642608642578, -0.021144866943359375, -0.7322235107421875, -0.4847259521484375, 0.49817657470703125, 0.5900955200195312, -1.5708198547363281, -0.2375640869140625, -0.23801803588867188, 0.230682373046875, 0.3599205017089844, -4.783668518066406, -0.322357177734375, 0.7555885314941406, -0.5579299926757812, -11.763927459716797, 0.6909599304199219, 0.7412261962890625, -1.2882118225097656, -4.857940673828125, 1.4708824157714844, -57.351993560791016], "custom_metrics": {}}}, "num_steps_sampled": 9903, "num_agent_steps_sampled": 19806, "num_steps_trained": 16064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 32128, "last_target_update_ts": 9810, "num_target_updates": 80}, "done": false, "episodes_total": 563, "training_iteration": 29, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-46", "timestamp": 1648811746, "time_this_iter_s": 1.285999059677124, "time_total_s": 38.39501357078552, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8715170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8715170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 38.39501357078552, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 59.05}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.72, "episode_len_mean": 18.01, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.71, "policy1": -13.01}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 12.0, -30.0, 14.0, -30.0, 8.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, 12.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0, -2.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0], "episode_lengths": [20, 4, 20, 3, 20, 6, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13], "policy_policy0_reward": [-10.0, 6.0, -20.0, 7.0, -20.0, 4.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0, -1.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0], "policy_policy1_reward": [-20.0, 6.0, -10.0, 7.0, -10.0, 4.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 6.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0, -1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3069718178392486, "mean_inference_ms": 1.7140507185288403, "mean_action_processing_ms": 0.11814682591131515, "mean_env_wait_ms": 0.07345209918519495, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10203, "timesteps_this_iter": 32, "agent_timesteps_total": 20406, "timers": {"load_time_ms": 0.436, "load_throughput": 73343.021, "learn_time_ms": 7.456, "learn_throughput": 4291.918, "update_time_ms": 4.817}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.97100830078125, "min_q": -70.42930603027344, "max_q": -63.74517822265625, "mean_td_error": -7.684943199157715, "model": {}}, "td_error": [-1.1896286010742188, -0.5846939086914062, -4.332759857177734, -1.3004074096679688, 0.7007522583007812, -2.7090606689453125, -4.0877227783203125, -66.91505432128906, -2.9785804748535156, -0.245269775390625, -2.21697998046875, -63.82685089111328, -0.636016845703125, -67.54322052001953, -1.766448974609375, -0.9501571655273438, -1.0112075805664062, -2.6966629028320312, -0.00820159912109375, -4.611705780029297, -2.114532470703125, -0.6117095947265625, -1.9056854248046875, -2.6712646484375, -4.677215576171875, -1.6238021850585938, -0.20299530029296875, -0.7335205078125, -1.490447998046875, -2.1969528198242188, 1.2412109375, -0.021392822265625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -56.66680145263672, "min_q": -60.484771728515625, "max_q": -53.589542388916016, "mean_td_error": -5.847924709320068, "model": {}}, "td_error": [-1.2228851318359375, 0.038303375244140625, -1.0763092041015625, 0.0141143798828125, 1.172088623046875, -0.42366790771484375, -4.605823516845703, -0.9113998413085938, -1.1505165100097656, -0.8250961303710938, -0.34761810302734375, -62.73979187011719, 0.23519134521484375, -0.3531761169433594, -0.9839057922363281, 0.917266845703125, 1.5485496520996094, 1.1343727111816406, 1.4753913879394531, -0.16540908813476562, -62.730648040771484, 1.0512542724609375, -0.038311004638671875, -52.90303421020508, -3.8963584899902344, 1.3787269592285156, -0.19603729248046875, -1.1418609619140625, 1.2944450378417969, -0.26177978515625, -0.9485054016113281, -0.47116851806640625], "custom_metrics": {}}}, "num_steps_sampled": 10203, "num_agent_steps_sampled": 20406, "num_steps_trained": 16576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33152, "last_target_update_ts": 10150, "num_target_updates": 83}, "done": false, "episodes_total": 579, "training_iteration": 30, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-47", "timestamp": 1648811747, "time_this_iter_s": 1.1243774890899658, "time_total_s": 39.51939105987549, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8715e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef8715e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 39.51939105987549, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 30.4, "ram_util_percent": 59.1}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.74, "episode_len_mean": 18.22, "episode_media": {}, "episodes_this_iter": 13, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 14.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.32, "policy1": -13.42}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -10.0, 8.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0, -2.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0, -40.0, -30.0, -30.0, -40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 15, 6, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13, 20, 20, 20, 20, 20, 6, 20, 6, 20, 20, 20, 6, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -15.0, 14.0, -20.0, -20.0, -10.0, -10.0, -20.0, 6.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0, -1.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -10.0, -20.0, -20.0, 5.0, -6.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0, -1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3068666051378679, "mean_inference_ms": 1.7153431476376624, "mean_action_processing_ms": 0.11813653677371072, "mean_env_wait_ms": 0.07343796292205168, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10421, "timesteps_this_iter": 32, "agent_timesteps_total": 20842, "timers": {"load_time_ms": 0.475, "load_throughput": 67378.378, "learn_time_ms": 7.588, "learn_throughput": 4217.407, "update_time_ms": 4.683}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.73705291748047, "min_q": -68.62277221679688, "max_q": -62.68682098388672, "mean_td_error": -8.515669822692871, "model": {}}, "td_error": [1.0878143310546875, -75.9627456665039, -0.4271659851074219, -1.0844573974609375, 0.2740325927734375, 0.1460418701171875, 0.5300140380859375, -0.6036300659179688, 0.7822494506835938, -0.941253662109375, -67.62277221679688, 0.152252197265625, 0.1015167236328125, -61.68682098388672, -0.3468475341796875, -0.4321441650390625, 0.02167510986328125, -1.1725997924804688, -0.07459259033203125, -0.04827117919921875, 0.25577545166015625, 0.416229248046875, -0.9269561767578125, -65.919677734375, 0.46012115478515625, -1.4019699096679688, 1.5453414916992188, 0.6257171630859375, -0.2126312255859375, 0.23388671875, -0.5897445678710938, 0.32019805908203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.1398811340332, "min_q": -62.893089294433594, "max_q": -51.94941329956055, "mean_td_error": -0.34800171852111816, "model": {}}, "td_error": [0.23228073120117188, 0.6771812438964844, -0.5895347595214844, -1.2439804077148438, -0.7717971801757812, -0.2064361572265625, -0.13341522216796875, -0.8293418884277344, -0.7322998046875, -0.7066230773925781, -0.019626617431640625, -0.4809837341308594, -0.6815872192382812, 0.6623153686523438, 0.5890007019042969, 0.5158882141113281, -0.40933990478515625, -0.3851585388183594, 0.7084693908691406, 0.3687858581542969, 0.6174430847167969, -5.066989898681641, 0.5570411682128906, -0.446380615234375, 1.2906532287597656, -1.0979576110839844, -0.5788345336914062, -5.160579681396484, 0.7059288024902344, -0.2856483459472656, 0.24211883544921875, 1.5233535766601562], "custom_metrics": {}}}, "num_steps_sampled": 10421, "num_agent_steps_sampled": 20842, "num_steps_trained": 16992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 33984, "last_target_update_ts": 10375, "num_target_updates": 85}, "done": false, "episodes_total": 592, "training_iteration": 31, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-48", "timestamp": 1648811748, "time_this_iter_s": 1.0324592590332031, "time_total_s": 40.55185031890869, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 40.55185031890869, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 33.9, "ram_util_percent": 59.1}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.3, "episode_len_mean": 18.15, "episode_media": {}, "episodes_this_iter": 18, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.15, "policy1": -13.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, 8.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -6.0, -30.0, -4.0, -2.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0, -40.0, -30.0, -30.0, -40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 6, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 13, 20, 12, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13, 20, 20, 20, 20, 20, 6, 20, 6, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, 4.0, -20.0, -20.0, -10.0, -20.0, 3.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -3.0, -10.0, -2.0, -1.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, 4.0, -10.0, -10.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -3.0, -20.0, -2.0, -1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30677158822537326, "mean_inference_ms": 1.7171648803246138, "mean_action_processing_ms": 0.11812630866834992, "mean_env_wait_ms": 0.07343252082397128, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 10739, "timesteps_this_iter": 32, "agent_timesteps_total": 21478, "timers": {"load_time_ms": 0.42, "load_throughput": 76238.414, "learn_time_ms": 7.514, "learn_throughput": 4258.906, "update_time_ms": 4.933}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.22802734375, "min_q": -70.9647216796875, "max_q": -64.99048614501953, "mean_td_error": -0.5750455856323242, "model": {}}, "td_error": [-0.2542572021484375, -0.6447677612304688, 1.134033203125, 0.5645675659179688, -0.5530776977539062, -1.4510040283203125, 0.650726318359375, -1.9063491821289062, 2.1103363037109375, -0.8231964111328125, -1.6721878051757812, -3.0412979125976562, -1.3532943725585938, -1.6409912109375, -1.3316650390625, -0.4720916748046875, 1.9171066284179688, 1.3712158203125, -0.167083740234375, -1.2779617309570312, -0.6682891845703125, -0.21506500244140625, -2.63104248046875, 0.148895263671875, -0.43346405029296875, 0.8735198974609375, -0.375579833984375, -0.530792236328125, 0.10173797607421875, -1.0238189697265625, -2.1254196166992188, -2.6809005737304688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -58.40528106689453, "min_q": -64.24978637695312, "max_q": -52.741695404052734, "mean_td_error": -5.754367828369141, "model": {}}, "td_error": [-0.31103515625, 5.341346740722656, -0.822235107421875, -62.40272903442383, -0.7345123291015625, -0.16534423828125, -0.19556808471679688, -0.6114883422851562, -1.4635086059570312, -0.239288330078125, -0.24621200561523438, -1.1367874145507812, -0.9518013000488281, -0.5472145080566406, -0.08919525146484375, -52.19041061401367, -0.17739105224609375, 0.0188751220703125, -0.505218505859375, -0.5360679626464844, -0.3742790222167969, -0.97247314453125, -0.5480232238769531, -0.3814048767089844, -0.7036514282226562, 0.1363983154296875, -61.741695404052734, -0.4529151916503906, -0.23714447021484375, 0.12807846069335938, -0.433868408203125, -0.5929946899414062], "custom_metrics": {}}}, "num_steps_sampled": 10739, "num_agent_steps_sampled": 21478, "num_steps_trained": 17568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 35136, "last_target_update_ts": 10699, "num_target_updates": 88}, "done": false, "episodes_total": 610, "training_iteration": 32, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-49", "timestamp": 1648811749, "time_this_iter_s": 1.2028343677520752, "time_total_s": 41.75468468666077, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 41.75468468666077, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.1}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.86, "episode_len_mean": 17.73, "episode_media": {}, "episodes_this_iter": 21, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.33, "policy1": -12.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -12.0, -40.0, -30.0, 0.0, -30.0, -40.0, -30.0, -14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0, -40.0, -30.0, -30.0, -40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 16, 20, 20, 10, 20, 20, 20, 17, 20, 20, 20, 20, 20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13, 20, 20, 20, 20, 20, 6, 20, 6, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -16.0, -20.0, -20.0, 0.0, -10.0, -20.0, -20.0, -17.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0], "policy_policy1_reward": [-10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, 4.0, -20.0, -10.0, 0.0, -20.0, -20.0, -10.0, 3.0, -10.0, -20.0, -20.0, -20.0, -20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30665543376531473, "mean_inference_ms": 1.7184999467706905, "mean_action_processing_ms": 0.11804716834482817, "mean_env_wait_ms": 0.0733932093277202, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11066, "timesteps_this_iter": 32, "agent_timesteps_total": 22132, "timers": {"load_time_ms": 0.409, "load_throughput": 78334.147, "learn_time_ms": 7.399, "learn_throughput": 4324.93, "update_time_ms": 4.839}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.21575164794922, "min_q": -72.01458740234375, "max_q": -65.85030364990234, "mean_td_error": -0.11746692657470703, "model": {}}, "td_error": [1.3071670532226562, 0.22319793701171875, 1.0754241943359375, 0.9944610595703125, 1.3081130981445312, 0.7302474975585938, -0.13854217529296875, 1.0863800048828125, 0.4612579345703125, 1.1511764526367188, -0.6701202392578125, 1.2613601684570312, -0.23467254638671875, 0.04161834716796875, -0.520294189453125, 0.4940948486328125, 0.2059478759765625, 0.11136627197265625, -0.9189682006835938, 1.4733657836914062, -3.7221221923828125, 0.4720611572265625, -0.5621337890625, -9.2977294921875, 0.13863372802734375, 0.3173980712890625, -0.681732177734375, 0.19823455810546875, 0.4838104248046875, -0.618133544921875, 0.10205078125, -0.0318603515625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.19812774658203, "min_q": -63.65480041503906, "max_q": -53.67774963378906, "mean_td_error": -9.527381896972656, "model": {}}, "td_error": [-0.08297348022460938, 0.07678985595703125, 0.2707099914550781, 0.29669189453125, -0.006137847900390625, -4.666202545166016, -0.79974365234375, 0.8819732666015625, -62.152767181396484, 0.11481857299804688, -57.41153335571289, -61.423744201660156, -0.042751312255859375, -0.172760009765625, 0.2091522216796875, 0.6767349243164062, -0.16483688354492188, 0.16212081909179688, -3.983318328857422, -56.539527893066406, -62.65480041503906, 0.8635597229003906, 0.3025054931640625, 0.2524604797363281, -0.4281005859375, 0.12736129760742188, 0.17447280883789062, 0.3500099182128906, 0.32634735107421875, -0.3348960876464844, 0.7390403747558594, 0.16313934326171875], "custom_metrics": {}}}, "num_steps_sampled": 11066, "num_agent_steps_sampled": 22132, "num_steps_trained": 18240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36480, "last_target_update_ts": 11015, "num_target_updates": 91}, "done": false, "episodes_total": 631, "training_iteration": 33, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-51", "timestamp": 1648811751, "time_this_iter_s": 1.3092601299285889, "time_total_s": 43.063944816589355, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 43.063944816589355, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.150000000000006}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.1, "episode_len_mean": 17.45, "episode_media": {}, "episodes_this_iter": 19, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.55, "policy1": -12.55}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -8.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -6.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0, -40.0, -30.0, -30.0, -40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 14, 20, 20, 20, 20, 20, 20, 13, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13, 20, 20, 20, 20, 20, 6, 20, 6, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, 6.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -3.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -14.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -3.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3064862536045761, "mean_inference_ms": 1.718920504002959, "mean_action_processing_ms": 0.11790059839148129, "mean_env_wait_ms": 0.07332160746739082, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11401, "timesteps_this_iter": 32, "agent_timesteps_total": 22802, "timers": {"load_time_ms": 0.443, "load_throughput": 72296.11, "learn_time_ms": 7.518, "learn_throughput": 4256.313, "update_time_ms": 4.85}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.1549072265625, "min_q": -74.0418930053711, "max_q": -67.4635009765625, "mean_td_error": -1.8011009693145752, "model": {}}, "td_error": [0.37351226806640625, -7.147102355957031, -0.09957122802734375, 1.0896377563476562, 0.9401321411132812, 0.3943023681640625, 0.5129623413085938, -0.4347076416015625, 1.4938278198242188, 0.7030181884765625, -0.47533416748046875, 0.509735107421875, 0.46555328369140625, 1.1717529296875, 1.8735504150390625, 0.492279052734375, 1.0557937622070312, 1.24127197265625, 0.9631195068359375, 0.1923980712890625, -70.70177459716797, 1.2076950073242188, 0.2032012939453125, 1.2722625732421875, 0.65216064453125, -0.1625518798828125, 1.08172607421875, 0.8542022705078125, 1.5908889770507812, 0.17603302001953125, -0.22713470458984375, 1.1019287109375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.55329895019531, "min_q": -66.63023376464844, "max_q": -56.37628936767578, "mean_td_error": -6.6690874099731445, "model": {}}, "td_error": [-3.4186172485351562, -3.406352996826172, -2.0843963623046875, -11.728404998779297, -1.9032096862792969, -1.1724624633789062, -1.1637649536132812, -64.37199401855469, -0.303680419921875, -2.8664703369140625, -2.0609359741210938, -1.2742919921875, -65.2673568725586, -0.06109619140625, -1.9150924682617188, 0.1655426025390625, -3.2958946228027344, -12.090995788574219, -3.2866439819335938, -2.0525131225585938, -2.3325576782226562, -0.6802406311035156, -1.4214553833007812, -3.142375946044922, -3.570880889892578, -2.2610130310058594, 0.3791770935058594, -12.164070129394531, -0.0926513671875, 0.056976318359375, -2.835308074951172, -1.7877731323242188], "custom_metrics": {}}}, "num_steps_sampled": 11401, "num_agent_steps_sampled": 22802, "num_steps_trained": 18816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 37632, "last_target_update_ts": 11341, "num_target_updates": 94}, "done": false, "episodes_total": 650, "training_iteration": 34, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-52", "timestamp": 1648811752, "time_this_iter_s": 1.2688980102539062, "time_total_s": 44.33284282684326, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101ddb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101ddb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 44.33284282684326, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 33.2, "ram_util_percent": 59.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -26.86, "episode_len_mean": 17.53, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.83, "policy1": -13.03}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, 6.0, -30.0, -30.0, -6.0, -40.0, -30.0, -30.0, -40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 13, 20, 20, 20, 20, 20, 6, 20, 6, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, 3.0, -20.0, -10.0, -13.0, -20.0, -20.0, -20.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, 7.0, -20.0, -10.0, -10.0, -20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.306251206748591, "mean_inference_ms": 1.7187721304736123, "mean_action_processing_ms": 0.1177242393581561, "mean_env_wait_ms": 0.07324417236923227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 11716, "timesteps_this_iter": 32, "agent_timesteps_total": 23432, "timers": {"load_time_ms": 0.464, "load_throughput": 68949.824, "learn_time_ms": 7.68, "learn_throughput": 4166.519, "update_time_ms": 4.664}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.81454467773438, "min_q": -73.5518569946289, "max_q": -67.0409927368164, "mean_td_error": -1.9792735576629639, "model": {}}, "td_error": [0.3636016845703125, 0.30025482177734375, -0.2123260498046875, -0.05278778076171875, 0.5384979248046875, -72.39453887939453, 0.09502410888671875, 0.880950927734375, 0.27454376220703125, 0.25504302978515625, -0.136749267578125, 0.12415313720703125, -0.01886749267578125, 0.8955078125, 0.43035125732421875, -0.287078857421875, -0.23914337158203125, 0.19158172607421875, 0.3669586181640625, 0.4100799560546875, 0.291290283203125, 1.0546188354492188, 0.5496063232421875, 0.02935791015625, 0.084625244140625, 0.29327392578125, 0.07196807861328125, 1.0598831176757812, 0.21450042724609375, -0.25537872314453125, 1.0607528686523438, 0.4236907958984375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.798912048339844, "min_q": -68.175048828125, "max_q": -56.50678634643555, "mean_td_error": -4.476251125335693, "model": {}}, "td_error": [0.30933380126953125, -9.500991821289062, -0.24755859375, 0.554962158203125, -0.10619354248046875, 0.9619140625, 0.4372749328613281, 1.0649871826171875, -0.00234222412109375, 0.70013427734375, -0.38895416259765625, -0.6142921447753906, 0.20198822021484375, -66.36663818359375, 0.2904510498046875, 0.3156280517578125, 0.3939552307128906, -0.06683349609375, 1.181915283203125, -66.29269409179688, 0.9429550170898438, -1.6199493408203125, -0.02188873291015625, 1.1129035949707031, 0.30218505859375, -0.3095855712890625, -0.103118896484375, 1.1394424438476562, -9.469108581542969, -0.1682891845703125, 0.8963432312011719, 1.232025146484375], "custom_metrics": {}}}, "num_steps_sampled": 11716, "num_agent_steps_sampled": 23432, "num_steps_trained": 19328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 38656, "last_target_update_ts": 11696, "num_target_updates": 97}, "done": false, "episodes_total": 666, "training_iteration": 35, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-53", "timestamp": 1648811753, "time_this_iter_s": 1.1492671966552734, "time_total_s": 45.482110023498535, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 45.482110023498535, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 31.55, "ram_util_percent": 59.2}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -27.32, "episode_len_mean": 17.56, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -13.76, "policy1": -13.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 8.0, -40.0, 8.0, -40.0, -30.0, -40.0, 8.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0], "episode_lengths": [20, 20, 6, 20, 6, 20, 20, 20, 6, 20, 20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -10.0, -20.0, 4.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, 4.0, -20.0, 4.0, -20.0, -20.0, -20.0, 4.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3061604751514768, "mean_inference_ms": 1.7193611037774084, "mean_action_processing_ms": 0.11764216863846531, "mean_env_wait_ms": 0.07323828910798662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12019, "timesteps_this_iter": 32, "agent_timesteps_total": 24038, "timers": {"load_time_ms": 0.501, "load_throughput": 63934.515, "learn_time_ms": 8.526, "learn_throughput": 3753.25, "update_time_ms": 6.461}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.40718078613281, "min_q": -72.56761932373047, "max_q": -67.50318908691406, "mean_td_error": -5.106409549713135, "model": {}}, "td_error": [-1.524078369140625, -0.09856414794921875, 0.2201080322265625, -67.11627960205078, -0.10225677490234375, -0.6396255493164062, -0.45149993896484375, -1.72296142578125, -1.8714523315429688, -1.4073944091796875, -70.85933685302734, -1.8374786376953125, -0.9618148803710938, -0.7800369262695312, -0.722381591796875, -0.05574798583984375, 0.9964599609375, -0.6135635375976562, -1.4091720581054688, -0.14461517333984375, -2.6886978149414062, -1.7822036743164062, -0.42864990234375, -0.9274978637695312, 0.0238494873046875, -2.4350814819335938, 0.12027740478515625, -2.8081207275390625, -0.3298187255859375, -1.0984420776367188, 0.5857772827148438, -0.5348052978515625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.65472412109375, "min_q": -65.77499389648438, "max_q": -58.629329681396484, "mean_td_error": -6.047985553741455, "model": {}}, "td_error": [0.7181243896484375, -1.5786399841308594, -57.629329681396484, -0.9349327087402344, 1.6511459350585938, 2.0572967529296875, -2.0575027465820312, -1.1788406372070312, -0.48259735107421875, -2.219921112060547, 0.8798904418945312, -0.11157989501953125, 1.4449310302734375, 0.6629486083984375, -2.2224349975585938, 0.43310546875, -0.3819313049316406, -0.40030670166015625, 0.9903106689453125, 1.5966644287109375, -1.6118850708007812, -1.7447967529296875, 1.0151748657226562, 1.9000930786132812, -64.77499389648438, -2.178936004638672, 1.5594329833984375, -67.69541931152344, 0.9864883422851562, -1.6526565551757812, -1.1870803833007812, 0.612640380859375], "custom_metrics": {}}}, "num_steps_sampled": 12019, "num_agent_steps_sampled": 24038, "num_steps_trained": 19808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 39616, "last_target_update_ts": 11919, "num_target_updates": 99}, "done": false, "episodes_total": 682, "training_iteration": 36, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-54", "timestamp": 1648811754, "time_this_iter_s": 1.2840352058410645, "time_total_s": 46.7661452293396, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fbcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 46.7661452293396, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 34.6, "ram_util_percent": 59.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -28.36, "episode_len_mean": 17.98, "episode_media": {}, "episodes_this_iter": 10, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.08, "policy1": -14.28}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -30.0, 10.0, 2.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 5, 9, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -20.0, -10.0, -20.0, 5.0, 1.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, 6.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, 1.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, 6.0, -10.0, -20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30624384337357496, "mean_inference_ms": 1.7196341360492595, "mean_action_processing_ms": 0.1176715491393233, "mean_env_wait_ms": 0.0732777056877079, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12219, "timesteps_this_iter": 32, "agent_timesteps_total": 24438, "timers": {"load_time_ms": 0.495, "load_throughput": 64630.292, "learn_time_ms": 9.276, "learn_throughput": 3449.644, "update_time_ms": 5.718}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.6832504272461, "min_q": -70.76577758789062, "max_q": -65.6522216796875, "mean_td_error": -3.8331680297851562, "model": {}}, "td_error": [0.5446395874023438, 1.1817550659179688, 0.23545074462890625, -0.2409210205078125, 1.081298828125, -0.0694580078125, 1.0794754028320312, -0.33522796630859375, 0.52850341796875, -69.21649169921875, 0.2836151123046875, 2.6919631958007812, -0.1861419677734375, 1.3203887939453125, -68.93170928955078, 0.259002685546875, -0.3445892333984375, 0.1112518310546875, 0.15123748779296875, 1.6482925415039062, 0.08573150634765625, 0.7633285522460938, -0.0980987548828125, 0.5206375122070312, 0.7931900024414062, -0.183746337890625, -0.5516586303710938, 0.5993728637695312, 0.9042739868164062, 0.939117431640625, 1.020538330078125, 0.75360107421875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.03523254394531, "min_q": -66.34686279296875, "max_q": -58.79680252075195, "mean_td_error": -6.583780765533447, "model": {}}, "td_error": [0.9129791259765625, 1.6043281555175781, 1.3063774108886719, 0.5797805786132812, -1.7630195617675781, 1.337249755859375, -11.010982513427734, 0.5059356689453125, -1.7721366882324219, -2.0855712890625, -58.080650329589844, 0.36661529541015625, -1.0498504638671875, 1.6043281555175781, 1.7815513610839844, -71.89006042480469, -2.1055908203125, 1.3766899108886719, -0.5229949951171875, -0.290374755859375, -12.150794982910156, -0.9271621704101562, -1.5498809814453125, -0.4124298095703125, 0.2729339599609375, 1.7453689575195312, 0.8090744018554688, -0.1065673828125, 0.8668365478515625, 0.5419845581054688, -58.97250747680664, -1.6024436950683594], "custom_metrics": {}}}, "num_steps_sampled": 12219, "num_agent_steps_sampled": 24438, "num_steps_trained": 20128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 40256, "last_target_update_ts": 12159, "num_target_updates": 101}, "done": false, "episodes_total": 692, "training_iteration": 37, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-56", "timestamp": 1648811756, "time_this_iter_s": 0.9586191177368164, "time_total_s": 47.724764347076416, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 47.724764347076416, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 32.2, "ram_util_percent": 59.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -29.6, "episode_len_mean": 18.35, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.35, "policy1": -15.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, 6.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -30.0, -30.0, -40.0, 4.0, -40.0, -40.0, 12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 7, 20, 20, 20, 20, 4, 20, 20, 20, 20, 8, 20, 20, 4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, 2.0, -20.0, -20.0, 6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, 3.0, -10.0, -20.0, -20.0, -20.0, 6.0, -10.0, -10.0, -10.0, -20.0, 2.0, -20.0, -20.0, 6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30651853461026973, "mean_inference_ms": 1.7213699780610754, "mean_action_processing_ms": 0.11782131008969224, "mean_env_wait_ms": 0.07338261598015519, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12534, "timesteps_this_iter": 32, "agent_timesteps_total": 25068, "timers": {"load_time_ms": 0.5, "load_throughput": 64016.85, "learn_time_ms": 8.521, "learn_throughput": 3755.308, "update_time_ms": 5.285}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.09414672851562, "min_q": -71.1622085571289, "max_q": -66.78816986083984, "mean_td_error": -4.313592910766602, "model": {}}, "td_error": [0.05370330810546875, 2.0008697509765625, -66.9289321899414, -0.0558013916015625, 0.46552276611328125, -0.47481536865234375, -0.1604461669921875, -0.15943145751953125, -0.6693496704101562, -1.6873016357421875, 0.2615814208984375, 0.5056838989257812, 1.897186279296875, -67.91162872314453, 0.320831298828125, 0.0930633544921875, 0.3234100341796875, -0.6614608764648438, 0.48706817626953125, -10.365890502929688, 0.1585693359375, -0.45520782470703125, 0.24762725830078125, 1.628387451171875, -0.13343048095703125, 0.36540985107421875, -0.162628173828125, 0.158905029296875, 0.2820587158203125, 0.11632537841796875, 0.4242706298828125, 2.0008697509765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.314170837402344, "min_q": -68.39979553222656, "max_q": -56.575218200683594, "mean_td_error": -6.481002330780029, "model": {}}, "td_error": [1.4907302856445312, -0.1398468017578125, 0.49462890625, -0.10954666137695312, 0.12591934204101562, -65.96984100341797, -65.85895538330078, 0.2388916015625, 0.1582794189453125, -9.160106658935547, 0.8027725219726562, -0.1621551513671875, 0.4431343078613281, -0.49446868896484375, 0.4636116027832031, 0.8390846252441406, 0.28845977783203125, 0.14356231689453125, 0.01729583740234375, 0.9905052185058594, -8.884944915771484, -66.36154174804688, 0.5005264282226562, 0.68634033203125, 0.685760498046875, -0.45904541015625, 0.7195892333984375, -0.26430511474609375, 0.35611724853515625, 0.43485260009765625, -0.03751373291015625, 0.6301193237304688], "custom_metrics": {}}}, "num_steps_sampled": 12534, "num_agent_steps_sampled": 25068, "num_steps_trained": 20640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 41280, "last_target_update_ts": 12514, "num_target_updates": 104}, "done": false, "episodes_total": 708, "training_iteration": 38, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-57", "timestamp": 1648811757, "time_this_iter_s": 1.3007521629333496, "time_total_s": 49.025516510009766, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018eb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018eb00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 49.025516510009766, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 32.45, "ram_util_percent": 59.3}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -30.08, "episode_len_mean": 18.59, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.19, "policy1": -15.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [12.0, -6.0, -40.0, 10.0, -40.0, 8.0, -30.0, 10.0, -30.0, 4.0, -40.0, -30.0, -30.0, -40.0, -40.0, 14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [4, 13, 20, 5, 20, 6, 20, 5, 20, 8, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [6.0, -13.0, -20.0, 5.0, -20.0, 4.0, -20.0, 5.0, -20.0, 2.0, -20.0, -20.0, -10.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [6.0, 7.0, -20.0, 5.0, -20.0, 4.0, -10.0, 5.0, -10.0, 2.0, -20.0, -10.0, -20.0, -20.0, -20.0, 7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3067616549042822, "mean_inference_ms": 1.7231290814388638, "mean_action_processing_ms": 0.11797377699388913, "mean_env_wait_ms": 0.07349442091513912, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 12837, "timesteps_this_iter": 32, "agent_timesteps_total": 25674, "timers": {"load_time_ms": 0.433, "load_throughput": 73908.441, "learn_time_ms": 7.937, "learn_throughput": 4031.688, "update_time_ms": 5.039}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.59976196289062, "min_q": -72.15727996826172, "max_q": -68.35831451416016, "mean_td_error": -3.729522228240967, "model": {}}, "td_error": [-1.5540695190429688, -0.1861114501953125, -1.7642593383789062, -0.43694305419921875, -1.782318115234375, -1.1780776977539062, -0.35779571533203125, -0.6595077514648438, -1.0972061157226562, -0.18814849853515625, -1.521240234375, -0.7320327758789062, -2.378265380859375, -2.0979080200195312, -1.9658279418945312, -10.619613647460938, -1.3289337158203125, -0.59954833984375, -2.36260986328125, -1.672271728515625, -1.5704421997070312, -1.453643798828125, -1.5261383056640625, -1.5171890258789062, -1.79010009765625, -0.9636459350585938, -0.707000732421875, -70.38884735107422, -1.4572601318359375, -1.0792236328125, -1.093658447265625, -1.3148727416992188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.473907470703125, "min_q": -66.49766540527344, "max_q": -56.696598052978516, "mean_td_error": -1.4789611101150513, "model": {}}, "td_error": [1.6568069458007812, -0.5853805541992188, 0.8402938842773438, 0.04640960693359375, 2.265430450439453, 0.5414886474609375, 0.2872467041015625, 1.6154022216796875, -64.08352661132812, 0.1709442138671875, 0.7333984375, -0.7676467895507812, 0.27642822265625, 1.1670646667480469, 2.9454498291015625, 1.1863174438476562, 0.2094268798828125, -1.223602294921875, 0.36635589599609375, 0.6609725952148438, 0.21162796020507812, 0.290435791015625, -1.758758544921875, 0.38883209228515625, 1.7685775756835938, 0.2915382385253906, -0.25785064697265625, 0.635711669921875, 0.3590965270996094, 1.2068710327148438, 0.46845245361328125, 0.759429931640625], "custom_metrics": {}}}, "num_steps_sampled": 12837, "num_agent_steps_sampled": 25674, "num_steps_trained": 21120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42240, "last_target_update_ts": 12737, "num_target_updates": 106}, "done": false, "episodes_total": 724, "training_iteration": 39, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-58", "timestamp": 1648811758, "time_this_iter_s": 1.104743242263794, "time_total_s": 50.13025975227356, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101dd830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 50.13025975227356, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 32.6, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.06, "episode_len_mean": 19.38, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.38, "policy1": -17.68}, "custom_metrics": {}, "hist_stats": {"episode_reward": [14.0, -30.0, -30.0, -40.0, -30.0, -18.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [3, 20, 20, 20, 20, 19, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [7.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, 5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [7.0, -10.0, -10.0, -20.0, -10.0, -9.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30695507069881856, "mean_inference_ms": 1.7246321491779215, "mean_action_processing_ms": 0.1181125742419757, "mean_env_wait_ms": 0.07360047842433215, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13137, "timesteps_this_iter": 32, "agent_timesteps_total": 26274, "timers": {"load_time_ms": 0.412, "load_throughput": 77744.282, "learn_time_ms": 7.745, "learn_throughput": 4131.81, "update_time_ms": 4.888}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.17355346679688, "min_q": -70.63358306884766, "max_q": -63.89541244506836, "mean_td_error": -11.069683074951172, "model": {}}, "td_error": [-1.449188232421875, -1.3108596801757812, 0.22731781005859375, -63.178855895996094, -0.5715408325195312, 1.1113853454589844, -0.5841445922851562, -0.8771591186523438, -1.3963470458984375, -0.03653717041015625, -63.4176025390625, -0.5751953125, -0.0557098388671875, -0.008209228515625, 0.20114898681640625, -74.12574768066406, -1.683990478515625, 1.3396835327148438, 0.8783950805664062, -1.0702056884765625, -0.762481689453125, -3.0806503295898438, -66.76253509521484, 0.28067779541015625, -0.40941619873046875, 0.5591812133789062, -63.236305236816406, -0.8481674194335938, 0.16326904296875, -13.398521423339844, 0.432586669921875, -0.5841522216796875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.96992492675781, "min_q": -67.62451171875, "max_q": -56.993202209472656, "mean_td_error": -0.8060928583145142, "model": {}}, "td_error": [0.4812660217285156, 0.618560791015625, -1.9679412841796875, 0.46395111083984375, -0.05994415283203125, -1.7122726440429688, -0.11138916015625, -0.0711822509765625, -0.31192779541015625, -0.12834930419921875, 0.2108001708984375, 0.0968780517578125, -0.69512939453125, 0.4400787353515625, -0.55517578125, -0.02526092529296875, 0.00041961669921875, 0.2811126708984375, -8.442970275878906, -0.41289520263671875, -0.883148193359375, 1.2390289306640625, 0.5341873168945312, 0.3529510498046875, 0.7402992248535156, -7.9650726318359375, -0.7070770263671875, 0.51513671875, -0.00341033935546875, 0.6195030212402344, 0.26891326904296875, -8.604911804199219], "custom_metrics": {}}}, "num_steps_sampled": 13137, "num_agent_steps_sampled": 26274, "num_steps_trained": 21600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 43200, "last_target_update_ts": 13097, "num_target_updates": 109}, "done": false, "episodes_total": 739, "training_iteration": 40, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-15-59", "timestamp": 1648811759, "time_this_iter_s": 1.098564624786377, "time_total_s": 51.22882437705994, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ee60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ee60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 51.22882437705994, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.92, "episode_len_mean": 19.56, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.56, "policy1": -18.36}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-10.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0], "episode_lengths": [15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [5.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3071128852998861, "mean_inference_ms": 1.7259528368239865, "mean_action_processing_ms": 0.11824338345573374, "mean_env_wait_ms": 0.07370634020508744, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13437, "timesteps_this_iter": 32, "agent_timesteps_total": 26874, "timers": {"load_time_ms": 0.435, "load_throughput": 73535.902, "learn_time_ms": 7.718, "learn_throughput": 4146.118, "update_time_ms": 4.855}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.25259399414062, "min_q": -70.11180877685547, "max_q": -66.1916732788086, "mean_td_error": -5.224967956542969, "model": {}}, "td_error": [-0.4546051025390625, -0.0211029052734375, -1.1712112426757812, -1.0538558959960938, -0.5325088500976562, -2.204681396484375, -1.0283737182617188, -0.7366180419921875, -1.037872314453125, 0.1194610595703125, -0.9774703979492188, -75.76983642578125, -1.3051681518554688, -66.72285461425781, -0.0359039306640625, -1.0945205688476562, -0.8324737548828125, -0.610382080078125, -0.9952163696289062, -0.5413131713867188, -1.5795364379882812, -0.0425262451171875, -1.00494384765625, -1.1887893676757812, -1.4224472045898438, -1.2019805908203125, -0.3230133056640625, -0.814361572265625, -1.06768798828125, -0.8191909790039062, -0.6907730102539062, -0.03720855712890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.61835479736328, "min_q": -67.58277893066406, "max_q": -56.46942901611328, "mean_td_error": -1.717170000076294, "model": {}}, "td_error": [-0.4380950927734375, 0.6649284362792969, 0.7884140014648438, -1.4769821166992188, -1.7530899047851562, 0.990570068359375, -0.5145187377929688, -55.46942901611328, -0.02454376220703125, -0.4019813537597656, 0.14672088623046875, 0.6870079040527344, -1.3582992553710938, -0.8208694458007812, 0.67388916015625, -0.41202545166015625, -0.8596343994140625, 0.22974395751953125, -0.5026931762695312, -1.4739532470703125, 1.4709587097167969, -1.524505615234375, 0.16208648681640625, -0.08409500122070312, 2.91925048828125, 0.10482025146484375, 0.24610137939453125, 1.9178466796875, -0.13857269287109375, 1.1560211181640625, -0.5600051879882812, 0.7054939270019531], "custom_metrics": {}}}, "num_steps_sampled": 13437, "num_agent_steps_sampled": 26874, "num_steps_trained": 22080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 44160, "last_target_update_ts": 13337, "num_target_updates": 111}, "done": false, "episodes_total": 754, "training_iteration": 41, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-00", "timestamp": 1648811760, "time_this_iter_s": 1.0811665058135986, "time_total_s": 52.309990882873535, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101ef560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101ef560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 52.309990882873535, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 32.1, "ram_util_percent": 59.4}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.82, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 7.0}, "policy_reward_mean": {"policy0": -14.71, "policy1": -18.11}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, 14.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, 7.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3072485394164765, "mean_inference_ms": 1.7269345715511504, "mean_action_processing_ms": 0.11835280982842367, "mean_env_wait_ms": 0.07378656121867866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 13737, "timesteps_this_iter": 32, "agent_timesteps_total": 27474, "timers": {"load_time_ms": 0.443, "load_throughput": 72214.424, "learn_time_ms": 7.492, "learn_throughput": 4271.185, "update_time_ms": 4.684}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.8909912109375, "min_q": -70.7863998413086, "max_q": -64.12177276611328, "mean_td_error": -2.6645188331604004, "model": {}}, "td_error": [0.28206634521484375, -0.7227935791015625, -1.954132080078125, -0.19159317016601562, 0.384674072265625, -1.8006439208984375, 1.6632919311523438, -1.7525787353515625, -1.0365066528320312, -2.2712478637695312, -1.8401870727539062, -1.66302490234375, -2.1742095947265625, -0.2634735107421875, -0.5849151611328125, -1.5501174926757812, -0.53839111328125, -4.4686431884765625, 1.5449600219726562, 1.0915374755859375, 1.9672470092773438, -0.9049453735351562, -1.7160568237304688, 2.08770751953125, -1.3555145263671875, -67.16151428222656, 0.1260833740234375, 0.32778167724609375, 1.4901580810546875, -0.29212188720703125, -1.5834579467773438, -0.40404510498046875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.33702850341797, "min_q": -67.2612075805664, "max_q": -54.98836135864258, "mean_td_error": -12.165468215942383, "model": {}}, "td_error": [0.641082763671875, -1.2483749389648438, -1.9446334838867188, -0.92645263671875, -0.736114501953125, -0.6845550537109375, -8.354812622070312, -0.208709716796875, -65.2918701171875, -53.98836135864258, 0.2267303466796875, -0.8894500732421875, -0.6445388793945312, 0.305084228515625, -8.223827362060547, 1.2777175903320312, 0.38968658447265625, -64.61859893798828, -62.86424255371094, 0.13561630249023438, 0.5979576110839844, -0.5386848449707031, 0.49156951904296875, -61.718658447265625, 0.2504730224609375, 1.2407989501953125, -0.36627197265625, 1.9065399169921875, -65.90363311767578, 0.19762420654296875, -0.02434539794921875, 2.2202835083007812], "custom_metrics": {}}}, "num_steps_sampled": 13737, "num_agent_steps_sampled": 27474, "num_steps_trained": 22560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 45120, "last_target_update_ts": 13697, "num_target_updates": 114}, "done": false, "episodes_total": 769, "training_iteration": 42, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-01", "timestamp": 1648811761, "time_this_iter_s": 1.0728647708892822, "time_total_s": 53.38285565376282, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 53.38285565376282, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 59.45}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.78, "episode_len_mean": 19.69, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 9.0}, "policy_reward_mean": {"policy0": -15.09, "policy1": -17.69}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -10.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 15, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, 5.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -15.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30722132822098774, "mean_inference_ms": 1.7266730041018659, "mean_action_processing_ms": 0.1183677293832406, "mean_env_wait_ms": 0.07380192825317851, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14048, "timesteps_this_iter": 32, "agent_timesteps_total": 28096, "timers": {"load_time_ms": 0.457, "load_throughput": 69959.723, "learn_time_ms": 7.741, "learn_throughput": 4133.821, "update_time_ms": 4.684}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.95639038085938, "min_q": -67.92323303222656, "max_q": -63.39917755126953, "mean_td_error": -1.330792784690857, "model": {}}, "td_error": [1.3632125854492188, 1.1152153015136719, -0.608245849609375, 1.0516281127929688, 1.7831954956054688, -0.2432708740234375, 1.3049163818359375, 0.5701980590820312, 0.7539901733398438, 1.0881080627441406, 1.6195602416992188, 0.28708648681640625, 1.6189727783203125, -8.933597564697266, -63.03794860839844, 0.303192138671875, 1.0805130004882812, 1.02020263671875, 0.8881149291992188, 0.21128082275390625, 1.2748870849609375, 0.510955810546875, 1.3526229858398438, 0.42816925048828125, 1.788787841796875, 1.2128753662109375, 1.6256637573242188, 0.7059173583984375, 1.418701171875, 0.9326171875, 1.6946334838867188, 1.2324752807617188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.23649978637695, "min_q": -66.16478729248047, "max_q": -55.98197937011719, "mean_td_error": -4.350413799285889, "model": {}}, "td_error": [-0.7502555847167969, 0.19962692260742188, 0.06171417236328125, -1.4840774536132812, -0.3188629150390625, -61.58082580566406, -0.7065963745117188, -1.4698982238769531, 2.8738441467285156, -1.1554946899414062, -1.1333694458007812, 0.595733642578125, -6.929328918457031, -0.22418212890625, -0.8682479858398438, 3.8067169189453125, -0.6652145385742188, -0.6825332641601562, -0.9308967590332031, -0.5618133544921875, -0.7400970458984375, -0.08104705810546875, -0.4561920166015625, -0.68402099609375, -0.21712493896484375, -0.6856422424316406, 0.04669189453125, 0.533355712890625, -0.0538482666015625, 0.45838165283203125, -0.6640548706054688, -64.74568176269531], "custom_metrics": {}}}, "num_steps_sampled": 14048, "num_agent_steps_sampled": 28096, "num_steps_trained": 23072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 46144, "last_target_update_ts": 14048, "num_target_updates": 117}, "done": false, "episodes_total": 785, "training_iteration": 43, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-03", "timestamp": 1648811763, "time_this_iter_s": 1.139040231704712, "time_total_s": 54.52189588546753, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101be200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 54.52189588546753, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 31.0, "ram_util_percent": 59.5}}
{"episode_reward_max": 14.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.92, "episode_len_mean": 19.61, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -15.41, "policy1": -17.51}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, 14.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 3, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, 7.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 7.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30713215411607203, "mean_inference_ms": 1.7258566742450014, "mean_action_processing_ms": 0.11834931811515359, "mean_env_wait_ms": 0.07379568216887276, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14355, "timesteps_this_iter": 32, "agent_timesteps_total": 28710, "timers": {"load_time_ms": 0.459, "load_throughput": 69690.912, "learn_time_ms": 8.657, "learn_throughput": 3696.236, "update_time_ms": 5.421}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.61758422851562, "min_q": -69.47551727294922, "max_q": -65.27103424072266, "mean_td_error": -2.5787906646728516, "model": {}}, "td_error": [-1.340667724609375, -0.5083999633789062, -0.3073577880859375, -0.36037445068359375, 0.4489898681640625, -8.806930541992188, -0.2238006591796875, -0.34494781494140625, -0.8365707397460938, -0.6911392211914062, 0.128997802734375, -0.75408935546875, -0.6689529418945312, -0.5268096923828125, -0.6596450805664062, -0.23001861572265625, -0.6926956176757812, 0.38697052001953125, -0.8735122680664062, -0.68304443359375, -0.06056976318359375, -0.6858444213867188, -0.00789642333984375, 0.436248779296875, -0.482513427734375, 0.38079071044921875, 0.08423614501953125, -64.35054016113281, -0.3297119140625, -0.15703582763671875, 0.46689605712890625, -0.2713623046875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.3930778503418, "min_q": -65.37832641601562, "max_q": -56.20799255371094, "mean_td_error": -7.566088676452637, "model": {}}, "td_error": [0.32907867431640625, -0.5189437866210938, -1.2795867919921875, -0.509979248046875, -0.304718017578125, 0.6051864624023438, -0.5117111206054688, 0.2907257080078125, -0.3820762634277344, 0.3674964904785156, 0.049007415771484375, 0.2532958984375, 0.11809158325195312, 0.21615982055664062, -0.6601028442382812, 0.5894317626953125, 0.577301025390625, 0.7506256103515625, 0.4399833679199219, 0.94110107421875, -63.961753845214844, 0.227020263671875, -60.78086853027344, 0.8172569274902344, -63.77815246582031, 0.2527313232421875, -0.4360160827636719, -0.6696548461914062, 0.07154083251953125, -55.20799255371094, 0.04148101806640625, -0.0507965087890625], "custom_metrics": {}}}, "num_steps_sampled": 14355, "num_agent_steps_sampled": 28710, "num_steps_trained": 23584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 47168, "last_target_update_ts": 14275, "num_target_updates": 119}, "done": false, "episodes_total": 801, "training_iteration": 44, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-04", "timestamp": 1648811764, "time_this_iter_s": 1.344846487045288, "time_total_s": 55.86674237251282, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef10267e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef10267e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 55.86674237251282, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 32.45, "ram_util_percent": 59.5}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.1, "episode_len_mean": 19.65, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -15.85, "policy1": -17.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30707639375715684, "mean_inference_ms": 1.7253973969550793, "mean_action_processing_ms": 0.11835524090545561, "mean_env_wait_ms": 0.07378981546752383, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14662, "timesteps_this_iter": 32, "agent_timesteps_total": 29324, "timers": {"load_time_ms": 0.414, "load_throughput": 77309.906, "learn_time_ms": 7.457, "learn_throughput": 4291.369, "update_time_ms": 4.682}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.524169921875, "min_q": -67.37167358398438, "max_q": -65.82879638671875, "mean_td_error": -0.4208188056945801, "model": {}}, "td_error": [0.6931610107421875, 0.8508987426757812, -0.8996124267578125, 0.00043487548828125, 0.7117919921875, -0.0603790283203125, -0.3138885498046875, 0.04476165771484375, -0.209320068359375, 0.7201766967773438, 0.8672714233398438, -0.33390045166015625, -0.27762603759765625, -10.628555297851562, -10.325096130371094, 0.793853759765625, 0.0980072021484375, 0.2436676025390625, 0.742645263671875, 0.6807861328125, 0.1892547607421875, -0.0927276611328125, 0.31792449951171875, 0.5413436889648438, 1.1933670043945312, 1.0618820190429688, 0.184234619140625, 0.020660400390625, -0.46349334716796875, -0.16046905517578125, -0.548919677734375, 0.89166259765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.23448181152344, "min_q": -67.3487548828125, "max_q": -58.198211669921875, "mean_td_error": -4.982745170593262, "model": {}}, "td_error": [0.77569580078125, -1.0929794311523438, -57.198211669921875, -0.22119903564453125, -0.7501564025878906, -1.6016044616699219, -0.3446044921875, -0.4303016662597656, -1.0133056640625, -1.1926841735839844, -0.4579315185546875, -1.6095809936523438, -0.9784660339355469, -1.8491325378417969, -0.8847846984863281, -0.2982635498046875, -0.0156707763671875, -1.3926315307617188, -65.78487396240234, -5.9460601806640625, -1.1668701171875, -0.437957763671875, -0.688751220703125, -0.48564910888671875, -1.8669204711914062, -0.33425140380859375, -1.1668701171875, -7.1994781494140625, -0.8182296752929688, -1.2574119567871094, -0.9411506652832031, -0.7975502014160156], "custom_metrics": {}}}, "num_steps_sampled": 14662, "num_agent_steps_sampled": 29324, "num_steps_trained": 24096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48192, "last_target_update_ts": 14622, "num_target_updates": 122}, "done": false, "episodes_total": 817, "training_iteration": 45, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-05", "timestamp": 1648811765, "time_this_iter_s": 1.2404859066009521, "time_total_s": 57.10722827911377, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c64d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c64d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 57.10722827911377, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 30.35, "ram_util_percent": 59.5}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -32.8, "episode_len_mean": 19.65, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -15.95, "policy1": -16.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30705946939960443, "mean_inference_ms": 1.7251371935841409, "mean_action_processing_ms": 0.11836888514340824, "mean_env_wait_ms": 0.07378382069316022, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 14962, "timesteps_this_iter": 32, "agent_timesteps_total": 29924, "timers": {"load_time_ms": 0.441, "load_throughput": 72636.502, "learn_time_ms": 7.671, "learn_throughput": 4171.75, "update_time_ms": 4.812}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.45256042480469, "min_q": -67.85787963867188, "max_q": -64.81749725341797, "mean_td_error": -4.748434066772461, "model": {}}, "td_error": [-0.9738922119140625, -0.15258026123046875, 0.0527191162109375, -0.31096649169921875, -66.85787963867188, -66.7543716430664, -0.10387420654296875, -0.13341522216796875, -0.6331787109375, -0.8119049072265625, -0.004364013671875, 0.15308380126953125, 0.5073471069335938, -0.35813140869140625, -0.33472442626953125, -0.438232421875, -0.9835891723632812, 0.254364013671875, -1.0425796508789062, -0.149505615234375, -0.7910690307617188, -0.23529052734375, -1.2432632446289062, 0.009979248046875, -0.121002197265625, 0.342803955078125, 0.5937576293945312, -0.45418548583984375, 0.7364044189453125, -11.293861389160156, -0.6693496704101562, 0.25086212158203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.95700454711914, "min_q": -67.00733184814453, "max_q": -57.979087829589844, "mean_td_error": -4.647558689117432, "model": {}}, "td_error": [-67.13084411621094, -0.3223915100097656, 0.1177215576171875, 0.5125045776367188, -0.5318870544433594, -0.7365455627441406, 0.179412841796875, -0.6466865539550781, -1.0355987548828125, 0.21900177001953125, 0.5445976257324219, -0.4537239074707031, -5.9246826171875, -0.4179534912109375, 0.49745941162109375, -1.2458229064941406, -63.667518615722656, -0.7682228088378906, -0.3244781494140625, 0.0536651611328125, -0.01617431640625, 0.222869873046875, -0.6920318603515625, -0.5419464111328125, -0.18987274169921875, 0.32039642333984375, 0.30097198486328125, -0.17460250854492188, -0.6133003234863281, 0.2540130615234375, -0.11966705322265625, -6.390541076660156], "custom_metrics": {}}}, "num_steps_sampled": 14962, "num_agent_steps_sampled": 29924, "num_steps_trained": 24576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 49152, "last_target_update_ts": 14862, "num_target_updates": 124}, "done": false, "episodes_total": 832, "training_iteration": 46, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-07", "timestamp": 1648811767, "time_this_iter_s": 1.1069059371948242, "time_total_s": 58.214134216308594, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 58.214134216308594, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 59.5}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.5, "episode_len_mean": 19.65, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -16.65, "policy1": -16.85}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30714023193969325, "mean_inference_ms": 1.725695064563931, "mean_action_processing_ms": 0.11843132833077204, "mean_env_wait_ms": 0.07379484745723684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15262, "timesteps_this_iter": 32, "agent_timesteps_total": 30524, "timers": {"load_time_ms": 0.454, "load_throughput": 70533.253, "learn_time_ms": 8.113, "learn_throughput": 3944.402, "update_time_ms": 5.087}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.76676940917969, "min_q": -69.98783111572266, "max_q": -67.87875366210938, "mean_td_error": -3.5853137969970703, "model": {}}, "td_error": [-2.0646209716796875, -0.6027984619140625, -2.4870986938476562, -1.789031982421875, -1.5286636352539062, -0.5741043090820312, -2.1049652099609375, -1.2815322875976562, -2.1875152587890625, -1.4166030883789062, -0.4812774658203125, -1.6333084106445312, -2.181121826171875, -0.26363372802734375, -1.7763900756835938, -0.8466110229492188, -1.5998458862304688, -1.8570098876953125, -67.5067138671875, -0.6778640747070312, -1.58074951171875, -0.9383544921875, -1.4538803100585938, -0.8292007446289062, -1.8787460327148438, -1.6351394653320312, -0.6538009643554688, -1.9508056640625, -1.9409332275390625, -2.020416259765625, -2.2284622192382812, -2.7588424682617188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.747833251953125, "min_q": -65.99185943603516, "max_q": -58.91916275024414, "mean_td_error": -3.487910509109497, "model": {}}, "td_error": [-0.28896331787109375, 0.36505889892578125, 0.401092529296875, -68.19357299804688, 0.04644775390625, 0.9647674560546875, 0.15555572509765625, 0.6423797607421875, -0.29656219482421875, 0.6385726928710938, 0.4240760803222656, -0.20398330688476562, 1.4489326477050781, 0.7178878784179688, 1.2519416809082031, 0.7609367370605469, 1.2058334350585938, -0.3387489318847656, 1.0519065856933594, -0.8317451477050781, 0.5465545654296875, 0.3547706604003906, 0.03542327880859375, 0.4841270446777344, 1.3417282104492188, 4.439960479736328, 1.1176338195800781, 0.9622001647949219, 1.1650924682617188, -0.37657928466796875, 0.6060981750488281, -62.21196365356445], "custom_metrics": {}}}, "num_steps_sampled": 15262, "num_agent_steps_sampled": 30524, "num_steps_trained": 25056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 50112, "last_target_update_ts": 15222, "num_target_updates": 127}, "done": false, "episodes_total": 847, "training_iteration": 47, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-08", "timestamp": 1648811768, "time_this_iter_s": 1.218806505203247, "time_total_s": 59.43294072151184, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 59.43294072151184, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 59.5}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.6, "episode_len_mean": 19.65, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -17.15, "policy1": -16.45}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 11, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -10.0, 9.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3072928896919628, "mean_inference_ms": 1.7269631480178633, "mean_action_processing_ms": 0.11853972643443368, "mean_env_wait_ms": 0.07382984038387835, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15562, "timesteps_this_iter": 32, "agent_timesteps_total": 31124, "timers": {"load_time_ms": 0.456, "load_throughput": 70179.204, "learn_time_ms": 8.003, "learn_throughput": 3998.443, "update_time_ms": 4.96}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.98738098144531, "min_q": -64.96314239501953, "max_q": -63.25566864013672, "mean_td_error": -5.322452068328857, "model": {}}, "td_error": [1.0243949890136719, 0.8252677917480469, 0.21996307373046875, 1.9477729797363281, 1.00555419921875, -0.43511199951171875, 0.5671005249023438, -0.3618354797363281, 1.173553466796875, 0.390838623046875, 0.5692825317382812, 1.5193901062011719, 0.0707550048828125, 0.3592376708984375, -0.3400230407714844, 1.0205230712890625, 1.1751174926757812, 0.45883941650390625, 0.18297576904296875, 0.8252677917480469, 1.9914016723632812, 0.12323760986328125, 0.8290176391601562, 0.49237060546875, 0.6624908447265625, -63.575050354003906, -63.76983642578125, -0.16823577880859375, -63.307594299316406, 1.02667236328125, 1.8371429443359375, 1.3410491943359375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.57133483886719, "min_q": -67.06127166748047, "max_q": -59.22972106933594, "mean_td_error": -1.8385623693466187, "model": {}}, "td_error": [1.4880180358886719, 0.599822998046875, 0.4912528991699219, 1.0796051025390625, 0.47109222412109375, 0.07498550415039062, 1.7631187438964844, 2.8591766357421875, 0.3532981872558594, 0.9455757141113281, -6.8691558837890625, -70.74685668945312, -0.15833282470703125, 1.5707778930664062, 0.8837661743164062, 0.67279052734375, 1.1576766967773438, 0.8119354248046875, -0.07283782958984375, 0.4100494384765625, 1.2616615295410156, -2.964588165283203, 1.4435462951660156, 0.7299461364746094, 0.0357208251953125, -0.215576171875, 0.712860107421875, 1.323760986328125, 0.488189697265625, -0.629241943359375, 1.5992202758789062, -0.4052581787109375], "custom_metrics": {}}}, "num_steps_sampled": 15562, "num_agent_steps_sampled": 31124, "num_steps_trained": 25536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 51072, "last_target_update_ts": 15462, "num_target_updates": 129}, "done": false, "episodes_total": 862, "training_iteration": 48, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-09", "timestamp": 1648811769, "time_this_iter_s": 1.1792726516723633, "time_total_s": 60.612213373184204, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d1a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 60.612213373184204, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 30.95, "ram_util_percent": 59.6}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -33.98, "episode_len_mean": 19.74, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -16.94, "policy1": -17.04}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3074736363322435, "mean_inference_ms": 1.728662974180718, "mean_action_processing_ms": 0.11868151102183855, "mean_env_wait_ms": 0.07387936612452395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 15862, "timesteps_this_iter": 32, "agent_timesteps_total": 31724, "timers": {"load_time_ms": 0.427, "load_throughput": 74931.737, "learn_time_ms": 7.625, "learn_throughput": 4196.927, "update_time_ms": 4.761}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -65.24050903320312, "min_q": -66.79238891601562, "max_q": -63.56904220581055, "mean_td_error": -6.912854194641113, "model": {}}, "td_error": [-0.7184219360351562, -0.24143218994140625, 1.0270919799804688, -64.28913879394531, 0.1319427490234375, 0.504791259765625, -0.8019790649414062, 0.2783966064453125, -0.6492080688476562, -0.1795196533203125, 0.43556976318359375, -0.267486572265625, 0.4459877014160156, -0.39600372314453125, -0.03551483154296875, -0.7525787353515625, -1.4904022216796875, -0.9038963317871094, -0.42501068115234375, -9.585346221923828, -0.170928955078125, -64.577392578125, -9.592449188232422, -65.79238891601562, -0.6188278198242188, 0.22342681884765625, -0.484283447265625, -0.15814971923828125, -0.49492645263671875, 0.8278961181640625, -0.6636962890625, -1.7974624633789062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -62.86228561401367, "min_q": -65.41378021240234, "max_q": -57.19341278076172, "mean_td_error": -2.94106388092041, "model": {}}, "td_error": [-63.23262023925781, 1.5940284729003906, 1.9884185791015625, 2.219940185546875, 1.3088607788085938, 1.4982337951660156, 1.7739486694335938, 1.2750091552734375, 1.1612091064453125, 1.4479789733886719, 1.3972358703613281, 1.6822509765625, 1.7396011352539062, 1.803680419921875, 1.9210319519042969, 2.1159210205078125, 1.4118499755859375, 2.2298355102539062, 0.45201873779296875, 2.152984619140625, 1.93243408203125, 1.6652069091796875, 0.8623428344726562, 1.5288467407226562, -5.9249114990234375, 0.9586257934570312, 1.5930671691894531, 1.7356948852539062, 1.0968856811523438, 0.6183395385742188, -61.79167938232422, -6.330314636230469], "custom_metrics": {}}}, "num_steps_sampled": 15862, "num_agent_steps_sampled": 31724, "num_steps_trained": 26016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52032, "last_target_update_ts": 15822, "num_target_updates": 132}, "done": false, "episodes_total": 877, "training_iteration": 49, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-10", "timestamp": 1648811770, "time_this_iter_s": 1.1463758945465088, "time_total_s": 61.75858926773071, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efa70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 61.75858926773071, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 30.2, "ram_util_percent": 59.6}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -34.48, "episode_len_mean": 19.74, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -7.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -17.34, "policy1": -17.14}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, 6.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, 6.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0], "episode_lengths": [20, 20, 7, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -7.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -7.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, 13.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, 13.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.307699311531481, "mean_inference_ms": 1.7307412946497245, "mean_action_processing_ms": 0.11884750226487079, "mean_env_wait_ms": 0.07394022867154199, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16162, "timesteps_this_iter": 32, "agent_timesteps_total": 32324, "timers": {"load_time_ms": 0.447, "load_throughput": 71544.631, "learn_time_ms": 8.498, "learn_throughput": 3765.76, "update_time_ms": 5.647}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.86095428466797, "min_q": -65.70736694335938, "max_q": -62.212406158447266, "mean_td_error": 2.0004966259002686, "model": {}}, "td_error": [3.4071807861328125, 1.5128097534179688, 1.28448486328125, 1.3609237670898438, 1.5805435180664062, 2.103252410888672, 1.7797470092773438, 2.9673614501953125, 0.76031494140625, 2.8701705932617188, 1.8328323364257812, 1.6775588989257812, 2.305206298828125, 2.595428466796875, 1.691009521484375, 1.2238082885742188, 2.4841995239257812, 1.5397224426269531, 1.1106414794921875, 1.6775588989257812, 1.7405242919921875, 1.9621734619140625, 2.494739532470703, 3.2573204040527344, 1.9178047180175781, 1.0482177734375, 2.8534202575683594, 3.1819000244140625, 1.294158935546875, 1.9496612548828125, 1.8458023071289062, 2.705413818359375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.03361511230469, "min_q": -67.65902709960938, "max_q": -56.96846008300781, "mean_td_error": -3.7417097091674805, "model": {}}, "td_error": [-6.875087738037109, 0.6395721435546875, 0.5231552124023438, 1.9992828369140625, 0.3691520690917969, -0.1581268310546875, -0.19536590576171875, 0.6261253356933594, -0.35103607177734375, 1.1300811767578125, 0.7127418518066406, 0.5272674560546875, 1.2727737426757812, 0.20729827880859375, -0.39206695556640625, 0.3632164001464844, -0.51531982421875, -55.96846008300781, -0.7480850219726562, -0.1285552978515625, 0.9354934692382812, -0.1883697509765625, 0.19355010986328125, 0.228973388671875, -0.47957611083984375, -1.416229248046875, -0.0807647705078125, 0.71563720703125, 0.079925537109375, 0.38428497314453125, -63.23455810546875, 0.08835601806640625], "custom_metrics": {}}}, "num_steps_sampled": 16162, "num_agent_steps_sampled": 32324, "num_steps_trained": 26496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 52992, "last_target_update_ts": 16062, "num_target_updates": 134}, "done": false, "episodes_total": 892, "training_iteration": 50, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-12", "timestamp": 1648811772, "time_this_iter_s": 1.287447452545166, "time_total_s": 63.04603672027588, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101df3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101df3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 63.04603672027588, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 59.6}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.7, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -17.9, "policy1": -17.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3078186342840722, "mean_inference_ms": 1.7321250122413634, "mean_action_processing_ms": 0.11896414950364498, "mean_env_wait_ms": 0.073978261036271, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16462, "timesteps_this_iter": 32, "agent_timesteps_total": 32924, "timers": {"load_time_ms": 0.414, "load_throughput": 77247.613, "learn_time_ms": 7.601, "learn_throughput": 4210.237, "update_time_ms": 4.486}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.51203918457031, "min_q": -70.13712310791016, "max_q": -67.07151794433594, "mean_td_error": -1.4822204113006592, "model": {}}, "td_error": [-2.9038467407226562, -1.1966552734375, -1.7908935546875, -1.3519439697265625, -1.3490982055664062, -1.4998703002929688, -1.5561676025390625, -1.4772796630859375, -1.2091903686523438, -1.6783828735351562, -0.7696533203125, -1.3124237060546875, -1.8427886962890625, -0.8876266479492188, -1.5828094482421875, -1.9839096069335938, -1.176971435546875, -2.0843048095703125, -0.6826400756835938, -1.99066162109375, -3.4487075805664062, -0.8382492065429688, -2.08087158203125, -1.1965103149414062, -1.5895004272460938, -1.2116775512695312, 0.0077972412109375, -0.4830169677734375, -1.8928909301757812, -1.3193893432617188, -1.59918212890625, -1.4517364501953125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.34107971191406, "min_q": -68.13311004638672, "max_q": -59.78068923950195, "mean_td_error": -6.689605236053467, "model": {}}, "td_error": [-0.75054931640625, -1.45367431640625, -0.795684814453125, -0.9407806396484375, -1.002655029296875, -0.573028564453125, -58.97584915161133, -66.06958770751953, -66.1273422241211, -0.38275146484375, -1.1152191162109375, -1.2078514099121094, 0.03815460205078125, -1.3847198486328125, -0.7529449462890625, -0.6305923461914062, -0.3217010498046875, -0.86376953125, -0.5805740356445312, -1.7315673828125, -1.0781097412109375, -1.1270065307617188, -0.32280731201171875, -0.75054931640625, -0.7132186889648438, -0.9474601745605469, -0.4719390869140625, -0.6267318725585938, -0.2391357421875, -0.215423583984375, -0.6347999572753906, -1.3174972534179688], "custom_metrics": {}}}, "num_steps_sampled": 16462, "num_agent_steps_sampled": 32924, "num_steps_trained": 26976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 53952, "last_target_update_ts": 16422, "num_target_updates": 137}, "done": false, "episodes_total": 907, "training_iteration": 51, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-13", "timestamp": 1648811773, "time_this_iter_s": 1.132995843887329, "time_total_s": 64.17903256416321, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101d17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 64.17903256416321, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 32.75, "ram_util_percent": 59.6}}
{"episode_reward_max": 2.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.28, "episode_len_mean": 19.89, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 1.0, "policy1": 1.0}, "policy_reward_mean": {"policy0": -17.89, "policy1": -17.39}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30790609144278064, "mean_inference_ms": 1.7335519498430556, "mean_action_processing_ms": 0.11908361508390138, "mean_env_wait_ms": 0.07401811445046502, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 16771, "timesteps_this_iter": 32, "agent_timesteps_total": 33542, "timers": {"load_time_ms": 0.411, "load_throughput": 77929.355, "learn_time_ms": 7.979, "learn_throughput": 4010.666, "update_time_ms": 4.96}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.18880462646484, "min_q": -68.28987884521484, "max_q": -66.24108123779297, "mean_td_error": 0.5492582321166992, "model": {}}, "td_error": [0.5187759399414062, -0.101348876953125, 2.1944198608398438, 0.662933349609375, 0.4110870361328125, 0.6149749755859375, 1.062713623046875, -0.9948272705078125, -0.3407440185546875, 0.356781005859375, 0.19969940185546875, 1.2841720581054688, 0.00319671630859375, 0.5476608276367188, 1.2836685180664062, 0.965484619140625, -0.13816070556640625, 0.9127044677734375, -0.23796844482421875, 1.3947067260742188, 0.9227523803710938, 1.2172622680664062, 0.5427780151367188, 0.6134719848632812, 0.4949493408203125, 0.4615325927734375, 0.432342529296875, 0.1269378662109375, 0.40312957763671875, 1.21697998046875, 0.09777069091796875, 0.4464263916015625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.10755920410156, "min_q": -66.65866088867188, "max_q": -59.231380462646484, "mean_td_error": -0.8572815656661987, "model": {}}, "td_error": [-0.8921356201171875, 0.13740158081054688, -0.0026702880859375, -0.29376220703125, 0.13683319091796875, -0.7336654663085938, -1.0009040832519531, -7.615478515625, 0.5972671508789062, -0.20540618896484375, -0.6349868774414062, 0.28383636474609375, -0.23180389404296875, 1.5588302612304688, -1.1146774291992188, -0.2915077209472656, -1.0161781311035156, -0.6700210571289062, -0.17476654052734375, 0.17871856689453125, -0.36285400390625, -8.289741516113281, -5.3450164794921875, 0.056854248046875, 1.439666748046875, -1.3318061828613281, 0.119476318359375, -0.5655288696289062, -0.5072860717773438, 0.3383522033691406, -1.0706443786621094, 0.07059478759765625], "custom_metrics": {}}}, "num_steps_sampled": 16771, "num_agent_steps_sampled": 33542, "num_steps_trained": 27488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54976, "last_target_update_ts": 16771, "num_target_updates": 140}, "done": false, "episodes_total": 923, "training_iteration": 52, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-14", "timestamp": 1648811774, "time_this_iter_s": 1.2101223468780518, "time_total_s": 65.38915491104126, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 65.38915491104126, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.6}}
{"episode_reward_max": 2.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.88, "episode_len_mean": 19.89, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 1.0, "policy1": 1.0}, "policy_reward_mean": {"policy0": -18.39, "policy1": -17.49}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30797359876621416, "mean_inference_ms": 1.7348174316775067, "mean_action_processing_ms": 0.11919212067005157, "mean_env_wait_ms": 0.07404584317547201, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17071, "timesteps_this_iter": 32, "agent_timesteps_total": 34142, "timers": {"load_time_ms": 0.434, "load_throughput": 73721.701, "learn_time_ms": 8.221, "learn_throughput": 3892.355, "update_time_ms": 5.102}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.54782104492188, "min_q": -69.80731964111328, "max_q": -65.67092895507812, "mean_td_error": -4.281747817993164, "model": {}}, "td_error": [0.48000335693359375, 0.75732421875, 0.9536361694335938, 0.7434616088867188, 0.00691986083984375, -0.6888046264648438, 0.07570648193359375, 0.14817047119140625, -0.26056671142578125, -0.26256561279296875, -0.6894302368164062, -0.5133590698242188, -2.0888595581054688, -68.80731964111328, -0.266571044921875, 0.3612213134765625, -0.046600341796875, 0.0490570068359375, -0.7133941650390625, 0.975433349609375, -64.71226501464844, -1.6188583374023438, -0.789886474609375, 0.06822967529296875, 0.8729705810546875, -0.5444717407226562, -0.7133941650390625, 0.21442413330078125, -0.10082244873046875, -0.0165252685546875, -0.10535430908203125, 0.2165679931640625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.45628356933594, "min_q": -66.96089172363281, "max_q": -57.36570739746094, "mean_td_error": -3.778566837310791, "model": {}}, "td_error": [1.3404426574707031, 0.50567626953125, 0.576629638671875, 0.5210800170898438, 0.27947235107421875, -0.28005218505859375, -63.733184814453125, 0.37416839599609375, 0.9889869689941406, 0.43541717529296875, 0.22646331787109375, -0.102142333984375, -0.42412567138671875, 0.41437530517578125, 0.9465599060058594, 0.09880828857421875, 0.436248779296875, 0.422149658203125, 0.8558502197265625, 1.3092384338378906, -0.37580108642578125, 0.5508575439453125, -0.46532440185546875, -0.28856658935546875, -62.848846435546875, -5.177886962890625, 0.583221435546875, 0.35540771484375, -0.5787811279296875, 0.9828033447265625, 0.601470947265625, 0.5552444458007812], "custom_metrics": {}}}, "num_steps_sampled": 17071, "num_agent_steps_sampled": 34142, "num_steps_trained": 27968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 55936, "last_target_update_ts": 17011, "num_target_updates": 142}, "done": false, "episodes_total": 938, "training_iteration": 53, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-15", "timestamp": 1648811775, "time_this_iter_s": 1.1491048336029053, "time_total_s": 66.53825974464417, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fbd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fbd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 66.53825974464417, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 30.8, "ram_util_percent": 59.6}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.1, "episode_len_mean": 19.65, "episode_media": {}, "episodes_this_iter": 17, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 1.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -17.95, "policy1": -17.15}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3080433703495433, "mean_inference_ms": 1.736063632477776, "mean_action_processing_ms": 0.11930302471430462, "mean_env_wait_ms": 0.0740655270809207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17387, "timesteps_this_iter": 32, "agent_timesteps_total": 34774, "timers": {"load_time_ms": 0.467, "load_throughput": 68562.387, "learn_time_ms": 8.132, "learn_throughput": 3935.081, "update_time_ms": 4.769}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.2440185546875, "min_q": -68.43956756591797, "max_q": -64.89183807373047, "mean_td_error": -1.4513607025146484, "model": {}}, "td_error": [1.3719635009765625, 1.9303741455078125, 0.443603515625, 1.0292205810546875, 0.25560760498046875, 1.7573776245117188, 0.8711929321289062, -6.599891662597656, 1.2528305053710938, 0.6703948974609375, 0.9261627197265625, 1.24700927734375, 0.9783706665039062, 1.6655120849609375, 1.1937484741210938, -7.127754211425781, 1.67718505859375, 0.8323745727539062, 0.46730804443359375, 0.9151611328125, 1.1772537231445312, 1.4476394653320312, 1.11181640625, 0.6477432250976562, 1.25396728515625, 0.874725341796875, 1.4489059448242188, 0.84967041015625, 0.878814697265625, 0.738677978515625, -63.89183807373047, 1.2613296508789062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.47269439697266, "min_q": -65.94815826416016, "max_q": -59.01746368408203, "mean_td_error": -1.4789021015167236, "model": {}}, "td_error": [0.436370849609375, 1.0351409912109375, 0.7357559204101562, -68.58612060546875, 0.35036468505859375, 1.0351409912109375, 0.1063079833984375, 0.8139495849609375, 1.0038528442382812, 0.5614852905273438, 0.9581680297851562, 1.1293563842773438, 1.141143798828125, 1.200225830078125, 0.7296981811523438, 0.92388916015625, 0.9044876098632812, 0.3362579345703125, 1.1073226928710938, -0.32132720947265625, 0.5401992797851562, 0.19219207763671875, 1.418853759765625, -0.3517913818359375, 0.6944656372070312, 0.4491729736328125, 0.4141998291015625, 0.8723373413085938, 0.7735519409179688, 0.3914642333984375, 0.582763671875, 1.09625244140625], "custom_metrics": {}}}, "num_steps_sampled": 17387, "num_agent_steps_sampled": 34774, "num_steps_trained": 28512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 57024, "last_target_update_ts": 17347, "num_target_updates": 145}, "done": false, "episodes_total": 955, "training_iteration": 54, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-17", "timestamp": 1648811777, "time_this_iter_s": 1.2738456726074219, "time_total_s": 67.81210541725159, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 67.81210541725159, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 30.85, "ram_util_percent": 59.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -34.38, "episode_len_mean": 19.49, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -17.49, "policy1": -16.89}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30812646091839996, "mean_inference_ms": 1.7372004042507898, "mean_action_processing_ms": 0.1194008670565751, "mean_env_wait_ms": 0.07407746169544716, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17691, "timesteps_this_iter": 32, "agent_timesteps_total": 35382, "timers": {"load_time_ms": 0.435, "load_throughput": 73543.961, "learn_time_ms": 7.868, "learn_throughput": 4066.896, "update_time_ms": 5.086}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.01862335205078, "min_q": -73.185546875, "max_q": -67.58438110351562, "mean_td_error": -3.298466444015503, "model": {}}, "td_error": [-0.8498306274414062, -1.0848541259765625, -0.6150665283203125, -0.02811431884765625, 0.07430267333984375, -1.4709243774414062, -1.379974365234375, -1.112548828125, 0.326416015625, -0.396240234375, 0.8323974609375, -0.30312347412109375, -0.0525054931640625, 0.3073883056640625, -1.1601333618164062, -1.4235992431640625, -0.293365478515625, -0.944183349609375, -0.017425537109375, -0.5822525024414062, -7.902809143066406, 0.3100433349609375, -0.6932220458984375, -0.7790908813476562, -0.9546661376953125, -0.6553955078125, 0.30460357666015625, -0.362274169921875, -1.6518402099609375, -71.51246643066406, -11.478202819824219, -0.0019683837890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.25433349609375, "min_q": -65.94108581542969, "max_q": -58.41928482055664, "mean_td_error": -7.103594779968262, "model": {}}, "td_error": [0.579559326171875, 1.668548583984375, 0.42086029052734375, 0.5819244384765625, 0.9135589599609375, 0.6518478393554688, 0.5908279418945312, 1.3523826599121094, 0.9426040649414062, -63.21062469482422, 0.7396621704101562, 0.5067062377929688, 1.0637664794921875, 1.254180908203125, -58.00992965698242, -67.55656433105469, -62.98461151123047, 0.37963104248046875, 0.6193504333496094, 1.0342559814453125, 1.20220947265625, 1.1870346069335938, 1.2465019226074219, 1.0710792541503906, 0.325836181640625, 0.7512626647949219, 0.0191650390625, 1.4545059204101562, 0.9127197265625, 0.8680419921875, 1.1105690002441406, 0.9980926513671875], "custom_metrics": {}}}, "num_steps_sampled": 17691, "num_agent_steps_sampled": 35382, "num_steps_trained": 29024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 58048, "last_target_update_ts": 17691, "num_target_updates": 148}, "done": false, "episodes_total": 971, "training_iteration": 55, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-18", "timestamp": 1648811778, "time_this_iter_s": 1.2050542831420898, "time_total_s": 69.01715970039368, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 69.01715970039368, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 31.4, "ram_util_percent": 59.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -34.68, "episode_len_mean": 19.49, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -17.89, "policy1": -16.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3081477120184866, "mean_inference_ms": 1.7378637269770523, "mean_action_processing_ms": 0.11945364544299931, "mean_env_wait_ms": 0.0740708927503348, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 17991, "timesteps_this_iter": 32, "agent_timesteps_total": 35982, "timers": {"load_time_ms": 0.422, "load_throughput": 75876.38, "learn_time_ms": 7.803, "learn_throughput": 4101.144, "update_time_ms": 5.115}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.76400756835938, "min_q": -73.58135223388672, "max_q": -70.00225830078125, "mean_td_error": -2.427496910095215, "model": {}}, "td_error": [0.02945709228515625, -0.20989990234375, 0.042572021484375, 0.247039794921875, -1.4280471801757812, -1.2742996215820312, -1.3434982299804688, 1.0226593017578125, -0.6251907348632812, 0.5238800048828125, 0.94805908203125, 0.44020843505859375, -0.785614013671875, -0.212432861328125, 0.03163909912109375, -0.99114990234375, -0.29833221435546875, -1.2652816772460938, -0.7390518188476562, 0.504425048828125, 1.2337417602539062, -0.344573974609375, 0.0290985107421875, -0.8490142822265625, -1.0140380859375, 0.7015533447265625, -70.22554016113281, 0.5092926025390625, -1.0252761840820312, 1.0450439453125, -1.2144775390625, -1.142852783203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.3226318359375, "min_q": -66.63009643554688, "max_q": -59.35578536987305, "mean_td_error": -0.0011208057403564453, "model": {}}, "td_error": [0.6429710388183594, 0.7125358581542969, 0.47623443603515625, 0.01985931396484375, -0.4055023193359375, 1.1493759155273438, 1.0975341796875, 0.203338623046875, 1.1019554138183594, 0.7944564819335938, 0.5399551391601562, 0.6976051330566406, 0.43651580810546875, 0.35736083984375, 0.6614227294921875, 0.59002685546875, 0.39813995361328125, 0.03401947021484375, 0.1537017822265625, 0.443267822265625, -0.6623916625976562, 0.46187591552734375, -0.33092498779296875, 0.932586669921875, 0.7051353454589844, -8.791679382324219, 0.6007308959960938, 1.1174964904785156, 0.07415771484375, -0.1725006103515625, 1.3906326293945312, -5.46575927734375], "custom_metrics": {}}}, "num_steps_sampled": 17991, "num_agent_steps_sampled": 35982, "num_steps_trained": 29504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59008, "last_target_update_ts": 17931, "num_target_updates": 150}, "done": false, "episodes_total": 986, "training_iteration": 56, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-19", "timestamp": 1648811779, "time_this_iter_s": 1.1578397750854492, "time_total_s": 70.17499947547913, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 70.17499947547913, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 29.95, "ram_util_percent": 59.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -34.78, "episode_len_mean": 19.49, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -18.19, "policy1": -16.59}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, 2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, 1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -10.0, 1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.308119948366137, "mean_inference_ms": 1.7382038612434059, "mean_action_processing_ms": 0.11948052938285207, "mean_env_wait_ms": 0.07404986520346162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18291, "timesteps_this_iter": 32, "agent_timesteps_total": 36582, "timers": {"load_time_ms": 0.445, "load_throughput": 71962.752, "learn_time_ms": 7.696, "learn_throughput": 4158.115, "update_time_ms": 4.537}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.1197509765625, "min_q": -74.28549194335938, "max_q": -70.42481231689453, "mean_td_error": -0.056412696838378906, "model": {}}, "td_error": [-0.7168426513671875, 0.07834625244140625, 1.326446533203125, 0.8033523559570312, 0.9661102294921875, -7.567634582519531, 0.35256195068359375, 0.45941925048828125, -0.460906982421875, 0.9306488037109375, 1.35479736328125, 0.9362411499023438, 0.16547393798828125, -7.185218811035156, 0.2200927734375, -0.8963775634765625, 0.5139923095703125, 1.22802734375, 0.7291412353515625, 0.45949554443359375, -0.574951171875, 2.009033203125, 1.3844451904296875, -0.07883453369140625, 0.8739547729492188, -0.432708740234375, -0.01007080078125, 0.3717041015625, 0.419952392578125, 0.0595550537109375, 0.4181976318359375, 0.05735015869140625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.85311126708984, "min_q": -66.80367279052734, "max_q": -60.36444854736328, "mean_td_error": -4.435949325561523, "model": {}}, "td_error": [-0.3107452392578125, 0.18896484375, -0.446380615234375, -0.37310028076171875, -8.30633544921875, -0.022857666015625, -0.0350494384765625, -1.0591354370117188, 0.236328125, -64.64207458496094, 0.08300018310546875, 0.07814788818359375, -0.19130706787109375, -0.250518798828125, -0.02625274658203125, -0.14424896240234375, -0.5251045227050781, -0.42766571044921875, 0.25299835205078125, 0.4799041748046875, -0.7185134887695312, 0.10495758056640625, 0.14029693603515625, 0.425811767578125, 0.1859893798828125, -63.60486602783203, -0.9639930725097656, 0.14311599731445312, -0.42311859130859375, -0.18395233154296875, -0.54766845703125, -1.0670013427734375], "custom_metrics": {}}}, "num_steps_sampled": 18291, "num_agent_steps_sampled": 36582, "num_steps_trained": 29984, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 59968, "last_target_update_ts": 18291, "num_target_updates": 153}, "done": false, "episodes_total": 1001, "training_iteration": 57, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-20", "timestamp": 1648811780, "time_this_iter_s": 1.1436636447906494, "time_total_s": 71.31866312026978, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff02018e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 71.31866312026978, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 31.6, "ram_util_percent": 59.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -34.88, "episode_len_mean": 19.49, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -18.09, "policy1": -16.79}, "custom_metrics": {}, "hist_stats": {"episode_reward": [2.0, -40.0, -30.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [9, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [1.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [1.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30808191079436803, "mean_inference_ms": 1.73837352908355, "mean_action_processing_ms": 0.11949458329866218, "mean_env_wait_ms": 0.07402403363128114, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18591, "timesteps_this_iter": 32, "agent_timesteps_total": 37182, "timers": {"load_time_ms": 0.436, "load_throughput": 73322.987, "learn_time_ms": 7.827, "learn_throughput": 4088.414, "update_time_ms": 4.822}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.20611572265625, "min_q": -77.46170043945312, "max_q": -73.88799285888672, "mean_td_error": -12.518190383911133, "model": {}}, "td_error": [-1.8949966430664062, -1.2616729736328125, -0.794158935546875, -2.5075225830078125, -0.6296463012695312, -0.96405029296875, -0.3162078857421875, -1.1772689819335938, -1.2052688598632812, -0.9132308959960938, -74.74269104003906, -1.1193389892578125, -1.2353668212890625, -0.15283966064453125, -0.03814697265625, -1.6455917358398438, -0.450531005859375, -1.0415878295898438, -2.003753662109375, -1.1255569458007812, -72.88799285888672, -0.7451095581054688, -0.8634872436523438, -2.7694931030273438, -0.48931884765625, -1.0398178100585938, -1.4188079833984375, -74.69351196289062, -0.6948089599609375, -72.95463562011719, -74.83197021484375, -1.9737396240234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.43492126464844, "min_q": -66.94791412353516, "max_q": -59.72986602783203, "mean_td_error": -4.702190399169922, "model": {}}, "td_error": [-0.9912567138671875, -0.2552146911621094, -0.3884773254394531, -75.61709594726562, 0.5902442932128906, 1.3012619018554688, -0.18035888671875, -0.091766357421875, -1.1093521118164062, -0.03533935546875, -0.4148406982421875, 0.4139251708984375, 0.20146560668945312, 1.6105575561523438, -75.33528137207031, 0.4717979431152344, -0.6112098693847656, -0.6406784057617188, 0.03514862060546875, 0.4715461730957031, -1.4817886352539062, 0.342010498046875, 2.537006378173828, 0.26085662841796875, -1.1849288940429688, -0.2626953125, -0.5294113159179688, -0.09052276611328125, -0.1499481201171875, 0.0835418701171875, 0.7484054565429688, -0.16768646240234375], "custom_metrics": {}}}, "num_steps_sampled": 18591, "num_agent_steps_sampled": 37182, "num_steps_trained": 30464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60928, "last_target_update_ts": 18531, "num_target_updates": 155}, "done": false, "episodes_total": 1016, "training_iteration": 58, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-21", "timestamp": 1648811781, "time_this_iter_s": 1.125654697418213, "time_total_s": 72.44431781768799, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 72.44431781768799, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 32.2, "ram_util_percent": 59.7}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.2, "episode_len_mean": 19.45, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 13.0}, "policy_reward_mean": {"policy0": -18.15, "policy1": -17.05}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, 2.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 9, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -9.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -7.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, 11.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 13.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3080422261564284, "mean_inference_ms": 1.7385604497409204, "mean_action_processing_ms": 0.11950981160977403, "mean_env_wait_ms": 0.07400105519891734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 18896, "timesteps_this_iter": 32, "agent_timesteps_total": 37792, "timers": {"load_time_ms": 0.494, "load_throughput": 64798.787, "learn_time_ms": 7.907, "learn_throughput": 4047.054, "update_time_ms": 4.655}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.5628662109375, "min_q": -74.28694152832031, "max_q": -69.5751724243164, "mean_td_error": -6.5307722091674805, "model": {}}, "td_error": [0.28802490234375, -3.1728668212890625, 0.27484893798828125, -0.5683059692382812, -0.3818511962890625, 0.222808837890625, -69.23951721191406, 0.31400299072265625, 1.3835296630859375, -0.6102523803710938, 0.5690460205078125, 0.0096588134765625, -0.27144622802734375, 1.2986526489257812, -72.00877380371094, 0.7639999389648438, 0.33510589599609375, -0.09015655517578125, 1.4105148315429688, -0.2385711669921875, 0.9808425903320312, 3.0840911865234375, 0.6735305786132812, -1.4817276000976562, 0.340301513671875, -0.5899810791015625, 0.26932525634765625, -0.0591583251953125, -0.9844131469726562, -0.254425048828125, -0.39846038818359375, -70.85307312011719], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.50244140625, "min_q": -65.83830261230469, "max_q": -59.73875427246094, "mean_td_error": -3.7047014236450195, "model": {}}, "td_error": [0.36183929443359375, -3.8101463317871094, -0.065765380859375, 0.5791091918945312, 0.159881591796875, 0.02155303955078125, 0.22918701171875, 0.1916351318359375, -58.73875427246094, 0.35863494873046875, 0.6585845947265625, 0.5080490112304688, -63.78227233886719, 0.5163116455078125, 0.5221710205078125, 0.00186920166015625, 0.14717864990234375, 0.065582275390625, 0.45269775390625, 0.154052734375, 0.54888916015625, -0.03391265869140625, 0.24739837646484375, 0.39325714111328125, 0.3428497314453125, 0.023193359375, 0.47829437255859375, 0.1347503662109375, 0.44788360595703125, 0.3713226318359375, -0.22784423828125, 0.19207000732421875], "custom_metrics": {}}}, "num_steps_sampled": 18896, "num_agent_steps_sampled": 37792, "num_steps_trained": 30976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 61952, "last_target_update_ts": 18876, "num_target_updates": 158}, "done": false, "episodes_total": 1032, "training_iteration": 59, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-23", "timestamp": 1648811783, "time_this_iter_s": 1.1946485042572021, "time_total_s": 73.63896632194519, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 73.63896632194519, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 32.25, "ram_util_percent": 59.75}}
{"episode_reward_max": 12.0, "episode_reward_min": -40.0, "episode_reward_mean": -35.52, "episode_len_mean": 19.56, "episode_media": {}, "episodes_this_iter": 16, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 6.0, "policy1": 6.0}, "policy_reward_mean": {"policy0": -17.96, "policy1": -17.56}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, 12.0, -30.0, -40.0, -40.0, -30.0, -30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 4, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, 6.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 6.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3079694959066758, "mean_inference_ms": 1.7386387515393664, "mean_action_processing_ms": 0.11951698718667732, "mean_env_wait_ms": 0.07397694523138329, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19203, "timesteps_this_iter": 32, "agent_timesteps_total": 38406, "timers": {"load_time_ms": 0.42, "load_throughput": 76100.09, "learn_time_ms": 7.617, "learn_throughput": 4200.947, "update_time_ms": 5.106}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.38944244384766, "min_q": -73.9136962890625, "max_q": -70.66542053222656, "mean_td_error": -7.35831356048584, "model": {}}, "td_error": [0.9200286865234375, 0.4076995849609375, -9.436508178710938, 0.5185470581054688, 0.2406005859375, 0.28678131103515625, 0.8547515869140625, 0.49072265625, -0.11667633056640625, 0.117034912109375, -0.12949371337890625, 0.29012298583984375, -0.6382980346679688, 0.1052093505859375, 0.37233734130859375, 0.566741943359375, -0.38234710693359375, 0.11150360107421875, 0.2452239990234375, -0.0437164306640625, 1.5544509887695312, 0.01340484619140625, 0.5581893920898438, -81.68521881103516, 0.8744277954101562, -81.43783569335938, 0.7704315185546875, 0.11981964111328125, -71.3445053100586, -1.1868896484375, 0.1655120849609375, 1.3519134521484375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.221214294433594, "min_q": -64.74681091308594, "max_q": -58.27891159057617, "mean_td_error": -9.796205520629883, "model": {}}, "td_error": [1.4117469787597656, 0.8269081115722656, 0.16115570068359375, 0.6935577392578125, 0.7905311584472656, 0.7334823608398438, 0.7728843688964844, 1.25714111328125, -8.235614776611328, 0.8538017272949219, 0.6198806762695312, -60.7836799621582, 0.15344619750976562, -73.42774963378906, 0.532562255859375, 1.8375930786132812, 0.4402885437011719, 0.5877838134765625, -3.602039337158203, 0.14056396484375, 0.506378173828125, 0.6506729125976562, -57.48622512817383, 0.4402885437011719, 0.19416046142578125, -61.69623947143555, -0.4738883972167969, -63.017539978027344, 0.7782249450683594, -0.18810272216796875, 0.32126617431640625, 0.7281875610351562], "custom_metrics": {}}}, "num_steps_sampled": 19203, "num_agent_steps_sampled": 38406, "num_steps_trained": 31488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 62976, "last_target_update_ts": 19103, "num_target_updates": 160}, "done": false, "episodes_total": 1048, "training_iteration": 60, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-24", "timestamp": 1648811784, "time_this_iter_s": 1.1844496726989746, "time_total_s": 74.82341599464417, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 74.82341599464417, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 30.549999999999997, "ram_util_percent": 59.8}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.14, "episode_len_mean": 19.72, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_mean": {"policy0": -18.32, "policy1": -17.82}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -30.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0], "policy_policy1_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30788401600506965, "mean_inference_ms": 1.7385120990652616, "mean_action_processing_ms": 0.11951122108391693, "mean_env_wait_ms": 0.07394721173610946, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19503, "timesteps_this_iter": 32, "agent_timesteps_total": 39006, "timers": {"load_time_ms": 0.429, "load_throughput": 74565.404, "learn_time_ms": 7.568, "learn_throughput": 4228.289, "update_time_ms": 5.145}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.93067169189453, "min_q": -73.73185729980469, "max_q": -69.14105987548828, "mean_td_error": -3.3856074810028076, "model": {}}, "td_error": [-69.37921905517578, 0.3550567626953125, 0.07923126220703125, -69.11995697021484, 0.9211578369140625, 1.2360916137695312, 1.060272216796875, 1.2219390869140625, 1.4395751953125, 1.2444839477539062, 0.40650177001953125, 1.607269287109375, 1.055816650390625, 1.14501953125, 1.3517837524414062, 0.0341796875, 1.2376174926757812, 1.8518142700195312, 1.413726806640625, 1.2165374755859375, 1.3413543701171875, 0.5543212890625, 0.8090972900390625, 0.6632919311523438, 1.0841522216796875, 1.1678466796875, 1.004852294921875, 1.3797225952148438, 1.276336669921875, 1.5398330688476562, 0.2565460205078125, 0.20430755615234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.03897857666016, "min_q": -67.58956146240234, "max_q": -61.27778244018555, "mean_td_error": -12.831755638122559, "model": {}}, "td_error": [-1.0412101745605469, -65.27934265136719, -0.14362335205078125, -0.7956771850585938, 0.14507293701171875, -0.61395263671875, -0.6798782348632812, -64.63783264160156, -65.78706359863281, -0.5449676513671875, 0.13622283935546875, 0.30841827392578125, -65.31525421142578, 0.784576416015625, -75.40723419189453, -0.4115142822265625, -0.8409881591796875, -0.6143112182617188, 0.38500213623046875, 0.2246551513671875, -0.30710601806640625, 0.5406417846679688, -0.9718780517578125, 0.0218048095703125, -65.54945373535156, -0.34926605224609375, -0.9290313720703125, -0.40523529052734375, -0.36357879638671875, -0.298126220703125, -1.4755172729492188, -0.4005470275878906], "custom_metrics": {}}}, "num_steps_sampled": 19503, "num_agent_steps_sampled": 39006, "num_steps_trained": 31968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 63936, "last_target_update_ts": 19463, "num_target_updates": 163}, "done": false, "episodes_total": 1063, "training_iteration": 61, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-25", "timestamp": 1648811785, "time_this_iter_s": 1.140821933746338, "time_total_s": 75.9642379283905, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ef80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872ef80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 75.9642379283905, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.8}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.34, "episode_len_mean": 19.72, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_mean": {"policy0": -18.32, "policy1": -18.02}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0], "policy_policy1_reward": [-20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30777234821960636, "mean_inference_ms": 1.7382411242642057, "mean_action_processing_ms": 0.11950459238075359, "mean_env_wait_ms": 0.07392722062424552, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 19803, "timesteps_this_iter": 32, "agent_timesteps_total": 39606, "timers": {"load_time_ms": 0.434, "load_throughput": 73750.057, "learn_time_ms": 7.756, "learn_throughput": 4125.777, "update_time_ms": 4.846}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.29837799072266, "min_q": -74.04376220703125, "max_q": -70.01311492919922, "mean_td_error": -4.456912040710449, "model": {}}, "td_error": [1.0876007080078125, 0.164215087890625, 0.15943145751953125, 1.0653762817382812, 1.0492706298828125, 0.075958251953125, 0.0841522216796875, 1.323577880859375, 0.7890243530273438, 0.6169967651367188, 0.03449249267578125, 1.8519439697265625, 0.31537628173828125, -81.0123519897461, -1.2655029296875, 1.4620208740234375, -0.2414093017578125, 0.8532485961914062, -8.693283081054688, 0.4224395751953125, 0.055877685546875, 2.1128005981445312, 1.1290969848632812, 1.6352386474609375, -71.62027740478516, 0.1819610595703125, -0.2132110595703125, 0.809814453125, 0.5891265869140625, -0.2852630615234375, 2.6609344482421875, 0.1801300048828125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.24177551269531, "min_q": -70.61685943603516, "max_q": -60.8940544128418, "mean_td_error": -6.974236011505127, "model": {}}, "td_error": [-0.8144683837890625, -0.2444915771484375, -69.29911041259766, 0.34146881103515625, -6.9315032958984375, -0.42540740966796875, -0.213043212890625, 0.074371337890625, -0.26445770263671875, -0.6734695434570312, 1.0989913940429688, -0.30860137939453125, -0.061000823974609375, 0.4288597106933594, -1.1727218627929688, -1.0675582885742188, -0.4008026123046875, -0.8457412719726562, 0.03153228759765625, -2.0761489868164062, -0.05739593505859375, -0.17392730712890625, -0.28490447998046875, -0.5351715087890625, -0.7392196655273438, 0.56427001953125, -0.38953399658203125, -69.2915267944336, -68.14692687988281, -0.234466552734375, -0.18585968017578125, -0.877593994140625], "custom_metrics": {}}}, "num_steps_sampled": 19803, "num_agent_steps_sampled": 39606, "num_steps_trained": 32448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 64896, "last_target_update_ts": 19703, "num_target_updates": 165}, "done": false, "episodes_total": 1078, "training_iteration": 62, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-26", "timestamp": 1648811786, "time_this_iter_s": 1.1296300888061523, "time_total_s": 77.09386801719666, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101beb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101beb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 77.09386801719666, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 59.8}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.94, "episode_len_mean": 19.72, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_mean": {"policy0": -18.22, "policy1": -18.72}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.307679824997827, "mean_inference_ms": 1.7380187098376734, "mean_action_processing_ms": 0.1195046639996309, "mean_env_wait_ms": 0.07392078521372233, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20103, "timesteps_this_iter": 32, "agent_timesteps_total": 40206, "timers": {"load_time_ms": 0.467, "load_throughput": 68495.906, "learn_time_ms": 7.871, "learn_throughput": 4065.455, "update_time_ms": 4.817}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.57762908935547, "min_q": -75.66107177734375, "max_q": -73.23759460449219, "mean_td_error": -3.086786985397339, "model": {}}, "td_error": [0.28448486328125, -1.0070571899414062, -0.9773712158203125, -10.094978332519531, -0.1667327880859375, -0.9055862426757812, -0.3699798583984375, -0.20578765869140625, -1.0553436279296875, -0.443695068359375, -73.1660385131836, -0.6922836303710938, -0.16912078857421875, 0.0271759033203125, -0.534027099609375, -0.0280303955078125, -0.6292800903320312, -0.1225738525390625, -0.695648193359375, -0.02593994140625, -0.39704132080078125, -0.9560546875, -1.0306167602539062, -0.849456787109375, -0.6384353637695312, 0.1851959228515625, -0.89312744140625, -1.230133056640625, -0.9601211547851562, -0.4895172119140625, -1.178558349609375, 0.6384963989257812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.32965087890625, "min_q": -72.48774719238281, "max_q": -63.07585144042969, "mean_td_error": -3.6042070388793945, "model": {}}, "td_error": [-1.5439109802246094, -1.8132171630859375, -1.2346649169921875, -1.118255615234375, -1.5625, -0.6578330993652344, -0.1313629150390625, -1.0193939208984375, -15.286109924316406, -1.1248550415039062, -2.0502853393554688, -1.36083984375, -1.032073974609375, -0.8307952880859375, -1.205413818359375, -0.2524261474609375, 0.5243606567382812, -1.47698974609375, -0.9589004516601562, -0.3003997802734375, -1.6240081787109375, -66.5330581665039, -2.3551788330078125, -1.47698974609375, -0.28842926025390625, -1.8113632202148438, -1.8173141479492188, -1.2403106689453125, -0.504730224609375, -0.7855453491210938, -1.1097030639648438, -1.3521347045898438], "custom_metrics": {}}}, "num_steps_sampled": 20103, "num_agent_steps_sampled": 40206, "num_steps_trained": 32928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 65856, "last_target_update_ts": 20063, "num_target_updates": 168}, "done": false, "episodes_total": 1093, "training_iteration": 63, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-28", "timestamp": 1648811788, "time_this_iter_s": 1.1508054733276367, "time_total_s": 78.24467349052429, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101efdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 78.24467349052429, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 59.8}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.74, "episode_len_mean": 19.72, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_mean": {"policy0": -17.62, "policy1": -19.12}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, 10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3076110062811898, "mean_inference_ms": 1.7380699817693277, "mean_action_processing_ms": 0.1195147837955309, "mean_env_wait_ms": 0.07393057575721029, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20403, "timesteps_this_iter": 32, "agent_timesteps_total": 40806, "timers": {"load_time_ms": 0.457, "load_throughput": 70007.16, "learn_time_ms": 8.409, "learn_throughput": 3805.63, "update_time_ms": 5.429}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.48181915283203, "min_q": -74.3347396850586, "max_q": -70.89270782470703, "mean_td_error": -0.29834461212158203, "model": {}}, "td_error": [-8.721931457519531, -0.5175628662109375, 0.48343658447265625, 1.1578521728515625, 0.22681427001953125, -0.41420745849609375, 0.568939208984375, 0.8743820190429688, -0.3614501953125, 0.49005889892578125, 0.531524658203125, 0.3590087890625, 0.0205078125, 0.3835601806640625, -0.33879852294921875, 0.841461181640625, -0.7927627563476562, 0.7409896850585938, 0.46659088134765625, -9.362045288085938, 0.6636962890625, 0.29361724853515625, 0.22212982177734375, 0.79241943359375, 0.021484375, 0.42633819580078125, 0.37288665771484375, 0.305938720703125, 0.474822998046875, -0.0190277099609375, -0.1243133544921875, 0.3866119384765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.2770767211914, "min_q": -67.00965881347656, "max_q": -58.8266487121582, "mean_td_error": -3.6949074268341064, "model": {}}, "td_error": [1.0278244018554688, 0.3621826171875, -0.39643096923828125, -58.498294830322266, -2.1322364807128906, 0.5589447021484375, 1.3913116455078125, 0.9645156860351562, 2.2299652099609375, -2.150177001953125, 0.49786376953125, -0.923309326171875, 1.1130447387695312, -65.4124526977539, 0.794097900390625, 1.9530715942382812, -1.2025604248046875, -1.1275787353515625, 0.3310089111328125, 0.54144287109375, -1.1164283752441406, 1.3623809814453125, -0.23648452758789062, 0.5277023315429688, -0.3979034423828125, 1.3972854614257812, 0.6628608703613281, 1.0287551879882812, 1.6107254028320312, -1.9448089599609375, -1.139739990234375, 0.08638763427734375], "custom_metrics": {}}}, "num_steps_sampled": 20403, "num_agent_steps_sampled": 40806, "num_steps_trained": 33408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66816, "last_target_update_ts": 20303, "num_target_updates": 170}, "done": false, "episodes_total": 1108, "training_iteration": 64, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-29", "timestamp": 1648811789, "time_this_iter_s": 1.194183349609375, "time_total_s": 79.43885684013367, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 79.43885684013367, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 29.450000000000003, "ram_util_percent": 59.849999999999994}}
{"episode_reward_max": 10.0, "episode_reward_min": -40.0, "episode_reward_mean": -36.94, "episode_len_mean": 19.72, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 5.0, "policy1": 5.0}, "policy_reward_mean": {"policy0": -17.72, "policy1": -19.22}, "custom_metrics": {}, "hist_stats": {"episode_reward": [10.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [5, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [5.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3075301377947098, "mean_inference_ms": 1.7380485587738947, "mean_action_processing_ms": 0.1195174528625126, "mean_env_wait_ms": 0.07394394681665944, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 20703, "timesteps_this_iter": 32, "agent_timesteps_total": 41406, "timers": {"load_time_ms": 0.442, "load_throughput": 72448.304, "learn_time_ms": 7.982, "learn_throughput": 4009.192, "update_time_ms": 4.835}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.0681381225586, "min_q": -77.34774780273438, "max_q": -72.29829406738281, "mean_td_error": -0.08209395408630371, "model": {}}, "td_error": [-0.32318878173828125, 0.45609283447265625, 0.6941909790039062, -0.00542449951171875, -0.49576568603515625, -0.25516510009765625, -0.875274658203125, -0.303955078125, 0.298248291015625, 0.2310333251953125, -0.8800277709960938, -0.27756500244140625, -0.38120269775390625, 0.46488189697265625, 0.3095245361328125, 0.418731689453125, -1.20843505859375, 0.4644622802734375, -0.39952850341796875, -0.2528228759765625, -0.14308929443359375, 0.15421295166015625, -0.13838958740234375, 0.25423431396484375, 0.21178436279296875, -0.87603759765625, -0.30835723876953125, 0.8742752075195312, -0.5759658813476562, 0.48387908935546875, -0.03771209716796875, -0.20465087890625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.50714874267578, "min_q": -65.62179565429688, "max_q": -58.97306442260742, "mean_td_error": -2.657440662384033, "model": {}}, "td_error": [-0.0999298095703125, -0.6590385437011719, -1.4877166748046875, -0.4969635009765625, -0.15438079833984375, -0.5902481079101562, -0.8364334106445312, -1.1397476196289062, -0.5054550170898438, -0.03520965576171875, -0.6119384765625, -1.3533782958984375, -1.038330078125, -0.8628196716308594, -0.2594413757324219, -0.8188629150390625, -0.6323356628417969, -0.33269500732421875, -0.774261474609375, -1.1129837036132812, -0.8335952758789062, -0.1150665283203125, 0.16266632080078125, -1.1825942993164062, -0.9849777221679688, -0.4065513610839844, -0.6383705139160156, -1.0479621887207031, -0.8048057556152344, -1.0295944213867188, -6.151172637939453, -58.20390319824219], "custom_metrics": {}}}, "num_steps_sampled": 20703, "num_agent_steps_sampled": 41406, "num_steps_trained": 33888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 67776, "last_target_update_ts": 20663, "num_target_updates": 173}, "done": false, "episodes_total": 1123, "training_iteration": 65, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-30", "timestamp": 1648811790, "time_this_iter_s": 1.1159446239471436, "time_total_s": 80.55480146408081, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 80.55480146408081, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 31.8, "ram_util_percent": 59.9}}
{"episode_reward_max": 6.0, "episode_reward_min": -40.0, "episode_reward_mean": -37.74, "episode_len_mean": 19.87, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": 3.0, "policy1": 3.0}, "policy_reward_mean": {"policy0": -18.17, "policy1": -19.57}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -30.0, -40.0, -40.0, 6.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 7, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -10.0, -20.0, -20.0, 3.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, 3.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3074725615282828, "mean_inference_ms": 1.73818902527109, "mean_action_processing_ms": 0.11953619752029165, "mean_env_wait_ms": 0.07396775899580793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21003, "timesteps_this_iter": 32, "agent_timesteps_total": 42006, "timers": {"load_time_ms": 0.442, "load_throughput": 72456.126, "learn_time_ms": 8.024, "learn_throughput": 3988.023, "update_time_ms": 4.841}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.46159362792969, "min_q": -78.40914916992188, "max_q": -74.62056732177734, "mean_td_error": -5.329656600952148, "model": {}}, "td_error": [-0.7875823974609375, -0.8490982055664062, -0.7712936401367188, -0.30251312255859375, -0.9941940307617188, -1.0013885498046875, -0.78814697265625, -0.8954544067382812, -0.351287841796875, -1.0378875732421875, -1.1956634521484375, 0.06827545166015625, -0.6098403930664062, -0.6564712524414062, -0.7338333129882812, -0.25717926025390625, -0.7053070068359375, -0.5933609008789062, -0.526611328125, -0.511077880859375, -76.13418579101562, -0.129791259765625, -0.6428146362304688, -1.0675582885742188, -0.02935791015625, -1.3726119995117188, -0.2230377197265625, -0.055633544921875, -0.44898223876953125, -75.9666519165039, -1.1869354248046875, 0.20845794677734375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -64.69635009765625, "min_q": -66.19210815429688, "max_q": -59.82297134399414, "mean_td_error": -0.6736559867858887, "model": {}}, "td_error": [-1.2598037719726562, -1.7615623474121094, -1.777618408203125, -1.1246185302734375, -0.3036613464355469, -0.727752685546875, -0.52490234375, -1.1183013916015625, -0.6509170532226562, -0.46074676513671875, -0.5113983154296875, 0.0218048095703125, -1.0621795654296875, -1.1595077514648438, -0.6874618530273438, -0.5133590698242188, -0.7132644653320312, -0.4758453369140625, -0.326446533203125, -0.7018318176269531, -0.788909912109375, -0.6381301879882812, -0.7101211547851562, 0.624298095703125, -0.5390586853027344, -0.8623123168945312, -0.7017669677734375, -0.17067718505859375, -0.46015167236328125, -0.6844863891601562, 0.00705718994140625, -0.7933578491210938], "custom_metrics": {}}}, "num_steps_sampled": 21003, "num_agent_steps_sampled": 42006, "num_steps_trained": 34368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 68736, "last_target_update_ts": 20903, "num_target_updates": 175}, "done": false, "episodes_total": 1138, "training_iteration": 66, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-31", "timestamp": 1648811791, "time_this_iter_s": 1.1713895797729492, "time_total_s": 81.72619104385376, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb842d4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb842d4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 81.72619104385376, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 31.650000000000002, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.1, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.5, "policy1": -19.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3074252355374633, "mean_inference_ms": 1.7383639631895982, "mean_action_processing_ms": 0.11955685620298069, "mean_env_wait_ms": 0.0739888945155482, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21303, "timesteps_this_iter": 32, "agent_timesteps_total": 42606, "timers": {"load_time_ms": 0.432, "load_throughput": 74063.419, "learn_time_ms": 8.071, "learn_throughput": 3964.874, "update_time_ms": 5.121}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.89244079589844, "min_q": -78.31930541992188, "max_q": -74.32705688476562, "mean_td_error": -2.4442219734191895, "model": {}}, "td_error": [0.5080490112304688, 0.3050384521484375, -0.4171295166015625, -0.4038543701171875, -0.9015960693359375, 0.21706390380859375, -0.27506256103515625, 0.0208282470703125, 0.9134368896484375, -11.360458374023438, -0.48021697998046875, 0.9034957885742188, -74.50552368164062, -0.13097381591796875, 0.29650115966796875, 0.7382049560546875, 0.3729248046875, 0.5949020385742188, 1.7962570190429688, 0.2958984375, 0.39913177490234375, 0.2097930908203125, -0.08115386962890625, 0.517852783203125, 0.22751617431640625, 0.28789520263671875, 0.5298309326171875, 0.09946441650390625, 0.4512939453125, 0.480133056640625, 0.00891876220703125, 0.16643524169921875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.895652770996094, "min_q": -63.431312561035156, "max_q": -57.898521423339844, "mean_td_error": -0.7590535879135132, "model": {}}, "td_error": [2.332347869873047, 2.43975830078125, 1.7079963684082031, 2.0197715759277344, 2.1405906677246094, 1.774993896484375, 1.7183914184570312, 0.3422813415527344, 0.6162528991699219, 2.4831314086914062, 1.3119659423828125, 0.8037109375, 1.7530021667480469, 1.6247367858886719, 1.6521224975585938, 1.7185096740722656, 1.6257972717285156, 1.7028923034667969, 3.193531036376953, 1.8698272705078125, 1.5508804321289062, 0.994903564453125, -8.8218994140625, 1.5883674621582031, 2.157756805419922, 1.9171409606933594, 2.7196502685546875, 1.6915664672851562, 1.2757606506347656, 1.4320564270019531, 2.395915985107422, -68.02342224121094], "custom_metrics": {}}}, "num_steps_sampled": 21303, "num_agent_steps_sampled": 42606, "num_steps_trained": 34848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 69696, "last_target_update_ts": 21263, "num_target_updates": 178}, "done": false, "episodes_total": 1153, "training_iteration": 67, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-32", "timestamp": 1648811792, "time_this_iter_s": 1.1509037017822266, "time_total_s": 82.87709474563599, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8413c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8413c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 82.87709474563599, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.2, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.6, "policy1": -19.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30739444236165825, "mean_inference_ms": 1.738668917943746, "mean_action_processing_ms": 0.1195881490951642, "mean_env_wait_ms": 0.07401470536308084, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21603, "timesteps_this_iter": 32, "agent_timesteps_total": 43206, "timers": {"load_time_ms": 0.448, "load_throughput": 71369.631, "learn_time_ms": 7.752, "learn_throughput": 4127.985, "update_time_ms": 4.866}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.73483276367188, "min_q": -79.68228149414062, "max_q": -73.52640533447266, "mean_td_error": -8.247315406799316, "model": {}}, "td_error": [-0.1401519775390625, -0.5412063598632812, -0.4117584228515625, -0.220062255859375, -0.14751434326171875, -78.22883605957031, -11.558341979980469, 0.07572174072265625, -76.1364517211914, -78.68228149414062, -0.16246795654296875, -0.1887054443359375, -0.5635757446289062, -0.6335067749023438, 0.08404541015625, -0.32523345947265625, -1.7656784057617188, -0.30803680419921875, -0.692291259765625, -0.41684722900390625, -12.019638061523438, -0.31911468505859375, 0.36502838134765625, 0.31884765625, -0.398345947265625, -0.1449737548828125, -0.06992340087890625, 0.76708984375, -0.66943359375, -0.26038360595703125, -0.15888214111328125, -0.361175537109375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.85492706298828, "min_q": -66.62782287597656, "max_q": -57.8209228515625, "mean_td_error": -8.9307222366333, "model": {}}, "td_error": [-1.0799217224121094, -2.1061134338378906, -0.9679336547851562, -2.868011474609375, -0.16938018798828125, -0.6582870483398438, -1.9393539428710938, -64.30341339111328, -1.1564979553222656, -1.4266510009765625, -1.7454261779785156, -1.1681938171386719, -1.2425003051757812, -1.201171875, -1.27783203125, -56.8209228515625, 0.190399169921875, -61.25321960449219, -1.6310081481933594, -3.593902587890625, -1.0920753479003906, -64.41859436035156, -0.8810997009277344, -3.478504180908203, -0.943328857421875, -1.1261444091796875, -1.2533111572265625, -0.9171409606933594, -0.8060340881347656, -0.6615180969238281, -1.6912612915039062, -2.094745635986328], "custom_metrics": {}}}, "num_steps_sampled": 21603, "num_agent_steps_sampled": 43206, "num_steps_trained": 35328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 70656, "last_target_update_ts": 21503, "num_target_updates": 180}, "done": false, "episodes_total": 1168, "training_iteration": 68, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-34", "timestamp": 1648811794, "time_this_iter_s": 1.159621000289917, "time_total_s": 84.0367157459259, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872eb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 84.0367157459259, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 32.5, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.4, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -18.9, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -10.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3073887705374161, "mean_inference_ms": 1.7391892507629396, "mean_action_processing_ms": 0.11962625243510859, "mean_env_wait_ms": 0.0740379605922595, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 21903, "timesteps_this_iter": 32, "agent_timesteps_total": 43806, "timers": {"load_time_ms": 0.419, "load_throughput": 76390.283, "learn_time_ms": 7.661, "learn_throughput": 4177.035, "update_time_ms": 4.693}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.66390991210938, "min_q": -76.50263214111328, "max_q": -72.65319061279297, "mean_td_error": -1.6814963817596436, "model": {}}, "td_error": [0.46846771240234375, 1.23583984375, 1.4597854614257812, 2.9805221557617188, 0.5081253051757812, 1.1743621826171875, 1.4629745483398438, -10.871719360351562, 0.8949127197265625, 0.6900558471679688, 1.256622314453125, -0.3011474609375, -0.271575927734375, 1.5898971557617188, 1.4968948364257812, 1.1072998046875, 1.4931106567382812, 0.6417312622070312, 0.783203125, 1.1305084228515625, -0.32872772216796875, 0.8834609985351562, 0.7916412353515625, 1.662628173828125, 0.911773681640625, 3.5374221801757812, -74.77803802490234, 0.8191452026367188, 0.8993988037109375, 0.484130859375, 0.9836196899414062, 1.3957901000976562], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -59.23076629638672, "min_q": -60.81609344482422, "max_q": -54.36737823486328, "mean_td_error": -3.140505790710449, "model": {}}, "td_error": [1.0631599426269531, 0.485626220703125, 1.2138404846191406, 0.7571983337402344, 0.5325355529785156, 0.25885772705078125, 0.5318603515625, 0.06440353393554688, 1.2357215881347656, 1.2499046325683594, 1.3046226501464844, 0.7021102905273438, 0.6534500122070312, 0.8849601745605469, 0.7990493774414062, -0.7363739013671875, 1.1139602661132812, -59.20399475097656, 0.7780303955078125, 0.43022918701171875, 0.069671630859375, -56.5932502746582, 1.961822509765625, 0.20493316650390625, -1.9449958801269531, 0.5306320190429688, -0.04979705810546875, 1.5494537353515625, 1.2222785949707031, 0.29720306396484375, 1.0265235900878906, -2.889812469482422], "custom_metrics": {}}}, "num_steps_sampled": 21903, "num_agent_steps_sampled": 43806, "num_steps_trained": 35808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 71616, "last_target_update_ts": 21863, "num_target_updates": 183}, "done": false, "episodes_total": 1183, "training_iteration": 69, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-35", "timestamp": 1648811795, "time_this_iter_s": 1.184631586074829, "time_total_s": 85.22134733200073, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 85.22134733200073, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 30.6, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.7, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.2, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30736486306865407, "mean_inference_ms": 1.7395941850424668, "mean_action_processing_ms": 0.11965881171719665, "mean_env_wait_ms": 0.07405043172632447, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22203, "timesteps_this_iter": 32, "agent_timesteps_total": 44406, "timers": {"load_time_ms": 0.433, "load_throughput": 73819.012, "learn_time_ms": 7.675, "learn_throughput": 4169.496, "update_time_ms": 4.737}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -77.9546890258789, "min_q": -79.3365707397461, "max_q": -76.02014923095703, "mean_td_error": -9.170734405517578, "model": {}}, "td_error": [-0.445037841796875, 0.980438232421875, 2.5007171630859375, 1.7609176635742188, -87.00434112548828, 1.213043212890625, -75.02014923095703, 2.1174163818359375, 1.6714096069335938, 0.9699478149414062, 1.6492080688476562, -0.29186248779296875, 0.221923828125, 2.2888870239257812, -75.45913696289062, 1.4486923217773438, 1.2909393310546875, 2.1482315063476562, 0.7781448364257812, 0.5576248168945312, 0.6992111206054688, 1.5210189819335938, 0.9427261352539062, 1.2758636474609375, -0.044921875, -8.458641052246094, 1.7078704833984375, 0.18025970458984375, 0.19837188720703125, 1.4739761352539062, -76.3755874633789, 0.03932952880859375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.19525909423828, "min_q": -65.94823455810547, "max_q": -57.078025817871094, "mean_td_error": -0.8302191495895386, "model": {}}, "td_error": [-10.844295501708984, -1.0555953979492188, 0.22953033447265625, -1.3419456481933594, 0.5726585388183594, -0.4132575988769531, -0.2985572814941406, -0.36037445068359375, -0.08306884765625, -1.481781005859375, -1.0858001708984375, -0.7161941528320312, 0.22900390625, -0.26625823974609375, -0.26625823974609375, -0.9770050048828125, -0.743316650390625, -2.5271835327148438, 1.0007286071777344, 0.05736541748046875, -0.00487518310546875, 0.2577972412109375, -0.21991729736328125, -0.3976898193359375, 0.7500534057617188, -1.1139297485351562, 0.2518272399902344, -0.01033782958984375, -4.495807647705078, -0.5459671020507812, 0.07857131958007812, -0.7451324462890625], "custom_metrics": {}}}, "num_steps_sampled": 22203, "num_agent_steps_sampled": 44406, "num_steps_trained": 36288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72576, "last_target_update_ts": 22103, "num_target_updates": 185}, "done": false, "episodes_total": 1198, "training_iteration": 70, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-36", "timestamp": 1648811796, "time_this_iter_s": 1.134673833847046, "time_total_s": 86.35602116584778, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837d8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837d8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 86.35602116584778, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 30.75, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3073219759799215, "mean_inference_ms": 1.7397234521102893, "mean_action_processing_ms": 0.11967426925242641, "mean_env_wait_ms": 0.07404924896549339, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22503, "timesteps_this_iter": 32, "agent_timesteps_total": 45006, "timers": {"load_time_ms": 0.423, "load_throughput": 75688.111, "learn_time_ms": 7.979, "learn_throughput": 4010.618, "update_time_ms": 4.746}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.10395812988281, "min_q": -83.23265075683594, "max_q": -76.59867858886719, "mean_td_error": -3.5630862712860107, "model": {}}, "td_error": [-0.7456893920898438, -0.9720840454101562, 0.6095428466796875, -0.26165008544921875, -0.8124465942382812, -1.6678543090820312, -1.6750869750976562, -0.0742340087890625, -0.7087478637695312, -0.8534469604492188, -1.0258026123046875, -7.793937683105469, -0.6515274047851562, -0.42996978759765625, -0.6492385864257812, -1.8275909423828125, -0.9520263671875, -0.993316650390625, -78.00054168701172, -0.328887939453125, -1.5102081298828125, -0.8179397583007812, -0.18148040771484375, -8.790382385253906, -0.4647216796875, -0.150146484375, -0.824981689453125, 1.9551544189453125, -0.8671417236328125, -1.1708831787109375, -0.33873748779296875, -1.042755126953125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -63.29362487792969, "min_q": -66.40083312988281, "max_q": -57.807220458984375, "mean_td_error": -5.206623554229736, "model": {}}, "td_error": [-0.08926773071289062, -0.9523887634277344, -0.8288917541503906, -0.3914031982421875, -0.6888656616210938, -1.5055809020996094, -0.06331253051757812, -0.13963699340820312, -0.7800521850585938, -3.4441070556640625, -1.2409248352050781, -0.9015235900878906, -0.8919601440429688, -1.5239830017089844, -1.0845489501953125, -0.7372932434082031, -0.7480812072753906, -0.6475982666015625, -0.45511627197265625, -64.85189819335938, -1.1160964965820312, -0.5180206298828125, -0.6932868957519531, -1.1826858520507812, 0.6385269165039062, -1.1255722045898438, -1.0895767211914062, -0.14992523193359375, -8.374473571777344, -0.164459228515625, 0.29927825927734375, -71.16922760009766], "custom_metrics": {}}}, "num_steps_sampled": 22503, "num_agent_steps_sampled": 45006, "num_steps_trained": 36768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 73536, "last_target_update_ts": 22463, "num_target_updates": 188}, "done": false, "episodes_total": 1213, "training_iteration": 71, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-37", "timestamp": 1648811797, "time_this_iter_s": 1.1020677089691162, "time_total_s": 87.4580888748169, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef873b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef873b050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 87.4580888748169, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 32.15, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.8, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.4, "policy1": -19.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30731543454510984, "mean_inference_ms": 1.740033460029507, "mean_action_processing_ms": 0.11970454498042449, "mean_env_wait_ms": 0.07404704589563077, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 22803, "timesteps_this_iter": 32, "agent_timesteps_total": 45606, "timers": {"load_time_ms": 0.41, "load_throughput": 78060.793, "learn_time_ms": 8.404, "learn_throughput": 3807.898, "update_time_ms": 4.923}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.39166259765625, "min_q": -82.85698699951172, "max_q": -77.52576446533203, "mean_td_error": -5.761109352111816, "model": {}}, "td_error": [-0.8693618774414062, -0.36406707763671875, -79.75252532958984, -0.9299240112304688, -1.8301467895507812, -0.0489501953125, 0.29856109619140625, 0.00618743896484375, -0.7857284545898438, -2.1006088256835938, -1.469085693359375, -0.8684158325195312, -1.6328125, -0.01898193359375, -0.5618133544921875, -1.0280990600585938, -80.32095336914062, -0.9141998291015625, -0.7398757934570312, -0.9801406860351562, -1.5306320190429688, -0.7655410766601562, -0.9299240112304688, -0.5905227661132812, -0.9141998291015625, -0.38898468017578125, -1.7482528686523438, -0.28794097900390625, -0.3391265869140625, -0.1345672607421875, -1.17633056640625, -0.638519287109375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -61.896263122558594, "min_q": -66.1885757446289, "max_q": -55.21514129638672, "mean_td_error": -4.501952171325684, "model": {}}, "td_error": [1.8756332397460938, 1.0619621276855469, 0.31429290771484375, -1.6271438598632812, 0.5222702026367188, 0.5813941955566406, -0.10518646240234375, -60.6553840637207, -55.433109283447266, 1.0429725646972656, -0.5839500427246094, 3.9066696166992188, 1.6880416870117188, -0.2413787841796875, 1.259002685546875, 1.0359039306640625, 0.9059677124023438, 0.7314453125, 3.8861160278320312, 4.0506439208984375, 1.6674652099609375, 1.130889892578125, 1.0858955383300781, 3.1348915100097656, 2.036579132080078, 0.7941741943359375, 1.2821578979492188, -61.78324890136719, 0.3024787902832031, 0.2952728271484375, 0.20061492919921875, 1.5742034912109375], "custom_metrics": {}}}, "num_steps_sampled": 22803, "num_agent_steps_sampled": 45606, "num_steps_trained": 37248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 74496, "last_target_update_ts": 22703, "num_target_updates": 190}, "done": false, "episodes_total": 1228, "training_iteration": 72, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-38", "timestamp": 1648811798, "time_this_iter_s": 1.1887972354888916, "time_total_s": 88.64688611030579, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fd0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 88.64688611030579, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 30.5, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -38.9, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3072856769286418, "mean_inference_ms": 1.7401419068392625, "mean_action_processing_ms": 0.11971814227031562, "mean_env_wait_ms": 0.07403234495455266, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23103, "timesteps_this_iter": 32, "agent_timesteps_total": 46206, "timers": {"load_time_ms": 0.467, "load_throughput": 68548.38, "learn_time_ms": 8.185, "learn_throughput": 3909.406, "update_time_ms": 5.06}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.7152328491211, "min_q": -78.7486343383789, "max_q": -72.65170288085938, "mean_td_error": 0.7939252853393555, "model": {}}, "td_error": [1.3612747192382812, 0.9411697387695312, 1.6046066284179688, 0.9674224853515625, 0.46820831298828125, 0.6751708984375, -0.0341644287109375, 0.7881393432617188, 0.7803802490234375, 0.733123779296875, 0.750091552734375, 0.2696685791015625, 0.7408676147460938, -0.6046905517578125, 0.64666748046875, 0.9149856567382812, 1.4772186279296875, 1.1840057373046875, 0.224761962890625, 0.563201904296875, 1.198272705078125, 0.9777145385742188, 0.7110824584960938, 0.519622802734375, 0.5839385986328125, 1.8501663208007812, 0.7591323852539062, 1.8282852172851562, 0.26885986328125, 0.67291259765625, 1.1523208618164062, 0.43119049072265625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.9083480834961, "min_q": -76.47852325439453, "max_q": -62.61832046508789, "mean_td_error": -12.11196517944336, "model": {}}, "td_error": [-3.994659423828125, -1.5565261840820312, -4.747886657714844, -3.9542312622070312, -1.1758193969726562, -3.7124481201171875, -3.5659255981445312, -3.799560546875, -73.92053985595703, -3.3398513793945312, -3.1335525512695312, -73.84464263916016, -2.3281326293945312, -5.658515930175781, -4.1017608642578125, -3.843292236328125, -3.0474319458007812, -3.5352935791015625, -3.9724884033203125, -70.79642486572266, -3.6768112182617188, -2.716583251953125, -2.6623802185058594, -73.02203369140625, -3.2776641845703125, -2.1279373168945312, -1.7346343994140625, -6.421844482421875, -3.5461883544921875, -3.6018142700195312, -3.233367919921875, -3.5326461791992188], "custom_metrics": {}}}, "num_steps_sampled": 23103, "num_agent_steps_sampled": 46206, "num_steps_trained": 37728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 75456, "last_target_update_ts": 23063, "num_target_updates": 193}, "done": false, "episodes_total": 1243, "training_iteration": 73, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-40", "timestamp": 1648811800, "time_this_iter_s": 1.129690408706665, "time_total_s": 89.77657651901245, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 89.77657651901245, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 31.75, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.5, "policy1": -19.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -30.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -30.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -10.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30724082377435324, "mean_inference_ms": 1.740029619011337, "mean_action_processing_ms": 0.11972255623185582, "mean_env_wait_ms": 0.07401765526052227, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23403, "timesteps_this_iter": 32, "agent_timesteps_total": 46806, "timers": {"load_time_ms": 0.451, "load_throughput": 70943.352, "learn_time_ms": 8.39, "learn_throughput": 3813.838, "update_time_ms": 4.775}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.85894775390625, "min_q": -80.14690399169922, "max_q": -71.02255249023438, "mean_td_error": 1.7429826259613037, "model": {}}, "td_error": [0.6666641235351562, 1.0782089233398438, 0.5529861450195312, 1.6259078979492188, -0.4832611083984375, 0.9154205322265625, 3.0004196166992188, 1.8077621459960938, 1.3141326904296875, 2.948577880859375, 1.814666748046875, 1.8976211547851562, 2.54052734375, 0.96026611328125, 3.7833175659179688, 1.4055557250976562, 1.1866836547851562, 1.6943588256835938, 1.7774505615234375, 2.5773849487304688, 1.9796371459960938, 3.8165740966796875, 3.415863037109375, 0.983795166015625, 0.19707489013671875, 2.7080459594726562, 1.7857513427734375, 0.7529296875, 4.351387023925781, 0.939544677734375, 1.8278732299804688, -0.0476837158203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -65.77133178710938, "min_q": -69.68990325927734, "max_q": -59.515411376953125, "mean_td_error": -1.210684895515442, "model": {}}, "td_error": [-67.14865112304688, 3.706268310546875, 4.468330383300781, 1.1184463500976562, 2.1547470092773438, 3.3087539672851562, 1.1324806213378906, 3.1613540649414062, 4.039642333984375, 3.2046775817871094, 2.6434059143066406, 4.421546936035156, 3.82867431640625, -0.64056396484375, -67.65222930908203, 4.551094055175781, 4.820793151855469, 2.1895370483398438, 3.827392578125, 1.9965896606445312, 2.82122802734375, 4.210479736328125, 3.5098190307617188, 3.1649398803710938, 3.5482940673828125, 3.2382278442382812, 3.595630645751953, 4.5572052001953125, 3.7626800537109375, 5.0876312255859375, 2.3562698364257812, 2.2733840942382812], "custom_metrics": {}}}, "num_steps_sampled": 23403, "num_agent_steps_sampled": 46806, "num_steps_trained": 38208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 76416, "last_target_update_ts": 23303, "num_target_updates": 195}, "done": false, "episodes_total": 1258, "training_iteration": 74, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-41", "timestamp": 1648811801, "time_this_iter_s": 1.112537145614624, "time_total_s": 90.88911366462708, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 90.88911366462708, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 33.25, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.5, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.7, "policy1": -19.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30718359360549075, "mean_inference_ms": 1.739735810427535, "mean_action_processing_ms": 0.11971216224869785, "mean_env_wait_ms": 0.07399470751685022, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 23703, "timesteps_this_iter": 32, "agent_timesteps_total": 47406, "timers": {"load_time_ms": 0.444, "load_throughput": 72082.561, "learn_time_ms": 7.683, "learn_throughput": 4164.812, "update_time_ms": 4.789}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.20428466796875, "min_q": -84.97614288330078, "max_q": -75.72018432617188, "mean_td_error": 0.21366405487060547, "model": {}}, "td_error": [-0.1597900390625, 0.0472412109375, -0.7767257690429688, 0.09889984130859375, -1.6234893798828125, -0.6915740966796875, -0.06475067138671875, 0.16448211669921875, 0.03115081787109375, -0.14714813232421875, 0.17613983154296875, 2.202239990234375, 0.0493316650390625, 0.12380218505859375, -0.2834625244140625, 0.12380218505859375, 0.17613983154296875, 0.21581268310546875, 0.16191864013671875, 0.1388702392578125, 0.9350204467773438, 0.5536575317382812, 0.54498291015625, 0.5077438354492188, -0.725921630859375, 0.2111053466796875, -0.134307861328125, 0.08414459228515625, 0.284149169921875, 0.33986663818359375, -0.08829498291015625, 4.362213134765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.81488037109375, "min_q": -75.14041900634766, "max_q": -67.10608673095703, "mean_td_error": -3.2214126586914062, "model": {}}, "td_error": [-0.946746826171875, -1.1546707153320312, -0.78302001953125, -0.4125213623046875, -1.2878875732421875, -2.16796875, -0.7753677368164062, -1.0298233032226562, -1.2186126708984375, -1.474212646484375, -1.5390243530273438, -1.4554519653320312, -1.2263031005859375, -1.497039794921875, -1.1413345336914062, 1.184356689453125, -1.6219863891601562, -3.080810546875, -0.7520904541015625, -0.8787918090820312, -69.16348266601562, 0.009033203125, -0.31500244140625, -0.6537628173828125, -0.9641952514648438, -1.8734207153320312, 0.2619171142578125, -0.33658599853515625, -1.6115570068359375, -1.9788284301757812, -2.301422119140625, -0.898590087890625], "custom_metrics": {}}}, "num_steps_sampled": 23703, "num_agent_steps_sampled": 47406, "num_steps_trained": 38688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 77376, "last_target_update_ts": 23663, "num_target_updates": 198}, "done": false, "episodes_total": 1273, "training_iteration": 75, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-42", "timestamp": 1648811802, "time_this_iter_s": 1.118636131286621, "time_total_s": 92.0077497959137, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 92.0077497959137, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 29.4, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.5, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.7, "policy1": -19.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3071457312181402, "mean_inference_ms": 1.7396150950699545, "mean_action_processing_ms": 0.11971972737891372, "mean_env_wait_ms": 0.07397857119372211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24003, "timesteps_this_iter": 32, "agent_timesteps_total": 48006, "timers": {"load_time_ms": 0.41, "load_throughput": 78115.311, "learn_time_ms": 8.415, "learn_throughput": 3802.547, "update_time_ms": 4.891}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.26385498046875, "min_q": -85.35073852539062, "max_q": -75.5019302368164, "mean_td_error": 0.4700002670288086, "model": {}}, "td_error": [0.9802093505859375, 0.48089599609375, 1.0760040283203125, 0.74725341796875, 0.2079620361328125, 0.8678665161132812, 0.6938095092773438, 0.47678375244140625, 0.3457183837890625, 1.4312973022460938, 0.6736679077148438, 0.5880584716796875, 0.454803466796875, 0.47025299072265625, 0.5716094970703125, 0.454803466796875, 0.46073150634765625, 0.5702362060546875, 1.0312042236328125, 0.0087127685546875, 0.2955780029296875, 0.166748046875, -0.4764556884765625, 0.340911865234375, 1.1807174682617188, 0.7779998779296875, 0.8588409423828125, -0.8914871215820312, 0.1367340087890625, 0.33953857421875, -0.24370574951171875, -0.03729248046875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.36347961425781, "min_q": -72.19837951660156, "max_q": -66.05364227294922, "mean_td_error": -0.9014346599578857, "model": {}}, "td_error": [-1.0532760620117188, -2.0206832885742188, -0.5294036865234375, -1.767791748046875, -2.3743743896484375, -1.7923431396484375, 1.6942825317382812, -1.7183151245117188, -1.711395263671875, -0.02774810791015625, 1.926544189453125, -0.4659423828125, -1.4110260009765625, -1.2093124389648438, -1.008148193359375, -2.4922866821289062, -0.1077423095703125, -0.850372314453125, -1.95330810546875, -2.5271072387695312, 1.799774169921875, -0.7049407958984375, -0.365570068359375, -0.6619186401367188, -0.7088546752929688, -0.34293365478515625, -2.3357315063476562, -1.9675750732421875, -1.1040115356445312, -1.4848403930664062, 1.4364776611328125, -1.0060348510742188], "custom_metrics": {}}}, "num_steps_sampled": 24003, "num_agent_steps_sampled": 48006, "num_steps_trained": 39168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78336, "last_target_update_ts": 23903, "num_target_updates": 200}, "done": false, "episodes_total": 1288, "training_iteration": 76, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-43", "timestamp": 1648811803, "time_this_iter_s": 1.2087500095367432, "time_total_s": 93.21649980545044, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 93.21649980545044, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 31.95, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.5, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.7, "policy1": -19.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3072082425826348, "mean_inference_ms": 1.7401327393235004, "mean_action_processing_ms": 0.11977621579813041, "mean_env_wait_ms": 0.07399235445552327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24303, "timesteps_this_iter": 32, "agent_timesteps_total": 48606, "timers": {"load_time_ms": 0.464, "load_throughput": 68896.734, "learn_time_ms": 8.79, "learn_throughput": 3640.444, "update_time_ms": 5.19}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -77.83004760742188, "min_q": -83.73381805419922, "max_q": -73.26004028320312, "mean_td_error": -1.3351225852966309, "model": {}}, "td_error": [-0.12561798095703125, 1.8349990844726562, 1.325164794921875, 1.1239471435546875, -3.31884765625, 1.7297592163085938, 1.604522705078125, 1.6069869995117188, 1.59808349609375, -81.03569793701172, 1.7717742919921875, 1.3103713989257812, 0.5537643432617188, 1.8223114013671875, 0.9876327514648438, 2.3502197265625, 0.9284286499023438, 1.0121612548828125, 1.8194351196289062, 0.1305999755859375, 1.4143447875976562, 1.890869140625, -0.367889404296875, 0.6907424926757812, 2.2494430541992188, 0.9974441528320312, 1.8430404663085938, 1.4445953369140625, 1.8275604248046875, 1.7717742919921875, 2.589935302734375, 1.8942184448242188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.90022277832031, "min_q": -69.4754867553711, "max_q": -66.21892547607422, "mean_td_error": -1.7040824890136719, "model": {}}, "td_error": [1.1222763061523438, -0.2073211669921875, 0.4850616455078125, 0.6453399658203125, 0.9985885620117188, 0.06522369384765625, 0.39061737060546875, 2.6408157348632812, -0.5354080200195312, 0.776275634765625, -0.2772979736328125, 0.7884674072265625, 0.234100341796875, -0.43743133544921875, 0.0225372314453125, 0.37447357177734375, 0.740325927734375, 2.6408157348632812, 0.435546875, -0.0693206787109375, -65.4149169921875, 0.33343505859375, -0.5150375366210938, 0.3635101318359375, 0.234100341796875, -0.6021270751953125, 0.8085861206054688, 1.2713470458984375, -1.4548492431640625, -0.12262725830078125, 0.2707672119140625, -0.5365142822265625], "custom_metrics": {}}}, "num_steps_sampled": 24303, "num_agent_steps_sampled": 48606, "num_steps_trained": 39648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 79296, "last_target_update_ts": 24263, "num_target_updates": 203}, "done": false, "episodes_total": 1303, "training_iteration": 77, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-45", "timestamp": 1648811805, "time_this_iter_s": 1.3158302307128906, "time_total_s": 94.53233003616333, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 94.53233003616333, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 32.15, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.6, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.8, "policy1": -19.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3073536252475386, "mean_inference_ms": 1.741352689125024, "mean_action_processing_ms": 0.1198868054133658, "mean_env_wait_ms": 0.07402798133063936, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24603, "timesteps_this_iter": 32, "agent_timesteps_total": 49206, "timers": {"load_time_ms": 0.467, "load_throughput": 68555.383, "learn_time_ms": 8.391, "learn_throughput": 3813.404, "update_time_ms": 5.371}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.65543365478516, "min_q": -82.75943756103516, "max_q": -75.18156433105469, "mean_td_error": -4.438077926635742, "model": {}}, "td_error": [-0.26557159423828125, 0.3555450439453125, 0.7213363647460938, 0.546234130859375, 0.6601181030273438, 0.03780364990234375, -78.89781188964844, -0.15802001953125, 0.9830551147460938, -0.6154403686523438, -74.4049301147461, 0.03327178955078125, 0.8959732055664062, 0.8962326049804688, 0.43228912353515625, 0.06293487548828125, -0.7036972045898438, 0.455474853515625, -0.240753173828125, 0.7743911743164062, 0.8469390869140625, -0.6244964599609375, -0.1508941650390625, 0.7849502563476562, 0.5728988647460938, 0.98638916015625, -0.1784515380859375, 0.8821182250976562, 1.166412353515625, 0.18514251708984375, 0.7510604858398438, 1.191009521484375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.1202392578125, "min_q": -69.45223999023438, "max_q": -64.8141860961914, "mean_td_error": 0.00030922889709472656, "model": {}}, "td_error": [-0.4906463623046875, 1.0076522827148438, 0.40964508056640625, 0.11481475830078125, 0.7787322998046875, -0.152130126953125, -1.3857421875, -0.137664794921875, 0.549468994140625, 0.11724090576171875, -0.5810470581054688, -0.350677490234375, -0.06893157958984375, 0.33264923095703125, 0.36916351318359375, -0.1798248291015625, 0.5697555541992188, -0.2406005859375, -0.12059783935546875, 0.1738128662109375, -0.233673095703125, 0.28958892822265625, -0.318695068359375, -0.40306854248046875, 0.10540771484375, -0.908355712890625, 0.0674591064453125, -0.20999908447265625, -1.556427001953125, 0.6835861206054688, 1.31854248046875, 0.46045684814453125], "custom_metrics": {}}}, "num_steps_sampled": 24603, "num_agent_steps_sampled": 49206, "num_steps_trained": 40128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 80256, "last_target_update_ts": 24503, "num_target_updates": 205}, "done": false, "episodes_total": 1318, "training_iteration": 78, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-46", "timestamp": 1648811806, "time_this_iter_s": 1.3314764499664307, "time_total_s": 95.86380648612976, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837d680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837d680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 95.86380648612976, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 33.4, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.7, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -10.0}, "policy_reward_mean": {"policy0": -19.8, "policy1": -19.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30748813967820277, "mean_inference_ms": 1.7425551212102963, "mean_action_processing_ms": 0.11999326075774552, "mean_env_wait_ms": 0.07406386208403874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 24903, "timesteps_this_iter": 32, "agent_timesteps_total": 49806, "timers": {"load_time_ms": 0.436, "load_throughput": 73435.317, "learn_time_ms": 7.846, "learn_throughput": 4078.624, "update_time_ms": 4.78}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.58735656738281, "min_q": -84.9720230102539, "max_q": -76.40267944335938, "mean_td_error": -3.6817989349365234, "model": {}}, "td_error": [-1.5561981201171875, -1.1321563720703125, -1.891021728515625, -1.8920059204101562, -1.808319091796875, -1.5810775756835938, -1.791168212890625, -1.7445297241210938, -1.5983352661132812, -0.4390869140625, -1.0609512329101562, -1.4362945556640625, -2.3362045288085938, -2.40478515625, -1.9046859741210938, -1.6516571044921875, -76.51002502441406, -0.2125701904296875, -0.5270538330078125, -2.4876785278320312, -2.2304153442382812, 4.405998229980469, -1.5561981201171875, -1.5254135131835938, -1.7571182250976562, -2.0096817016601562, -1.1376113891601562, -0.08100128173828125, -1.79107666015625, -1.7506179809570312, -0.8375473022460938, -1.5810775756835938], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.15036010742188, "min_q": -70.76245880126953, "max_q": -66.16787719726562, "mean_td_error": -5.028358459472656, "model": {}}, "td_error": [-10.766166687011719, -1.190460205078125, -0.186767578125, -0.28490447998046875, -69.70249938964844, -0.6075363159179688, -0.0526123046875, -0.7215042114257812, 0.39196014404296875, -0.5004348754882812, -0.9778900146484375, -0.30678558349609375, -1.2379837036132812, 0.204559326171875, -0.5004348754882812, 0.20477294921875, -0.34917449951171875, -0.2905426025390625, -1.1393356323242188, -0.8706283569335938, 0.12937164306640625, 0.2264556884765625, -0.531402587890625, -0.21518707275390625, -66.91389465332031, -1.7462081909179688, -0.499969482421875, -0.5851669311523438, -0.16397857666015625, -0.7215042114257812, -0.28011322021484375, -0.7215118408203125], "custom_metrics": {}}}, "num_steps_sampled": 24903, "num_agent_steps_sampled": 49806, "num_steps_trained": 40608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 81216, "last_target_update_ts": 24863, "num_target_updates": 208}, "done": false, "episodes_total": 1333, "training_iteration": 79, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-47", "timestamp": 1648811807, "time_this_iter_s": 1.159714698791504, "time_total_s": 97.02352118492126, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 97.02352118492126, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 31.9, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.8, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -19.8, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30762791581705456, "mean_inference_ms": 1.7438242027030446, "mean_action_processing_ms": 0.12010131007904062, "mean_env_wait_ms": 0.0741040796566542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25203, "timesteps_this_iter": 32, "agent_timesteps_total": 50406, "timers": {"load_time_ms": 0.468, "load_throughput": 68401.655, "learn_time_ms": 7.803, "learn_throughput": 4100.956, "update_time_ms": 5.041}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.63277435302734, "min_q": -84.79539489746094, "max_q": -75.8634033203125, "mean_td_error": -1.6542418003082275, "model": {}}, "td_error": [0.27809906005859375, 0.6519927978515625, 0.257965087890625, 0.6551132202148438, 1.213531494140625, 0.9245223999023438, 0.3740692138671875, 0.85614013671875, 0.22930145263671875, 0.8622207641601562, -1.2848434448242188, 1.1635284423828125, 2.0657577514648438, 0.6551132202148438, -0.165802001953125, 0.13877105712890625, 0.04144287109375, 0.29482269287109375, -74.90809631347656, 0.9874801635742188, 0.9354934692382812, 0.6519927978515625, 0.27809906005859375, 0.584716796875, 1.1575469970703125, 1.0415267944335938, 2.377655029296875, 0.6551132202148438, 1.161224365234375, 1.6255569458007812, 0.7527999877929688, 0.5514068603515625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.47571563720703, "min_q": -71.09736633300781, "max_q": -65.33911895751953, "mean_td_error": -1.3916115760803223, "model": {}}, "td_error": [-0.776031494140625, 0.4743804931640625, 1.1095046997070312, 0.9418487548828125, 1.0784835815429688, 0.28778839111328125, -0.07758331298828125, 1.7315521240234375, 1.1924819946289062, 1.1418685913085938, 0.8891830444335938, 0.9405441284179688, 0.5830230712890625, 1.7698745727539062, 0.6225814819335938, 1.1462783813476562, -0.1457672119140625, -0.13625335693359375, -0.23651885986328125, 1.1585617065429688, 0.9201431274414062, 1.2330169677734375, 1.9193878173828125, 0.6448822021484375, -66.31822204589844, 0.4257659912109375, -0.6762466430664062, 0.5561599731445312, 1.031402587890625, 0.5051498413085938, 1.4071273803710938, 0.12406158447265625], "custom_metrics": {}}}, "num_steps_sampled": 25203, "num_agent_steps_sampled": 50406, "num_steps_trained": 41088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 82176, "last_target_update_ts": 25103, "num_target_updates": 210}, "done": false, "episodes_total": 1348, "training_iteration": 80, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-48", "timestamp": 1648811808, "time_this_iter_s": 1.1411702632904053, "time_total_s": 98.16469144821167, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 98.16469144821167, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 30.200000000000003, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.9, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -19.9, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3077771743798931, "mean_inference_ms": 1.745212628519069, "mean_action_processing_ms": 0.12021159458476398, "mean_env_wait_ms": 0.07414619751636757, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25503, "timesteps_this_iter": 32, "agent_timesteps_total": 51006, "timers": {"load_time_ms": 0.512, "load_throughput": 62441.371, "learn_time_ms": 8.035, "learn_throughput": 3982.568, "update_time_ms": 4.897}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.44232177734375, "min_q": -86.77590942382812, "max_q": -75.6025619506836, "mean_td_error": -0.27019643783569336, "model": {}}, "td_error": [-0.30966949462890625, -0.04437255859375, 0.2647552490234375, -0.86224365234375, -0.43727874755859375, -0.43727874755859375, -0.5382232666015625, 0.4156036376953125, -0.8230743408203125, -0.866424560546875, -0.7242431640625, -0.5382232666015625, -0.16313934326171875, -2.1835250854492188, 0.47714996337890625, -0.58905029296875, 5.978759765625, -0.5966415405273438, -0.6469039916992188, -0.5484390258789062, -2.70208740234375, -0.7986373901367188, 0.2647552490234375, -0.76654052734375, 0.01056671142578125, 0.3462677001953125, -0.47513580322265625, -0.604736328125, 0.6686630249023438, -0.7053146362304688, -0.6279067993164062, -0.08371734619140625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.49234008789062, "min_q": -70.19202423095703, "max_q": -63.809181213378906, "mean_td_error": 1.3621811866760254, "model": {}}, "td_error": [0.9298095703125, 1.2061004638671875, 1.9109725952148438, 1.3719100952148438, 2.1002120971679688, 1.73419189453125, 0.83026123046875, 2.0479888916015625, 1.5433807373046875, 1.1525344848632812, 1.3639068603515625, 1.5656814575195312, 0.7580795288085938, 1.1320648193359375, 1.52777099609375, 1.2590866088867188, 1.5168991088867188, 0.9773712158203125, 0.838653564453125, 1.34417724609375, 1.0351409912109375, 1.5858230590820312, 1.5132827758789062, 1.366180419921875, 1.8193588256835938, 0.012359619140625, 1.4340133666992188, 0.967529296875, 1.7388458251953125, 1.2590866088867188, 1.9054107666015625, 1.8417129516601562], "custom_metrics": {}}}, "num_steps_sampled": 25503, "num_agent_steps_sampled": 51006, "num_steps_trained": 41568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 83136, "last_target_update_ts": 25463, "num_target_updates": 213}, "done": false, "episodes_total": 1363, "training_iteration": 81, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-50", "timestamp": 1648811810, "time_this_iter_s": 1.1420798301696777, "time_total_s": 99.30677127838135, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff0201a6830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff0201a6830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 99.30677127838135, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 32.5, "ram_util_percent": 59.9}}
{"episode_reward_max": -30.0, "episode_reward_min": -40.0, "episode_reward_mean": -39.9, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -10.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -19.9, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -30.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -10.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3079363006836137, "mean_inference_ms": 1.7465971361846266, "mean_action_processing_ms": 0.12031933065805334, "mean_env_wait_ms": 0.07418745080186556, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 25803, "timesteps_this_iter": 32, "agent_timesteps_total": 51606, "timers": {"load_time_ms": 0.448, "load_throughput": 71468.439, "learn_time_ms": 8.098, "learn_throughput": 3951.392, "update_time_ms": 5.022}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.31236267089844, "min_q": -84.84400177001953, "max_q": -72.83712768554688, "mean_td_error": -2.0423762798309326, "model": {}}, "td_error": [-75.16552734375, 2.3014984130859375, 1.3341522216796875, 0.11855316162109375, -0.2245941162109375, 0.4507598876953125, 0.5111312866210938, 0.6236343383789062, 1.0277938842773438, 0.5497817993164062, -0.7919692993164062, -0.416473388671875, 0.1108856201171875, 0.39745330810546875, 0.25815582275390625, -0.9606170654296875, -0.9998321533203125, 0.2641754150390625, -0.2739410400390625, 0.6347579956054688, 0.6236343383789062, 0.6236343383789062, 0.43563079833984375, 0.11354827880859375, 0.27178192138671875, -0.33313751220703125, -0.00693511962890625, 0.36004638671875, 1.4324417114257812, 0.5587081909179688, 0.38294219970703125, 0.431884765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -67.53262329101562, "min_q": -70.22142028808594, "max_q": -64.8604507446289, "mean_td_error": 0.3999063968658447, "model": {}}, "td_error": [0.6334609985351562, -0.4548492431640625, -0.8835525512695312, 0.6290359497070312, -0.5544815063476562, 0.18596649169921875, 0.9128341674804688, 0.32764434814453125, 0.573944091796875, 0.7556686401367188, 0.1845703125, -0.4548492431640625, -0.5127334594726562, 0.076934814453125, 0.80987548828125, 1.1537399291992188, 1.1123275756835938, 0.8004989624023438, 0.5884170532226562, -0.125, 0.9863433837890625, 1.1005706787109375, 0.83209228515625, -0.5544815063476562, 0.83209228515625, 0.23020172119140625, 0.320465087890625, 0.7002410888671875, 0.8252334594726562, 0.6923599243164062, 0.35467529296875, 0.7177581787109375], "custom_metrics": {}}}, "num_steps_sampled": 25803, "num_agent_steps_sampled": 51606, "num_steps_trained": 42048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84096, "last_target_update_ts": 25703, "num_target_updates": 215}, "done": false, "episodes_total": 1378, "training_iteration": 82, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-51", "timestamp": 1648811811, "time_this_iter_s": 1.1661605834960938, "time_total_s": 100.47293186187744, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84133b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84133b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 100.47293186187744, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 33.05, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30810386582319776, "mean_inference_ms": 1.7478861455208428, "mean_action_processing_ms": 0.12041576262411872, "mean_env_wait_ms": 0.07421631384218945, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26103, "timesteps_this_iter": 32, "agent_timesteps_total": 52206, "timers": {"load_time_ms": 0.459, "load_throughput": 69658.36, "learn_time_ms": 7.848, "learn_throughput": 4077.472, "update_time_ms": 4.807}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.34668731689453, "min_q": -83.39066314697266, "max_q": -71.55197143554688, "mean_td_error": -2.3027188777923584, "model": {}}, "td_error": [1.022674560546875, -77.38099670410156, 0.26419830322265625, 1.2378311157226562, 0.29232025146484375, 0.7409744262695312, 0.4143829345703125, 0.9357757568359375, 1.1944580078125, -0.058990478515625, 0.9127655029296875, 1.9862899780273438, 1.5486831665039062, 0.241119384765625, 0.05956268310546875, 0.15476226806640625, -0.2364349365234375, 0.97174072265625, 0.2409210205078125, 0.25634002685546875, 0.534820556640625, -0.7978439331054688, -0.68182373046875, -0.0993804931640625, 0.33705902099609375, 0.34726715087890625, 0.6217193603515625, 0.830718994140625, 1.08837890625, 0.6442031860351562, -12.156181335449219, 0.8456802368164062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.19611358642578, "min_q": -73.30998229980469, "max_q": -66.96865844726562, "mean_td_error": -4.818744659423828, "model": {}}, "td_error": [0.13519287109375, 0.26148223876953125, -0.38165283203125, -1.85809326171875, -67.85006713867188, -0.6945877075195312, -0.222808837890625, -2.61981201171875, -0.6826553344726562, -1.3125839233398438, -0.56341552734375, -0.7088165283203125, -0.51873779296875, -0.9103622436523438, -0.7278976440429688, -0.7519378662109375, -0.49908447265625, -1.4762725830078125, -0.222808837890625, -0.4461517333984375, -0.9107742309570312, -0.6888656616210938, -0.2175445556640625, -0.5339431762695312, -67.69049835205078, -0.399993896484375, -0.26584625244140625, -0.20719146728515625, 2.2171554565429688, -1.34619140625, 0.2568511962890625, -2.3619232177734375], "custom_metrics": {}}}, "num_steps_sampled": 26103, "num_agent_steps_sampled": 52206, "num_steps_trained": 42528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 85056, "last_target_update_ts": 26063, "num_target_updates": 218}, "done": false, "episodes_total": 1393, "training_iteration": 83, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-52", "timestamp": 1648811812, "time_this_iter_s": 1.267446517944336, "time_total_s": 101.74037837982178, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef87714d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 101.74037837982178, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 34.3, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30819155974734835, "mean_inference_ms": 1.7485940485230906, "mean_action_processing_ms": 0.12046719898130111, "mean_env_wait_ms": 0.07421326176349848, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26403, "timesteps_this_iter": 32, "agent_timesteps_total": 52806, "timers": {"load_time_ms": 0.442, "load_throughput": 72397.501, "learn_time_ms": 7.854, "learn_throughput": 4074.439, "update_time_ms": 4.824}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.2740478515625, "min_q": -87.39598846435547, "max_q": -74.17301940917969, "mean_td_error": -7.266983985900879, "model": {}}, "td_error": [-0.7339324951171875, -1.3946914672851562, 1.7386245727539062, -0.7384262084960938, -0.937103271484375, -1.3675079345703125, 0.2681884765625, 0.34789276123046875, -0.9491043090820312, -0.13492584228515625, -0.5825729370117188, 0.34789276123046875, 0.941162109375, 0.03939056396484375, -0.6006927490234375, 0.5458145141601562, -1.3001861572265625, -78.27229309082031, 0.23119354248046875, -0.06961822509765625, -0.982086181640625, 0.14212799072265625, 0.0372772216796875, -0.38330841064453125, -85.75234985351562, -0.5349807739257812, 1.5131072998046875, 2.252288818359375, -0.4854583740234375, -0.0897674560546875, -74.90660858154297, 9.267166137695312], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -70.3971176147461, "min_q": -72.74483489990234, "max_q": -67.33726501464844, "mean_td_error": -2.058100700378418, "model": {}}, "td_error": [0.55816650390625, 0.2514190673828125, 0.16678619384765625, 1.6189498901367188, 0.566192626953125, 0.7840118408203125, 1.9722137451171875, 0.920135498046875, 0.17972564697265625, 0.4871368408203125, -0.152557373046875, 0.6101455688476562, 0.6101455688476562, 0.1753387451171875, 0.5092315673828125, -1.8928756713867188, 0.533172607421875, 1.004730224609375, 0.07785797119140625, 1.1061477661132812, 0.7837142944335938, -11.309524536132812, 0.31304931640625, 0.9067764282226562, -0.9377975463867188, 0.8000564575195312, 0.20011138916015625, 0.5162124633789062, -0.61810302734375, 0.9481353759765625, 0.19451904296875, -67.74244689941406], "custom_metrics": {}}}, "num_steps_sampled": 26403, "num_agent_steps_sampled": 52806, "num_steps_trained": 43008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86016, "last_target_update_ts": 26303, "num_target_updates": 220}, "done": false, "episodes_total": 1408, "training_iteration": 84, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-53", "timestamp": 1648811813, "time_this_iter_s": 1.1423330307006836, "time_total_s": 102.88271141052246, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 102.88271141052246, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 32.95, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30822478851889734, "mean_inference_ms": 1.748847658343268, "mean_action_processing_ms": 0.12048275987114973, "mean_env_wait_ms": 0.07419918802157445, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 26703, "timesteps_this_iter": 32, "agent_timesteps_total": 53406, "timers": {"load_time_ms": 0.431, "load_throughput": 74198.534, "learn_time_ms": 7.986, "learn_throughput": 4007.133, "update_time_ms": 5.376}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -77.80313873291016, "min_q": -87.11518096923828, "max_q": -74.13426971435547, "mean_td_error": -1.4046995639801025, "model": {}}, "td_error": [1.2399520874023438, 0.8885421752929688, -0.5254287719726562, 0.542510986328125, 0.8885421752929688, 1.449188232421875, -0.8885955810546875, 1.2237701416015625, 1.7891006469726562, 0.7873992919921875, 1.185699462890625, 0.0340576171875, 1.3461151123046875, 0.9980926513671875, 1.646392822265625, 1.403533935546875, 0.750274658203125, 1.4007415771484375, 1.5396804809570312, 0.76507568359375, 1.1865463256835938, 0.5947418212890625, 1.4369964599609375, 0.9658966064453125, 1.7973861694335938, 1.0205535888671875, 0.2443084716796875, 1.1450424194335938, 0.5671234130859375, 1.0754013061523438, -74.37837219238281, 0.9293441772460938], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.30126953125, "min_q": -76.46977996826172, "max_q": -65.47965240478516, "mean_td_error": 0.4947323799133301, "model": {}}, "td_error": [0.5369720458984375, -1.0176773071289062, 0.7296218872070312, 0.708038330078125, 0.500030517578125, 0.9294509887695312, 0.500030517578125, 0.3110504150390625, 0.59893798828125, 0.17330169677734375, -1.3279800415039062, -0.8789520263671875, -0.30678558349609375, 0.590911865234375, 0.8302001953125, 1.0827789306640625, 0.401580810546875, 2.2166748046875, 1.01019287109375, -3.3583297729492188, 0.3296661376953125, 0.46834564208984375, 3.0544662475585938, 0.42987823486328125, 1.2602157592773438, 0.8794784545898438, 0.33069610595703125, 0.16417694091796875, 1.04901123046875, 1.3115005493164062, 0.8640670776367188, 1.4598846435546875], "custom_metrics": {}}}, "num_steps_sampled": 26703, "num_agent_steps_sampled": 53406, "num_steps_trained": 43488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 86976, "last_target_update_ts": 26663, "num_target_updates": 223}, "done": false, "episodes_total": 1423, "training_iteration": 85, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-54", "timestamp": 1648811814, "time_this_iter_s": 1.1488280296325684, "time_total_s": 104.03153944015503, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84223b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84223b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 104.03153944015503, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 31.7, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30829879590543896, "mean_inference_ms": 1.7494336068834482, "mean_action_processing_ms": 0.12052399855026007, "mean_env_wait_ms": 0.0742040203257484, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27003, "timesteps_this_iter": 32, "agent_timesteps_total": 54006, "timers": {"load_time_ms": 0.486, "load_throughput": 65847.877, "learn_time_ms": 8.627, "learn_throughput": 3709.363, "update_time_ms": 5.396}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -80.71260070800781, "min_q": -89.08502197265625, "max_q": -75.75321197509766, "mean_td_error": -6.259445667266846, "model": {}}, "td_error": [-4.408058166503906, -1.6524124145507812, -74.8237075805664, -0.6529083251953125, -1.046051025390625, -2.0442352294921875, -1.033416748046875, -2.4508132934570312, -2.7375030517578125, -2.1420211791992188, -1.392822265625, -75.91110229492188, -2.2098541259765625, -1.1153411865234375, -1.68310546875, -3.5596389770507812, -1.4097213745117188, -1.42803955078125, -0.8422470092773438, -1.9548110961914062, 0.00439453125, -2.1528091430664062, -2.0387191772460938, -0.8061752319335938, -1.371673583984375, -1.0252761840820312, -1.3152542114257812, -0.5070953369140625, -1.89202880859375, -2.23291015625, -1.0302810668945312, -1.4366226196289062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.90045166015625, "min_q": -77.6129379272461, "max_q": -68.18451690673828, "mean_td_error": -9.056550979614258, "model": {}}, "td_error": [1.2605438232421875, -0.8057861328125, 0.0, 0.9818191528320312, 1.2568130493164062, -0.09209442138671875, -2.1714248657226562, -71.10120391845703, -1.2140426635742188, 0.27533721923828125, 0.22660064697265625, -67.28430938720703, -0.8889083862304688, 0.22660064697265625, 0.0120391845703125, -0.6990737915039062, -74.20638275146484, -0.34778594970703125, 0.751007080078125, -0.6948623657226562, 1.6726608276367188, 0.17386627197265625, 0.12854766845703125, -75.14888763427734, -0.8371505737304688, 0.756744384765625, -1.3353958129882812, 0.8119354248046875, 0.11643218994140625, 0.22660064697265625, -1.5089187622070312, -0.3509674072265625], "custom_metrics": {}}}, "num_steps_sampled": 27003, "num_agent_steps_sampled": 54006, "num_steps_trained": 43968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 87936, "last_target_update_ts": 26903, "num_target_updates": 225}, "done": false, "episodes_total": 1438, "training_iteration": 86, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-56", "timestamp": 1648811816, "time_this_iter_s": 1.2693426609039307, "time_total_s": 105.30088210105896, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 105.30088210105896, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 31.1, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3084211791949271, "mean_inference_ms": 1.7504107781716147, "mean_action_processing_ms": 0.12059835246068375, "mean_env_wait_ms": 0.07422983246229248, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27303, "timesteps_this_iter": 32, "agent_timesteps_total": 54606, "timers": {"load_time_ms": 0.444, "load_throughput": 72032.27, "learn_time_ms": 8.287, "learn_throughput": 3861.27, "update_time_ms": 5.349}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.69735717773438, "min_q": -85.50373077392578, "max_q": -71.31427001953125, "mean_td_error": -11.651859283447266, "model": {}}, "td_error": [-72.8214340209961, 0.1126251220703125, 0.923553466796875, 0.41751861572265625, 0.5008621215820312, -76.62653350830078, 1.4814834594726562, 1.3368988037109375, 0.8797607421875, -1.1609725952148438, 0.2183380126953125, 1.0269775390625, -74.0679931640625, 0.38259124755859375, 0.6244964599609375, 0.22463226318359375, 1.00213623046875, -2.8116226196289062, 2.475311279296875, 0.30379486083984375, 1.0269775390625, -81.32742309570312, 0.5677413940429688, 1.1362228393554688, -80.6861343383789, 0.5722122192382812, 1.0806732177734375, -0.327239990234375, -0.17711639404296875, -0.648468017578125, 0.9556503295898438, 0.5449981689453125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -71.75310516357422, "min_q": -75.50682067871094, "max_q": -66.05335235595703, "mean_td_error": -2.4208593368530273, "model": {}}, "td_error": [-65.05335235595703, -0.7961196899414062, 0.7095184326171875, 0.16363525390625, 0.04347991943359375, 0.24219512939453125, 0.09336090087890625, -0.6121292114257812, -0.01747894287109375, 0.7546157836914062, 0.29926300048828125, -0.7366180419921875, -0.493682861328125, -0.1363372802734375, 0.2987060546875, 0.28546142578125, 0.647430419921875, -0.6966400146484375, -0.1961822509765625, 1.2234573364257812, -0.1961822509765625, -13.597846984863281, 1.99053955078125, 1.3065261840820312, 0.7095184326171875, -0.918975830078125, -0.26328277587890625, -0.185546875, -0.0087890625, -1.0891189575195312, -0.19618988037109375, -1.0407333374023438], "custom_metrics": {}}}, "num_steps_sampled": 27303, "num_agent_steps_sampled": 54606, "num_steps_trained": 44448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 88896, "last_target_update_ts": 27263, "num_target_updates": 228}, "done": false, "episodes_total": 1453, "training_iteration": 87, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-57", "timestamp": 1648811817, "time_this_iter_s": 1.2630071640014648, "time_total_s": 106.56388926506042, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84133b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb84133b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 106.56388926506042, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 30.9, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30857112053635255, "mean_inference_ms": 1.7515277662286184, "mean_action_processing_ms": 0.1206841957589737, "mean_env_wait_ms": 0.07426355547092531, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27603, "timesteps_this_iter": 32, "agent_timesteps_total": 55206, "timers": {"load_time_ms": 0.482, "load_throughput": 66365.57, "learn_time_ms": 8.16, "learn_throughput": 3921.64, "update_time_ms": 4.922}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.25967407226562, "min_q": -83.65037536621094, "max_q": -71.67064666748047, "mean_td_error": 0.5345897674560547, "model": {}}, "td_error": [-0.04266357421875, 0.8610000610351562, 0.5261688232421875, 0.7689971923828125, 0.9368438720703125, 0.3939208984375, -0.2229766845703125, 0.9316635131835938, 1.3775253295898438, 0.9082489013671875, -0.0023651123046875, -0.5432662963867188, 1.51507568359375, 2.060089111328125, -0.5598068237304688, 1.64996337890625, 0.8217086791992188, 0.7833404541015625, 0.4855804443359375, 1.3437957763671875, 1.2388992309570312, 0.3939208984375, 0.9675674438476562, 0.324920654296875, -0.934539794921875, 0.4617156982421875, -0.8042373657226562, -0.431427001953125, 0.8936309814453125, 0.3939208984375, -0.4195556640625, 1.0292129516601562], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.17123413085938, "min_q": -76.53202056884766, "max_q": -65.21110534667969, "mean_td_error": -6.932674407958984, "model": {}}, "td_error": [-0.27142333984375, -0.14012908935546875, -0.4961395263671875, -0.45845794677734375, 1.3420181274414062, -0.25464630126953125, -0.5909576416015625, 0.000640869140625, -0.5673446655273438, 0.39533233642578125, -4.093452453613281, -2.2648468017578125, -0.03205108642578125, -0.4961395263671875, 1.8562774658203125, 1.8562774658203125, 0.865020751953125, -68.22306060791016, 1.1451187133789062, 0.40834808349609375, -0.3091583251953125, -0.39846038818359375, -0.5673446655273438, -72.89873504638672, -0.16616058349609375, 0.0139312744140625, -73.36286926269531, -0.5105743408203125, -0.4961395263671875, -2.8391342163085938, 0.04925537109375, -0.3405914306640625], "custom_metrics": {}}}, "num_steps_sampled": 27603, "num_agent_steps_sampled": 55206, "num_steps_trained": 44928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 89856, "last_target_update_ts": 27503, "num_target_updates": 230}, "done": false, "episodes_total": 1468, "training_iteration": 88, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-16-58", "timestamp": 1648811818, "time_this_iter_s": 1.2134308815002441, "time_total_s": 107.77732014656067, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb83b2170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 107.77732014656067, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3087360246058879, "mean_inference_ms": 1.752764588360344, "mean_action_processing_ms": 0.12078414202718925, "mean_env_wait_ms": 0.07430832546130325, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 27903, "timesteps_this_iter": 32, "agent_timesteps_total": 55806, "timers": {"load_time_ms": 0.429, "load_throughput": 74648.347, "learn_time_ms": 8.143, "learn_throughput": 3929.654, "update_time_ms": 5.168}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.11831665039062, "min_q": -84.35906219482422, "max_q": -76.05496215820312, "mean_td_error": -9.136615753173828, "model": {}}, "td_error": [-83.35906219482422, -2.1700668334960938, -2.28363037109375, -1.4665756225585938, -1.6868743896484375, -1.9511871337890625, -1.9134674072265625, -1.3442153930664062, -2.2111282348632812, -77.20855712890625, -1.6015396118164062, -1.3351669311523438, -0.8170166015625, -2.2819061279296875, -2.4720535278320312, -0.40021514892578125, -0.0157928466796875, -1.6015396118164062, -2.0290298461914062, -1.5279006958007812, -1.667083740234375, -0.7493209838867188, -78.54618835449219, -2.2155227661132812, -0.23138427734375, -11.254524230957031, -0.0157928466796875, -1.8452224731445312, -1.1540756225585938, -0.6850433349609375, -1.7345123291015625, -2.5960922241210938], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.32603454589844, "min_q": -79.00492858886719, "max_q": -68.01847076416016, "mean_td_error": -9.087311744689941, "model": {}}, "td_error": [0.427459716796875, 1.3165054321289062, -67.01847076416016, 1.0448074340820312, 1.5663909912109375, 0.45740509033203125, -0.06473541259765625, -1.3750839233398438, -0.21781158447265625, -74.47683715820312, 0.284088134765625, 0.18805694580078125, 0.1188812255859375, -0.29126739501953125, 0.20043182373046875, 0.5360565185546875, 0.02771759033203125, -71.2051010131836, -3.9897079467773438, -3.6178359985351562, 0.9849624633789062, -0.06473541259765625, 0.28668975830078125, 0.24596405029296875, 0.48616790771484375, -2.4161834716796875, 0.4456939697265625, -0.5460357666015625, 0.03345489501953125, 0.5565032958984375, -0.41014862060546875, -74.30724334716797], "custom_metrics": {}}}, "num_steps_sampled": 27903, "num_agent_steps_sampled": 55806, "num_steps_trained": 45408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90816, "last_target_update_ts": 27863, "num_target_updates": 233}, "done": false, "episodes_total": 1483, "training_iteration": 89, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-00", "timestamp": 1648811820, "time_this_iter_s": 1.2318482398986816, "time_total_s": 109.00916838645935, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101fb680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 109.00916838645935, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 32.6, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30885441493594246, "mean_inference_ms": 1.7537566253820551, "mean_action_processing_ms": 0.12086713194935206, "mean_env_wait_ms": 0.07435047772551609, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28203, "timesteps_this_iter": 32, "agent_timesteps_total": 56406, "timers": {"load_time_ms": 0.456, "load_throughput": 70215.918, "learn_time_ms": 7.966, "learn_throughput": 4016.907, "update_time_ms": 4.974}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -79.70747375488281, "min_q": -86.28327178955078, "max_q": -75.5434799194336, "mean_td_error": -5.922764778137207, "model": {}}, "td_error": [-0.5540084838867188, -0.1650238037109375, -1.006378173828125, -0.7465591430664062, -1.1075820922851562, -5.576995849609375, -1.3734512329101562, -0.5191421508789062, -0.6752395629882812, -0.4689483642578125, -1.0708389282226562, -1.1033248901367188, -1.1075820922851562, -0.656951904296875, -1.1033248901367188, -0.0846099853515625, -1.199066162109375, -1.2824478149414062, -3.166473388671875, -1.1075820922851562, -1.0240631103515625, -1.1033248901367188, 0.424896240234375, 0.21807861328125, -1.304656982421875, -0.6342544555664062, -81.17180633544922, -0.8544998168945312, -1.006378173828125, -1.1075820922851562, -1.7259521484375, -76.16340637207031], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.03221130371094, "min_q": -77.0412368774414, "max_q": -67.28609466552734, "mean_td_error": -4.6648054122924805, "model": {}}, "td_error": [-0.0382537841796875, 0.08683013916015625, 0.16301727294921875, -0.17043304443359375, -0.5201034545898438, 1.1240081787109375, -2.3141860961914062, 0.14078521728515625, -1.0422134399414062, 1.0513458251953125, 0.17707061767578125, -0.17043304443359375, -74.14327239990234, 0.570953369140625, 1.1010513305664062, -0.2104034423828125, -1.5649490356445312, 1.48138427734375, -4.6188812255859375, -0.6244049072265625, 0.9197463989257812, 0.4136810302734375, 1.23779296875, -1.4732894897460938, 0.35036468505859375, -0.8587493896484375, 1.1657638549804688, 0.3875732421875, -71.58136749267578, 0.04726409912109375, 1.566802978515625, -1.928253173828125], "custom_metrics": {}}}, "num_steps_sampled": 28203, "num_agent_steps_sampled": 56406, "num_steps_trained": 45888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 91776, "last_target_update_ts": 28103, "num_target_updates": 235}, "done": false, "episodes_total": 1498, "training_iteration": 90, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-01", "timestamp": 1648811821, "time_this_iter_s": 1.133533000946045, "time_total_s": 110.1427013874054, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c64d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c64d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 110.1427013874054, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 32.2, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30897815245531796, "mean_inference_ms": 1.7547554912406074, "mean_action_processing_ms": 0.12095138614032862, "mean_env_wait_ms": 0.07439593367024537, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28503, "timesteps_this_iter": 32, "agent_timesteps_total": 57006, "timers": {"load_time_ms": 0.458, "load_throughput": 69926.919, "learn_time_ms": 8.067, "learn_throughput": 3966.878, "update_time_ms": 5.16}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.46788024902344, "min_q": -84.87553405761719, "max_q": -74.9965591430664, "mean_td_error": -5.6885457038879395, "model": {}}, "td_error": [-1.357421875, -1.2258377075195312, -0.43666839599609375, -0.067779541015625, -0.10221099853515625, -1.5046768188476562, -2.1525955200195312, -2.0667724609375, -0.8658218383789062, -1.1686248779296875, -1.650634765625, -0.9284210205078125, -0.32897186279296875, -0.29434967041015625, -0.08113861083984375, -1.23980712890625, -83.25654602050781, 0.0008544921875, -1.0734710693359375, -0.7816543579101562, 4.4088897705078125, -1.8085098266601562, -1.5146484375, -0.374755859375, -1.5728759765625, -0.5316543579101562, -1.40283203125, -0.9517898559570312, -1.753875732421875, -73.9965591430664, -0.816619873046875, -1.13568115234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -72.76592254638672, "min_q": -76.82707977294922, "max_q": -66.1324234008789, "mean_td_error": -4.401476860046387, "model": {}}, "td_error": [0.3159027099609375, -0.5238800048828125, -0.10771942138671875, 0.70062255859375, 0.5384674072265625, 1.0746917724609375, 0.6976089477539062, 0.08213043212890625, -3.6401138305664062, 0.7809066772460938, -1.2717666625976562, 0.1536865234375, 2.1285552978515625, 0.198638916015625, 1.3432540893554688, 0.18421173095703125, 0.0887451171875, 1.0694503784179688, 1.5187835693359375, 0.8250808715820312, 0.6938552856445312, -0.512054443359375, -80.86079406738281, 0.04022216796875, 1.754425048828125, -65.91059112548828, -3.4645462036132812, 0.18421173095703125, -0.0555419921875, 0.70062255859375, 0.18421173095703125, 0.241455078125], "custom_metrics": {}}}, "num_steps_sampled": 28503, "num_agent_steps_sampled": 57006, "num_steps_trained": 46368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 92736, "last_target_update_ts": 28463, "num_target_updates": 238}, "done": false, "episodes_total": 1513, "training_iteration": 91, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-02", "timestamp": 1648811822, "time_this_iter_s": 1.158008098602295, "time_total_s": 111.30070948600769, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb8422e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 111.30070948600769, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3091072524150128, "mean_inference_ms": 1.755774430995977, "mean_action_processing_ms": 0.12103659235787494, "mean_env_wait_ms": 0.0744390858888662, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 28803, "timesteps_this_iter": 32, "agent_timesteps_total": 57606, "timers": {"load_time_ms": 0.498, "load_throughput": 64225.155, "learn_time_ms": 8.241, "learn_throughput": 3882.885, "update_time_ms": 5.194}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -78.39582061767578, "min_q": -86.00703430175781, "max_q": -72.92739868164062, "mean_td_error": -1.161005973815918, "model": {}}, "td_error": [-0.72332763671875, -0.6403274536132812, -0.6221694946289062, -0.5214614868164062, -0.8968734741210938, -0.3614349365234375, -0.62054443359375, -0.964019775390625, -0.5028762817382812, -0.6629638671875, -0.9692840576171875, -1.0757980346679688, -0.8896484375, -2.1841354370117188, -0.72332763671875, -0.5879287719726562, -1.6143035888671875, -0.25925445556640625, -1.346160888671875, -0.6214370727539062, -0.21320343017578125, -0.8163909912109375, -0.28586578369140625, -0.6288070678710938, -11.379829406738281, -0.964019775390625, -1.5744857788085938, -0.4353790283203125, -0.8262710571289062, -1.4105072021484375, -0.9562225341796875, -0.873931884765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -73.18492889404297, "min_q": -77.53153228759766, "max_q": -69.02201080322266, "mean_td_error": -1.164764165878296, "model": {}}, "td_error": [-1.5955810546875, 1.0680694580078125, 0.2073211669921875, 1.616973876953125, 2.0178298950195312, 0.8832855224609375, 0.0549774169921875, 1.1126937866210938, 2.3621826171875, 1.3929214477539062, 0.36472320556640625, 1.2546768188476562, 2.2411041259765625, -1.5955810546875, 1.8346023559570312, 1.4602127075195312, 0.733001708984375, 2.7282485961914062, 0.6628189086914062, 1.1121292114257812, 1.0195159912109375, 1.4849166870117188, 2.2099533081054688, 0.725738525390625, 2.0402069091796875, 2.2099533081054688, -71.53148651123047, 0.5023193359375, 0.8438796997070312, 1.0795364379882812, 1.0089492797851562, 1.2174530029296875], "custom_metrics": {}}}, "num_steps_sampled": 28803, "num_agent_steps_sampled": 57606, "num_steps_trained": 46848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 93696, "last_target_update_ts": 28703, "num_target_updates": 240}, "done": false, "episodes_total": 1528, "training_iteration": 92, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-03", "timestamp": 1648811823, "time_this_iter_s": 1.195202350616455, "time_total_s": 112.49591183662415, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101e5ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fef101e5ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 112.49591183662415, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 32.4, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.309212275708661, "mean_inference_ms": 1.756612950094962, "mean_action_processing_ms": 0.12110817409991097, "mean_env_wait_ms": 0.07447503799139207, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29103, "timesteps_this_iter": 32, "agent_timesteps_total": 58206, "timers": {"load_time_ms": 0.48, "load_throughput": 66725.194, "learn_time_ms": 8.309, "learn_throughput": 3851.353, "update_time_ms": 5.283}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -76.37184143066406, "min_q": -83.63836669921875, "max_q": -71.65473937988281, "mean_td_error": -4.601147174835205, "model": {}}, "td_error": [0.257965087890625, 0.6244735717773438, 0.257965087890625, 1.2918930053710938, -0.13196563720703125, 2.7148284912109375, 0.14471435546875, -0.26543426513671875, 0.11617279052734375, -0.7990951538085938, -0.06839752197265625, 0.22015380859375, 1.8194046020507812, 0.04524993896484375, -2.1501846313476562, 0.37911224365234375, -72.45427703857422, -0.5856857299804688, -0.0099639892578125, 0.7958450317382812, -78.16328430175781, 0.11626434326171875, 0.5768661499023438, -2.755615234375, 0.14502716064453125, 0.04763031005859375, 0.3404693603515625, 0.46686553955078125, 0.44432830810546875, -0.09149932861328125, -0.443359375, -0.1231842041015625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -66.89043426513672, "min_q": -71.9821548461914, "max_q": -63.275718688964844, "mean_td_error": 2.321451425552368, "model": {}}, "td_error": [2.6895675659179688, 4.09527587890625, 3.0968170166015625, 2.413299560546875, 5.917472839355469, 1.27734375, 2.9842376708984375, 2.821685791015625, 2.6630020141601562, 4.149223327636719, 2.9999313354492188, 2.6595993041992188, -1.3835067749023438, 4.871147155761719, 0.701446533203125, 4.056175231933594, -1.3835067749023438, 2.66619873046875, -1.3835067749023438, 1.3785552978515625, 2.890380859375, 1.04522705078125, 2.9266357421875, 1.1650390625, 3.082733154296875, 1.0453109741210938, 3.082733154296875, 2.358123779296875, 2.6630020141601562, 2.4690704345703125, 1.8155517578125, 2.452178955078125], "custom_metrics": {}}}, "num_steps_sampled": 29103, "num_agent_steps_sampled": 58206, "num_steps_trained": 47328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 94656, "last_target_update_ts": 29063, "num_target_updates": 243}, "done": false, "episodes_total": 1543, "training_iteration": 93, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-05", "timestamp": 1648811825, "time_this_iter_s": 1.2151620388031006, "time_total_s": 113.71107387542725, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feeb837def0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 113.71107387542725, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 31.200000000000003, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.30929431227912907, "mean_inference_ms": 1.7573434182164471, "mean_action_processing_ms": 0.1211720150719544, "mean_env_wait_ms": 0.07450992711259259, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29403, "timesteps_this_iter": 32, "agent_timesteps_total": 58806, "timers": {"load_time_ms": 0.418, "load_throughput": 76481.696, "learn_time_ms": 7.989, "learn_throughput": 4005.304, "update_time_ms": 5.137}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -75.49994659423828, "min_q": -82.53350830078125, "max_q": -69.7665786743164, "mean_td_error": -9.42234992980957, "model": {}}, "td_error": [0.74786376953125, 1.0036392211914062, -79.42256927490234, 0.8930740356445312, 0.43410491943359375, -0.92352294921875, -75.5101318359375, -0.4866943359375, 2.6582260131835938, 0.31114959716796875, 0.22663116455078125, -0.33031463623046875, 1.2904891967773438, 0.9553604125976562, 0.4286346435546875, 0.733154296875, 0.8337936401367188, 0.5747909545898438, 0.33045196533203125, -0.02735137939453125, 0.665008544921875, -0.6219482421875, 0.06507110595703125, -80.69037628173828, -0.1051483154296875, -79.95209503173828, 0.49819183349609375, 0.8337936401367188, 0.8480606079101562, 1.520233154296875, 1.4397506713867188, -0.7365341186523438], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -68.24205017089844, "min_q": -71.28748321533203, "max_q": -64.23401641845703, "mean_td_error": -0.12882351875305176, "model": {}}, "td_error": [-0.15573883056640625, 3.5623397827148438, 2.1060943603515625, 1.3333587646484375, 3.9032745361328125, 0.7301712036132812, 0.470855712890625, 1.0704498291015625, 0.5982589721679688, 3.4806060791015625, 0.6929550170898438, 1.4294967651367188, 3.4806060791015625, 1.343994140625, 3.4806060791015625, 3.396209716796875, 3.1151885986328125, 2.1060943603515625, 2.1060943603515625, 3.7859725952148438, 1.7194061279296875, 3.4481964111328125, 4.178611755371094, 1.8999481201171875, -0.10277557373046875, -68.2188949584961, 4.178611755371094, 2.1060943603515625, -0.30048370361328125, 1.1982269287109375, 2.1060943603515625, 1.6277236938476562], "custom_metrics": {}}}, "num_steps_sampled": 29403, "num_agent_steps_sampled": 58806, "num_steps_trained": 47808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 95616, "last_target_update_ts": 29303, "num_target_updates": 245}, "done": false, "episodes_total": 1558, "training_iteration": 94, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-06", "timestamp": 1648811826, "time_this_iter_s": 1.2008066177368164, "time_total_s": 114.91188049316406, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7ff020132200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 114.91188049316406, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 31.95, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3093939034972593, "mean_inference_ms": 1.758269321473926, "mean_action_processing_ms": 0.12125234263398646, "mean_env_wait_ms": 0.07455426347915933, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 29703, "timesteps_this_iter": 32, "agent_timesteps_total": 59406, "timers": {"load_time_ms": 0.557, "load_throughput": 57402.159, "learn_time_ms": 8.526, "learn_throughput": 3753.103, "update_time_ms": 5.431}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.2337417602539, "min_q": -82.79456329345703, "max_q": -71.16112518310547, "mean_td_error": -1.6882703304290771, "model": {}}, "td_error": [0.3614654541015625, -0.3529815673828125, 0.26721954345703125, -0.3529815673828125, 0.0634307861328125, 0.36130523681640625, -0.25980377197265625, -0.45880889892578125, 3.1324539184570312, 0.05027008056640625, 0.03387451171875, 0.2624359130859375, -0.1945648193359375, -0.6692123413085938, 1.8377685546875, -0.1945648193359375, -0.8480758666992188, -0.17778778076171875, -0.25980377197265625, -0.005828857421875, -0.15283203125, 0.39203643798828125, -0.24173736572265625, 2.8607330322265625, -70.48633575439453, 0.0786895751953125, -0.26232147216796875, 0.4615478515625, -0.5694427490234375, 10.827903747558594, 0.27277374267578125, 0.19852447509765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.48809051513672, "min_q": -72.63365936279297, "max_q": -65.9869384765625, "mean_td_error": -4.242748260498047, "model": {}}, "td_error": [0.6891632080078125, 0.03887176513671875, -14.356277465820312, 0.623382568359375, 0.996826171875, 0.737518310546875, 1.8409576416015625, 0.70703125, -1.1774749755859375, 0.11228179931640625, -0.40822601318359375, 0.6711654663085938, 0.7566604614257812, 1.8787841796875, 0.8158111572265625, 0.6155548095703125, 0.78302001953125, -67.39124298095703, 0.5877456665039062, 1.1387481689453125, 0.283233642578125, 1.124481201171875, 1.1041946411132812, -0.9280853271484375, 0.8378143310546875, 0.8501205444335938, 0.7963790893554688, 0.7387008666992188, 0.7249069213867188, -0.7334213256835938, -71.27185821533203, 1.0452957153320312], "custom_metrics": {}}}, "num_steps_sampled": 29703, "num_agent_steps_sampled": 59406, "num_steps_trained": 48288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96576, "last_target_update_ts": 29663, "num_target_updates": 248}, "done": false, "episodes_total": 1573, "training_iteration": 95, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-07", "timestamp": 1648811827, "time_this_iter_s": 1.2881834506988525, "time_total_s": 116.20006394386292, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c676440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7fee9c676440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 116.20006394386292, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 32.1, "ram_util_percent": 59.9}}
{"episode_reward_max": -40.0, "episode_reward_min": -40.0, "episode_reward_mean": -40.0, "episode_len_mean": 20.0, "episode_media": {}, "episodes_this_iter": 15, "policy_reward_min": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_max": {"policy0": -20.0, "policy1": -20.0}, "policy_reward_mean": {"policy0": -20.0, "policy1": -20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0, -40.0], "episode_lengths": [20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20, 20], "policy_policy0_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0], "policy_policy1_reward": [-20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0, -20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.3095222110276509, "mean_inference_ms": 1.7595237880252086, "mean_action_processing_ms": 0.12135346185867447, "mean_env_wait_ms": 0.07460993674870131, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 1, "timesteps_total": 30003, "timesteps_this_iter": 32, "agent_timesteps_total": 60006, "timers": {"load_time_ms": 0.501, "load_throughput": 63910.16, "learn_time_ms": 8.823, "learn_throughput": 3626.859, "update_time_ms": 6.506}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -74.20606231689453, "min_q": -83.14420318603516, "max_q": -71.06665802001953, "mean_td_error": -2.535921573638916, "model": {}}, "td_error": [-0.07349395751953125, 0.25847625732421875, -0.26969146728515625, -0.45507049560546875, -1.0364456176757812, -1.1384201049804688, -0.08036041259765625, 0.32134246826171875, 0.02754974365234375, -0.472686767578125, 0.0220184326171875, 0.1871185302734375, 0.25847625732421875, -1.2104034423828125, -0.6454620361328125, -74.16815948486328, -0.42636871337890625, -1.11224365234375, -0.01969146728515625, 0.32134246826171875, -0.9406280517578125, 0.42745208740234375, 0.4047393798828125, -0.5884857177734375, -1.078125, 0.1614990234375, -0.27335357666015625, 0.32134246826171875, 0.510467529296875, 0.25847625732421875, 0.8588638305664062, -1.4995651245117188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 0.009999999776482582, "mean_q": -69.87606811523438, "min_q": -71.7522964477539, "max_q": -67.72464752197266, "mean_td_error": -1.7002253532409668, "model": {}}, "td_error": [1.2308731079101562, -0.11777496337890625, 1.1542587280273438, -0.18183135986328125, -0.0196075439453125, 0.6999893188476562, 0.47438812255859375, 0.7502288818359375, 0.9274978637695312, 1.0632705688476562, 0.8049850463867188, 1.0788116455078125, 1.327972412109375, 0.8351058959960938, -9.876243591308594, 0.7663726806640625, 0.47699737548828125, 1.2150192260742188, 2.0015182495117188, 1.282928466796875, 0.6972427368164062, 0.8181610107421875, -68.2006607055664, 0.5908660888671875, 0.2038116455078125, 0.645904541015625, 1.2150192260742188, 0.8838043212890625, 0.5908660888671875, 1.0457916259765625, 0.8727569580078125, 0.33446502685546875], "custom_metrics": {}}}, "num_steps_sampled": 30003, "num_agent_steps_sampled": 60006, "num_steps_trained": 48768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 97536, "last_target_update_ts": 29903, "num_target_updates": 250}, "done": true, "episodes_total": 1588, "training_iteration": 96, "trial_id": "f3a64_00000", "experiment_id": "43f8d33789234291abbd5b44824e2889", "date": "2022-04-01_04-17-09", "timestamp": 1648811829, "time_this_iter_s": 1.339681625366211, "time_total_s": 117.53974556922913, "pid": 20461, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 1, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "complete_episodes", "gamma": 0.99, "lr": 0.01, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1], "food_loc": {"food1": [3, 3], "food2": [5, 5]}, "agent_loc": {"0": [4, 4], "1": [6, 7]}, "board_size": [7, 10], "mode": "comp", "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.0, "epsilon_timesteps": 25000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 100, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([ 7 10  7 10  8 11  8 11])", "Discrete(4)", {"agent_id": 1}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7feef872e830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 100, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 100, "buffer_size": 20000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [256], "double_q": true, "n_step": 1, "prioritized_replay": false, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 117.53974556922913, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 32.0, "ram_util_percent": 59.9}}
