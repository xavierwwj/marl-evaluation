{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 26.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 8.9, "policy1": 8.9, "policy2": 8.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 30.0, 60.0, 120.0, 60.0, 30.0, 30.0, 30.0, 60.0, 0.0, 30.0, 60.0, 0.0, 30.0, -30.0, 30.0, 60.0, 30.0, -30.0, 0.0, 0.0, 0.0, 90.0, 30.0, 60.0, 30.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 60.0, 60.0, 30.0, -30.0, 30.0, 0.0, 30.0, 60.0, 0.0, 30.0, 60.0, 90.0, 60.0, 120.0, 60.0, 30.0, 30.0, 30.0, -30.0, -30.0, 60.0, 0.0, 30.0, 0.0, 30.0, 0.0, -30.0, 60.0, 0.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, 60.0, 0.0, -30.0, 0.0, 60.0, 30.0, 30.0, -30.0, 0.0, -30.0, 30.0, 60.0, 0.0, 30.0, 0.0, 30.0, 0.0, 90.0, 60.0, 0.0, 0.0, 60.0, 0.0, 0.0, 30.0, 0.0, 60.0, 60.0, 0.0, 30.0, 30.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 10.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, -10.0, 10.0, 20.0, 10.0, -10.0, 0.0, 0.0, 0.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, -10.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, -10.0, -10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 0.0, -10.0, 10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, 30.0, 20.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 10.0], "policy_policy1_reward": [10.0, 10.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, -10.0, 10.0, 20.0, 10.0, -10.0, 0.0, 0.0, 0.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, -10.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, -10.0, -10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 0.0, -10.0, 10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, 30.0, 20.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 10.0], "policy_policy2_reward": [10.0, 10.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, -10.0, 10.0, 20.0, 10.0, -10.0, 0.0, 0.0, 0.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, -10.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 10.0, 10.0, 10.0, -10.0, -10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 0.0, -10.0, 10.0, 20.0, 0.0, 10.0, 0.0, 10.0, 0.0, 30.0, 20.0, 0.0, 0.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 0.9811372153843814, "mean_inference_ms": 22.09887627085207, "mean_action_processing_ms": 0.2247453207083841, "mean_env_wait_ms": 0.12284823557133734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 1008, "timesteps_this_iter": 32, "agent_timesteps_total": 3024, "timers": {"load_time_ms": 0.607, "load_throughput": 52717.097, "learn_time_ms": 730.814, "learn_throughput": 43.787, "update_time_ms": 178.923}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 0.022280067205429077, "min_q": -0.04151158779859543, "max_q": 0.11347043514251709, "mean_td_error": -1.4717438220977783, "model": {}}, "td_error": [-19.01288414001465, 1.121019721031189, -8.950616836547852, 1.0088499784469604, 1.029590368270874, 1.0176236629486084, -8.998527526855469, 0.9724056720733643, 0.9861986637115479, 1.0086066722869873, 1.084335207939148, 0.9995811581611633, -9.042259216308594, 1.120814323425293, 0.9902989864349365, 1.016882061958313, 1.0003817081451416, -8.982812881469727, -8.997397422790527, 1.0332683324813843, 1.0994408130645752, 1.0244269371032715, 1.037262201309204, 1.01836359500885, -8.941396713256836, 1.0264272689819336, 0.9841023087501526, 1.0343996286392212, 1.063631296157837, 1.0523178577423096, 1.0343996286392212, 1.0654680728912354], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.0494181290268898, "min_q": -0.09078138321638107, "max_q": 0.03317980468273163, "mean_td_error": -0.36793777346611023, "model": {}}, "td_error": [0.8551474809646606, 0.9088572859764099, 0.8092858791351318, 0.8742176294326782, 0.8689680695533752, 0.8792175054550171, 0.8368552923202515, -9.150213241577148, 0.834724485874176, 0.8581787347793579, -8.993037223815918, 0.8092858791351318, 0.9786601066589355, 0.9699655175209045, 0.8226031064987183, 0.9098994135856628, 0.8092858791351318, 0.9284654855728149, 0.8397355079650879, 1.008438229560852, -9.135632514953613, 0.7979109287261963, 0.9108960628509521, -9.116948127746582, 0.8858639001846313, 0.9175255298614502, 0.9107081294059753, 0.9482239484786987, 0.8443812131881714, 0.94281405210495, 0.8045746684074402, 0.8571327924728394], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.024109777063131332, "min_q": -0.07273825258016586, "max_q": 0.08697186410427094, "mean_td_error": 0.36941051483154297, "model": {}}, "td_error": [1.0759320259094238, 1.0146673917770386, 0.9575673937797546, 0.9393752217292786, 1.0700407028198242, 1.0047677755355835, -9.03950023651123, 1.0087711811065674, 0.973997950553894, 1.038360595703125, 1.0008000135421753, 1.01090669631958, 0.9685594439506531, 0.9148755073547363, 1.015405535697937, 0.9384511113166809, 0.9236834049224854, 1.0725443363189697, 1.010412335395813, 0.9863964915275574, 1.0598726272583008, 0.9805129170417786, 0.9770548343658447, 0.9818274974822998, -8.922054290771484, 0.9891513586044312, 0.9517632126808167, 0.9557901620864868, 0.9546830058097839, 0.9763492345809937, 1.02779221534729, 1.002379059791565], "custom_metrics": {}}}, "num_steps_sampled": 1008, "num_agent_steps_sampled": 3024, "num_steps_trained": 32, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96, "last_target_update_ts": 1008, "num_target_updates": 1}, "done": false, "episodes_total": 100, "training_iteration": 1, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-22-59", "timestamp": 1648912979, "time_this_iter_s": 8.231413841247559, "time_total_s": 8.231413841247559, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54980b3b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54980b3b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 8.231413841247559, "timesteps_since_restore": 32, "iterations_since_restore": 1, "perf": {"cpu_util_percent": 47.51666666666667, "ram_util_percent": 56.35833333333333}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 25.8, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 8.6, "policy1": 8.6, "policy2": 8.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 30.0, 30.0, 90.0, 0.0, 0.0, 30.0, 60.0, 30.0, 30.0, 0.0, 30.0, 90.0, 30.0, 0.0, 90.0, -30.0, -30.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, 60.0, 30.0, 30.0, 0.0, -30.0, 0.0, 30.0, 30.0, 0.0, 60.0, 60.0, 30.0, 60.0, -30.0, 30.0, 30.0, 30.0, 60.0, 30.0, 0.0, 30.0, 0.0, 30.0, 60.0, 0.0, 0.0, 0.0, 30.0, 30.0, 0.0, 0.0, 30.0, 0.0, 0.0, 30.0, 30.0, 0.0, 30.0, 0.0, 30.0, 30.0, 0.0, 30.0, 60.0, 30.0, 30.0, 60.0, 0.0, 90.0, 0.0, 0.0, 60.0, 60.0, 0.0, -30.0, 0.0, 60.0, -30.0, 90.0, 30.0, 60.0, 30.0, 60.0, 30.0, 0.0, 30.0, 30.0, 0.0, 60.0, 60.0, 0.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 10.0, 10.0, 30.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 0.0, 10.0, 30.0, 10.0, 0.0, 30.0, -10.0, -10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, -10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 20.0, -10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, 20.0, 20.0, 0.0, -10.0, 0.0, 20.0, -10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 0.0], "policy_policy1_reward": [0.0, 10.0, 10.0, 30.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 0.0, 10.0, 30.0, 10.0, 0.0, 30.0, -10.0, -10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, -10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 20.0, -10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, 20.0, 20.0, 0.0, -10.0, 0.0, 20.0, -10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 0.0], "policy_policy2_reward": [0.0, 10.0, 10.0, 30.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 0.0, 10.0, 30.0, 10.0, 0.0, 30.0, -10.0, -10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, -10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 20.0, -10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, 20.0, 20.0, 0.0, -10.0, 0.0, 20.0, -10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0040880429862753, "mean_inference_ms": 23.480096783968474, "mean_action_processing_ms": 0.23302984709786895, "mean_env_wait_ms": 0.12951617193694162, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 2016, "timesteps_this_iter": 32, "agent_timesteps_total": 6048, "timers": {"load_time_ms": 0.606, "load_throughput": 52804.205, "learn_time_ms": 223.965, "learn_throughput": 142.88, "update_time_ms": 113.363}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.8218063116073608, "min_q": -1.4159821271896362, "max_q": 0.15640750527381897, "mean_td_error": -3.391876220703125, "model": {}}, "td_error": [1.1477720737457275, -8.58163070678711, 0.8687065839767456, -9.289809226989746, 0.584522008895874, -18.827789306640625, -9.44298267364502, -9.470161437988281, 0.9889021515846252, 0.050623536109924316, -8.617178916931152, -9.465404510498047, -9.045207023620605, 0.634023904800415, -9.276214599609375, 0.6054567098617554, 0.8713507056236267, 0.48078393936157227, 0.19663286209106445, -0.2868664264678955, 0.2632240056991577, 0.11916100978851318, 0.3949223756790161, 0.8659044504165649, -8.956439971923828, 1.0989747047424316, 0.38818931579589844, 1.0699018239974976, 0.6156527996063232, -9.322669982910156, 0.08452427387237549, -9.28691291809082], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -1.083381175994873, "min_q": -1.6283260583877563, "max_q": -0.3915434181690216, "mean_td_error": -5.2041826248168945, "model": {}}, "td_error": [0.38574618101119995, 0.08054792881011963, -19.48182487487793, -9.733065605163574, -9.658059120178223, -8.935434341430664, -8.929351806640625, -9.281073570251465, -9.658059120178223, -9.641091346740723, -9.305866241455078, 0.2726883888244629, 0.7724124193191528, 0.381428599357605, -9.913924217224121, 0.07988250255584717, 0.10128998756408691, 0.5751383304595947, -9.11460018157959, -9.195704460144043, 0.4524869918823242, 0.21288728713989258, 0.18417513370513916, 0.7423983216285706, -10.367730140686035, 0.11733567714691162, 0.7229187488555908, -9.518486022949219, -9.773311614990234, 0.0056830644607543945, -9.3915433883667, -9.7217378616333], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.9110921025276184, "min_q": -1.569349765777588, "max_q": -0.2029290795326233, "mean_td_error": -2.355648994445801, "model": {}}, "td_error": [-9.542760848999023, -8.855637550354004, 0.28562796115875244, 0.24698340892791748, 0.7217945456504822, 0.24075424671173096, -0.11098003387451172, 0.0814814567565918, 0.6436014771461487, 0.587171196937561, -9.433890342712402, 0.6358860731124878, -0.09988152980804443, 0.028775572776794434, 0.6280727386474609, 0.6468377113342285, 0.6358860731124878, 0.18882310390472412, -0.45738542079925537, 0.21612298488616943, 0.45931994915008545, -9.024043083190918, 0.22614312171936035, 0.3727205991744995, 0.632817268371582, -9.398051261901855, -9.11144733428955, 0.42484939098358154, 0.5581612586975098, -18.695518493652344, -9.378975868225098, 0.2659740447998047], "custom_metrics": {}}}, "num_steps_sampled": 2016, "num_agent_steps_sampled": 6048, "num_steps_trained": 2048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 6144, "last_target_update_ts": 1520, "num_target_updates": 2}, "done": false, "episodes_total": 200, "training_iteration": 2, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-23-39", "timestamp": 1648913019, "time_this_iter_s": 40.673210859298706, "time_total_s": 48.904624700546265, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54980b3050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54980b3050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 48.904624700546265, "timesteps_since_restore": 64, "iterations_since_restore": 2, "perf": {"cpu_util_percent": 49.50689655172414, "ram_util_percent": 61.66724137931035}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 29.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 9.8, "policy1": 9.8, "policy2": 9.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 30.0, 0.0, 0.0, 30.0, 30.0, 30.0, -30.0, 0.0, 30.0, 30.0, 30.0, 0.0, 90.0, 30.0, 60.0, 0.0, 0.0, 0.0, 60.0, 0.0, 60.0, 30.0, 30.0, 90.0, 60.0, 90.0, 60.0, 30.0, 30.0, 60.0, 30.0, 30.0, 30.0, 0.0, 60.0, -30.0, 0.0, 30.0, 60.0, 60.0, 90.0, 30.0, 30.0, 30.0, 0.0, 0.0, 30.0, 0.0, 0.0, 90.0, 30.0, 60.0, 60.0, 0.0, 30.0, 30.0, 0.0, 60.0, 60.0, 30.0, 0.0, 60.0, 60.0, 0.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 30.0, 0.0, 60.0, 60.0, 30.0, 0.0, 0.0, 0.0, 30.0, 0.0, 0.0, 60.0, 30.0, 30.0, 60.0, 0.0, 0.0, 30.0, 0.0, -30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 30.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [-10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, -10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 30.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0], "policy_policy1_reward": [-10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, -10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 30.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0], "policy_policy2_reward": [-10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, -10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 0.0, 30.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0124111112546728, "mean_inference_ms": 24.063224679097797, "mean_action_processing_ms": 0.23616942893246215, "mean_env_wait_ms": 0.13144414680007274, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 3024, "timesteps_this_iter": 32, "agent_timesteps_total": 9072, "timers": {"load_time_ms": 0.622, "load_throughput": 51465.826, "learn_time_ms": 233.043, "learn_throughput": 137.314, "update_time_ms": 113.507}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.8958443999290466, "min_q": -1.5894020795822144, "max_q": 0.07995408773422241, "mean_td_error": -3.251180648803711, "model": {}}, "td_error": [-19.215879440307617, 0.12222880125045776, 0.03322720527648926, 1.079397201538086, -9.682676315307617, 1.099419355392456, -8.989140510559082, 0.3380763530731201, 0.8817713260650635, 0.11480832099914551, -9.332260131835938, -8.35968017578125, 0.2156815528869629, 0.725967288017273, 0.6147795915603638, -8.939210891723633, 1.761979579925537, -9.502558708190918, 0.2685180902481079, -7.4556565284729, -8.088903427124023, -10.025887489318848, -0.08910059928894043, 0.9551714658737183, -7.767352104187012, 1.0038083791732788, 0.21056914329528809, 1.091734766960144, 0.7170575857162476, -0.08620142936706543, -8.839245796203613, 1.1017805337905884], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -1.4275410175323486, "min_q": -2.2299439907073975, "max_q": -0.6905803680419922, "mean_td_error": -3.0609071254730225, "model": {}}, "td_error": [0.8643901348114014, 0.20751237869262695, 0.6567881107330322, 0.0049250125885009766, -9.460885047912598, -8.634456634521484, 0.3251490592956543, -8.866819381713867, -8.610342979431152, 0.25923776626586914, 0.07768893241882324, 0.9214169979095459, -9.003568649291992, 1.0259963274002075, 0.542832612991333, 0.2791411876678467, 0.15510821342468262, -8.828715324401855, -9.136029243469238, -9.374868392944336, 0.2073366641998291, -8.916829109191895, 0.8459407091140747, -9.217243194580078, -9.168989181518555, 0.4727952480316162, 0.8673191070556641, 0.12768232822418213, -8.610342979431152, 0.7754949331283569, 1.1134059429168701, 0.14990246295928955], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.6400994062423706, "min_q": -2.3800485134124756, "max_q": 1.5836353302001953, "mean_td_error": -3.5743348598480225, "model": {}}, "td_error": [0.39000749588012695, 0.1500476598739624, -7.960501194000244, -8.006613731384277, -9.081981658935547, -9.210857391357422, 0.8555951118469238, -18.333845138549805, 0.9985213279724121, -8.772098541259766, 2.211775779724121, 0.24487841129302979, 1.4769928455352783, -6.567071914672852, 0.38378268480300903, 0.16106057167053223, -9.991722106933594, 0.22874999046325684, 0.9267137050628662, -8.202276229858398, 1.156049132347107, 1.3348095417022705, 1.0828709602355957, -8.995665550231934, -9.175657272338867, 0.5806005001068115, -8.445318222045898, 0.4079587459564209, 0.650659441947937, -7.851719379425049, -8.084542274475098, 1.0600813627243042], "custom_metrics": {}}}, "num_steps_sampled": 3024, "num_agent_steps_sampled": 9072, "num_steps_trained": 4064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 12192, "last_target_update_ts": 2544, "num_target_updates": 4}, "done": false, "episodes_total": 300, "training_iteration": 3, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-24-19", "timestamp": 1648913059, "time_this_iter_s": 39.81398248672485, "time_total_s": 88.71860718727112, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498010b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498010b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 88.71860718727112, "timesteps_since_restore": 96, "iterations_since_restore": 3, "perf": {"cpu_util_percent": 50.67321428571429, "ram_util_percent": 62.58749999999999}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 30.6, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 10.2, "policy1": 10.2, "policy2": 10.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 30.0, 0.0, 30.0, 60.0, 0.0, 60.0, 60.0, 30.0, 0.0, 60.0, 30.0, 30.0, 60.0, 60.0, 0.0, 30.0, 0.0, 60.0, 30.0, 30.0, -30.0, 90.0, 60.0, 0.0, -30.0, 30.0, 120.0, 30.0, 60.0, 30.0, 60.0, 90.0, 0.0, 60.0, 30.0, 0.0, 30.0, 60.0, -30.0, 0.0, 0.0, 0.0, 60.0, 60.0, 0.0, 30.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 90.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 60.0, 60.0, 60.0, 30.0, 0.0, 30.0, 0.0, 30.0, -30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 30.0, 0.0, 30.0, 60.0, 0.0, 0.0, 30.0, 60.0, 30.0, 0.0, 30.0, 30.0, 60.0, 0.0, -30.0, 60.0, 30.0, 30.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 30.0, 20.0, 0.0, -10.0, 10.0, 40.0, 10.0, 20.0, 10.0, 20.0, 30.0, 0.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, -10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 20.0, 10.0, 10.0, 20.0], "policy_policy1_reward": [0.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 30.0, 20.0, 0.0, -10.0, 10.0, 40.0, 10.0, 20.0, 10.0, 20.0, 30.0, 0.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, -10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 20.0, 10.0, 10.0, 20.0], "policy_policy2_reward": [0.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, -10.0, 30.0, 20.0, 0.0, -10.0, 10.0, 40.0, 10.0, 20.0, 10.0, 20.0, 30.0, 0.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 0.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, -10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, -10.0, 20.0, 10.0, 10.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0243266141568232, "mean_inference_ms": 24.57313288309648, "mean_action_processing_ms": 0.23935411801068823, "mean_env_wait_ms": 0.1336258750250129, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 4032, "timesteps_this_iter": 32, "agent_timesteps_total": 12096, "timers": {"load_time_ms": 0.658, "load_throughput": 48604.957, "learn_time_ms": 246.935, "learn_throughput": 129.589, "update_time_ms": 106.581}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 0.0002552419900894165, "min_q": -3.0347957611083984, "max_q": 2.7553443908691406, "mean_td_error": -3.1369051933288574, "model": {}}, "td_error": [0.2597028613090515, 0.7657519578933716, -7.791697025299072, 0.8277775049209595, 1.178565502166748, 1.815165400505066, -6.830094814300537, 1.1194698810577393, -0.41059112548828125, -8.30322551727295, -7.620244026184082, -1.086375117301941, -8.3525390625, 1.481877326965332, -7.7665181159973145, -17.306211471557617, -6.010926723480225, 1.2447117567062378, 2.0598716735839844, 0.15525543689727783, -0.03814697265625, 1.4407875537872314, 3.8577826023101807, -17.306211471557617, -0.1368732452392578, -8.717183113098145, -7.786458969116211, 0.8735013008117676, 1.3342349529266357, -6.76102876663208, 1.4508416652679443, -8.021942138671875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.9868118762969971, "min_q": -2.711453914642334, "max_q": 1.1231483221054077, "mean_td_error": -4.3808441162109375, "model": {}}, "td_error": [0.5600371360778809, -0.24583816528320312, -8.99157428741455, -8.345977783203125, 1.4225492477416992, -8.952720642089844, -9.072240829467773, 0.28255629539489746, -8.937835693359375, -0.2841557264328003, 1.1955190896987915, 0.0985574722290039, 1.791266679763794, -0.7526819705963135, -7.593533515930176, -8.97058391571045, -9.145231246948242, -7.597283840179443, -8.946760177612305, -8.97058391571045, 1.4965025186538696, -9.404645919799805, -1.6139721870422363, -18.27764129638672, 1.5642871856689453, -8.089908599853516, -9.21379280090332, 0.5266919136047363, 0.7799702882766724, 1.8057775497436523, -7.6485772132873535, -0.6551949977874756], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 0.5082546472549438, "min_q": -1.6743320226669312, "max_q": 2.8001997470855713, "mean_td_error": -3.8312835693359375, "model": {}}, "td_error": [2.7916603088378906, -7.471381187438965, 0.4577038884162903, 0.4837530851364136, -7.3047990798950195, -5.899567604064941, -8.284749031066895, -0.08838430047035217, -8.265409469604492, -6.824151992797852, 1.4300405979156494, 0.7695090770721436, -26.750808715820312, 0.8517807722091675, 1.355644702911377, -6.767942905426025, -9.12966251373291, -7.867762088775635, 0.05282026529312134, -6.433370590209961, 1.5164117813110352, 1.0909204483032227, 1.5583937168121338, -6.390336036682129, -7.479435443878174, -7.497117519378662, -7.245421409606934, -9.0126371383667, 1.1820220947265625, 0.5896019339561462, 1.8348017930984497, 0.1467992067337036], "custom_metrics": {}}}, "num_steps_sampled": 4032, "num_agent_steps_sampled": 12096, "num_steps_trained": 6080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 18240, "last_target_update_ts": 3568, "num_target_updates": 6}, "done": false, "episodes_total": 400, "training_iteration": 4, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-25-00", "timestamp": 1648913100, "time_this_iter_s": 40.982540130615234, "time_total_s": 129.70114731788635, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549821c8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549821c8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 129.70114731788635, "timesteps_since_restore": 128, "iterations_since_restore": 4, "perf": {"cpu_util_percent": 52.04310344827586, "ram_util_percent": 63.87413793103448}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 30.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 0.0, 30.0, 30.0, 60.0, 30.0, 60.0, 60.0, 60.0, 0.0, 0.0, 30.0, 30.0, 30.0, -30.0, 0.0, 60.0, 30.0, 30.0, 0.0, 0.0, 30.0, 60.0, 0.0, 30.0, 60.0, 0.0, 30.0, 60.0, 0.0, 30.0, 30.0, 30.0, 0.0, 90.0, 60.0, 90.0, 30.0, -30.0, 60.0, 30.0, 60.0, 0.0, 30.0, 30.0, 120.0, -30.0, 60.0, 30.0, 30.0, -30.0, 90.0, 0.0, 30.0, 0.0, 0.0, 60.0, 30.0, 60.0, 30.0, 60.0, -30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, -30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, 30.0, 0.0, 60.0, 0.0, 0.0, 30.0, -30.0, 30.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 20.0, 30.0, 10.0, -10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, 40.0, -10.0, 20.0, 10.0, 10.0, -10.0, 30.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 0.0, 10.0, -10.0, 10.0, 0.0], "policy_policy1_reward": [30.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 20.0, 30.0, 10.0, -10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, 40.0, -10.0, 20.0, 10.0, 10.0, -10.0, 30.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 0.0, 10.0, -10.0, 10.0, 0.0], "policy_policy2_reward": [30.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, -10.0, 0.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 20.0, 30.0, 10.0, -10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, 40.0, -10.0, 20.0, 10.0, 10.0, -10.0, 30.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 0.0, 10.0, -10.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0254970152731642, "mean_inference_ms": 24.822257937749725, "mean_action_processing_ms": 0.24041734358131828, "mean_env_wait_ms": 0.1345725403618567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 5040, "timesteps_this_iter": 32, "agent_timesteps_total": 15120, "timers": {"load_time_ms": 0.712, "load_throughput": 44950.51, "learn_time_ms": 253.438, "learn_throughput": 126.264, "update_time_ms": 99.667}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 1.3486380577087402, "min_q": -2.5722405910491943, "max_q": 5.860602378845215, "mean_td_error": -2.7697534561157227, "model": {}}, "td_error": [-0.39641642570495605, 0.05927109718322754, -5.892489910125732, 2.5886778831481934, 1.0489866733551025, 0.5350741744041443, -1.5194368362426758, -14.789806365966797, -5.33585262298584, -8.808134078979492, -8.113371849060059, -4.131315231323242, -21.881750106811523, 2.5064873695373535, -0.6848517656326294, 1.010436773300171, 2.947887420654297, 1.5753566026687622, 1.2874634265899658, -0.17756348848342896, -4.924782752990723, 2.085043430328369, 0.619430422782898, -0.7976939678192139, -1.3923113346099854, -8.978048324584961, -0.20634114742279053, 1.185734748840332, -8.866819381713867, -5.353066444396973, 1.9041684865951538, -5.736080646514893], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": -0.8619527816772461, "min_q": -3.2337515354156494, "max_q": 0.7488331198692322, "mean_td_error": -3.456470012664795, "model": {}}, "td_error": [-7.73331880569458, 0.6025116443634033, -18.11409568786621, 1.392716407775879, 0.11176550388336182, -0.043344736099243164, -8.717344284057617, 1.848575234413147, 0.3509960174560547, -1.55861234664917, -7.613656520843506, -8.174029350280762, -7.062124252319336, -9.627372741699219, 1.2166752815246582, 1.9307985305786133, 0.49452006816864014, 2.267406940460205, -8.347090721130371, 0.7250162363052368, 0.7734761238098145, -27.73041534423828, 1.7362679243087769, 1.7364208698272705, 1.5126632452011108, -9.054792404174805, -8.065736770629883, 1.128650426864624, 0.3258722424507141, 0.9709609746932983, -7.329127311706543, -0.5612761974334717], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 2.9649441242218018, "min_q": -5.066000938415527, "max_q": 8.755941390991211, "mean_td_error": -2.6445424556732178, "model": {}}, "td_error": [0.4339573383331299, -4.066000938415527, 2.268768310546875, -7.315128326416016, -8.647422790527344, -3.6036787033081055, -6.203556060791016, -0.4726749658584595, -8.110589981079102, -0.7313988208770752, -0.5204477310180664, -4.920340538024902, -12.743067741394043, -0.9937548637390137, -12.404155731201172, 1.8082942962646484, -0.12358617782592773, 2.0058536529541016, -0.13538289070129395, -6.335621356964111, 1.990527868270874, -1.8854198455810547, 1.600416660308838, -0.9827642440795898, 1.3409724235534668, 0.6547319889068604, -6.988443374633789, 1.1760139465332031, 4.209632873535156, -7.917088508605957, -7.052826881408691, 0.03882551193237305], "custom_metrics": {}}}, "num_steps_sampled": 5040, "num_agent_steps_sampled": 15120, "num_steps_trained": 8096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 24288, "last_target_update_ts": 4592, "num_target_updates": 8}, "done": false, "episodes_total": 504, "training_iteration": 5, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-25-41", "timestamp": 1648913141, "time_this_iter_s": 40.19830632209778, "time_total_s": 169.89945363998413, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d4170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d4170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 169.89945363998413, "timesteps_since_restore": 160, "iterations_since_restore": 5, "perf": {"cpu_util_percent": 51.96140350877192, "ram_util_percent": 64.1842105263158}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 29.1, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 9.7, "policy1": 9.7, "policy2": 9.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 30.0, 30.0, 0.0, -30.0, 0.0, 60.0, 0.0, 30.0, 30.0, 30.0, 0.0, 30.0, 0.0, 60.0, 30.0, 0.0, -30.0, 60.0, 0.0, 30.0, 90.0, 30.0, 30.0, 30.0, 30.0, 30.0, 120.0, 30.0, 30.0, 30.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 90.0, -30.0, 60.0, 30.0, 0.0, 0.0, 0.0, 0.0, 30.0, 30.0, 0.0, 30.0, 0.0, 60.0, 0.0, 30.0, 30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 0.0, 60.0, 0.0, 30.0, 0.0, 30.0, 30.0, 60.0, 30.0, 90.0, 0.0, 30.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 0.0, 0.0, 30.0, 0.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 60.0, 60.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, -10.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0], "policy_policy1_reward": [10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, -10.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0], "policy_policy2_reward": [10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, -10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, -10.0, 20.0, 10.0, 0.0, 0.0, 0.0, 0.0, 10.0, 10.0, 0.0, 10.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0285094646295017, "mean_inference_ms": 24.98464500045273, "mean_action_processing_ms": 0.2412819657511689, "mean_env_wait_ms": 0.1351637156373684, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 6048, "timesteps_this_iter": 32, "agent_timesteps_total": 18144, "timers": {"load_time_ms": 0.633, "load_throughput": 50516.665, "learn_time_ms": 239.964, "learn_throughput": 133.353, "update_time_ms": 100.878}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 2.051800012588501, "min_q": -2.7394042015075684, "max_q": 6.230290412902832, "mean_td_error": -1.8288248777389526, "model": {}}, "td_error": [-7.543437957763672, 2.0748863220214844, -4.559150218963623, -2.22936749458313, 6.230701446533203, -8.34886360168457, 2.013141632080078, 3.738330841064453, -10.818049430847168, -6.703269958496094, -6.591426849365234, -4.148764610290527, -0.0693655014038086, -8.582436561584473, -8.294793128967285, 2.5787112712860107, 3.6600568294525146, 0.8086230754852295, -5.173192024230957, 1.4775460958480835, 3.2008392810821533, 1.101386308670044, -0.2578200101852417, -5.038640975952148, -2.340433120727539, 1.066677451133728, -6.755774021148682, -0.020555973052978516, 0.3211354613304138, 2.915940046310425, -5.5231733322143555, 3.288147211074829], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 0.13007459044456482, "min_q": -3.444162368774414, "max_q": 4.284672260284424, "mean_td_error": -2.772287607192993, "model": {}}, "td_error": [-6.814276218414307, 2.4123494625091553, -7.583686828613281, -2.2282416820526123, -7.34383487701416, -5.350488662719727, 1.1670494079589844, -0.6064160466194153, 0.0006966590881347656, -0.46385467052459717, 4.123825550079346, 0.14275586605072021, -6.74855375289917, -1.819920301437378, -7.113532066345215, -7.29901123046875, -0.27678871154785156, -0.543143093585968, -0.0661170482635498, 0.9657126665115356, 1.26496422290802, -2.433846950531006, -5.868450164794922, -2.2343251705169678, 2.232170343399048, -1.1881181001663208, -6.268634796142578, -5.442057132720947, -8.757744789123535, -6.296098232269287, 0.18271684646606445, -8.458304405212402], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 3.6000442504882812, "min_q": -5.118766784667969, "max_q": 11.01778507232666, "mean_td_error": -0.577806830406189, "model": {}}, "td_error": [-2.211923599243164, -0.6579053401947021, 0.8373332023620605, 0.4937930107116699, -2.938483715057373, 0.9231934547424316, -3.541860580444336, 0.4400908946990967, -5.551276206970215, -1.067598819732666, 6.658295631408691, 9.435747146606445, -5.165185451507568, -8.134763717651367, 1.4663047790527344, 1.644272804260254, -4.913704872131348, -1.3078889846801758, 0.20799732208251953, 0.22077512741088867, -6.749541282653809, 0.8899612426757812, 1.9200172424316406, 0.6810929775238037, 0.48607587814331055, 6.337551116943359, -3.0844149589538574, 1.5023566484451294, 0.03134298324584961, 0.5918251276016235, -1.6498889923095703, -6.28341007232666], "custom_metrics": {}}}, "num_steps_sampled": 6048, "num_agent_steps_sampled": 18144, "num_steps_trained": 10112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 30336, "last_target_update_ts": 5616, "num_target_updates": 10}, "done": false, "episodes_total": 604, "training_iteration": 6, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-26-21", "timestamp": 1648913181, "time_this_iter_s": 40.18875789642334, "time_total_s": 210.08821153640747, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d45f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d45f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 210.08821153640747, "timesteps_since_restore": 192, "iterations_since_restore": 6, "perf": {"cpu_util_percent": 51.56140350877193, "ram_util_percent": 64.93859649122807}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 38.1, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 12.7, "policy1": 12.7, "policy2": 12.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 30.0, 60.0, 30.0, 0.0, 90.0, 60.0, 90.0, 90.0, 60.0, 90.0, 30.0, 60.0, 30.0, 30.0, 90.0, 30.0, 30.0, 60.0, 0.0, 0.0, 30.0, 30.0, 30.0, 0.0, 60.0, 0.0, 90.0, 30.0, 60.0, 60.0, 60.0, 30.0, 0.0, 30.0, 30.0, -30.0, 60.0, 0.0, 60.0, 30.0, 0.0, 60.0, 30.0, 30.0, 30.0, 90.0, 60.0, 30.0, 0.0, 30.0, 30.0, 60.0, 0.0, 0.0, 0.0, 0.0, 30.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 60.0, 0.0, 30.0, 60.0, 30.0, 60.0, 90.0, 30.0, 60.0, 60.0, 0.0, 0.0, 60.0, 30.0, 30.0, 0.0, 90.0, 30.0, 90.0, 0.0, 30.0, 0.0, 30.0, 0.0, 60.0, 60.0, -30.0, 60.0, 30.0, 90.0, 0.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 30.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 0.0, 10.0, 0.0, 10.0, 0.0, 20.0, 20.0, -10.0, 20.0, 10.0, 30.0, 0.0, 30.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 30.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 0.0, 10.0, 0.0, 10.0, 0.0, 20.0, 20.0, -10.0, 20.0, 10.0, 30.0, 0.0, 30.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 30.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 0.0, 10.0, 0.0, 10.0, 0.0, 20.0, 20.0, -10.0, 20.0, 10.0, 30.0, 0.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0362135114480686, "mean_inference_ms": 25.364387879628293, "mean_action_processing_ms": 0.24345279077632573, "mean_env_wait_ms": 0.13667888749422497, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 7056, "timesteps_this_iter": 32, "agent_timesteps_total": 21168, "timers": {"load_time_ms": 0.665, "load_throughput": 48130.864, "learn_time_ms": 240.314, "learn_throughput": 133.159, "update_time_ms": 100.348}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 3.260375499725342, "min_q": -4.413882255554199, "max_q": 9.434905052185059, "mean_td_error": -1.3399866819381714, "model": {}}, "td_error": [1.3019040822982788, 2.2733888626098633, -7.478913307189941, 1.4359331130981445, -0.10573035478591919, -6.493647575378418, 0.36425161361694336, 2.0850634574890137, 0.559870719909668, 2.338108539581299, 1.4067761898040771, -6.207040786743164, -11.167318344116211, 6.592845439910889, -3.760064125061035, 1.71637761592865, 0.969969630241394, 0.48337793350219727, -8.147157669067383, -9.974411010742188, -1.5747079849243164, -0.42020320892333984, 0.7613015174865723, 1.3820874691009521, -1.5818376541137695, -3.413882255554199, -0.12220191955566406, 0.872859001159668, 0.812002420425415, -3.03409481048584, -5.205286502838135, 0.4508042335510254], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 1.2278482913970947, "min_q": -2.2444701194763184, "max_q": 5.245903491973877, "mean_td_error": -3.5016605854034424, "model": {}}, "td_error": [-1.4693948030471802, 0.21100831031799316, -1.1103487014770508, -16.310409545898438, 1.0148673057556152, -0.6158686876296997, 0.31178832054138184, 1.2129805088043213, -16.722328186035156, -8.346824645996094, -6.406032562255859, -6.566493511199951, -4.7367844581604, -8.264110565185547, -0.8643143177032471, 1.4509767293930054, -16.84482765197754, -6.397263526916504, 0.1259058713912964, 1.1251827478408813, 0.722618579864502, 1.9251594543457031, 0.7260875701904297, 3.046412467956543, -4.592877388000488, 0.5976240634918213, 0.9465885162353516, 1.5358211994171143, -7.230106830596924, 2.907467842102051, -13.666231155395508, -9.769408226013184], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 6.982072830200195, "min_q": -3.5220816135406494, "max_q": 16.679759979248047, "mean_td_error": -0.5812633633613586, "model": {}}, "td_error": [-0.020246505737304688, -4.849578857421875, 0.4399089813232422, 0.31252431869506836, -6.198884963989258, -0.014578819274902344, 0.015714645385742188, -4.274106979370117, -1.0366978645324707, -2.4875407218933105, -0.36198902130126953, -0.39098477363586426, 0.842073917388916, -1.6186895370483398, 3.9051260948181152, 1.940699577331543, -0.11537742614746094, -1.9274225234985352, -7.119789123535156, 4.283049583435059, -2.3557868003845215, -9.662324905395508, -0.3453025817871094, 8.35607624053955, 0.30948591232299805, -0.45229268074035645, -4.4767045974731445, 1.3443751335144043, 2.0241880416870117, 1.6254757642745972, 2.090916633605957, 1.618255615234375], "custom_metrics": {}}}, "num_steps_sampled": 7056, "num_agent_steps_sampled": 21168, "num_steps_trained": 12128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 36384, "last_target_update_ts": 6640, "num_target_updates": 12}, "done": false, "episodes_total": 704, "training_iteration": 7, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-27-02", "timestamp": 1648913222, "time_this_iter_s": 41.21833086013794, "time_total_s": 251.3065423965454, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549804bdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549804bdd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 251.3065423965454, "timesteps_since_restore": 224, "iterations_since_restore": 7, "perf": {"cpu_util_percent": 52.56440677966102, "ram_util_percent": 65.4322033898305}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 38.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 12.9, "policy1": 12.9, "policy2": 12.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [-30.0, 90.0, 30.0, 60.0, 30.0, 60.0, 60.0, -30.0, 30.0, 30.0, 90.0, 60.0, 0.0, 60.0, -30.0, 30.0, 0.0, 90.0, 30.0, 60.0, 30.0, 30.0, 60.0, 0.0, 60.0, 30.0, 60.0, 0.0, 0.0, 90.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, 30.0, 0.0, 60.0, 0.0, 60.0, 60.0, 90.0, 30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 60.0, 60.0, 30.0, 90.0, 90.0, 30.0, -30.0, 30.0, 0.0, 0.0, 30.0, 0.0, 60.0, 30.0, 60.0, 30.0, 60.0, 30.0, 60.0, 30.0, 60.0, 90.0, 90.0, 90.0, -30.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 60.0, -30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 0.0, 60.0, 30.0, 30.0, 30.0, 0.0, 60.0, 60.0, 0.0, 30.0, 30.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [-10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, -10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 20.0, 0.0, 0.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, -10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0, 30.0, 30.0, -10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0], "policy_policy1_reward": [-10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, -10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 20.0, 0.0, 0.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, -10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0, 30.0, 30.0, -10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0], "policy_policy2_reward": [-10.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, -10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 20.0, 0.0, 0.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, -10.0, 10.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0, 30.0, 30.0, -10.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 0.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0349016173026557, "mean_inference_ms": 25.406604364004597, "mean_action_processing_ms": 0.24363509368707362, "mean_env_wait_ms": 0.13673258229654264, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 8064, "timesteps_this_iter": 32, "agent_timesteps_total": 24192, "timers": {"load_time_ms": 0.689, "load_throughput": 46454.98, "learn_time_ms": 241.831, "learn_throughput": 132.324, "update_time_ms": 97.187}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 4.6849822998046875, "min_q": -1.407548427581787, "max_q": 11.799108505249023, "mean_td_error": -0.8835780620574951, "model": {}}, "td_error": [3.972029685974121, -1.4791450500488281, -1.9113945960998535, -8.19504165649414, -2.6185922622680664, -2.6020851135253906, 0.42507410049438477, -1.7997655868530273, 0.726837158203125, 1.0156991481781006, 0.5024878978729248, 1.2138290405273438, -4.788302421569824, 0.6646285057067871, 7.9857988357543945, 1.2211878299713135, 0.28274548053741455, -2.293272018432617, 2.204364776611328, -6.019626140594482, 2.3561997413635254, -6.816940784454346, -0.7438461780548096, 3.654797077178955, -1.0778160095214844, 0.5935591459274292, 2.657398223876953, 4.193367958068848, -14.643027305603027, -9.156784057617188, -2.2357168197631836, 4.436854839324951], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 2.483574867248535, "min_q": -3.307037830352783, "max_q": 9.105192184448242, "mean_td_error": -3.8076915740966797, "model": {}}, "td_error": [-6.489197254180908, 0.5563256740570068, -4.8768205642700195, -6.618361473083496, -3.511317253112793, -5.829458236694336, -5.385086536407471, -3.2903146743774414, -11.361837387084961, -8.351245880126953, -0.19163036346435547, 1.4236648082733154, -6.098133563995361, -5.900106430053711, -2.307037830352783, -2.1095588207244873, 1.964102029800415, -6.24611234664917, 1.7700371742248535, 1.683853268623352, 2.0505380630493164, -13.696755409240723, -10.333026885986328, -7.815103530883789, -0.019618749618530273, -10.501319885253906, 0.16794252395629883, 4.704510688781738, -3.0180253982543945, 2.0490477085113525, -16.407649993896484, 2.1415605545043945], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.303028106689453, "min_q": -2.8441693782806396, "max_q": 19.954418182373047, "mean_td_error": -0.8371862769126892, "model": {}}, "td_error": [-0.19318914413452148, -4.226382255554199, 0.006554126739501953, -0.1396198272705078, -1.6994266510009766, -9.322059631347656, -2.2286109924316406, 5.207338333129883, -1.537881851196289, -0.9966373443603516, 2.1195621490478516, 0.552838921546936, -1.8441693782806396, -2.2540950775146484, -0.9728155136108398, 1.273802399635315, -1.892465591430664, 6.909232139587402, -0.5850486755371094, 1.448378562927246, -0.37137603759765625, -6.687311172485352, -2.971555709838867, 1.7580986022949219, -2.0813865661621094, 1.7416248321533203, 0.9898161888122559, 0.7267856597900391, -3.758474349975586, -2.3085856437683105, -2.7274932861328125, -0.7254047393798828], "custom_metrics": {}}}, "num_steps_sampled": 8064, "num_agent_steps_sampled": 24192, "num_steps_trained": 14144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 42432, "last_target_update_ts": 7664, "num_target_updates": 14}, "done": false, "episodes_total": 804, "training_iteration": 8, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-27-42", "timestamp": 1648913262, "time_this_iter_s": 39.65907955169678, "time_total_s": 290.9656219482422, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498228d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498228d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 290.9656219482422, "timesteps_since_restore": 256, "iterations_since_restore": 8, "perf": {"cpu_util_percent": 51.89642857142858, "ram_util_percent": 65.12142857142857}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 33.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 11.0, "policy1": 11.0, "policy2": 11.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 60.0, 0.0, 30.0, 30.0, 0.0, 30.0, -30.0, 0.0, 30.0, 30.0, 90.0, 60.0, 0.0, 60.0, 60.0, 0.0, 30.0, 0.0, 30.0, 60.0, 60.0, 90.0, 60.0, 30.0, 0.0, 90.0, 0.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, -30.0, 30.0, 60.0, 60.0, 60.0, 0.0, 60.0, 30.0, 0.0, 90.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 30.0, 0.0, 90.0, 30.0, 30.0, 30.0, 30.0, 0.0, 0.0, 0.0, 30.0, 60.0, 30.0, 0.0, 30.0, 60.0, 30.0, 30.0, 30.0, 0.0, -30.0, 0.0, 60.0, 0.0, 60.0, 60.0, -30.0, 60.0, -30.0, 60.0, 30.0, 0.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, -10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 20.0, 20.0, -10.0, 20.0, -10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_policy1_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, -10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 20.0, 20.0, -10.0, 20.0, -10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0], "policy_policy2_reward": [0.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 10.0, 30.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, -10.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 10.0, 10.0, 0.0, 0.0, 0.0, 10.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, -10.0, 0.0, 20.0, 0.0, 20.0, 20.0, -10.0, 20.0, -10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0362856185294393, "mean_inference_ms": 25.515976142336903, "mean_action_processing_ms": 0.24470273173816837, "mean_env_wait_ms": 0.137256178471316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 9072, "timesteps_this_iter": 32, "agent_timesteps_total": 27216, "timers": {"load_time_ms": 0.632, "load_throughput": 50627.184, "learn_time_ms": 243.651, "learn_throughput": 131.336, "update_time_ms": 103.925}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 3.6212401390075684, "min_q": -2.824902057647705, "max_q": 14.733597755432129, "mean_td_error": -1.6408742666244507, "model": {}}, "td_error": [0.4982938766479492, 0.28156566619873047, -0.006231784820556641, -7.293581008911133, -1.1131534576416016, -1.8337373733520508, 1.8129115104675293, 0.42224669456481934, 4.25924015045166, -5.38101863861084, 0.17038917541503906, -1.0821404457092285, 2.183556079864502, -6.115665435791016, -1.824902057647705, -7.8886895179748535, -9.21273136138916, 0.4424295425415039, 3.4222445487976074, -0.9122486114501953, 6.7476325035095215, 1.018078327178955, -4.05046272277832, -1.2902183532714844, -4.250720977783203, -3.3207387924194336, -1.6426234245300293, 2.883610486984253, -3.652207374572754, -1.9906842708587646, -3.0944576263427734, -10.693960189819336], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 4.203786849975586, "min_q": -2.2561864852905273, "max_q": 12.87338638305664, "mean_td_error": -2.9355010986328125, "model": {}}, "td_error": [4.291508674621582, -5.757333755493164, 3.4285483360290527, -12.253015518188477, -10.606939315795898, 1.5507421493530273, 0.008690834045410156, 0.4245584011077881, -7.174549102783203, 1.7398185729980469, -7.604816913604736, -6.509300708770752, -5.322144031524658, -11.58720874786377, 1.121614933013916, -0.03625202178955078, 0.5662959218025208, 0.28557372093200684, -1.1414525508880615, -6.076773643493652, -5.210500240325928, -2.8125314712524414, -7.306403160095215, -3.14517879486084, 6.53462553024292, -2.2444117069244385, -6.965787887573242, 2.6212315559387207, -10.994949340820312, -3.000246047973633, -4.362064838409424, 3.6026158332824707], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.043418884277344, "min_q": -1.6436715126037598, "max_q": 25.056684494018555, "mean_td_error": 0.4284338355064392, "model": {}}, "td_error": [4.591946601867676, -6.833959579467773, -0.8037776947021484, 1.9994659423828125, -1.3721355199813843, 0.33072376251220703, 0.049634456634521484, 5.305426597595215, 2.6271445751190186, 0.5739974975585938, -0.13402938842773438, 0.277587890625, -2.504940986633301, 1.9448456764221191, -7.033416748046875, -0.22432899475097656, 3.5970096588134766, -0.6050987243652344, 3.116128921508789, 0.5402073860168457, 1.1425285339355469, 0.08081626892089844, 0.18813705444335938, 1.208176612854004, 3.274311065673828, 0.5112168192863464, -3.1400375366210938, 1.6357994079589844, 2.233776092529297, 1.2216815948486328, 0.7739906311035156, -0.8629436492919922], "custom_metrics": {}}}, "num_steps_sampled": 9072, "num_agent_steps_sampled": 27216, "num_steps_trained": 16160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 48480, "last_target_update_ts": 8688, "num_target_updates": 16}, "done": false, "episodes_total": 904, "training_iteration": 9, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-28-23", "timestamp": 1648913303, "time_this_iter_s": 40.73545718193054, "time_total_s": 331.70107913017273, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d4560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981d4560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 331.70107913017273, "timesteps_since_restore": 288, "iterations_since_restore": 9, "perf": {"cpu_util_percent": 51.81206896551724, "ram_util_percent": 65.40689655172413}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 32.88461538461539, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 10.961538461538462, "policy1": 10.961538461538462, "policy2": 10.961538461538462}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 0.0, 0.0, 30.0, 0.0, 60.0, 60.0, 90.0, 30.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 30.0, 60.0, 30.0, 30.0, 0.0, 0.0, 60.0, 30.0, 30.0, 30.0, 30.0, 0.0, 60.0, 60.0, 0.0, 90.0, 30.0, 0.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 60.0, 0.0, 60.0, 60.0, 30.0, 120.0, 60.0, 0.0, 60.0, 90.0, 90.0, 30.0, 30.0, 0.0, -30.0, 90.0, 60.0, 60.0, 60.0, 30.0, 30.0, -30.0, 30.0, 60.0, 0.0, 0.0, 60.0, 90.0, 0.0, 30.0, 0.0, 30.0, 60.0, 0.0, 30.0, 60.0, 60.0, 0.0, 60.0, 30.0, 30.0, 0.0, 30.0, 30.0, 0.0, 30.0, 30.0, 0.0, 60.0, 60.0, 30.0, 0.0, 0.0, -30.0, 30.0, 0.0, -30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 30.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 10.0, 0.0, -10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, -10.0, 10.0, 20.0, 0.0, 0.0, 20.0, 30.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, -10.0, 10.0, 0.0, -10.0], "policy_policy1_reward": [20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 30.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 10.0, 0.0, -10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, -10.0, 10.0, 20.0, 0.0, 0.0, 20.0, 30.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, -10.0, 10.0, 0.0, -10.0], "policy_policy2_reward": [20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 20.0, 30.0, 10.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 0.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 10.0, 0.0, -10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, -10.0, 10.0, 20.0, 0.0, 0.0, 20.0, 30.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 10.0, 10.0, 0.0, 20.0, 20.0, 10.0, 0.0, 0.0, -10.0, 10.0, 0.0, -10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0365215808046755, "mean_inference_ms": 25.599438323240722, "mean_action_processing_ms": 0.24497062145174142, "mean_env_wait_ms": 0.1373125985708089, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 10080, "timesteps_this_iter": 32, "agent_timesteps_total": 30240, "timers": {"load_time_ms": 0.627, "load_throughput": 50996.515, "learn_time_ms": 237.13, "learn_throughput": 134.947, "update_time_ms": 100.702}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 5.2988176345825195, "min_q": -1.9831054210662842, "max_q": 14.410431861877441, "mean_td_error": -2.207395076751709, "model": {}}, "td_error": [-2.385038375854492, -2.080472707748413, -8.815799713134766, 0.6629457473754883, 10.977179527282715, 2.7659811973571777, -1.036454439163208, -7.603067398071289, -1.8666398525238037, 0.26892948150634766, 1.172900676727295, -1.4012351036071777, 0.28789496421813965, 3.849996566772461, 1.0436525344848633, -1.0651817321777344, -0.9523553848266602, -7.79998779296875, -10.84391975402832, -4.569748878479004, -7.215816497802734, 0.20133352279663086, -1.0720043182373047, 0.6926051378250122, -6.769248962402344, -4.399436950683594, -4.105727195739746, -9.420974731445312, 3.707801103591919, -5.050126552581787, -8.024011611938477, 0.20938587188720703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 4.259673118591309, "min_q": -1.7565540075302124, "max_q": 13.28981876373291, "mean_td_error": -0.8942780494689941, "model": {}}, "td_error": [2.1581692695617676, 3.7323567867279053, 1.2196321487426758, -6.813938617706299, 0.6140284538269043, -4.505681037902832, -7.698940277099609, 5.806285381317139, 0.17648398876190186, -3.1561155319213867, 1.918492317199707, 0.1751314401626587, 0.6987452507019043, 2.884153366088867, -1.6039950847625732, 1.2579879760742188, 1.2115554809570312, -4.805690765380859, 2.280918598175049, 1.2716069221496582, 0.7612278461456299, 1.5746476650238037, -1.9302406311035156, 0.5927002429962158, -0.1356821060180664, -6.135670185089111, -0.1096644401550293, 1.6658157110214233, -19.721660614013672, 1.584155797958374, -5.63780403137207, 2.054091691970825], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.683721542358398, "min_q": -3.188479423522949, "max_q": 23.34276580810547, "mean_td_error": -0.27226006984710693, "model": {}}, "td_error": [14.485880851745605, 1.1732745170593262, -0.3242807388305664, -3.720104217529297, 2.921049118041992, -0.3827383518218994, -3.335866928100586, 0.7184944152832031, -1.8402462005615234, -0.4346456527709961, 0.7833559513092041, -0.4793281555175781, -3.455108642578125, -4.304755210876465, 9.88604736328125, 0.9775209426879883, -0.6429915428161621, -0.7459430694580078, 0.42444515228271484, 9.963594436645508, -0.9539051055908203, -0.0063304901123046875, 0.5762472152709961, -5.889429092407227, -1.2331600189208984, -2.5221099853515625, 0.43056201934814453, -4.939249038696289, -0.33627843856811523, -7.744208335876465, -5.889430999755859, -1.8726835250854492], "custom_metrics": {}}}, "num_steps_sampled": 10080, "num_agent_steps_sampled": 30240, "num_steps_trained": 18176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 54528, "last_target_update_ts": 9712, "num_target_updates": 18}, "done": false, "episodes_total": 1008, "training_iteration": 10, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-29-04", "timestamp": 1648913344, "time_this_iter_s": 40.40354037284851, "time_total_s": 372.10461950302124, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549802b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549802b7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 372.10461950302124, "timesteps_since_restore": 320, "iterations_since_restore": 10, "perf": {"cpu_util_percent": 52.90175438596491, "ram_util_percent": 65.44210526315788}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 30.6, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 10.2, "policy1": 10.2, "policy2": 10.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 30.0, 30.0, 0.0, 60.0, 30.0, 0.0, 90.0, 90.0, 30.0, 30.0, 30.0, 30.0, 90.0, 30.0, 30.0, 60.0, 0.0, 60.0, -30.0, 60.0, 0.0, 30.0, 30.0, 30.0, 0.0, 30.0, 30.0, 90.0, 90.0, 60.0, 60.0, 60.0, 0.0, 0.0, 30.0, 0.0, 60.0, 30.0, 0.0, 0.0, 30.0, 0.0, 30.0, 60.0, 30.0, 30.0, 30.0, 30.0, 90.0, -30.0, 60.0, 60.0, 0.0, 30.0, 0.0, 0.0, 60.0, 30.0, 60.0, 60.0, 30.0, 60.0, 0.0, 30.0, 30.0, -30.0, 60.0, 90.0, 60.0, 30.0, 30.0, 0.0, 0.0, 60.0, 0.0, 60.0, 60.0, 30.0, 30.0, 60.0, -30.0, 0.0, 30.0, 0.0, 60.0, -30.0, 0.0, 120.0, 0.0, 0.0, 0.0, 0.0, -30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 0.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 20.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 30.0, -10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, -10.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0], "policy_policy1_reward": [10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 0.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 20.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 30.0, -10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, -10.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0], "policy_policy2_reward": [10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 0.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 20.0, -10.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 0.0, 20.0, 10.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 30.0, -10.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 0.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, -10.0, 0.0, 40.0, 0.0, 0.0, 0.0, 0.0, -10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.038230931419265, "mean_inference_ms": 25.6258402109748, "mean_action_processing_ms": 0.24516568302549352, "mean_env_wait_ms": 0.13737673369117734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 11088, "timesteps_this_iter": 32, "agent_timesteps_total": 33264, "timers": {"load_time_ms": 0.738, "load_throughput": 43364.585, "learn_time_ms": 237.135, "learn_throughput": 134.944, "update_time_ms": 97.786}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.280101776123047, "min_q": -2.704059362411499, "max_q": 18.209348678588867, "mean_td_error": -0.3478083610534668, "model": {}}, "td_error": [0.4014015197753906, 1.4249916076660156, -0.10891056060791016, -0.8492879867553711, -1.3125114440917969, 2.0711307525634766, 2.04708194732666, -7.817188262939453, 0.23079228401184082, 2.483976364135742, 0.25218868255615234, 1.992136836051941, -2.2292017936706543, -0.7884113788604736, -0.07793235778808594, 1.5808541774749756, 9.45948314666748, -3.8819446563720703, -0.5349750518798828, -5.088753700256348, -2.1161766052246094, 2.1473140716552734, -1.909097671508789, 1.2298986911773682, -3.865093231201172, -0.5940272808074951, -8.984743118286133, 2.3930463790893555, 0.3126058578491211, -2.1161766052246094, -0.12284278869628906, 3.240504741668701], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 4.95168924331665, "min_q": -2.942301034927368, "max_q": 16.235645294189453, "mean_td_error": -0.3102805018424988, "model": {}}, "td_error": [-1.4644556045532227, 1.7157845497131348, -2.247999906539917, 1.7345056533813477, 0.3248329162597656, 4.294265270233154, -0.5659812688827515, 1.6485772132873535, 2.6754016876220703, -3.2870922088623047, -1.3277528285980225, -1.184147834777832, -0.67327880859375, -4.648765563964844, 3.285252094268799, -0.4196963310241699, -1.927969217300415, -6.3625640869140625, -9.879262924194336, 1.6240129470825195, 2.608541488647461, 3.8900046348571777, -0.25438642501831055, 1.358144760131836, -1.2811369895935059, -1.6978635787963867, -2.183539390563965, 0.8584721088409424, 1.4982070922851562, 1.4034079313278198, -0.9064006805419922, 1.4639062881469727], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.160551071166992, "min_q": -2.235562324523926, "max_q": 24.29730987548828, "mean_td_error": 0.4669557809829712, "model": {}}, "td_error": [0.6968708038330078, 1.0223350524902344, 1.2942848205566406, -1.8952598571777344, -0.9218697547912598, 0.7783288955688477, 2.036522388458252, -0.4539833068847656, -0.767603874206543, -1.199252963066101, -0.5976028442382812, 15.1911039352417, 1.0984458923339844, -3.665569305419922, 1.7623348236083984, 0.6535453796386719, 1.238013744354248, 2.127068281173706, -1.1885700225830078, 1.200674057006836, -2.4127120971679688, 3.181600570678711, 2.0188217163085938, 1.7212562561035156, -0.57171630859375, 1.6768913269042969, -0.23286819458007812, -4.848979949951172, 1.072718620300293, 0.15677261352539062, -0.5083084106445312, -4.72070837020874], "custom_metrics": {}}}, "num_steps_sampled": 11088, "num_agent_steps_sampled": 33264, "num_steps_trained": 20192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 60576, "last_target_update_ts": 10736, "num_target_updates": 20}, "done": false, "episodes_total": 1108, "training_iteration": 11, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-29-43", "timestamp": 1648913383, "time_this_iter_s": 39.66021513938904, "time_total_s": 411.7648346424103, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ca8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ca8c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 411.7648346424103, "timesteps_since_restore": 352, "iterations_since_restore": 11, "perf": {"cpu_util_percent": 51.81578947368421, "ram_util_percent": 65.56140350877192}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 42.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 14.1, "policy1": 14.1, "policy2": 14.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 60.0, 0.0, 60.0, 60.0, 30.0, 60.0, 30.0, 90.0, 60.0, 60.0, 30.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 0.0, 30.0, 120.0, 30.0, 60.0, 30.0, 30.0, 30.0, 30.0, 60.0, 30.0, 60.0, 0.0, 0.0, 60.0, 60.0, 0.0, 30.0, 30.0, 120.0, 30.0, 30.0, 30.0, 60.0, 90.0, 60.0, 30.0, 30.0, 60.0, 120.0, 30.0, -30.0, 30.0, 30.0, 0.0, 30.0, 60.0, 90.0, 30.0, 30.0, 30.0, 0.0, 60.0, 0.0, 90.0, 0.0, 60.0, 0.0, 30.0, 0.0, 90.0, 0.0, 120.0, 30.0, 30.0, 30.0, 90.0, 30.0, 30.0, 90.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 0.0, 60.0, 60.0, 60.0, 30.0, 60.0, 120.0, 30.0, 60.0, 0.0, 0.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 40.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 10.0, -10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 30.0, 0.0, 40.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0], "policy_policy1_reward": [10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 40.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 10.0, -10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 30.0, 0.0, 40.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0], "policy_policy2_reward": [10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 0.0, 10.0, 40.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 10.0, -10.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 0.0, 20.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 30.0, 0.0, 40.0, 10.0, 10.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 20.0, 0.0, 0.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0379545747741197, "mean_inference_ms": 25.683295273583784, "mean_action_processing_ms": 0.24527076847297097, "mean_env_wait_ms": 0.13752474272546691, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 12096, "timesteps_this_iter": 32, "agent_timesteps_total": 36288, "timers": {"load_time_ms": 0.763, "load_throughput": 41939.108, "learn_time_ms": 244.269, "learn_throughput": 131.003, "update_time_ms": 102.889}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.06900691986084, "min_q": -0.4851118326187134, "max_q": 20.0994930267334, "mean_td_error": -2.0193004608154297, "model": {}}, "td_error": [1.308359146118164, -17.355670928955078, -17.051008224487305, 1.095442295074463, 0.3656444549560547, 9.074660301208496, 6.960419178009033, -1.2978451251983643, -1.7590599060058594, 3.1518802642822266, -0.8564382791519165, 1.660827875137329, -24.701217651367188, -5.301451683044434, -7.007715225219727, -1.0761356353759766, -1.5653234720230103, 2.117177963256836, -5.231982707977295, 1.1234683990478516, -0.3111686706542969, -0.19206708669662476, -5.337132453918457, 5.057753562927246, 2.3237361907958984, -2.405397415161133, 0.060805320739746094, 1.6128759384155273, 1.769968032836914, -8.36440372467041, -5.932306289672852, 3.4456920623779297], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 7.752697944641113, "min_q": -1.5557907819747925, "max_q": 17.81733512878418, "mean_td_error": -0.12927685678005219, "model": {}}, "td_error": [-9.209293365478516, -4.3723602294921875, 11.243851661682129, -5.8524017333984375, -3.180440902709961, 3.5510387420654297, -6.3452372550964355, 1.413818359375, -2.121570348739624, 1.3406734466552734, -0.5584888458251953, 0.8925962448120117, -0.4826732873916626, -0.9414215087890625, 0.4420827627182007, 6.445572376251221, 2.013401985168457, -3.657618999481201, -0.9653911590576172, 4.731986045837402, 0.2902679443359375, -6.992804527282715, 3.611349105834961, -0.6850743293762207, 8.288583755493164, 1.5828213691711426, 4.607674598693848, 0.5077495574951172, 0.1460915207862854, 0.38875478506088257, -9.840655326843262, -0.42974162101745605], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.684244155883789, "min_q": -1.9731340408325195, "max_q": 22.49809455871582, "mean_td_error": -0.7118021845817566, "model": {}}, "td_error": [-1.9986426830291748, -4.306173801422119, -6.20759391784668, 0.41713523864746094, 10.73460578918457, -1.5466985702514648, -4.071441650390625, -1.4172000885009766, 5.574788570404053, -1.5288925170898438, 1.6026949882507324, 0.06374168395996094, 1.275024175643921, -0.5380363464355469, -0.5663785934448242, 0.0804222822189331, -5.467201232910156, 5.508900165557861, -10.79881477355957, 9.099575996398926, 12.58796215057373, 0.4872243404388428, -1.015925407409668, -2.527294158935547, 0.4091963768005371, -2.8206844329833984, -2.158113479614258, -1.5223350524902344, -0.9214634895324707, -1.6058237552642822, -19.373672485351562, -0.22655487060546875], "custom_metrics": {}}}, "num_steps_sampled": 12096, "num_agent_steps_sampled": 36288, "num_steps_trained": 22208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 66624, "last_target_update_ts": 11760, "num_target_updates": 22}, "done": false, "episodes_total": 1208, "training_iteration": 12, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-30-24", "timestamp": 1648913424, "time_this_iter_s": 40.8896918296814, "time_total_s": 452.6545264720917, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981f3440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981f3440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 452.6545264720917, "timesteps_since_restore": 384, "iterations_since_restore": 12, "perf": {"cpu_util_percent": 51.641379310344824, "ram_util_percent": 65.4844827586207}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 42.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 14.1, "policy1": 14.1, "policy2": 14.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 60.0, 30.0, 0.0, 30.0, 0.0, 30.0, 30.0, 30.0, -30.0, 60.0, 90.0, 30.0, 30.0, 60.0, 60.0, 30.0, 60.0, 0.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, 0.0, 0.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 0.0, 30.0, 60.0, 90.0, 60.0, 30.0, 90.0, 90.0, 90.0, 30.0, 60.0, 90.0, 60.0, 30.0, 30.0, 90.0, 60.0, 90.0, 30.0, 30.0, 60.0, 30.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 0.0, 30.0, 30.0, 60.0, 60.0, 30.0, 30.0, 60.0, 30.0, 0.0, 60.0, 60.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 30.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, -10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, -10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 20.0, 10.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, -10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 0.0, 0.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 10.0, 0.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.039732182793476, "mean_inference_ms": 25.746018758517135, "mean_action_processing_ms": 0.24552661033167072, "mean_env_wait_ms": 0.1375822348677606, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 13104, "timesteps_this_iter": 32, "agent_timesteps_total": 39312, "timers": {"load_time_ms": 0.695, "load_throughput": 46058.038, "learn_time_ms": 255.959, "learn_throughput": 125.02, "update_time_ms": 102.902}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.943800926208496, "min_q": -1.641663908958435, "max_q": 21.17970848083496, "mean_td_error": -0.0266951322555542, "model": {}}, "td_error": [1.3087701797485352, -2.87606143951416, 2.823070526123047, -7.640163421630859, 0.7616918087005615, 0.610139787197113, 0.4641909599304199, 0.11045074462890625, 0.7093000411987305, 1.8979206085205078, -0.20359039306640625, 0.2534370422363281, 2.7941832542419434, -1.8762626647949219, -1.901808738708496, 2.0831458568573, 1.7216477394104004, 0.3403968811035156, 1.7471013069152832, -3.5911197662353516, -7.374581336975098, 0.17659854888916016, 0.20872116088867188, 1.1527996063232422, 0.8412342071533203, 0.3894519805908203, -0.038535475730895996, 4.752854347229004, -2.742466926574707, -0.936314582824707, 1.2268104553222656, 1.9527435302734375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 6.8930230140686035, "min_q": -2.77602481842041, "max_q": 17.461471557617188, "mean_td_error": -1.0813770294189453, "model": {}}, "td_error": [-1.299677848815918, 6.3291120529174805, 3.408080577850342, -3.975832939147949, -4.600842475891113, -6.16866397857666, -4.712461471557617, -1.0375032424926758, 3.3297629356384277, -0.19940757751464844, -1.0683937072753906, 0.8067233562469482, -5.925014495849609, 0.7431468963623047, 1.1727309226989746, -1.7760248184204102, 0.31519538164138794, -1.7854785919189453, 1.4878559112548828, 0.0863652229309082, -5.304976940155029, -2.744232177734375, -0.3508930206298828, -0.1310821771621704, 1.9600324630737305, -6.760381698608398, -5.457331657409668, -1.8246183395385742, 0.9511508941650391, -2.2758536338806152, 2.076662540435791, 0.12778544425964355], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.149798393249512, "min_q": -1.9722367525100708, "max_q": 23.932849884033203, "mean_td_error": -0.7158638834953308, "model": {}}, "td_error": [-1.1730995178222656, -0.6910018920898438, 0.4718894958496094, 1.1535186767578125, -5.521047592163086, -23.155353546142578, 0.7584375143051147, 1.750143051147461, -2.4696483612060547, 0.411826491355896, 2.416952133178711, 1.4389724731445312, 0.8640263080596924, 0.5779457092285156, 1.0138740539550781, 0.3419933319091797, -4.114744186401367, 2.1391611099243164, -1.7563304901123047, 1.761800765991211, 6.331666946411133, 1.4539356231689453, -4.100973129272461, 2.358632802963257, 0.3717937469482422, 1.0065956115722656, 0.5386664867401123, -0.0780181884765625, 2.4899511337280273, -8.52351188659668, -0.5029811859130859, -0.47271728515625], "custom_metrics": {}}}, "num_steps_sampled": 13104, "num_agent_steps_sampled": 39312, "num_steps_trained": 24224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 72672, "last_target_update_ts": 12784, "num_target_updates": 24}, "done": false, "episodes_total": 1308, "training_iteration": 13, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-31-05", "timestamp": 1648913465, "time_this_iter_s": 40.79997515678406, "time_total_s": 493.45450162887573, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498228b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f5498228b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 493.45450162887573, "timesteps_since_restore": 416, "iterations_since_restore": 13, "perf": {"cpu_util_percent": 52.98620689655173, "ram_util_percent": 65.41379310344827}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 37.8, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 12.6, "policy1": 12.6, "policy2": 12.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 0.0, 30.0, -30.0, 0.0, 30.0, 60.0, 90.0, 30.0, 0.0, 30.0, 30.0, 0.0, 0.0, 0.0, 60.0, 30.0, 0.0, 90.0, 60.0, 60.0, 90.0, 0.0, 30.0, 60.0, 30.0, 60.0, 0.0, 60.0, 30.0, 30.0, 0.0, 90.0, 0.0, 90.0, 60.0, 0.0, 60.0, 60.0, 30.0, 0.0, 30.0, 60.0, -30.0, 30.0, 60.0, 30.0, 60.0, 0.0, 0.0, 30.0, 30.0, 60.0, 60.0, 90.0, 60.0, -30.0, 0.0, 30.0, 0.0, 60.0, 60.0, 60.0, 60.0, 120.0, 0.0, 30.0, 60.0, 0.0, 30.0, 60.0, 0.0, 60.0, 60.0, 30.0, 60.0, 30.0, 30.0, 60.0, 0.0, 60.0, 90.0, 0.0, 30.0, 30.0, 60.0, 60.0, 30.0, 30.0, 30.0, 60.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 120.0, 30.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 10.0], "policy_policy1_reward": [10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 10.0], "policy_policy2_reward": [10.0, 0.0, 10.0, -10.0, 0.0, 10.0, 20.0, 30.0, 10.0, 0.0, 10.0, 10.0, 0.0, 0.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, 20.0, 0.0, 20.0, 10.0, 10.0, 0.0, 30.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, -10.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0, 10.0, 20.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0405330625530278, "mean_inference_ms": 25.72037524087937, "mean_action_processing_ms": 0.24566821992549326, "mean_env_wait_ms": 0.13770991933686974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 14112, "timesteps_this_iter": 32, "agent_timesteps_total": 42336, "timers": {"load_time_ms": 0.696, "load_throughput": 45988.6, "learn_time_ms": 235.015, "learn_throughput": 136.162, "update_time_ms": 103.584}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.417871475219727, "min_q": -2.0928971767425537, "max_q": 18.779537200927734, "mean_td_error": 0.07798033952713013, "model": {}}, "td_error": [-0.2911992073059082, 0.9819008111953735, 1.0074748992919922, -1.8315048217773438, -0.11044692993164062, 2.2946434020996094, 12.383661270141602, 4.42817497253418, 7.478374481201172, -7.805796146392822, 2.420461654663086, 2.1212029457092285, 2.316302537918091, 1.0430392026901245, -0.05124950408935547, -0.7511677742004395, -2.135284900665283, 0.015331029891967773, -1.3717041015625, -2.7899885177612305, -3.0669994354248047, -9.01889705657959, -0.9339027404785156, -0.5488204956054688, 0.73956298828125, 0.16017723083496094, -1.3985185623168945, 3.839470863342285, -3.7943267822265625, -5.565802574157715, -0.1713886260986328, 2.902592182159424], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 7.342414379119873, "min_q": -2.31241774559021, "max_q": 17.433612823486328, "mean_td_error": 0.21215003728866577, "model": {}}, "td_error": [-0.1416858434677124, -0.4794197082519531, -0.548335075378418, 0.2704610824584961, -0.4945106506347656, 1.9753093719482422, 1.3070793151855469, 1.0842432975769043, 0.5880935788154602, 14.158243179321289, 2.077397346496582, 0.1153022050857544, -1.9203072786331177, -5.299673080444336, -1.1561565399169922, 0.4197502136230469, 11.652284622192383, -0.2097761631011963, -5.1886491775512695, 0.2132406234741211, 1.69826078414917, 0.5643487572669983, -2.900625228881836, 3.5646848678588867, 1.1105891466140747, -5.72349739074707, 1.5508365631103516, 0.5501006245613098, -0.32665157318115234, -7.864001750946045, -6.6062703132629395, 2.7481346130371094], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.204845428466797, "min_q": -2.3960397243499756, "max_q": 23.826629638671875, "mean_td_error": 0.6461063027381897, "model": {}}, "td_error": [14.550691604614258, 1.0657291412353516, 0.9076652526855469, 3.063826560974121, 1.0371742248535156, 0.9540481567382812, 0.11966383457183838, 0.35771942138671875, -0.7912082672119141, 8.044364929199219, -0.14536476135253906, -1.5709266662597656, -1.1169013977050781, 7.874716758728027, 1.06402587890625, 0.8881542682647705, -0.28906452655792236, -5.076298713684082, 0.8877143859863281, -0.1693553924560547, -4.141155242919922, -4.53647518157959, -0.8052959442138672, 0.2280714511871338, 1.537776231765747, -0.3404362201690674, -0.4095125198364258, -0.052043914794921875, 0.003002166748046875, -3.129060745239258, -0.25783050060272217, 0.9219875335693359], "custom_metrics": {}}}, "num_steps_sampled": 14112, "num_agent_steps_sampled": 42336, "num_steps_trained": 26240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 78720, "last_target_update_ts": 13808, "num_target_updates": 26}, "done": false, "episodes_total": 1408, "training_iteration": 14, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-31-45", "timestamp": 1648913505, "time_this_iter_s": 40.00605225563049, "time_total_s": 533.4605538845062, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e2320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e2320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 533.4605538845062, "timesteps_since_restore": 448, "iterations_since_restore": 14, "perf": {"cpu_util_percent": 51.6875, "ram_util_percent": 65.48035714285713}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 38.07692307692308, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 12.692307692307692, "policy1": 12.692307692307692, "policy2": 12.692307692307692}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 30.0, 0.0, 90.0, -30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 90.0, 60.0, 60.0, 30.0, 30.0, 90.0, 60.0, 60.0, 30.0, 30.0, 30.0, 90.0, 30.0, 0.0, 30.0, 60.0, 120.0, 30.0, 0.0, 30.0, 60.0, -30.0, 30.0, 0.0, 90.0, 30.0, 60.0, 60.0, 30.0, 60.0, 60.0, 90.0, 0.0, 30.0, 60.0, 30.0, -30.0, 0.0, 30.0, 60.0, 0.0, 60.0, 0.0, 30.0, 30.0, 30.0, 0.0, 60.0, 60.0, 60.0, 0.0, 30.0, 0.0, 0.0, 30.0, 60.0, 30.0, 30.0, 30.0, 90.0, 30.0, 60.0, 60.0, 30.0, 60.0, 0.0, 30.0, 30.0, -30.0, 60.0, 0.0, 30.0, 60.0, 60.0, 60.0, 30.0, -30.0, 90.0, 60.0, 30.0, 30.0, 30.0, 30.0, 60.0, 30.0, 30.0, 0.0, 0.0, 30.0, 60.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 10.0, 0.0, 30.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, -10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, -10.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0], "policy_policy1_reward": [10.0, 10.0, 0.0, 30.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, -10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, -10.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0], "policy_policy2_reward": [10.0, 10.0, 0.0, 30.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, -10.0, 10.0, 0.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 10.0, -10.0, 0.0, 10.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 10.0, 0.0, 20.0, 20.0, 20.0, 0.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 10.0, 10.0, -10.0, 20.0, 0.0, 10.0, 20.0, 20.0, 20.0, 10.0, -10.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 10.0, 10.0, 0.0, 0.0, 10.0, 20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0411019711165288, "mean_inference_ms": 25.748753919704857, "mean_action_processing_ms": 0.24580462084217572, "mean_env_wait_ms": 0.13776362746268217, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 15120, "timesteps_this_iter": 32, "agent_timesteps_total": 45360, "timers": {"load_time_ms": 0.704, "load_throughput": 45443.619, "learn_time_ms": 239.11, "learn_throughput": 133.83, "update_time_ms": 104.795}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.519979476928711, "min_q": -2.001777172088623, "max_q": 21.133256912231445, "mean_td_error": 0.10520345717668533, "model": {}}, "td_error": [12.361434936523438, -0.9371087551116943, -2.235868453979492, 0.4703204929828644, 0.9678316116333008, 1.375722885131836, -5.616856575012207, -8.525554656982422, -0.3372344970703125, -0.3123607635498047, -3.017354965209961, 1.4127273559570312, -1.2168622016906738, -1.1370320320129395, -0.9371087551116943, 0.8437126874923706, 2.182325839996338, 0.9543952345848083, 1.5369701385498047, -4.50131368637085, 8.182799339294434, -0.3020038604736328, -5.991206169128418, 1.4607739448547363, -1.001777172088623, 0.9207696914672852, 2.6702518463134766, 1.769754409790039, 1.0803974866867065, -0.3420677185058594, -2.2245683670043945, 3.8126027584075928], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.875565528869629, "min_q": -2.0387039184570312, "max_q": 22.904926300048828, "mean_td_error": -0.07074770331382751, "model": {}}, "td_error": [-0.7281646728515625, 1.1897954940795898, 2.636432647705078, -1.4707221984863281, 2.6102094650268555, -1.4707221984863281, 1.386148452758789, -2.910912036895752, -8.144769668579102, 0.7474632263183594, 1.0765419006347656, 0.042737364768981934, -7.60658597946167, 0.9090291261672974, -0.12233877182006836, -2.550313949584961, 2.065694808959961, -1.0387039184570312, -0.2961769104003906, 0.8882217407226562, -1.125539779663086, 2.839461326599121, 5.819671630859375, -7.088510513305664, 4.752779006958008, 0.050983428955078125, 0.3728179931640625, 1.2943581342697144, -1.623051643371582, 1.0826282501220703, -1.7464523315429688, 5.894064903259277], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.480226516723633, "min_q": -2.2126917839050293, "max_q": 21.07721519470215, "mean_td_error": -0.3716813027858734, "model": {}}, "td_error": [-3.526378631591797, -0.053934574127197266, -1.292628288269043, 1.0924453735351562, -0.4066638946533203, 13.080364227294922, 1.0556464195251465, -0.12057304382324219, -5.62663459777832, 0.8858394622802734, 0.9163662195205688, -5.729726791381836, -1.4289255142211914, 1.56107759475708, 0.7963638305664062, -0.5903892517089844, -1.81475830078125, 5.840740203857422, -3.894014358520508, 0.3734779357910156, -5.174368858337402, 0.9805736541748047, 1.0299263000488281, -1.2688186168670654, 1.4429537057876587, 0.9044818878173828, 1.0559444427490234, -7.743938446044922, -0.8819961547851562, -2.1134700775146484, -1.0127429962158203, -0.23004150390625], "custom_metrics": {}}}, "num_steps_sampled": 15120, "num_agent_steps_sampled": 45360, "num_steps_trained": 28256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 84768, "last_target_update_ts": 14832, "num_target_updates": 28}, "done": false, "episodes_total": 1512, "training_iteration": 15, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-32-26", "timestamp": 1648913546, "time_this_iter_s": 40.65263104438782, "time_total_s": 574.113184928894, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e2f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e2f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 574.113184928894, "timesteps_since_restore": 480, "iterations_since_restore": 15, "perf": {"cpu_util_percent": 51.87068965517242, "ram_util_percent": 65.60517241379311}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 48.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 16.0, "policy1": 16.0, "policy2": 16.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 60.0, 0.0, 60.0, 90.0, 0.0, 90.0, 60.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 90.0, 30.0, 0.0, 30.0, 60.0, 120.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 30.0, 60.0, -30.0, 60.0, 30.0, 120.0, 0.0, 30.0, 60.0, 30.0, 30.0, 30.0, 90.0, 90.0, 30.0, 60.0, 90.0, 30.0, 60.0, 90.0, 30.0, 60.0, 0.0, 30.0, 90.0, 30.0, 30.0, 60.0, 30.0, 30.0, 60.0, 30.0, 30.0, 60.0, 90.0, 90.0, 60.0, 30.0, -30.0, 30.0, 0.0, 60.0, 0.0, 60.0, 30.0, 60.0, 60.0, 90.0, 0.0, 30.0, 60.0, 60.0, 90.0, 0.0, 60.0, 60.0, 30.0, 60.0, 90.0, 60.0, 0.0, 60.0, 30.0, 0.0, 0.0, 60.0, 30.0, 60.0, 30.0, 30.0, 90.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 40.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 10.0, -10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 30.0, 20.0, 0.0, 20.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 20.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 40.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 10.0, -10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 30.0, 20.0, 0.0, 20.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 20.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 20.0, 0.0, 20.0, 30.0, 0.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 0.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 40.0, 0.0, 10.0, 20.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 10.0, -10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 30.0, 20.0, 0.0, 20.0, 10.0, 0.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0430977476343697, "mean_inference_ms": 25.757864867668427, "mean_action_processing_ms": 0.2460539148842878, "mean_env_wait_ms": 0.13797981639136575, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 16128, "timesteps_this_iter": 32, "agent_timesteps_total": 48384, "timers": {"load_time_ms": 0.614, "load_throughput": 52115.294, "learn_time_ms": 226.984, "learn_throughput": 140.979, "update_time_ms": 102.103}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.763460159301758, "min_q": -0.4764649569988251, "max_q": 21.728410720825195, "mean_td_error": -0.5442585945129395, "model": {}}, "td_error": [-0.6361169815063477, -0.3141450881958008, -0.8629217147827148, 0.3349189758300781, -0.9378185272216797, -1.0197010040283203, 1.4121074676513672, -2.535205364227295, -4.910519599914551, -2.862076759338379, 2.9364748001098633, -0.012035369873046875, 0.8962593078613281, 0.6216697692871094, 1.3097376823425293, 0.288970947265625, -1.761739730834961, 2.297290802001953, -6.07997989654541, 1.5868804454803467, -0.7961997985839844, -0.43477675318717957, 2.479278564453125, -5.18501091003418, 2.0949792861938477, 1.123030424118042, -1.202468991279602, 1.6258907318115234, -8.745206832885742, 0.1559429168701172, 0.7438049912452698, 0.9724111557006836], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.09073543548584, "min_q": -2.8367269039154053, "max_q": 20.479637145996094, "mean_td_error": -0.6675266623497009, "model": {}}, "td_error": [-1.00946044921875, 0.2334766387939453, -1.5754432678222656, -1.6301450729370117, -0.3994884490966797, 1.1320817470550537, 0.1749734878540039, -0.5382564067840576, -1.9690895080566406, 1.8851537704467773, -1.7767753601074219, -9.790207862854004, 0.35795068740844727, 0.5965547561645508, -0.4188518524169922, 0.7871685028076172, -1.9113502502441406, 1.08941650390625, 1.8462295532226562, -0.9231109619140625, 0.2334766387939453, 0.778109073638916, 0.857818603515625, -7.550486087799072, -2.3992881774902344, -4.354360103607178, 1.6206531524658203, 1.1771395206451416, -2.382373809814453, -2.0496177673339844, 9.101780891418457, -2.5545296669006348], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.5645112991333, "min_q": -1.4037752151489258, "max_q": 20.941152572631836, "mean_td_error": 0.48047906160354614, "model": {}}, "td_error": [-6.698337554931641, 9.1859769821167, -0.179732084274292, -3.2572007179260254, -3.099318504333496, -0.6551313400268555, 1.2231760025024414, 0.3642721176147461, -0.089080810546875, -3.712644577026367, 0.9960956573486328, -4.876469612121582, -0.5384550094604492, 9.203407287597656, -1.796288013458252, -1.7581901550292969, 0.1384258270263672, -0.058304786682128906, 0.7024132609367371, 0.054877281188964844, -0.4134049415588379, 6.53253173828125, 0.9207286834716797, -0.027753829956054688, -8.315290451049805, 0.761258602142334, -0.21303558349609375, -1.3367230892181396, -0.5178451538085938, 10.338637351989746, -0.32583045959472656, 12.822563171386719], "custom_metrics": {}}}, "num_steps_sampled": 16128, "num_agent_steps_sampled": 48384, "num_steps_trained": 30272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 90816, "last_target_update_ts": 15856, "num_target_updates": 30}, "done": false, "episodes_total": 1612, "training_iteration": 16, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-33-06", "timestamp": 1648913586, "time_this_iter_s": 40.1389057636261, "time_total_s": 614.2520906925201, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981c3b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981c3b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 614.2520906925201, "timesteps_since_restore": 512, "iterations_since_restore": 16, "perf": {"cpu_util_percent": 52.824561403508774, "ram_util_percent": 65.7421052631579}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 48.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 16.1, "policy1": 16.1, "policy2": 16.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 60.0, 30.0, 30.0, 0.0, 30.0, 60.0, 60.0, 60.0, 0.0, 120.0, 60.0, 60.0, 90.0, 0.0, 30.0, 30.0, 60.0, 0.0, 60.0, 30.0, 90.0, 90.0, 60.0, 90.0, 90.0, 60.0, 0.0, 30.0, 90.0, 0.0, 30.0, 30.0, 0.0, 0.0, 60.0, 60.0, 30.0, 60.0, 30.0, 30.0, 90.0, 30.0, 30.0, 0.0, 30.0, 60.0, 30.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, -30.0, 60.0, 0.0, 60.0, 30.0, 0.0, 60.0, 120.0, 90.0, 60.0, 30.0, 60.0, 90.0, 90.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 60.0, 60.0, -30.0, 90.0, 90.0, 60.0, 30.0, 30.0, 30.0, 60.0, 90.0, -30.0, 60.0, 30.0, 60.0, 120.0, 0.0, 60.0, 60.0, 0.0, 0.0, 90.0, 30.0, 60.0, 0.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 20.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 0.0, 10.0, 30.0, 0.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, -10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, -10.0, 20.0, 10.0, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, 0.0, 30.0, 10.0, 20.0, 0.0, 20.0], "policy_policy1_reward": [30.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 20.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 0.0, 10.0, 30.0, 0.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, -10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, -10.0, 20.0, 10.0, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, 0.0, 30.0, 10.0, 20.0, 0.0, 20.0], "policy_policy2_reward": [30.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 20.0, 20.0, 30.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 0.0, 10.0, 30.0, 0.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 30.0, 10.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, -10.0, 20.0, 0.0, 20.0, 10.0, 0.0, 20.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 20.0, -10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, -10.0, 20.0, 10.0, 20.0, 40.0, 0.0, 20.0, 20.0, 0.0, 0.0, 30.0, 10.0, 20.0, 0.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.043236992879398, "mean_inference_ms": 25.798132692223525, "mean_action_processing_ms": 0.24611083323368527, "mean_env_wait_ms": 0.13796092470718793, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 17136, "timesteps_this_iter": 32, "agent_timesteps_total": 51408, "timers": {"load_time_ms": 0.636, "load_throughput": 50323.47, "learn_time_ms": 239.946, "learn_throughput": 133.363, "update_time_ms": 99.775}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.160857200622559, "min_q": -1.4134972095489502, "max_q": 21.171586990356445, "mean_td_error": -0.36732879281044006, "model": {}}, "td_error": [-1.3084516525268555, 0.05615556240081787, -0.1691950559616089, -0.3473472595214844, -6.939579010009766, -0.6425457000732422, 1.1909732818603516, -0.9317828416824341, -3.622046947479248, 0.36851567029953003, 0.42771613597869873, 0.9494543075561523, 0.2586536407470703, 0.3188209533691406, 1.370713710784912, -1.405202865600586, -7.2777252197265625, -0.7966117858886719, 0.2375507354736328, -0.8671531677246094, 13.551660537719727, 0.9709377288818359, -0.34556007385253906, 0.4196404814720154, 0.5482540130615234, 0.021305084228515625, 0.37461090087890625, -1.2855939865112305, 0.9146846532821655, -6.946949005126953, -1.2681150436401367, 0.4196901321411133], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.05772876739502, "min_q": -1.1696258783340454, "max_q": 23.913162231445312, "mean_td_error": -0.9514333009719849, "model": {}}, "td_error": [0.9441305994987488, -6.1500091552734375, -2.1301612854003906, 7.12097692489624, -0.903839111328125, -10.169626235961914, 0.8227100372314453, -8.563605308532715, 2.6338539123535156, 16.473438262939453, 5.060983657836914, -1.341285228729248, 0.6251010894775391, 1.2427387237548828, -2.336101531982422, -2.2443127632141113, -1.5202583074569702, -9.01265811920166, -1.69805908203125, -4.54563570022583, 0.17727088928222656, -2.4595069885253906, -9.784820556640625, -0.904217004776001, 0.2574958801269531, -3.0928702354431152, -8.802512168884277, 6.772880554199219, 1.0673309564590454, 2.4814200401306152, 2.9608497619628906, -3.42756986618042], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.17923355102539, "min_q": -0.8290053606033325, "max_q": 21.94741439819336, "mean_td_error": 0.19047299027442932, "model": {}}, "td_error": [2.6352243423461914, 0.8395149111747742, 0.506141722202301, -4.998958587646484, -4.1828532218933105, 0.17099463939666748, 1.4971803426742554, 0.7404327392578125, -3.9623899459838867, 0.3614234924316406, 3.3739013671875, 1.698762059211731, 1.4089488983154297, 9.269657135009766, -4.257357597351074, 0.197601318359375, -0.34722900390625, 1.0730934143066406, 0.7624588012695312, -0.8526401519775391, 2.470919609069824, -1.4448261260986328, 0.48380088806152344, -9.32262897491455, -7.347010135650635, 13.359111785888672, 2.3257126808166504, 0.017063140869140625, -3.551877021789551, 0.15046119689941406, 0.2933177351951599, 2.727184295654297], "custom_metrics": {}}}, "num_steps_sampled": 17136, "num_agent_steps_sampled": 51408, "num_steps_trained": 32288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 96864, "last_target_update_ts": 16880, "num_target_updates": 32}, "done": false, "episodes_total": 1712, "training_iteration": 17, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-33-47", "timestamp": 1648913627, "time_this_iter_s": 40.39645004272461, "time_total_s": 654.6485407352448, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 654.6485407352448, "timesteps_since_restore": 544, "iterations_since_restore": 17, "perf": {"cpu_util_percent": 51.90175438596492, "ram_util_percent": 65.59473684210526}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 43.2, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 14.4, "policy1": 14.4, "policy2": 14.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 30.0, 30.0, 0.0, 60.0, 0.0, 60.0, 60.0, 30.0, 60.0, 30.0, 30.0, 60.0, 30.0, 60.0, 90.0, 30.0, 60.0, 60.0, 60.0, 30.0, 120.0, 0.0, 0.0, 60.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 30.0, 60.0, 60.0, 0.0, 30.0, 60.0, 30.0, 60.0, 120.0, 30.0, 0.0, 30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 90.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, -30.0, 0.0, 0.0, 30.0, 60.0, 0.0, 60.0, 60.0, 30.0, 90.0, 30.0, 30.0, 60.0, 0.0, 0.0, 90.0, 60.0, 30.0, 90.0, 30.0, 90.0, 30.0, 60.0, 30.0, 0.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, 60.0, 60.0, 30.0, 90.0, 60.0, 0.0, 0.0, -30.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 40.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 30.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, -10.0, 10.0], "policy_policy1_reward": [20.0, 10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 40.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 30.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, -10.0, 10.0], "policy_policy2_reward": [20.0, 10.0, 10.0, 0.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 40.0, 0.0, 0.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, -10.0, 0.0, 0.0, 10.0, 20.0, 0.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 0.0, 30.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.043200282659566, "mean_inference_ms": 25.815333068331412, "mean_action_processing_ms": 0.2461377418800574, "mean_env_wait_ms": 0.1379770146925491, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 18144, "timesteps_this_iter": 32, "agent_timesteps_total": 54432, "timers": {"load_time_ms": 0.765, "load_throughput": 41822.799, "learn_time_ms": 238.338, "learn_throughput": 134.263, "update_time_ms": 102.045}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.519084930419922, "min_q": -1.236918568611145, "max_q": 20.669069290161133, "mean_td_error": 0.5947653651237488, "model": {}}, "td_error": [-1.4211492538452148, -0.766446053981781, 2.1001439094543457, 0.9285420179367065, 1.5336792469024658, 0.8008251190185547, 1.8632478713989258, -0.7406363487243652, 0.5194168090820312, -0.31781864166259766, 1.9629034996032715, 2.6976518630981445, 1.4443893432617188, -0.1809101104736328, -0.5991373062133789, 3.3680419921875, -0.3348998427391052, 1.5587434768676758, 1.6160449981689453, -9.712076187133789, 1.9206600189208984, -1.5280818939208984, -0.5482559204101562, 3.1686410903930664, -0.07182645797729492, 1.833822250366211, -0.3601675033569336, 2.467041015625, -0.18963396549224854, 3.3175125122070312, -0.2972745895385742, 2.9994993209838867], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.305274963378906, "min_q": -2.1523449420928955, "max_q": 22.79673194885254, "mean_td_error": -0.3066510558128357, "model": {}}, "td_error": [2.344540596008301, -0.18081068992614746, -1.083841323852539, -3.2325592041015625, 0.8789844512939453, -1.9294242858886719, 13.304658889770508, 1.1503057479858398, -1.1277942657470703, -1.4692440032958984, -2.1857001781463623, 1.5202808380126953, 0.6103878021240234, 0.18564152717590332, -0.15584254264831543, 1.0065879821777344, -3.2361831665039062, 0.19989490509033203, 1.124300479888916, -0.894742488861084, -0.0551300048828125, 0.13594436645507812, -5.016679763793945, 2.656655788421631, -1.0078511238098145, -9.194714546203613, 0.7188272476196289, -0.7194623947143555, -1.9985995292663574, -1.7294368743896484, 4.839583396911621, -5.2714104652404785], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.066904067993164, "min_q": -0.9808306694030762, "max_q": 23.340953826904297, "mean_td_error": -0.448297917842865, "model": {}}, "td_error": [-0.7070431709289551, 0.9598293304443359, 0.032579243183135986, -2.9491195678710938, -0.8543262481689453, -1.0604944229125977, 0.028366446495056152, 6.81497049331665, 1.5926322937011719, -6.6518049240112305, -0.05785369873046875, -2.8247671127319336, 5.903790473937988, 0.8289451599121094, -4.30383825302124, 0.9535314440727234, -0.46241915225982666, 0.22937774658203125, 0.1561756134033203, 2.793093681335449, -3.4094581604003906, -1.2690224647521973, -3.0750865936279297, 0.11683225631713867, -1.1034679412841797, 0.7237558364868164, -0.9833805561065674, -0.09123992919921875, -3.858663558959961, -0.5501823425292969, -0.41747188568115234, -0.8497734069824219], "custom_metrics": {}}}, "num_steps_sampled": 18144, "num_agent_steps_sampled": 54432, "num_steps_trained": 34304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 102912, "last_target_update_ts": 17904, "num_target_updates": 34}, "done": false, "episodes_total": 1812, "training_iteration": 18, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-34-27", "timestamp": 1648913667, "time_this_iter_s": 39.89803600311279, "time_total_s": 694.5465767383575, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981caf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981caf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 694.5465767383575, "timesteps_since_restore": 576, "iterations_since_restore": 18, "perf": {"cpu_util_percent": 51.88947368421053, "ram_util_percent": 65.5}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 40.2, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 13.4, "policy1": 13.4, "policy2": 13.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 60.0, 60.0, 0.0, 30.0, 30.0, 60.0, 60.0, 60.0, 30.0, 90.0, 30.0, 90.0, 60.0, 30.0, 60.0, 60.0, 0.0, 30.0, 30.0, 60.0, 90.0, 0.0, 0.0, 30.0, -30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 30.0, 60.0, 0.0, 30.0, 60.0, 30.0, 60.0, 60.0, 0.0, 0.0, 90.0, 0.0, 30.0, 30.0, 0.0, 30.0, 60.0, 90.0, 90.0, 0.0, 30.0, 0.0, 0.0, 90.0, 0.0, 0.0, 90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, 0.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, 60.0, 30.0, 30.0, 60.0, 0.0, 30.0, 60.0, 30.0, 0.0, 60.0, 30.0, 90.0, 0.0, 0.0, 30.0, 0.0, 30.0, 60.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 0.0, 0.0, 10.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 0.0, 0.0, 30.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 0.0, 0.0, 30.0, 0.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 0.0, 20.0, 10.0, 30.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 0.0, 0.0, 10.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 0.0, 0.0, 30.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 0.0, 0.0, 30.0, 0.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 0.0, 20.0, 10.0, 30.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 20.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 0.0, 0.0, 10.0, -10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 20.0, 20.0, 0.0, 0.0, 30.0, 0.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 0.0, 0.0, 30.0, 0.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 0.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 10.0, 20.0, 10.0, 0.0, 20.0, 10.0, 30.0, 0.0, 0.0, 10.0, 0.0, 10.0, 20.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044288398976066, "mean_inference_ms": 25.850276280903174, "mean_action_processing_ms": 0.24651507789642085, "mean_env_wait_ms": 0.13839326041256073, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 19152, "timesteps_this_iter": 32, "agent_timesteps_total": 57456, "timers": {"load_time_ms": 0.679, "load_throughput": 47135.286, "learn_time_ms": 242.793, "learn_throughput": 131.8, "update_time_ms": 103.186}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 6.973541259765625, "min_q": -1.0822840929031372, "max_q": 21.514326095581055, "mean_td_error": -0.8995442390441895, "model": {}}, "td_error": [1.6288522481918335, 2.521141767501831, 1.3986653089523315, 1.2821656465530396, -2.2309160232543945, 0.7505846619606018, 1.1443381309509277, 1.44210946559906, 5.189751148223877, 1.6170768737792969, 1.3657207489013672, -6.680757522583008, -2.6217384338378906, -8.375669479370117, -7.673337936401367, -0.049442172050476074, 0.18457508087158203, 2.7320494651794434, -1.3309202194213867, 0.5226497650146484, -8.83975601196289, -0.9390525817871094, 1.6169716119766235, -2.1593685150146484, -5.463667392730713, 2.467527389526367, 0.2529315948486328, -1.7736101150512695, 1.6912834644317627, -0.7721004486083984, 0.6383801698684692, -8.321850776672363], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.708110809326172, "min_q": -1.595657229423523, "max_q": 25.368877410888672, "mean_td_error": 0.0782836377620697, "model": {}}, "td_error": [-0.17733192443847656, 2.534719467163086, 3.6481122970581055, -6.8426055908203125, 1.8969998359680176, 2.121082305908203, 1.1927604675292969, 0.6652584075927734, -1.1009979248046875, -0.8384721279144287, -0.11322593688964844, -0.12705326080322266, 0.33337855339050293, 3.2180957794189453, -2.2553768157958984, 0.8974819183349609, -0.07796168327331543, -0.6458206176757812, -1.3508005142211914, 6.446232318878174, 2.742586135864258, -2.9826698303222656, 0.8013153076171875, -0.2648385763168335, -3.0934810638427734, 0.9877432584762573, -3.1799745559692383, -4.16946268081665, -1.058253288269043, 1.1796278953552246, 0.7396849393844604, 1.3783245086669922], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.500396728515625, "min_q": -2.3826534748077393, "max_q": 23.966678619384766, "mean_td_error": -0.11409804224967957, "model": {}}, "td_error": [-1.7936716079711914, -0.5699281692504883, 0.5484471321105957, 1.0809326171875, 0.9975830316543579, -0.17949676513671875, -9.86830997467041, 4.763017177581787, -3.277811050415039, 2.2101938724517822, -0.5754482746124268, -2.274698257446289, 3.831531047821045, -1.6554908752441406, -4.252691268920898, -0.7646760940551758, -0.9820914268493652, 0.3230893611907959, 0.3094291090965271, -2.0301713943481445, 0.2807159423828125, -1.7251056432724, 0.6350431442260742, -0.8715019226074219, 0.8694939613342285, -2.425832748413086, 0.04853248596191406, -3.8680953979492188, -1.2208538055419922, 19.62202262878418, 0.6952065229415894, -1.5305004119873047], "custom_metrics": {}}}, "num_steps_sampled": 19152, "num_agent_steps_sampled": 57456, "num_steps_trained": 36320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 108960, "last_target_update_ts": 18928, "num_target_updates": 36}, "done": false, "episodes_total": 1912, "training_iteration": 19, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-35-08", "timestamp": 1648913708, "time_this_iter_s": 40.6017849445343, "time_total_s": 735.1483616828918, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ca9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ca9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 735.1483616828918, "timesteps_since_restore": 608, "iterations_since_restore": 19, "perf": {"cpu_util_percent": 52.92413793103447, "ram_util_percent": 65.51379310344828}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 46.44230769230769, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 15.48076923076923, "policy1": 15.48076923076923, "policy2": 15.48076923076923}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 0.0, 60.0, 30.0, 0.0, 30.0, 30.0, 60.0, 90.0, 60.0, 60.0, 60.0, 0.0, 90.0, 90.0, 60.0, 30.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 60.0, 0.0, 90.0, 60.0, 60.0, 0.0, 60.0, 60.0, 0.0, 30.0, 30.0, 0.0, 90.0, 0.0, 60.0, 30.0, 30.0, 30.0, 30.0, 30.0, 60.0, 60.0, 90.0, 0.0, 30.0, 60.0, 60.0, 90.0, 0.0, 90.0, 30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 0.0, 90.0, 60.0, 30.0, 60.0, 30.0, 90.0, 30.0, 90.0, 30.0, 30.0, 60.0, 0.0, 90.0, 30.0, 60.0, 60.0, 90.0, 60.0, 30.0, 30.0, 60.0, 0.0, 90.0, 30.0, 30.0, 120.0, 60.0, 30.0, 60.0, 60.0, 30.0, 0.0, 60.0, 90.0, 0.0, 30.0, 60.0, 0.0, 30.0, 30.0, 90.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 30.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 10.0, 40.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 30.0, 20.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 30.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 10.0, 40.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 30.0, 20.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 0.0, 20.0, 10.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 20.0, 20.0, 0.0, 10.0, 10.0, 0.0, 30.0, 0.0, 20.0, 10.0, 10.0, 10.0, 10.0, 10.0, 20.0, 20.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 10.0, 10.0, 40.0, 20.0, 10.0, 20.0, 20.0, 10.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 0.0, 10.0, 10.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.045795701084996, "mean_inference_ms": 25.859847602757217, "mean_action_processing_ms": 0.2468807951275069, "mean_env_wait_ms": 0.13843869860270175, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 20160, "timesteps_this_iter": 32, "agent_timesteps_total": 60480, "timers": {"load_time_ms": 0.831, "load_throughput": 38514.083, "learn_time_ms": 248.836, "learn_throughput": 128.599, "update_time_ms": 103.705}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.706348419189453, "min_q": -1.766737699508667, "max_q": 20.66351890563965, "mean_td_error": 0.3862608075141907, "model": {}}, "td_error": [1.3103570938110352, 0.4613819122314453, 1.5664749145507812, -5.8023223876953125, -1.5152664184570312, 1.4709644317626953, -0.7385125160217285, 1.5630764961242676, 3.2423758506774902, 0.8629064559936523, -6.901602745056152, 16.62679672241211, 0.7024953961372375, -0.35503333806991577, -4.929856300354004, 0.19747352600097656, -3.417477607727051, -1.0681877136230469, 1.9400463104248047, -1.6162662506103516, -2.4808216094970703, 10.874470710754395, -0.14838027954101562, -0.33687496185302734, 4.846164703369141, -0.766737699508667, 1.7611002922058105, 0.1345844268798828, 0.8749938607215881, 1.7151837348937988, 0.9547958374023438, -8.667957305908203], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.097803115844727, "min_q": -1.9268467426300049, "max_q": 21.929981231689453, "mean_td_error": -0.42420095205307007, "model": {}}, "td_error": [-9.483033180236816, -1.1115379333496094, -3.626540184020996, -1.2355155944824219, 8.523605346679688, -4.2546706199646, 13.789761543273926, -0.7631063461303711, 2.9612369537353516, -3.0454092025756836, -0.7149143218994141, -1.6952342987060547, 1.508213996887207, 0.4584007263183594, -7.434614181518555, -0.16885554790496826, -9.498209953308105, 0.357014000415802, 0.583740234375, -1.7297725677490234, 0.2610816955566406, 0.1994485855102539, -0.4886207580566406, -3.545496940612793, -0.7772140502929688, 1.3663252592086792, 2.299488067626953, -1.6753597259521484, 1.0316839218139648, 2.2540340423583984, 2.720491409301758, -0.6408510208129883], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.866411209106445, "min_q": -2.3607637882232666, "max_q": 25.779190063476562, "mean_td_error": 0.5202193260192871, "model": {}}, "td_error": [-3.111795425415039, 1.8238162994384766, -0.34840989112854004, -3.4208712577819824, -2.6682567596435547, -5.236091613769531, 1.9691922664642334, 0.22499719262123108, 0.5565884113311768, -0.035521745681762695, 14.755891799926758, -2.2594451904296875, -0.9636058807373047, 1.7467854022979736, -2.3160266876220703, 6.680768013000488, -0.005955696105957031, 3.8905029296875, -1.5377674102783203, 0.8171367645263672, 0.5177015066146851, 1.254016399383545, 0.2295074462890625, 2.0232086181640625, -2.62408447265625, 1.2406930923461914, 0.34462451934814453, 0.25919198989868164, -0.4147148132324219, 5.162530422210693, 0.6421623229980469, -2.5497522354125977], "custom_metrics": {}}}, "num_steps_sampled": 20160, "num_agent_steps_sampled": 60480, "num_steps_trained": 38336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 115008, "last_target_update_ts": 19952, "num_target_updates": 38}, "done": false, "episodes_total": 2016, "training_iteration": 20, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-35-49", "timestamp": 1648913749, "time_this_iter_s": 40.95715618133545, "time_total_s": 776.1055178642273, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e8170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e8170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 776.1055178642273, "timesteps_since_restore": 640, "iterations_since_restore": 20, "perf": {"cpu_util_percent": 51.81379310344828, "ram_util_percent": 65.97068965517242}}
{"episode_reward_max": 90.0, "episode_reward_min": -30.0, "episode_reward_mean": 48.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_mean": {"policy0": 16.3, "policy1": 16.3, "policy2": 16.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 0.0, 30.0, 60.0, 90.0, 90.0, 60.0, 90.0, 90.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 30.0, 60.0, 90.0, 90.0, 60.0, 90.0, 60.0, 30.0, 90.0, 90.0, 0.0, 60.0, 60.0, 90.0, 90.0, 30.0, 30.0, 60.0, 30.0, 60.0, 0.0, 30.0, 90.0, 30.0, 90.0, 0.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 30.0, 60.0, -30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 60.0, 0.0, 0.0, 30.0, 30.0, 60.0, 90.0, 30.0, 30.0, 30.0, 60.0, 30.0, 90.0, 60.0, 0.0, 0.0, 0.0, 0.0, 30.0, 60.0, 90.0, 30.0, 30.0, 90.0, 30.0, 90.0, 30.0, 30.0, 90.0, 90.0, 60.0, 90.0, 60.0, 0.0, 0.0, 30.0, 60.0, 90.0, 90.0, 30.0, 30.0, 30.0, 30.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 30.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 20.0], "policy_policy1_reward": [20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 30.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 20.0], "policy_policy2_reward": [20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 10.0, 20.0, 0.0, 10.0, 30.0, 10.0, 30.0, 0.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, -10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 10.0, 20.0, 10.0, 30.0, 20.0, 0.0, 0.0, 0.0, 0.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 10.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0458380856631992, "mean_inference_ms": 25.868345642504256, "mean_action_processing_ms": 0.24703663597705117, "mean_env_wait_ms": 0.13850604836935815, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 21168, "timesteps_this_iter": 32, "agent_timesteps_total": 63504, "timers": {"load_time_ms": 0.664, "load_throughput": 48186.159, "learn_time_ms": 236.247, "learn_throughput": 135.451, "update_time_ms": 102.256}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.693081855773926, "min_q": -2.1312835216522217, "max_q": 20.635793685913086, "mean_td_error": -0.46394315361976624, "model": {}}, "td_error": [0.9153940081596375, -0.17945051193237305, -0.9863572120666504, -5.866488456726074, -0.5995699763298035, -7.082038879394531, 1.002767562866211, -1.042684555053711, -0.1096343994140625, -0.24414730072021484, -0.015707969665527344, 6.683605194091797, -2.910238265991211, 0.7070295810699463, 0.2633695602416992, -0.880885124206543, -0.3174009323120117, -2.324237823486328, -1.6346096992492676, 0.7644920349121094, -2.095614433288574, -8.218024253845215, -0.3902146816253662, -2.8918895721435547, -0.7628116607666016, -0.4510960578918457, 1.1013774871826172, 1.2411384582519531, -0.3174009323120117, -2.8304977416992188, 11.89786148071289, 2.7277841567993164], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.714591979980469, "min_q": -2.00581955909729, "max_q": 23.3212890625, "mean_td_error": 0.678100049495697, "model": {}}, "td_error": [-8.699112892150879, -6.209046363830566, 1.3652286529541016, -1.1130962371826172, 0.7403173446655273, -8.096538543701172, 2.0330371856689453, 1.4050486087799072, 1.6228599548339844, 2.0378761291503906, -2.898710250854492, 1.4586963653564453, 2.767772674560547, 2.269195556640625, 1.0956487655639648, 2.037379264831543, -0.14072513580322266, 0.6969575881958008, 0.6280453205108643, -3.276531219482422, 1.2417469024658203, -1.434164047241211, -2.9782180786132812, -0.3436821699142456, 10.895227432250977, -0.15100479125976562, 0.420712947845459, 2.934598922729492, 17.211498260498047, 0.9868049621582031, 1.829706072807312, 1.3616724014282227], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.19350814819336, "min_q": -1.2613074779510498, "max_q": 24.624784469604492, "mean_td_error": -0.09930925071239471, "model": {}}, "td_error": [0.20229387283325195, -0.32218360900878906, -0.5879144668579102, -1.1683101654052734, 0.15453147888183594, 0.9903841018676758, -3.2548561096191406, 1.4583415985107422, 1.7407665252685547, 0.9580459594726562, 0.4733924865722656, -0.4142932891845703, -1.3057241439819336, -2.157705307006836, -0.47723388671875, 0.8721243143081665, 0.030811309814453125, -1.6409778594970703, 0.9855833053588867, -2.762880325317383, 1.6120619773864746, 1.3287248611450195, 2.0985820293426514, -0.4134349822998047, 1.4275007247924805, 0.026760578155517578, -3.626507043838501, -1.2447776794433594, 0.27588558197021484, 1.2336235046386719, -1.1683082580566406, 1.4977970123291016], "custom_metrics": {}}}, "num_steps_sampled": 21168, "num_agent_steps_sampled": 63504, "num_steps_trained": 40352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 121056, "last_target_update_ts": 20976, "num_target_updates": 40}, "done": false, "episodes_total": 2116, "training_iteration": 21, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-36-29", "timestamp": 1648913789, "time_this_iter_s": 40.24885678291321, "time_total_s": 816.3543746471405, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7de710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7de710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 816.3543746471405, "timesteps_since_restore": 672, "iterations_since_restore": 21, "perf": {"cpu_util_percent": 51.68245614035088, "ram_util_percent": 65.60701754385964}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 48.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 16.3, "policy1": 16.3, "policy2": 16.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 60.0, 90.0, 60.0, -30.0, 90.0, 60.0, 60.0, 90.0, 90.0, 60.0, 60.0, 90.0, 30.0, 60.0, 60.0, 60.0, 30.0, 0.0, 30.0, 60.0, 60.0, 60.0, 90.0, 60.0, 0.0, 0.0, 30.0, 90.0, 30.0, 30.0, 90.0, 30.0, 30.0, 60.0, -30.0, 60.0, 90.0, 90.0, 30.0, 0.0, 90.0, 60.0, 60.0, 30.0, 60.0, 0.0, 120.0, 30.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0, 30.0, 0.0, 0.0, 60.0, 60.0, 30.0, 0.0, 90.0, 30.0, 30.0, 0.0, 90.0, 30.0, 30.0, 60.0, 90.0, 60.0, 30.0, 60.0, 90.0, 0.0, 30.0, 90.0, 0.0, 0.0, 0.0, 90.0, 90.0, 60.0, 60.0, 60.0, 0.0, 0.0, 30.0, 60.0, 60.0, 0.0, 60.0, 30.0, 30.0, 60.0, 60.0, 90.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 20.0, 30.0, 20.0, -10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, -10.0, 20.0, 30.0, 30.0, 10.0, 0.0, 30.0, 20.0, 20.0, 10.0, 20.0, 0.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 20.0, 30.0, 0.0, 10.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0], "policy_policy1_reward": [10.0, 20.0, 30.0, 20.0, -10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, -10.0, 20.0, 30.0, 30.0, 10.0, 0.0, 30.0, 20.0, 20.0, 10.0, 20.0, 0.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 20.0, 30.0, 0.0, 10.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0], "policy_policy2_reward": [10.0, 20.0, 30.0, 20.0, -10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 0.0, 0.0, 10.0, 30.0, 10.0, 10.0, 30.0, 10.0, 10.0, 20.0, -10.0, 20.0, 30.0, 30.0, 10.0, 0.0, 30.0, 20.0, 20.0, 10.0, 20.0, 0.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 0.0, 0.0, 20.0, 20.0, 10.0, 0.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 20.0, 30.0, 0.0, 10.0, 30.0, 0.0, 0.0, 0.0, 30.0, 30.0, 20.0, 20.0, 20.0, 0.0, 0.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.045105487403835, "mean_inference_ms": 25.8614585569466, "mean_action_processing_ms": 0.24691994282659707, "mean_env_wait_ms": 0.1385020070295274, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 22176, "timesteps_this_iter": 32, "agent_timesteps_total": 66528, "timers": {"load_time_ms": 0.663, "load_throughput": 48281.495, "learn_time_ms": 229.357, "learn_throughput": 139.521, "update_time_ms": 99.885}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.158086776733398, "min_q": -1.6964770555496216, "max_q": 18.89200210571289, "mean_td_error": 0.12345868349075317, "model": {}}, "td_error": [2.041013717651367, 0.7656040191650391, -1.7964324951171875, 0.2422657012939453, -2.309328079223633, 1.5798156261444092, -3.0625972747802734, 1.989611029624939, 0.6424179077148438, -2.4497427940368652, 0.00041496753692626953, -8.324618339538574, -2.17242431640625, 17.777544021606445, 0.19478559494018555, 1.2234020233154297, -0.12850987911224365, 1.6584124565124512, -3.661815643310547, -5.274068355560303, 1.8240644931793213, 5.169364929199219, -1.9456558227539062, 1.2701148986816406, -4.8785400390625, 0.1465010643005371, -1.6550312042236328, 1.070446252822876, 0.5943101644515991, -0.033319711685180664, 2.2320027351379395, 1.2206707000732422], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.791372299194336, "min_q": -1.7029966115951538, "max_q": 24.601530075073242, "mean_td_error": -0.6949852705001831, "model": {}}, "td_error": [-1.7700309753417969, -1.3971176147460938, -10.427006721496582, -10.015811920166016, 1.7403125762939453, -0.5312175750732422, -1.6834516525268555, -3.433290481567383, 1.6553573608398438, -2.7903480529785156, -4.507777690887451, -0.39600133895874023, 0.12358856201171875, 8.628293991088867, 0.6639223098754883, -7.779466152191162, 1.0971412658691406, 0.37900257110595703, 0.6425590515136719, -1.2302184104919434, 3.3873939514160156, 0.6789740324020386, -1.3856525421142578, -1.8372573852539062, 1.804530143737793, 1.063680648803711, 8.20421028137207, 0.6484279632568359, -5.6784844398498535, 7.980830192565918, -1.4768314361572266, -4.597790718078613], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.831306457519531, "min_q": -3.16483473777771, "max_q": 25.504287719726562, "mean_td_error": 0.2924596071243286, "model": {}}, "td_error": [-2.16483473777771, 0.49294471740722656, -1.1463265419006348, -0.9397397041320801, 11.60257339477539, 1.2543048858642578, -0.8697414398193359, -1.8552422523498535, 0.8254213333129883, 0.041538238525390625, -2.7885282039642334, 2.581594944000244, -0.6707005500793457, -5.458334922790527, 2.3076553344726562, 1.8208541870117188, 1.3009357452392578, -0.40256309509277344, -3.054727554321289, -0.29266357421875, -3.1615428924560547, 0.517674446105957, -0.6720366477966309, 1.6040630340576172, 1.102869987487793, 0.3765373229980469, 10.33169937133789, 0.015897750854492188, -1.2841124534606934, -1.9688405990600586, 0.855596661567688, -0.9435194730758667], "custom_metrics": {}}}, "num_steps_sampled": 22176, "num_agent_steps_sampled": 66528, "num_steps_trained": 42368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 127104, "last_target_update_ts": 22000, "num_target_updates": 42}, "done": false, "episodes_total": 2216, "training_iteration": 22, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-37-08", "timestamp": 1648913828, "time_this_iter_s": 39.39502954483032, "time_total_s": 855.7494041919708, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7de9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7de9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 855.7494041919708, "timesteps_since_restore": 704, "iterations_since_restore": 22, "perf": {"cpu_util_percent": 52.832142857142856, "ram_util_percent": 65.65}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 51.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 17.3, "policy1": 17.3, "policy2": 17.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 30.0, 90.0, 60.0, 90.0, 60.0, 0.0, 60.0, 60.0, 30.0, 120.0, 30.0, 60.0, 90.0, 60.0, 60.0, 30.0, -30.0, 30.0, 60.0, 60.0, 90.0, 30.0, 0.0, 60.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 0.0, 30.0, 60.0, 90.0, 90.0, 60.0, 60.0, 60.0, 90.0, 30.0, 60.0, 60.0, 30.0, 60.0, 0.0, 0.0, 0.0, 60.0, 90.0, 90.0, 30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 60.0, 60.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 30.0, 90.0, 60.0, 30.0, 30.0, 90.0, 30.0, 90.0, 60.0, 30.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 0.0, 60.0, 30.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 10.0, 20.0, 30.0, 20.0, 20.0, 10.0, -10.0, 10.0, 20.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 10.0], "policy_policy1_reward": [20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 10.0, 20.0, 30.0, 20.0, 20.0, 10.0, -10.0, 10.0, 20.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 10.0], "policy_policy2_reward": [20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 40.0, 10.0, 20.0, 30.0, 20.0, 20.0, 10.0, -10.0, 10.0, 20.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 0.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 0.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 10.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0465729107049824, "mean_inference_ms": 25.882592216861525, "mean_action_processing_ms": 0.24719633726245355, "mean_env_wait_ms": 0.13866047417477986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 23184, "timesteps_this_iter": 32, "agent_timesteps_total": 69552, "timers": {"load_time_ms": 0.635, "load_throughput": 50370.685, "learn_time_ms": 260.238, "learn_throughput": 122.964, "update_time_ms": 109.359}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 7.955334186553955, "min_q": -2.6975817680358887, "max_q": 21.106517791748047, "mean_td_error": -0.3843653202056885, "model": {}}, "td_error": [-1.9712839126586914, -1.7742061614990234, 2.4687957763671875, -1.3950252532958984, 2.05230712890625, 2.2683629989624023, 4.067108631134033, 1.9575928449630737, -2.8688526153564453, -1.6975817680358887, -4.011137008666992, -2.2298741340637207, 1.1256616115570068, 0.3556666374206543, 1.992488145828247, 0.7543604373931885, -6.498110771179199, 0.94024658203125, -1.4782519340515137, 0.14264845848083496, 0.5578069686889648, 0.3142814636230469, -1.163590431213379, -1.5229988098144531, -1.7961623668670654, 3.018766403198242, -6.544838905334473, 1.096125602722168, 2.9681529998779297, -4.126543045043945, 0.9220722913742065, -0.2236785888671875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.691448211669922, "min_q": -1.6583188772201538, "max_q": 24.413766860961914, "mean_td_error": 0.30478954315185547, "model": {}}, "td_error": [0.14275598526000977, 13.82923412322998, -0.98193359375, -0.719264030456543, -0.34906578063964844, 0.36989498138427734, -0.44864845275878906, 0.9897959232330322, 0.6002235412597656, -1.3305110931396484, -0.9512635469436646, -0.6583188772201538, -1.8367443084716797, 1.094857096672058, -0.2348613739013672, -8.486345291137695, -1.9299335479736328, 0.5124249458312988, 1.4575538635253906, 1.5779080390930176, -1.2429389953613281, 0.9073963165283203, -0.011611580848693848, -7.495209693908691, 0.17757415771484375, 9.718260765075684, -5.61680793762207, 1.5510673522949219, 0.9972667694091797, -2.1509876251220703, 11.296257019042969, -1.024759292602539], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.418027877807617, "min_q": -2.160027027130127, "max_q": 24.938480377197266, "mean_td_error": -0.18695658445358276, "model": {}}, "td_error": [-0.7943506240844727, -5.096131324768066, 1.213925838470459, -1.0655603408813477, 2.3961143493652344, 0.9933242797851562, -10.483473777770996, 9.427770614624023, -0.6768207550048828, 0.2497730255126953, 2.532177686691284, 0.9429359436035156, 0.6780614852905273, 0.09189224243164062, -1.994887351989746, 2.3865842819213867, 7.626618385314941, 0.6412825584411621, -0.13017559051513672, 6.586154937744141, -1.0990097522735596, -4.1529221534729, -8.615764617919922, -1.2201576232910156, 1.8235397338867188, -4.736806869506836, 0.31089019775390625, -2.1617565155029297, -1.4262728691101074, -2.876901626586914, -0.27417564392089844, 2.921511173248291], "custom_metrics": {}}}, "num_steps_sampled": 23184, "num_agent_steps_sampled": 69552, "num_steps_trained": 44384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 133152, "last_target_update_ts": 23024, "num_target_updates": 44}, "done": false, "episodes_total": 2316, "training_iteration": 23, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-37-49", "timestamp": 1648913869, "time_this_iter_s": 40.523526430130005, "time_total_s": 896.2729306221008, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549802bcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f549802bcb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 896.2729306221008, "timesteps_since_restore": 736, "iterations_since_restore": 23, "perf": {"cpu_util_percent": 51.56315789473684, "ram_util_percent": 65.45087719298246}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 57.6, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 19.2, "policy1": 19.2, "policy2": 19.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 30.0, 90.0, 60.0, 30.0, 120.0, 90.0, 60.0, 60.0, 30.0, 30.0, 30.0, 120.0, 90.0, 30.0, 60.0, 30.0, 30.0, 30.0, 60.0, 90.0, 30.0, 60.0, 30.0, 60.0, -30.0, 60.0, 30.0, 60.0, 60.0, 30.0, 60.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 90.0, 60.0, 30.0, 60.0, 120.0, 30.0, 30.0, 0.0, 0.0, 60.0, 60.0, 120.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 30.0, 60.0, -30.0, 120.0, 30.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 90.0, 120.0, 60.0, 60.0, 30.0, 90.0, 90.0, 60.0, 30.0, 90.0, 60.0, 120.0, 0.0, 30.0, 0.0, 60.0, 60.0, 60.0, -30.0, 60.0, 90.0, 30.0, 60.0, 90.0, 120.0, 120.0, 60.0, 30.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, -10.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, -10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0], "policy_policy1_reward": [30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, -10.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, -10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0], "policy_policy2_reward": [30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 20.0, 10.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 20.0, 10.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 0.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, -10.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 0.0, 10.0, 0.0, 20.0, 20.0, 20.0, -10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0451862173132473, "mean_inference_ms": 25.884620038551393, "mean_action_processing_ms": 0.2469547150804693, "mean_env_wait_ms": 0.13854864668818542, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 24192, "timesteps_this_iter": 32, "agent_timesteps_total": 72576, "timers": {"load_time_ms": 0.69, "load_throughput": 46405.189, "learn_time_ms": 249.147, "learn_throughput": 128.438, "update_time_ms": 96.175}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.13357162475586, "min_q": -1.9344017505645752, "max_q": 21.15193748474121, "mean_td_error": -1.126734972000122, "model": {}}, "td_error": [1.946934700012207, 2.273080825805664, -5.747868537902832, -1.567403793334961, 0.28787851333618164, -10.218177795410156, 1.1852455139160156, -3.812654495239258, -5.460686683654785, 0.010126113891601562, -1.1841297149658203, 1.8490530252456665, 1.1534194946289062, 0.556339681148529, 1.0086584091186523, -0.7420039176940918, -4.702657699584961, -2.752145767211914, 0.20136618614196777, 0.9334356784820557, -1.7522153854370117, -0.5241813659667969, -0.04334831237792969, -1.004140853881836, 0.47973668575286865, -2.7175707817077637, -0.611968994140625, -0.3774890899658203, -1.6114883422851562, 0.9796981811523438, -4.643246650695801, 0.5528848171234131], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.623406410217285, "min_q": -0.8833227753639221, "max_q": 23.534151077270508, "mean_td_error": -0.5155609250068665, "model": {}}, "td_error": [8.856390953063965, 1.1953544616699219, -6.134557723999023, 0.3319425582885742, -6.079790115356445, -0.27460479736328125, -1.489328384399414, -0.9001064300537109, 1.781564712524414, 1.436594009399414, -8.871635437011719, -1.4047889709472656, 1.6967415809631348, 0.9884252548217773, -0.010437965393066406, 1.5190038681030273, -2.7417807579040527, -1.3589668273925781, -7.591732978820801, -2.572469711303711, -1.9962084293365479, 0.031206130981445312, 13.633512496948242, -1.5638160705566406, 2.284299850463867, 2.4620184898376465, -8.025429725646973, 1.9706459045410156, 2.3605918884277344, -5.520620346069336, 1.8298120498657227, -2.3397789001464844], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.446111679077148, "min_q": -2.2975828647613525, "max_q": 24.881582260131836, "mean_td_error": 0.5317806601524353, "model": {}}, "td_error": [1.426736831665039, -1.7090263366699219, 1.2683563232421875, -0.1339092254638672, 22.05759620666504, -1.3627605438232422, 0.7852258682250977, -1.4975175857543945, 2.783906936645508, -0.8647192716598511, 14.996160507202148, -9.290913581848145, -5.266326427459717, -5.731245040893555, -1.9618616104125977, -2.5568180084228516, -0.26474952697753906, 4.835135459899902, -0.2046494483947754, 2.182281494140625, -0.13495826721191406, 1.1117210388183594, -2.8202619552612305, 0.21365010738372803, -0.0823206901550293, -0.7263460159301758, -1.796147108078003, -0.19750022888183594, 0.28273898363113403, 0.05408668518066406, 0.7211160659790039, 0.9003000259399414], "custom_metrics": {}}}, "num_steps_sampled": 24192, "num_agent_steps_sampled": 72576, "num_steps_trained": 46400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 139200, "last_target_update_ts": 24048, "num_target_updates": 46}, "done": false, "episodes_total": 2416, "training_iteration": 24, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-38-28", "timestamp": 1648913908, "time_this_iter_s": 39.334349632263184, "time_total_s": 935.607280254364, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 935.607280254364, "timesteps_since_restore": 768, "iterations_since_restore": 24, "perf": {"cpu_util_percent": 52.294642857142854, "ram_util_percent": 64.94464285714285}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 54.51923076923077, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 18.173076923076923, "policy1": 18.173076923076923, "policy2": 18.173076923076923}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, -30.0, 90.0, 90.0, 0.0, 90.0, 90.0, 0.0, 0.0, 90.0, 90.0, 60.0, 90.0, 60.0, 120.0, 30.0, 90.0, 90.0, 60.0, 30.0, 30.0, 30.0, 30.0, 0.0, 60.0, 120.0, 60.0, 60.0, 60.0, 60.0, 90.0, 30.0, 30.0, 30.0, 90.0, 60.0, 0.0, 30.0, 30.0, 30.0, 30.0, 120.0, 0.0, 30.0, 90.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 90.0, 60.0, 0.0, 90.0, 60.0, 30.0, 60.0, -30.0, 60.0, 90.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 60.0, 60.0, 90.0, 30.0, 60.0, 30.0, 90.0, 60.0, 30.0, 60.0, 30.0, 60.0, 30.0, 90.0, 60.0, 30.0, 120.0, -30.0, 30.0, 60.0, 90.0, 90.0, 90.0, 60.0, -30.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 60.0, 120.0, 0.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, -10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 0.0, 0.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 40.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 10.0, 10.0, 10.0, 10.0, 40.0, 0.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 10.0, 20.0, -10.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 40.0, -10.0, 10.0, 20.0, 30.0, 30.0, 30.0, 20.0, -10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0], "policy_policy1_reward": [10.0, -10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 0.0, 0.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 40.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 10.0, 10.0, 10.0, 10.0, 40.0, 0.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 10.0, 20.0, -10.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 40.0, -10.0, 10.0, 20.0, 30.0, 30.0, 30.0, 20.0, -10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0], "policy_policy2_reward": [10.0, -10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 0.0, 0.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 10.0, 0.0, 20.0, 40.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 20.0, 0.0, 10.0, 10.0, 10.0, 10.0, 40.0, 0.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 10.0, 20.0, -10.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 40.0, -10.0, 10.0, 20.0, 30.0, 30.0, 30.0, 20.0, -10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 0.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.045885038383422, "mean_inference_ms": 25.919186522177036, "mean_action_processing_ms": 0.24707710680517392, "mean_env_wait_ms": 0.13868378525857908, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 25200, "timesteps_this_iter": 32, "agent_timesteps_total": 75600, "timers": {"load_time_ms": 0.646, "load_throughput": 49499.439, "learn_time_ms": 241.224, "learn_throughput": 132.657, "update_time_ms": 96.359}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.249052047729492, "min_q": -1.7663187980651855, "max_q": 19.828941345214844, "mean_td_error": 1.7003827095031738, "model": {}}, "td_error": [-1.147714614868164, 1.186931848526001, 1.369903802871704, 2.6744070053100586, 1.9733896255493164, -0.7562046051025391, -1.045928955078125, -1.4088850021362305, -0.029773712158203125, 0.5820461511611938, -1.1592689752578735, 4.852139472961426, 1.9421433210372925, -1.8008055686950684, 11.564274787902832, -2.732578754425049, -2.5192527770996094, 1.2443495988845825, 3.3974547386169434, 4.8331756591796875, 1.7085254192352295, -4.236989974975586, 14.466558456420898, 1.4424629211425781, 2.581684112548828, 0.9662284851074219, 3.0132007598876953, 3.9417552947998047, 3.941770553588867, 3.708242416381836, 0.39500999450683594, -0.5360069274902344], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.441225051879883, "min_q": -3.0126144886016846, "max_q": 23.127906799316406, "mean_td_error": -0.7402334809303284, "model": {}}, "td_error": [2.976186752319336, 1.9754257202148438, -3.2780990600585938, -4.738137245178223, -1.4481697082519531, -0.35919189453125, -0.7245235443115234, -10.197922706604004, -0.5232142210006714, -0.016919612884521484, 0.0023565292358398438, -0.9256478548049927, -0.19808697700500488, 2.676935911178589, 1.825859546661377, 2.1940345764160156, 2.0785138607025146, -0.7403926849365234, 9.761367797851562, 2.1523361206054688, -4.060917854309082, -1.9716529846191406, 0.9482240676879883, 0.43898773193359375, -3.7016940116882324, -9.700636863708496, 2.114887237548828, 2.8036975860595703, -0.17661714553833008, -2.815929412841797, -8.113632202148438, -1.944899559020996], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.891397476196289, "min_q": -2.812427043914795, "max_q": 24.578807830810547, "mean_td_error": -1.033547282218933, "model": {}}, "td_error": [-6.605925559997559, -2.8874902725219727, 1.246145248413086, -1.0933418273925781, 0.33302879333496094, 2.0614404678344727, -0.7236995697021484, 0.0431060791015625, -2.1432228088378906, -2.445474624633789, -1.2201385498046875, 0.85406494140625, -1.048593521118164, -1.096242904663086, 0.8092772960662842, -0.33710384368896484, -0.9075069427490234, -7.305811882019043, 0.49654388427734375, -1.4749116897583008, 1.0291461944580078, -1.5215364694595337, -5.1760149002075195, -0.5776786804199219, -2.8594484329223633, 1.7718701362609863, -0.5823554992675781, 1.0974969863891602, -0.8036022186279297, -2.0392684936523438, -0.31844234466552734, 0.35217857360839844], "custom_metrics": {}}}, "num_steps_sampled": 25200, "num_agent_steps_sampled": 75600, "num_steps_trained": 48416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 145248, "last_target_update_ts": 25072, "num_target_updates": 48}, "done": false, "episodes_total": 2520, "training_iteration": 25, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-39-09", "timestamp": 1648913949, "time_this_iter_s": 40.48078918457031, "time_total_s": 976.0880694389343, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 976.0880694389343, "timesteps_since_restore": 800, "iterations_since_restore": 25, "perf": {"cpu_util_percent": 53.2844827586207, "ram_util_percent": 65.29310344827586}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 57.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 19.1, "policy1": 19.1, "policy2": 19.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 90.0, 60.0, 60.0, 90.0, 90.0, 90.0, 60.0, 0.0, 30.0, 30.0, 60.0, 90.0, 60.0, 120.0, 30.0, 30.0, 120.0, 60.0, 60.0, 30.0, 60.0, 60.0, 30.0, 90.0, 0.0, 90.0, 60.0, 30.0, 30.0, 90.0, 30.0, 60.0, 0.0, 90.0, 60.0, 90.0, 90.0, 60.0, 60.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 90.0, 0.0, 60.0, 60.0, 90.0, 60.0, 90.0, 30.0, 60.0, 90.0, 60.0, 120.0, 30.0, 30.0, 30.0, 90.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, -30.0, 60.0, 30.0, 30.0, 60.0, 30.0, 90.0, 30.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 60.0, 60.0, 0.0, 60.0, 90.0, 60.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 40.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 30.0, 0.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, -10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 30.0, 20.0, 20.0, 30.0], "policy_policy1_reward": [0.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 40.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 30.0, 0.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, -10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 30.0, 20.0, 20.0, 30.0], "policy_policy2_reward": [0.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 0.0, 10.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 40.0, 20.0, 20.0, 10.0, 20.0, 20.0, 10.0, 30.0, 0.0, 30.0, 20.0, 10.0, 10.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 10.0, 10.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, -10.0, 20.0, 10.0, 10.0, 20.0, 10.0, 30.0, 10.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 30.0, 20.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0457959645179764, "mean_inference_ms": 25.92290310064345, "mean_action_processing_ms": 0.24699534457384423, "mean_env_wait_ms": 0.13872500359511786, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 26208, "timesteps_this_iter": 32, "agent_timesteps_total": 78624, "timers": {"load_time_ms": 0.615, "load_throughput": 51994.161, "learn_time_ms": 244.205, "learn_throughput": 131.037, "update_time_ms": 104.506}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 6.233911514282227, "min_q": -2.2891669273376465, "max_q": 21.07740020751953, "mean_td_error": -0.47804147005081177, "model": {}}, "td_error": [0.18403208255767822, 1.0194950103759766, 0.8257379531860352, -1.0991809368133545, -7.983644485473633, 0.3540540933609009, -1.570220947265625, -4.217384338378906, -0.41745424270629883, 8.097638130187988, -0.7197055816650391, -0.034784555435180664, 2.5980868339538574, 0.36331629753112793, -1.8310856819152832, 1.457352638244629, 2.4977240562438965, -0.15391600131988525, -2.0208396911621094, -0.1977081298828125, -0.6855125427246094, 0.666062593460083, 1.457352638244629, -3.3414697647094727, 2.5433883666992188, -6.41187858581543, -9.532369613647461, 0.24565792083740234, 0.22515392303466797, -1.7054119110107422, 1.019789695739746, 3.0703988075256348], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.975011825561523, "min_q": -1.4383265972137451, "max_q": 21.139225006103516, "mean_td_error": -0.6554268598556519, "model": {}}, "td_error": [-0.185791015625, 0.8247795104980469, 0.6567316055297852, -9.24095630645752, 0.322479248046875, -1.7472991943359375, 2.5143566131591797, -0.9906845092773438, -4.087143898010254, -4.972073554992676, -1.604645848274231, -0.4609527587890625, -2.0200119018554688, 0.6996669769287109, -1.1814517974853516, -3.3970890045166016, 2.5298357009887695, 0.7154642343521118, 0.7146997451782227, -3.002901077270508, 0.4136848449707031, 1.2210845947265625, 10.705209732055664, -3.204486846923828, -1.7421560287475586, 0.28342628479003906, -3.3970890045166016, 0.8516521453857422, 1.863327980041504, -6.770272254943848, 1.4124164581298828, 1.302531123161316], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 7.3465070724487305, "min_q": -2.248961925506592, "max_q": 21.56682014465332, "mean_td_error": -1.9348713159561157, "model": {}}, "td_error": [1.6973819732666016, -0.8396701812744141, -0.610011100769043, -10.068778038024902, -3.6812210083007812, 1.0976390838623047, 0.7704753875732422, 1.175696849822998, 3.083963394165039, -0.059940338134765625, -10.068778038024902, 0.04203033447265625, -1.4402275085449219, -10.895456314086914, 0.9606857299804688, 3.6619110107421875, -0.9317402243614197, -0.7969331741333008, -7.103656768798828, -0.8861352205276489, 2.051910400390625, -1.8326025009155273, 0.9365265369415283, 12.901273727416992, -7.536659240722656, -9.464614868164062, -7.9798903465271, 0.15620732307434082, 0.5512065887451172, -0.4264686107635498, -17.538562774658203, 1.158559799194336], "custom_metrics": {}}}, "num_steps_sampled": 26208, "num_agent_steps_sampled": 78624, "num_steps_trained": 50432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 151296, "last_target_update_ts": 26096, "num_target_updates": 50}, "done": false, "episodes_total": 2620, "training_iteration": 26, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-39-50", "timestamp": 1648913990, "time_this_iter_s": 40.74301767349243, "time_total_s": 1016.8310871124268, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c8b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c8b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1016.8310871124268, "timesteps_since_restore": 832, "iterations_since_restore": 26, "perf": {"cpu_util_percent": 51.5896551724138, "ram_util_percent": 65.69827586206897}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 63.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 21.3, "policy1": 21.3, "policy2": 21.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 90.0, 60.0, 30.0, 90.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 60.0, 90.0, 30.0, 60.0, 60.0, 90.0, 90.0, 30.0, 30.0, 30.0, 120.0, 90.0, 90.0, 60.0, 120.0, 60.0, 30.0, 90.0, 60.0, 30.0, 60.0, 90.0, 30.0, 60.0, 60.0, 60.0, 60.0, 90.0, 30.0, 90.0, 60.0, 90.0, 120.0, 30.0, 60.0, 30.0, 60.0, 30.0, 30.0, 30.0, 0.0, 30.0, 90.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0, 30.0, 30.0, 90.0, 90.0, 60.0, 30.0, 60.0, 120.0, 60.0, 90.0, 60.0, 30.0, 0.0, 120.0, 90.0, 60.0, 30.0, 0.0, 90.0, 60.0, 30.0, 60.0, 30.0, 120.0, 90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 120.0, 90.0, 90.0, 60.0, 90.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 10.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 0.0, 40.0, 30.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0], "policy_policy1_reward": [40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 10.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 0.0, 40.0, 30.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0], "policy_policy2_reward": [40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 30.0, 10.0, 10.0, 10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 10.0, 20.0, 10.0, 10.0, 10.0, 0.0, 10.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 0.0, 40.0, 30.0, 20.0, 10.0, 0.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.045484686493435, "mean_inference_ms": 25.946315424482574, "mean_action_processing_ms": 0.2470608321644645, "mean_env_wait_ms": 0.138680940161375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 27216, "timesteps_this_iter": 32, "agent_timesteps_total": 81648, "timers": {"load_time_ms": 0.763, "load_throughput": 41922.079, "learn_time_ms": 241.015, "learn_throughput": 132.772, "update_time_ms": 111.063}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.434375762939453, "min_q": -1.3387017250061035, "max_q": 21.451065063476562, "mean_td_error": -0.7284888029098511, "model": {}}, "td_error": [-0.037555694580078125, -5.695944786071777, 0.5625896453857422, -0.20765036344528198, -0.3727836608886719, 0.2703132629394531, -0.028619766235351562, -0.047687530517578125, -1.9556732177734375, -0.43582725524902344, -1.4042778015136719, 4.729085922241211, 2.0643062591552734, 0.3633542060852051, 0.26935338973999023, -9.354301452636719, 0.9028739929199219, -0.3827190399169922, -0.0020933151245117188, -3.9961178302764893, -0.48865658044815063, -8.398603439331055, -0.3784475326538086, 0.5047264099121094, -0.3258570432662964, 3.6981000900268555, -1.8367729187011719, -6.339259147644043, 0.3543548583984375, -0.6055469512939453, 1.6768391132354736, 3.5868570804595947], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 6.794961929321289, "min_q": -2.161653995513916, "max_q": 18.649974822998047, "mean_td_error": -0.378204882144928, "model": {}}, "td_error": [0.9935351610183716, 2.802429676055908, -0.25397682189941406, 0.0003604888916015625, -0.9342451095581055, 2.860706329345703, 0.7945213317871094, 0.6204420328140259, 9.135149002075195, -0.34865760803222656, 1.5135377645492554, 1.9458084106445312, -0.41915273666381836, -7.305646896362305, -5.317850112915039, -10.011080741882324, -9.435302734375, 0.9710121154785156, 1.425940990447998, -0.19962918758392334, -4.4263916015625, -3.5762081146240234, 5.453892707824707, 0.6176519393920898, -0.5787067413330078, 1.751442551612854, 0.24895381927490234, 2.029775619506836, -0.1589488983154297, -0.08102798461914062, 3.413614511489868, -5.634505271911621], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.195786476135254, "min_q": -3.10972261428833, "max_q": 24.474897384643555, "mean_td_error": -0.16054415702819824, "model": {}}, "td_error": [11.417722702026367, -4.20347785949707, 2.071059226989746, -0.269584059715271, 2.0783748626708984, -0.2781982421875, -2.4010682106018066, -4.951163291931152, -2.4684906005859375, -2.505167007446289, 10.867119789123535, 2.93817138671875, 0.16501522064208984, -0.22455596923828125, 2.2380337715148926, -9.781071662902832, 0.25264137983322144, 1.9781522750854492, 0.9331092834472656, -1.8848304748535156, -3.6175289154052734, -3.2407312393188477, 1.6904783248901367, -2.154024124145508, 0.20173275470733643, -3.103364944458008, 0.2833433151245117, -0.5114898681640625, -2.5607872009277344, -0.08972454071044922, 2.1024160385131836, -0.10952627658843994], "custom_metrics": {}}}, "num_steps_sampled": 27216, "num_agent_steps_sampled": 81648, "num_steps_trained": 52448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 157344, "last_target_update_ts": 27120, "num_target_updates": 52}, "done": false, "episodes_total": 2720, "training_iteration": 27, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-40-30", "timestamp": 1648914030, "time_this_iter_s": 40.494044065475464, "time_total_s": 1057.3251311779022, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ef7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1057.3251311779022, "timesteps_since_restore": 864, "iterations_since_restore": 27, "perf": {"cpu_util_percent": 51.901754385964914, "ram_util_percent": 65.81052631578947}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 53.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 17.8, "policy1": 17.8, "policy2": 17.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 30.0, 60.0, 60.0, 60.0, 0.0, 60.0, 0.0, 30.0, 30.0, 60.0, 0.0, 60.0, 90.0, 30.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 90.0, 30.0, 60.0, 90.0, 60.0, 60.0, 90.0, 30.0, 0.0, 90.0, 0.0, 60.0, 0.0, 30.0, 0.0, 30.0, 30.0, 30.0, 0.0, 90.0, 0.0, 120.0, 60.0, 0.0, 90.0, 60.0, 90.0, 60.0, 60.0, 30.0, 60.0, 120.0, 90.0, 30.0, 60.0, 60.0, 30.0, 60.0, 60.0, 120.0, 30.0, 90.0, 60.0, 90.0, 90.0, 30.0, 90.0, 30.0, 60.0, 30.0, 90.0, 60.0, 30.0, 90.0, 90.0, 30.0, 30.0, 60.0, 90.0, 90.0, 60.0, 90.0, 30.0, 60.0, 60.0, 0.0, 60.0, 30.0, 90.0, 90.0, 90.0, 30.0, 60.0, 30.0, 60.0, -30.0, 30.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 0.0, 40.0, 20.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 40.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0], "policy_policy1_reward": [30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 0.0, 40.0, 20.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 40.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0], "policy_policy2_reward": [30.0, 10.0, 20.0, 20.0, 20.0, 0.0, 20.0, 0.0, 10.0, 10.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 0.0, 30.0, 0.0, 20.0, 0.0, 10.0, 0.0, 10.0, 10.0, 10.0, 0.0, 30.0, 0.0, 40.0, 20.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 20.0, 10.0, 20.0, 20.0, 40.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, -10.0, 10.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0455890791061762, "mean_inference_ms": 25.957188804578344, "mean_action_processing_ms": 0.2471060933278914, "mean_env_wait_ms": 0.13875383585459183, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 28224, "timesteps_this_iter": 32, "agent_timesteps_total": 84672, "timers": {"load_time_ms": 0.679, "load_throughput": 47100.55, "learn_time_ms": 241.869, "learn_throughput": 132.303, "update_time_ms": 96.657}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.964648246765137, "min_q": -1.5080883502960205, "max_q": 23.407766342163086, "mean_td_error": -1.9945178031921387, "model": {}}, "td_error": [14.890304565429688, -8.095610618591309, -3.221896171569824, -1.5331439971923828, 1.9083714485168457, 3.24859619140625, 0.6555280685424805, 1.80916428565979, -2.111185073852539, -16.822235107421875, 1.6098575592041016, -0.05897045135498047, -2.1211109161376953, -2.606017589569092, -2.0145440101623535, 0.504913330078125, -13.729513168334961, -9.24240779876709, 0.6852942705154419, -0.5080883502960205, -7.575985431671143, -4.898825645446777, -1.0501322746276855, -0.6101436614990234, 0.1861705780029297, 1.9864387512207031, -4.724832534790039, 0.3060538172721863, 1.0039787292480469, 1.760627269744873, -2.525989055633545, -10.92923641204834], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.29156494140625, "min_q": -1.521465539932251, "max_q": 19.856178283691406, "mean_td_error": -2.1309261322021484, "model": {}}, "td_error": [-0.3205137252807617, -2.966510772705078, 1.40899658203125, 2.9986143112182617, 3.886592149734497, -9.77208137512207, -3.3569111824035645, -1.2228965759277344, -9.071020126342773, -2.1637611389160156, -1.4948415756225586, -7.384581089019775, 1.4734039306640625, -4.855152130126953, 1.4760780334472656, -0.39604663848876953, -2.507495880126953, 1.0195293426513672, -2.112095832824707, -2.230241298675537, -2.945720672607422, 3.0306243896484375, -8.854649543762207, -1.7203764915466309, -0.5090456008911133, -4.907199382781982, -2.4490184783935547, 2.4532392024993896, -0.6710834503173828, -0.4461653232574463, 2.831590175628662, -16.410892486572266], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.558544158935547, "min_q": -2.89622163772583, "max_q": 22.562776565551758, "mean_td_error": -1.1955556869506836, "model": {}}, "td_error": [-0.197454571723938, -0.5382776260375977, -1.2270326614379883, 0.8666801452636719, 0.8089970946311951, -1.9172289371490479, -0.02756786346435547, 0.044769287109375, 2.2413883209228516, -7.4597272872924805, 1.4710960388183594, 1.1361205577850342, -1.9035600423812866, -1.3585782051086426, -6.84089469909668, -5.601202011108398, -9.186767578125, 0.8203709125518799, -0.15776324272155762, 1.355489730834961, -1.89622163772583, -0.25199127197265625, 1.7992935180664062, -0.5513943433761597, 1.2571754455566406, 1.72119140625, -2.1256024837493896, -1.3172845840454102, -2.1209664344787598, -3.6612019538879395, -0.7577924728393555, -2.681844711303711], "custom_metrics": {}}}, "num_steps_sampled": 28224, "num_agent_steps_sampled": 84672, "num_steps_trained": 54464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 163392, "last_target_update_ts": 28144, "num_target_updates": 54}, "done": false, "episodes_total": 2820, "training_iteration": 28, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-41-12", "timestamp": 1648914072, "time_this_iter_s": 40.92985153198242, "time_total_s": 1098.2549827098846, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1098.2549827098846, "timesteps_since_restore": 896, "iterations_since_restore": 28, "perf": {"cpu_util_percent": 52.62586206896552, "ram_util_percent": 65.98275862068965}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 56.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 18.9, "policy1": 18.9, "policy2": 18.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 60.0, 0.0, 30.0, 90.0, 60.0, 30.0, 30.0, 60.0, 90.0, 0.0, 60.0, 60.0, 60.0, 90.0, 60.0, 30.0, 0.0, 30.0, 60.0, 30.0, 90.0, 90.0, 30.0, 120.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 0.0, 60.0, 60.0, 60.0, 60.0, 90.0, 0.0, 30.0, 120.0, 120.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 30.0, 30.0, 60.0, 90.0, 30.0, 30.0, 60.0, 90.0, 60.0, 90.0, 30.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 30.0, 60.0, 90.0, 90.0, 0.0, 30.0, 60.0, 60.0, 90.0, 60.0, 60.0, 30.0, 90.0, 90.0, 30.0, 90.0, 90.0, 60.0, 30.0, 30.0, 0.0, 90.0, 60.0, 0.0, 60.0, 60.0, 30.0, 60.0, 60.0, 60.0, 90.0, 60.0, 30.0, 90.0, 0.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 20.0, 0.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 0.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 10.0, 40.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 30.0, 0.0, 10.0, 40.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 30.0, 0.0, 40.0], "policy_policy1_reward": [10.0, 20.0, 0.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 0.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 10.0, 40.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 30.0, 0.0, 10.0, 40.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 30.0, 0.0, 40.0], "policy_policy2_reward": [10.0, 20.0, 0.0, 10.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 0.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 0.0, 10.0, 20.0, 10.0, 30.0, 30.0, 10.0, 40.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 0.0, 20.0, 20.0, 20.0, 20.0, 30.0, 0.0, 10.0, 40.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 30.0, 30.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 20.0, 10.0, 30.0, 0.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0443343022140732, "mean_inference_ms": 25.954515047708792, "mean_action_processing_ms": 0.2468981288137995, "mean_env_wait_ms": 0.1386732601046252, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 29232, "timesteps_this_iter": 32, "agent_timesteps_total": 87696, "timers": {"load_time_ms": 0.609, "load_throughput": 52564.317, "learn_time_ms": 237.353, "learn_throughput": 134.82, "update_time_ms": 110.11}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.594270706176758, "min_q": -1.6517047882080078, "max_q": 22.768142700195312, "mean_td_error": 0.06067383289337158, "model": {}}, "td_error": [-2.3417816162109375, 0.5926742553710938, 0.46454620361328125, -1.7390422821044922, 1.5843353271484375, -0.4261493682861328, -5.418042182922363, 1.9021520614624023, -0.008588790893554688, 5.322415351867676, 5.5067267417907715, 9.48936939239502, -2.308304786682129, 0.5521082878112793, -2.4842796325683594, 0.14133358001708984, -1.2977428436279297, 2.8623218536376953, -0.9940023422241211, -0.6455857753753662, -5.773194789886475, 4.902789115905762, -0.008450686931610107, 1.2285963296890259, 2.8572444915771484, 1.7365179061889648, 4.270490646362305, 1.230600357055664, -7.321467876434326, -9.090707778930664, -0.6517047882080078, -2.193613052368164], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.946919441223145, "min_q": -1.9293110370635986, "max_q": 21.07292366027832, "mean_td_error": 0.1898307204246521, "model": {}}, "td_error": [-0.7838153839111328, -6.993192672729492, -0.17090415954589844, 6.238016605377197, 0.6675987243652344, 0.7656230926513672, 0.12366276979446411, -0.009656429290771484, 0.5353164672851562, -0.8118666410446167, -1.3505992889404297, 3.394725799560547, 0.4604281187057495, 1.771280288696289, -8.788491249084473, 0.5928936004638672, -1.254770278930664, 3.2026500701904297, -0.3432807922363281, -1.5704402923583984, 1.5418052673339844, 0.2797737121582031, -0.8453148007392883, 2.690544366836548, 12.475668907165527, -0.65423583984375, 0.9948749542236328, -3.4364967346191406, 0.7380300164222717, -1.700735092163086, -0.9293110370635986, -0.7551994323730469], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.446128845214844, "min_q": -1.632556438446045, "max_q": 23.55789566040039, "mean_td_error": 0.8044864535331726, "model": {}}, "td_error": [-0.3864150047302246, -5.5659894943237305, 0.40193700790405273, 1.4666414260864258, 0.6059021353721619, 1.0566884279251099, 1.6876239776611328, -0.9097292423248291, 2.0480031967163086, 2.4809837341308594, 1.059030532836914, -1.5075132846832275, 0.0796431303024292, -0.4869495630264282, -0.48663330078125, 0.008237361907958984, 0.33341026306152344, 0.864227294921875, -0.24088096618652344, 0.9335651397705078, 0.2831721305847168, 0.6376744508743286, 0.0831136703491211, 0.28391265869140625, -0.3723011016845703, 16.118234634399414, 0.39500850439071655, 2.33950138092041, -1.624333381652832, -1.5877227783203125, 4.437836170196533, 1.3076858520507812], "custom_metrics": {}}}, "num_steps_sampled": 29232, "num_agent_steps_sampled": 87696, "num_steps_trained": 56480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 169440, "last_target_update_ts": 29168, "num_target_updates": 56}, "done": false, "episodes_total": 2920, "training_iteration": 29, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-41-52", "timestamp": 1648914112, "time_this_iter_s": 40.69585609436035, "time_total_s": 1138.950838804245, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1138.950838804245, "timesteps_since_restore": 928, "iterations_since_restore": 29, "perf": {"cpu_util_percent": 51.82931034482758, "ram_util_percent": 65.78448275862068}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 53.07692307692308, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 17.692307692307693, "policy1": 17.692307692307693, "policy2": 17.692307692307693}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 60.0, 90.0, 90.0, 60.0, 90.0, 0.0, 60.0, 60.0, 30.0, 60.0, 30.0, 120.0, 30.0, 60.0, 0.0, 90.0, 0.0, 30.0, 60.0, 0.0, 0.0, 30.0, 30.0, 90.0, 0.0, 60.0, 30.0, 0.0, 90.0, 60.0, 0.0, 60.0, 90.0, 60.0, 0.0, 30.0, 90.0, 90.0, 120.0, 60.0, 60.0, 60.0, 0.0, 30.0, 60.0, 60.0, 30.0, 0.0, 30.0, 60.0, 60.0, 90.0, 60.0, 30.0, 30.0, 90.0, 60.0, 0.0, 90.0, 60.0, 60.0, 90.0, 30.0, 60.0, 60.0, 90.0, 30.0, 60.0, 120.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 30.0, 60.0, 60.0, 30.0, 60.0, 0.0, 90.0, 90.0, 60.0, 30.0, 30.0, 30.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 90.0, 90.0, 90.0, 30.0, 60.0, 90.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 40.0, 10.0, 20.0, 0.0, 30.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 30.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 30.0, 20.0, 0.0, 10.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0], "policy_policy1_reward": [40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 40.0, 10.0, 20.0, 0.0, 30.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 30.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 30.0, 20.0, 0.0, 10.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0], "policy_policy2_reward": [40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 20.0, 10.0, 40.0, 10.0, 20.0, 0.0, 30.0, 0.0, 10.0, 20.0, 0.0, 0.0, 10.0, 10.0, 30.0, 0.0, 20.0, 10.0, 0.0, 30.0, 20.0, 0.0, 20.0, 30.0, 20.0, 0.0, 10.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 20.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 0.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 20.0, 20.0, 10.0, 20.0, 0.0, 30.0, 30.0, 20.0, 10.0, 10.0, 10.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0442367670255717, "mean_inference_ms": 25.9701818673167, "mean_action_processing_ms": 0.24696702506866675, "mean_env_wait_ms": 0.13866425821853998, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 30240, "timesteps_this_iter": 32, "agent_timesteps_total": 90720, "timers": {"load_time_ms": 0.672, "load_throughput": 47603.379, "learn_time_ms": 247.697, "learn_throughput": 129.19, "update_time_ms": 103.244}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.341719627380371, "min_q": -1.6436357498168945, "max_q": 22.257247924804688, "mean_td_error": -1.0959770679473877, "model": {}}, "td_error": [-8.148140907287598, 0.07071781158447266, 3.871835708618164, 0.6889972686767578, 0.00404810905456543, -1.7454605102539062, 2.2750072479248047, -0.0055217742919921875, 0.7858853340148926, -10.085481643676758, -3.0569515228271484, 2.3485143184661865, 1.6837224960327148, -3.2959604263305664, -4.434215545654297, -1.1349430084228516, 3.3932418823242188, -0.9827938079833984, 3.277772903442383, -2.1089162826538086, -7.758440017700195, -4.029129505157471, 2.1662235260009766, -1.3753900527954102, 0.9878218173980713, -0.8901081085205078, 1.6777400970458984, 0.12046432495117188, -8.377748489379883, -0.9201908111572266, -2.026327133178711, 1.9524621963500977], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.749028205871582, "min_q": -0.6636493802070618, "max_q": 21.87202262878418, "mean_td_error": -0.01940162479877472, "model": {}}, "td_error": [1.9031307697296143, 2.686112403869629, 13.4447021484375, -6.7641801834106445, -7.675204277038574, 1.683030605316162, -0.4769916534423828, 1.5753631591796875, -1.6888923645019531, 1.3064308166503906, 0.3060874938964844, 1.6029441356658936, 1.9481157064437866, 0.3188915252685547, -0.8835697174072266, -0.6042046546936035, 0.1485433578491211, -3.5069570541381836, -8.033933639526367, -1.6186628341674805, 12.565869331359863, -1.3002429008483887, 2.42319917678833, 0.6408157348632812, 2.47963809967041, -1.5437488555908203, -3.238554000854492, -0.8064494132995605, -1.032308578491211, 1.6642446517944336, -8.570338249206543, 0.4262669086456299], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.80660629272461, "min_q": -1.1351380348205566, "max_q": 27.514957427978516, "mean_td_error": -0.32368797063827515, "model": {}}, "td_error": [-9.223172187805176, -0.13513803482055664, 0.3624610900878906, 1.8243904113769531, 1.3830256462097168, -0.4990959167480469, -0.3847990036010742, -3.1967639923095703, 1.0197374820709229, 0.5415325164794922, 9.816815376281738, -1.3516597747802734, -0.48590087890625, 1.5126209259033203, 0.118896484375, 1.2575798034667969, -3.3718605041503906, 0.5686454772949219, 0.6217632293701172, -1.5390758514404297, 1.3858368396759033, -3.845561981201172, -1.3771748542785645, -0.2564678192138672, -0.7290325164794922, -3.999858856201172, 0.845070481300354, 0.3261505961418152, 0.24556636810302734, -0.6717052459716797, -1.439143180847168, 0.3183021545410156], "custom_metrics": {}}}, "num_steps_sampled": 30240, "num_agent_steps_sampled": 90720, "num_steps_trained": 58496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 175488, "last_target_update_ts": 30192, "num_target_updates": 58}, "done": false, "episodes_total": 3024, "training_iteration": 30, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-42-33", "timestamp": 1648914153, "time_this_iter_s": 40.89251661300659, "time_total_s": 1179.8433554172516, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7d4440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7d4440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1179.8433554172516, "timesteps_since_restore": 960, "iterations_since_restore": 30, "perf": {"cpu_util_percent": 51.83965517241379, "ram_util_percent": 65.89827586206896}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 60.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 20.1, "policy1": 20.1, "policy2": 20.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 90.0, 60.0, 60.0, 30.0, 60.0, 30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 60.0, 60.0, 120.0, 60.0, 60.0, 60.0, 90.0, 30.0, 90.0, 30.0, 30.0, 90.0, 60.0, 90.0, 60.0, 30.0, 30.0, 60.0, 90.0, 30.0, 90.0, 30.0, 30.0, 0.0, 90.0, 30.0, 90.0, 60.0, 90.0, 60.0, 60.0, 60.0, 60.0, 90.0, 30.0, 60.0, 30.0, 90.0, 30.0, 90.0, 30.0, 90.0, 90.0, 60.0, 30.0, 60.0, 120.0, 30.0, 90.0, 60.0, 60.0, 30.0, 30.0, 30.0, 30.0, 60.0, 90.0, 60.0, 30.0, 90.0, 90.0, 0.0, 90.0, 90.0, 60.0, 60.0, 90.0, 30.0, 90.0, 120.0, 60.0, 0.0, 90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 60.0, 90.0, 30.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0], "policy_policy1_reward": [20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0], "policy_policy2_reward": [20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 20.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 30.0, 10.0, 30.0, 10.0, 10.0, 0.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 10.0, 30.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 40.0, 10.0, 30.0, 20.0, 20.0, 10.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 0.0, 30.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 0.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044701678521286, "mean_inference_ms": 25.975532321485634, "mean_action_processing_ms": 0.24712374859425013, "mean_env_wait_ms": 0.13870531048219947, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 31248, "timesteps_this_iter": 32, "agent_timesteps_total": 93744, "timers": {"load_time_ms": 0.618, "load_throughput": 51789.523, "learn_time_ms": 239.457, "learn_throughput": 133.636, "update_time_ms": 105.971}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.913095474243164, "min_q": -1.2514461278915405, "max_q": 23.19940757751465, "mean_td_error": 0.3768507242202759, "model": {}}, "td_error": [-3.538816452026367, -1.0739946365356445, 1.4227371215820312, -3.485748291015625, -0.6285305023193359, -1.2969894409179688, 0.8927097320556641, 0.5412807464599609, -2.55197811126709, -0.398834228515625, 0.9067091941833496, 11.175432205200195, -0.030427932739257812, -0.9949977397918701, 1.6347362995147705, 0.45040130615234375, -5.752151966094971, 2.929258108139038, 0.3763751983642578, 2.1156649589538574, 2.351853847503662, 0.8266301155090332, 0.35532641410827637, -1.7821941375732422, -2.546670913696289, -0.29472148418426514, 1.2012910842895508, 2.693815231323242, 5.057712554931641, -0.7356643676757812, -0.34601640701293945, 2.585024833679199], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.428661346435547, "min_q": -3.074613571166992, "max_q": 21.232009887695312, "mean_td_error": -1.035336971282959, "model": {}}, "td_error": [-6.216204643249512, 0.4241703152656555, -4.4063520431518555, -0.7460803985595703, 1.1386890411376953, -0.22860431671142578, -1.7417917251586914, -0.2816884517669678, 0.2561088800430298, 3.0614280700683594, -3.276731491088867, 0.3108093738555908, 1.2913179397583008, 0.32759666442871094, -5.648847579956055, 2.486478805541992, -1.6481914520263672, 0.9701271057128906, -0.7411966323852539, -1.2278079986572266, -0.592366099357605, -3.7775115966796875, -0.2801704406738281, 0.7999444007873535, 0.6101431846618652, 0.5129203796386719, -7.951663494110107, -2.653529167175293, -2.074613571166992, 0.7312332391738892, 0.0198822021484375, -2.5782814025878906], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.49404525756836, "min_q": 1.0281022787094116, "max_q": 27.627992630004883, "mean_td_error": -0.5978060960769653, "model": {}}, "td_error": [-5.963099479675293, -0.3244493007659912, -4.216716766357422, 0.8556746244430542, -0.17769622802734375, -0.9111957550048828, 5.6147236824035645, -1.308262825012207, -1.2670860290527344, -0.5227298736572266, 2.26324462890625, 1.02093505859375, -3.5899181365966797, 0.16815948486328125, 0.11697673797607422, 0.2863578796386719, -1.8431644439697266, -2.363872528076172, -1.5607285499572754, 0.8537864685058594, 0.17512893676757812, 1.9772014617919922, -2.589907646179199, -3.046802520751953, 1.4995059967041016, -0.17351865768432617, -1.0016155242919922, 0.24733924865722656, 0.11388778686523438, -1.603139877319336, -0.5431404113769531, -1.315671443939209], "custom_metrics": {}}}, "num_steps_sampled": 31248, "num_agent_steps_sampled": 93744, "num_steps_trained": 60512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 181536, "last_target_update_ts": 31216, "num_target_updates": 60}, "done": false, "episodes_total": 3124, "training_iteration": 31, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-43-15", "timestamp": 1648914195, "time_this_iter_s": 41.230605363845825, "time_total_s": 1221.0739607810974, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1221.0739607810974, "timesteps_since_restore": 992, "iterations_since_restore": 31, "perf": {"cpu_util_percent": 52.64655172413793, "ram_util_percent": 66.00689655172413}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 73.2, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 24.4, "policy1": 24.4, "policy2": 24.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 30.0, 90.0, 60.0, 90.0, 60.0, 120.0, 0.0, 120.0, 60.0, 90.0, 60.0, 120.0, 60.0, 90.0, 60.0, 90.0, 30.0, 120.0, 30.0, 60.0, 60.0, 90.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 90.0, 60.0, 90.0, 60.0, 60.0, 120.0, 0.0, 120.0, 60.0, 90.0, 60.0, 90.0, 30.0, 90.0, 60.0, 90.0, 60.0, 90.0, 30.0, 30.0, 120.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0, 90.0, 120.0, 90.0, 60.0, 120.0, 60.0, 90.0, 30.0, 90.0, 120.0, 30.0, 0.0, 90.0, 120.0, 90.0, 60.0, 30.0, 120.0, 30.0, 90.0, 60.0, 30.0, 90.0, 60.0, 90.0, 60.0, 90.0, 90.0, 30.0, 60.0, 30.0, 60.0, 60.0, 60.0, 120.0, 30.0, 60.0, 120.0, 60.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 40.0, 10.0, 20.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 10.0, 0.0, 30.0, 40.0, 30.0, 20.0, 10.0, 40.0, 10.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0], "policy_policy1_reward": [30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 40.0, 10.0, 20.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 10.0, 0.0, 30.0, 40.0, 30.0, 20.0, 10.0, 40.0, 10.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0], "policy_policy2_reward": [30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 40.0, 10.0, 20.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 0.0, 40.0, 20.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 10.0, 0.0, 30.0, 40.0, 30.0, 20.0, 10.0, 40.0, 10.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044297573068315, "mean_inference_ms": 25.99205743135759, "mean_action_processing_ms": 0.24716795710252076, "mean_env_wait_ms": 0.13876287226195075, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 32256, "timesteps_this_iter": 32, "agent_timesteps_total": 96768, "timers": {"load_time_ms": 0.685, "load_throughput": 46695.797, "learn_time_ms": 238.83, "learn_throughput": 133.987, "update_time_ms": 100.213}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.912124633789062, "min_q": -1.6310893297195435, "max_q": 25.91645050048828, "mean_td_error": -0.7449861764907837, "model": {}}, "td_error": [-0.9613027572631836, 4.034041404724121, 1.4628257751464844, 3.446774482727051, 0.847529411315918, -0.31054484844207764, -1.8652801513671875, -1.645467758178711, -0.9771213531494141, -6.430922508239746, 1.9016351699829102, 2.3407535552978516, 7.110215663909912, -0.3817020058631897, 0.37491172552108765, -6.110289573669434, -1.1657404899597168, -3.7142281532287598, -6.476329803466797, -2.0030124187469482, -7.1167497634887695, 2.035501480102539, -1.7891731262207031, 1.0308189392089844, -5.778299331665039, -2.1259765625, 2.022397994995117, 1.8438153266906738, 0.08165168762207031, 0.07211017608642578, -2.961310863494873, -0.6310893297195435], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 8.880457878112793, "min_q": -2.7632975578308105, "max_q": 22.446149826049805, "mean_td_error": -0.9334967732429504, "model": {}}, "td_error": [-9.176361083984375, 0.8146724700927734, 1.4121360778808594, 1.8277232646942139, 1.24068021774292, 0.7358427047729492, -2.5369186401367188, 0.7846481800079346, 1.7978286743164062, -11.824430465698242, 0.837235689163208, -2.3661537170410156, 1.7068737745285034, -3.4895315170288086, 2.464447021484375, -0.1552276611328125, 0.43032073974609375, -1.78839111328125, 1.9744243621826172, 0.9395608901977539, -4.635026454925537, -4.976015090942383, 2.1517295837402344, 1.141822338104248, -4.142678260803223, -0.7310266494750977, -2.953944206237793, -2.8333358764648438, -0.4921029806137085, -0.948577880859375, 2.0151309967041016, 0.9027500152587891], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.222311019897461, "min_q": -1.9619603157043457, "max_q": 26.711395263671875, "mean_td_error": -0.18227314949035645, "model": {}}, "td_error": [-0.12419509887695312, -3.0430164337158203, -2.0993175506591797, -1.0131795406341553, -7.710236549377441, -1.1315199136734009, -0.43468666076660156, -1.667283058166504, 0.5469341278076172, 2.2894821166992188, 2.9831628799438477, -1.4333114624023438, 0.060131072998046875, -1.5587100982666016, -1.475515365600586, -0.9603157043457031, -0.7124080657958984, -0.12646079063415527, -1.1411447525024414, 0.4422283172607422, 0.8493118286132812, -2.0141725540161133, 1.2561874389648438, 3.733975648880005, 2.7554054260253906, 7.1241302490234375, 0.9503993988037109, 1.8648090362548828, -0.8071060180664062, 0.8644886016845703, -1.932718276977539, -2.168088912963867], "custom_metrics": {}}}, "num_steps_sampled": 32256, "num_agent_steps_sampled": 96768, "num_steps_trained": 62528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 187584, "last_target_update_ts": 32240, "num_target_updates": 62}, "done": false, "episodes_total": 3224, "training_iteration": 32, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-43-55", "timestamp": 1648914235, "time_this_iter_s": 40.71312475204468, "time_total_s": 1261.787085533142, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e35f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e35f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1261.787085533142, "timesteps_since_restore": 1024, "iterations_since_restore": 32, "perf": {"cpu_util_percent": 51.932758620689654, "ram_util_percent": 65.76896551724138}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 70.5, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 23.5, "policy1": 23.5, "policy2": 23.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 60.0, 60.0, 120.0, 60.0, 30.0, 90.0, 90.0, 90.0, 90.0, 90.0, 120.0, 120.0, 120.0, -30.0, 90.0, 60.0, 120.0, 60.0, 30.0, 0.0, 60.0, 60.0, 120.0, 60.0, 90.0, 30.0, 90.0, 120.0, 90.0, 60.0, 60.0, 60.0, 90.0, 120.0, 60.0, 60.0, 90.0, 30.0, 90.0, 30.0, 90.0, 60.0, 60.0, 30.0, 120.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 30.0, 120.0, 60.0, 90.0, 60.0, 60.0, 30.0, 120.0, 30.0, 30.0, 60.0, 30.0, 30.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 30.0, 60.0, 90.0, 60.0, 90.0, 90.0, 30.0, 60.0, 60.0, 30.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 120.0, 90.0, 90.0, 30.0, 90.0, 30.0, 60.0, 30.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 20.0, 20.0, 40.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, -10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 20.0, 30.0, 20.0, 20.0, 10.0, 40.0, 10.0, 10.0, 20.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0], "policy_policy1_reward": [20.0, 20.0, 20.0, 40.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, -10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 20.0, 30.0, 20.0, 20.0, 10.0, 40.0, 10.0, 10.0, 20.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0], "policy_policy2_reward": [20.0, 20.0, 20.0, 40.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, -10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 20.0, 30.0, 10.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 20.0, 30.0, 20.0, 20.0, 10.0, 40.0, 10.0, 10.0, 20.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 10.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0441174884964475, "mean_inference_ms": 25.99713122083602, "mean_action_processing_ms": 0.24712840367269384, "mean_env_wait_ms": 0.1388196333449119, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 33264, "timesteps_this_iter": 32, "agent_timesteps_total": 99792, "timers": {"load_time_ms": 0.695, "load_throughput": 46050.137, "learn_time_ms": 233.791, "learn_throughput": 136.874, "update_time_ms": 106.244}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.237770080566406, "min_q": -2.25764799118042, "max_q": 23.49811363220215, "mean_td_error": -0.14225700497627258, "model": {}}, "td_error": [0.3561067581176758, 3.1242027282714844, -0.09186172485351562, -2.582702159881592, -2.5640459060668945, -3.8714656829833984, -0.45979738235473633, -0.24164199829101562, -0.9283591508865356, -3.134087562561035, 1.0234413146972656, -1.6388115882873535, -0.6396365165710449, 0.07575607299804688, 0.4265098571777344, -7.756168365478516, -0.4146285057067871, -1.7563343048095703, -0.7605799436569214, 2.3328285217285156, 1.166067123413086, -1.0610618591308594, -0.36225664615631104, 9.437078475952148, 2.1483497619628906, 1.1739459037780762, 0.3805065155029297, -1.640798568725586, -0.8236856460571289, 2.769026279449463, 2.205080032348633, -0.44320034980773926], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.40591049194336, "min_q": -2.3872859477996826, "max_q": 24.12150764465332, "mean_td_error": -1.620365023612976, "model": {}}, "td_error": [1.3714962005615234, -4.478876113891602, -0.16623306274414062, -3.402862548828125, -9.816176414489746, 1.1000723838806152, -4.428127288818359, -2.2837867736816406, -1.147819995880127, 0.5222930908203125, -7.694619178771973, -5.292390823364258, -1.6077322959899902, -0.9973888397216797, -1.237396240234375, 2.700798988342285, -1.9420533180236816, 1.912198781967163, -1.043114185333252, 0.4333686828613281, 1.4457998275756836, 0.2072162628173828, 0.18156397342681885, -0.8352546691894531, -9.592126846313477, -0.9444193840026855, -0.052410125732421875, 1.5516376495361328, 1.5170300006866455, -3.157674789428711, -2.8995418548583984, -1.7751522064208984], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.913637161254883, "min_q": -1.7863223552703857, "max_q": 27.54751205444336, "mean_td_error": -1.3278274536132812, "model": {}}, "td_error": [-0.12372171878814697, -0.5797775983810425, -3.080617904663086, -0.5653777122497559, 1.2012863159179688, -0.4582080841064453, 0.23599541187286377, -0.7782840728759766, -1.3698692321777344, -3.258981704711914, -3.0728302001953125, 2.9346113204956055, -0.7863223552703857, -1.1671085357666016, -1.325516700744629, 1.9440803527832031, -3.6246337890625, -3.176891326904297, 1.9453226327896118, -0.4367799758911133, -0.592687726020813, 0.7895145416259766, -4.180656433105469, -2.6094970703125, 0.07372057437896729, -1.0505475997924805, -0.4793434143066406, -1.2136688232421875, -1.2309379577636719, -1.9797916412353516, -13.127012252807617, -1.3459434509277344], "custom_metrics": {}}}, "num_steps_sampled": 33264, "num_agent_steps_sampled": 99792, "num_steps_trained": 64544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 193632, "last_target_update_ts": 33264, "num_target_updates": 64}, "done": false, "episodes_total": 3324, "training_iteration": 33, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-44-36", "timestamp": 1648914276, "time_this_iter_s": 40.48331379890442, "time_total_s": 1302.2703993320465, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cc4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1302.2703993320465, "timesteps_since_restore": 1056, "iterations_since_restore": 33, "perf": {"cpu_util_percent": 51.65344827586207, "ram_util_percent": 65.61724137931034}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 60.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 30.0, 0.0, 90.0, 60.0, 90.0, 60.0, 60.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 60.0, 90.0, 30.0, 30.0, 30.0, 90.0, 90.0, 30.0, 30.0, 30.0, 60.0, 90.0, 120.0, 60.0, 0.0, 60.0, 60.0, 90.0, 30.0, 60.0, 60.0, 90.0, 30.0, 60.0, 0.0, 90.0, 60.0, 60.0, 0.0, 30.0, 90.0, 90.0, 30.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 30.0, 90.0, 60.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 30.0, 0.0, 120.0, 60.0, 30.0, 30.0, 30.0, 0.0, 60.0, 30.0, 60.0, 90.0, 60.0, 90.0, 60.0, 30.0, 30.0, 60.0, 120.0, 90.0, 30.0, 60.0, 30.0, 60.0, 30.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 0.0, 40.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0], "policy_policy1_reward": [20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 0.0, 40.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0], "policy_policy2_reward": [20.0, 10.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 10.0, 10.0, 10.0, 30.0, 30.0, 10.0, 10.0, 10.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 20.0, 30.0, 10.0, 20.0, 20.0, 30.0, 10.0, 20.0, 0.0, 30.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 20.0, 20.0, 10.0, 0.0, 40.0, 20.0, 10.0, 10.0, 10.0, 0.0, 20.0, 10.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 20.0, 40.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0438011858118, "mean_inference_ms": 25.99064562170184, "mean_action_processing_ms": 0.2470542967479473, "mean_env_wait_ms": 0.1387643291007291, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 34272, "timesteps_this_iter": 32, "agent_timesteps_total": 102816, "timers": {"load_time_ms": 0.622, "load_throughput": 51414.567, "learn_time_ms": 247.466, "learn_throughput": 129.311, "update_time_ms": 107.195}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.456202507019043, "min_q": -1.02023446559906, "max_q": 24.95181655883789, "mean_td_error": -0.1811942458152771, "model": {}}, "td_error": [-3.026266098022461, -0.1665668487548828, 0.04956483840942383, 1.596548080444336, 1.5466059446334839, -1.7858638763427734, -1.6291694641113281, 1.4078712463378906, -3.444356918334961, 0.2403411865234375, -0.019396483898162842, -1.7858638763427734, 1.5542855262756348, -12.371063232421875, 9.126575469970703, 0.7131776809692383, 0.9867343902587891, -0.05094146728515625, 11.286107063293457, 1.2022056579589844, -0.2050008773803711, -0.3499298095703125, 1.3534355163574219, 3.46390438079834, -2.451322555541992, -0.8129831552505493, -0.996169924736023, -8.702430725097656, 2.479879856109619, 0.2009207010269165, -0.1665668487548828, -5.04248046875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.471308708190918, "min_q": -3.2997312545776367, "max_q": 24.445112228393555, "mean_td_error": -0.15482649207115173, "model": {}}, "td_error": [-3.184915542602539, -1.273275375366211, 2.003152847290039, -0.9785037636756897, 4.971475601196289, -0.516413688659668, 1.532252550125122, -0.3974466323852539, -3.065052032470703, -1.5652976036071777, -0.28883713483810425, 15.432517051696777, -1.6387567520141602, 2.2509994506835938, -2.418240547180176, 4.510860443115234, 1.1964929103851318, 1.557332992553711, -2.2997312545776367, 0.9625904560089111, 1.731919288635254, -7.260056495666504, -4.767251014709473, 0.4534168243408203, -1.2381906509399414, -1.7646074295043945, 1.9199676513671875, 2.414155960083008, -3.8454437255859375, -8.507940292358398, -2.289257049560547, 1.4076366424560547], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.306827545166016, "min_q": -1.663582444190979, "max_q": 27.12517738342285, "mean_td_error": 0.2589453458786011, "model": {}}, "td_error": [-1.5728225708007812, 0.35196441411972046, 0.14287567138671875, 1.6528282165527344, 0.7870273590087891, -2.579740524291992, -2.6423397064208984, 0.48286235332489014, -6.619616508483887, 0.3384893536567688, 0.6051319241523743, 0.46212005615234375, -2.021299362182617, 0.8859578371047974, 0.1384735107421875, 3.0849056243896484, -0.7989540100097656, 1.7234153747558594, 0.7607326507568359, 1.2840286493301392, -0.04332733154296875, -0.37877464294433594, -1.4973201751708984, 5.664145469665527, 0.7003097534179688, -0.9302177429199219, -0.5655879974365234, 0.5797456502914429, 1.6805496215820312, 3.0269734859466553, 0.77972412109375, 2.803988456726074], "custom_metrics": {}}}, "num_steps_sampled": 34272, "num_agent_steps_sampled": 102816, "num_steps_trained": 66560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 199680, "last_target_update_ts": 33776, "num_target_updates": 65}, "done": false, "episodes_total": 3424, "training_iteration": 34, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-45-17", "timestamp": 1648914317, "time_this_iter_s": 40.676347732543945, "time_total_s": 1342.9467470645905, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cc830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cc830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1342.9467470645905, "timesteps_since_restore": 1088, "iterations_since_restore": 34, "perf": {"cpu_util_percent": 52.77368421052631, "ram_util_percent": 65.79473684210525}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 59.42307692307692, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 19.807692307692307, "policy1": 19.807692307692307, "policy2": 19.807692307692307}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 30.0, 60.0, 30.0, 60.0, 30.0, 60.0, 60.0, 90.0, 90.0, 60.0, 90.0, 120.0, 60.0, 90.0, 0.0, 60.0, 90.0, 120.0, 0.0, 30.0, -30.0, 60.0, 60.0, 30.0, 0.0, 30.0, 120.0, 0.0, 90.0, 60.0, 30.0, 120.0, 120.0, 90.0, 120.0, 120.0, 60.0, 60.0, 90.0, 30.0, 60.0, 90.0, 30.0, 60.0, 90.0, 60.0, 60.0, 90.0, 60.0, 60.0, 120.0, 60.0, 60.0, 30.0, 90.0, 30.0, 30.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 0.0, 60.0, 90.0, 0.0, 30.0, 60.0, 90.0, 0.0, 30.0, 30.0, 0.0, 60.0, 30.0, 90.0, 90.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 0.0, 120.0, 60.0, 60.0, 120.0, 120.0, 120.0, 60.0, 60.0, 30.0, 30.0, 60.0, 0.0, 90.0, 0.0, 0.0, -30.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 0.0, 20.0, 30.0, 40.0, 0.0, 10.0, -10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 40.0, 0.0, 30.0, 20.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 30.0, 0.0, 10.0, 10.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, -10.0, 10.0], "policy_policy1_reward": [20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 0.0, 20.0, 30.0, 40.0, 0.0, 10.0, -10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 40.0, 0.0, 30.0, 20.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 30.0, 0.0, 10.0, 10.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, -10.0, 10.0], "policy_policy2_reward": [20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 0.0, 20.0, 30.0, 40.0, 0.0, 10.0, -10.0, 20.0, 20.0, 10.0, 0.0, 10.0, 40.0, 0.0, 30.0, 20.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 10.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 0.0, 20.0, 30.0, 0.0, 10.0, 20.0, 30.0, 0.0, 10.0, 10.0, 0.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 0.0, 30.0, 0.0, 0.0, -10.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0441046914685652, "mean_inference_ms": 26.005896422182158, "mean_action_processing_ms": 0.24717052214514054, "mean_env_wait_ms": 0.13889738416309572, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 35280, "timesteps_this_iter": 32, "agent_timesteps_total": 105840, "timers": {"load_time_ms": 0.66, "load_throughput": 48475.053, "learn_time_ms": 250.035, "learn_throughput": 127.982, "update_time_ms": 105.505}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.20741081237793, "min_q": -2.0343356132507324, "max_q": 26.462303161621094, "mean_td_error": -0.5514987111091614, "model": {}}, "td_error": [-0.7441768646240234, -1.499201774597168, 0.16302800178527832, -1.228653073310852, 0.4671018719673157, -5.536137580871582, 0.10209095478057861, 1.84295654296875, 0.7842455506324768, -0.5493278503417969, -0.7081403732299805, -1.683279037475586, -0.8196659088134766, -5.210573196411133, 1.3339519500732422, 0.9301872253417969, 0.8176329135894775, 0.7725200653076172, 1.8857163190841675, -2.0457286834716797, -6.319338798522949, 0.4915752410888672, -0.2786064147949219, -1.525217056274414, 0.03776955604553223, 2.641683578491211, -1.3461437225341797, 2.542156219482422, 1.1036653518676758, -1.282796859741211, -3.6292686462402344, 0.8420162200927734], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.366527557373047, "min_q": -2.819805145263672, "max_q": 23.775936126708984, "mean_td_error": -0.4119615852832794, "model": {}}, "td_error": [-0.7378940582275391, 0.7705764770507812, 0.7216072082519531, -2.2221946716308594, -7.25819206237793, 2.0252504348754883, 1.634638786315918, -0.6675424575805664, 0.6599065661430359, 0.7909793853759766, 1.0870740413665771, 0.6634235382080078, 2.2554540634155273, -2.5299510955810547, 0.20380401611328125, 0.8514478206634521, -0.03115546703338623, 1.2201642990112305, 2.9771475791931152, -9.96699047088623, 1.6969938278198242, -7.316440105438232, 0.4494056701660156, 2.4617843627929688, -4.017038822174072, -7.929765224456787, 3.118009567260742, 0.18801116943359375, 5.674171447753906, 0.7456588745117188, 0.6061215400695801, -1.3072364330291748], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.443412780761719, "min_q": -2.028654098510742, "max_q": 27.075876235961914, "mean_td_error": 0.03542482852935791, "model": {}}, "td_error": [-0.38437747955322266, 1.7201366424560547, 1.680678367614746, 0.7518997192382812, 2.122403144836426, 8.970125198364258, -9.983778953552246, 1.6805620193481445, 3.0780372619628906, -1.6642770767211914, -0.8383960723876953, -1.657491683959961, 0.3209199905395508, -0.3889303207397461, -0.3861083984375, 2.894902229309082, -0.9290523529052734, -0.09984970092773438, -1.0286540985107422, 0.22983551025390625, -1.3891735076904297, 2.88350772857666, 0.09088325500488281, 2.301210403442383, -0.13622093200683594, -2.3110103607177734, -7.7025957107543945, 0.37300682067871094, -1.8540267944335938, 0.9232332706451416, -0.04367256164550781, 1.9098683595657349], "custom_metrics": {}}}, "num_steps_sampled": 35280, "num_agent_steps_sampled": 105840, "num_steps_trained": 68576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 205728, "last_target_update_ts": 34800, "num_target_updates": 67}, "done": false, "episodes_total": 3528, "training_iteration": 35, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-45-58", "timestamp": 1648914358, "time_this_iter_s": 41.26890683174133, "time_total_s": 1384.2156538963318, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7f17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7f17a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1384.2156538963318, "timesteps_since_restore": 1120, "iterations_since_restore": 35, "perf": {"cpu_util_percent": 51.82542372881356, "ram_util_percent": 65.9915254237288}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 66.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 22.0, "policy1": 22.0, "policy2": 22.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 120.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 120.0, 90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 60.0, 90.0, 0.0, 60.0, 60.0, 30.0, 90.0, 60.0, 0.0, 60.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 90.0, 120.0, 60.0, 90.0, 0.0, 90.0, 30.0, 60.0, 90.0, 30.0, 30.0, 90.0, 30.0, 90.0, 90.0, 60.0, 90.0, 0.0, 60.0, 90.0, 60.0, 60.0, 30.0, 90.0, 90.0, 60.0, 90.0, 90.0, 120.0, 60.0, 90.0, 60.0, 0.0, 30.0, 120.0, 60.0, 60.0, 30.0, 30.0, 60.0, 90.0, 60.0, 60.0, 120.0, 60.0, 90.0, 0.0, 60.0, 60.0, 120.0, 90.0, 90.0, 60.0, 30.0, 60.0, 30.0, 30.0, 60.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 0.0, 10.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0], "policy_policy1_reward": [0.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 0.0, 10.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0], "policy_policy2_reward": [0.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 0.0, 20.0, 20.0, 10.0, 30.0, 20.0, 0.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 40.0, 20.0, 30.0, 0.0, 30.0, 10.0, 20.0, 30.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 0.0, 20.0, 30.0, 20.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 0.0, 10.0, 40.0, 20.0, 20.0, 10.0, 10.0, 20.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 0.0, 20.0, 20.0, 40.0, 30.0, 30.0, 20.0, 10.0, 20.0, 10.0, 10.0, 20.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0449422847130168, "mean_inference_ms": 26.028004283089373, "mean_action_processing_ms": 0.24733996162679436, "mean_env_wait_ms": 0.13898328976424618, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 36288, "timesteps_this_iter": 32, "agent_timesteps_total": 108864, "timers": {"load_time_ms": 0.603, "load_throughput": 53048.389, "learn_time_ms": 239.267, "learn_throughput": 133.742, "update_time_ms": 105.281}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.138280868530273, "min_q": 0.2569619417190552, "max_q": 25.719907760620117, "mean_td_error": 0.36754029989242554, "model": {}}, "td_error": [1.7544481754302979, -1.7371253967285156, 7.609455585479736, 0.27267932891845703, -1.8245277404785156, 10.236844062805176, -1.5041027069091797, -0.9852008819580078, 9.708377838134766, -0.8686990737915039, 3.049846649169922, 1.1380729675292969, -1.8969993591308594, -4.889854431152344, -3.1271705627441406, 1.0574951171875, -4.610246658325195, -2.4167003631591797, 1.360361099243164, 0.7070050239562988, -2.001082420349121, -2.591817855834961, -0.8369507789611816, 1.2569619417190552, -1.5192842483520508, -0.2990589141845703, 0.16425418853759766, 1.1805419921875, 2.019752264022827, 1.7609643936157227, -1.0514392852783203, 0.6444911956787109], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.329310417175293, "min_q": -1.3812477588653564, "max_q": 21.551834106445312, "mean_td_error": -1.0493884086608887, "model": {}}, "td_error": [-9.765189170837402, 2.8893795013427734, -7.949794769287109, -4.294597625732422, 0.667205810546875, -8.23647403717041, 2.0110580921173096, 0.4937591552734375, -0.19684123992919922, 3.8479251861572266, 1.9325933456420898, -2.62017822265625, -0.5100717544555664, 3.5703372955322266, 3.853271484375, -0.08295488357543945, -1.7791614532470703, 0.35326528549194336, -1.4757699966430664, 1.6086912155151367, -1.7618381977081299, -6.871599197387695, -1.1406078338623047, -2.0883731842041016, -1.4806671142578125, -9.046603202819824, -0.3845977783203125, 2.1291580200195312, -1.104257583618164, 1.536773920059204, 0.8012841939926147, 1.5144462585449219], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.388653755187988, "min_q": -1.5626013278961182, "max_q": 26.560558319091797, "mean_td_error": -0.14097940921783447, "model": {}}, "td_error": [-0.5626013278961182, 0.9074764251708984, -1.060781478881836, -2.5753555297851562, 0.8101334571838379, 1.28277587890625, -6.196992874145508, -0.48814964294433594, 0.5328884124755859, 1.4945869445800781, -2.146472930908203, 1.0203800201416016, -5.48756217956543, -0.19948387145996094, -3.138533592224121, -1.5210647583007812, 0.5380079746246338, 0.7415637969970703, 1.0961170196533203, 2.1468753814697266, -0.20052337646484375, -3.9679698944091797, 0.051616668701171875, -1.9185972213745117, 0.7021360397338867, 0.8921771049499512, -4.669783592224121, 0.9067897796630859, 0.8865175247192383, 1.355173110961914, -1.2247896194458008, 15.482105255126953], "custom_metrics": {}}}, "num_steps_sampled": 36288, "num_agent_steps_sampled": 108864, "num_steps_trained": 70592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 211776, "last_target_update_ts": 35824, "num_target_updates": 69}, "done": false, "episodes_total": 3628, "training_iteration": 36, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-46-40", "timestamp": 1648914400, "time_this_iter_s": 41.450098752975464, "time_total_s": 1425.6657526493073, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e3710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1425.6657526493073, "timesteps_since_restore": 1152, "iterations_since_restore": 36, "perf": {"cpu_util_percent": 52.467241379310344, "ram_util_percent": 65.99655172413792}}
{"episode_reward_max": 120.0, "episode_reward_min": -30.0, "episode_reward_mean": 69.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 23.0, "policy1": 23.0, "policy2": 23.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 30.0, 60.0, -30.0, 90.0, 60.0, 60.0, 120.0, 30.0, 0.0, 30.0, 60.0, 90.0, 90.0, 90.0, 120.0, 90.0, 60.0, 30.0, 60.0, 90.0, 30.0, 90.0, 90.0, 120.0, 60.0, 90.0, 30.0, 60.0, 30.0, 60.0, 60.0, 90.0, 60.0, 90.0, 60.0, 60.0, 60.0, 90.0, 120.0, 90.0, 60.0, 60.0, 0.0, 90.0, 120.0, 0.0, 60.0, 90.0, 90.0, 90.0, 60.0, 120.0, 120.0, 90.0, 90.0, 30.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 60.0, 120.0, 90.0, 30.0, 90.0, 60.0, 30.0, 30.0, 90.0, 60.0, 30.0, 60.0, 30.0, 120.0, 120.0, 120.0, 90.0, 60.0, 60.0, 90.0, 60.0, 60.0, 30.0, 30.0, 0.0, 30.0, 60.0, 90.0, 60.0, 120.0, 30.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 10.0, 20.0, -10.0, 30.0, 20.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 0.0, 30.0, 40.0, 0.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0], "policy_policy1_reward": [20.0, 10.0, 20.0, -10.0, 30.0, 20.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 0.0, 30.0, 40.0, 0.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0], "policy_policy2_reward": [20.0, 10.0, 20.0, -10.0, 30.0, 20.0, 20.0, 40.0, 10.0, 0.0, 10.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 10.0, 20.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 0.0, 30.0, 40.0, 0.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0, 10.0, 20.0, 10.0, 40.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 10.0, 10.0, 0.0, 10.0, 20.0, 30.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0449151634850387, "mean_inference_ms": 26.031951680579706, "mean_action_processing_ms": 0.24736359675512232, "mean_env_wait_ms": 0.1390668342324428, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 37296, "timesteps_this_iter": 32, "agent_timesteps_total": 111888, "timers": {"load_time_ms": 0.674, "load_throughput": 47482.127, "learn_time_ms": 234.188, "learn_throughput": 136.642, "update_time_ms": 100.774}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.828168869018555, "min_q": 0.31900298595428467, "max_q": 29.75398063659668, "mean_td_error": -0.5699810981750488, "model": {}}, "td_error": [-0.7114372253417969, 0.7703657150268555, -0.3835010528564453, 0.6511802673339844, -5.597068786621094, -0.44444751739501953, 3.7168173789978027, 0.7485516667366028, -5.530017852783203, -2.2520952224731445, -5.889351844787598, 0.1364290714263916, -2.0802650451660156, -3.559518814086914, 1.226628303527832, -1.710662841796875, -4.090951919555664, 0.9966716766357422, 2.840123176574707, -1.947591781616211, -3.350391387939453, -0.19799518585205078, 1.7177329063415527, -0.04505157470703125, -0.021066665649414062, 5.298220634460449, -2.09434175491333, 2.0149927139282227, 0.11432075500488281, -1.4387502670288086, 0.5838499069213867, 2.2892284393310547], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 9.510419845581055, "min_q": -1.4826185703277588, "max_q": 23.321182250976562, "mean_td_error": 0.1646290421485901, "model": {}}, "td_error": [2.348353147506714, 10.360418319702148, -0.5955791473388672, 0.31557655334472656, 2.0690431594848633, 2.547347068786621, -0.9615617990493774, -0.7466754913330078, 3.196077346801758, 0.2272777557373047, -6.508665561676025, 0.7018222808837891, 3.4777679443359375, 3.515094757080078, -5.800034523010254, -0.8775858879089355, 5.631350994110107, -1.1443274021148682, -1.254481315612793, 1.3113415241241455, 4.0536956787109375, -3.0946502685546875, 2.2758216857910156, -8.102319717407227, 1.1844840049743652, -0.8656959533691406, 8.718868255615234, -3.2471611499786377, -3.563507556915283, -6.720134735107422, 0.7290551662445068, -3.9128847122192383], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.233697891235352, "min_q": -1.8333499431610107, "max_q": 25.079051971435547, "mean_td_error": -0.5842185616493225, "model": {}}, "td_error": [1.272507667541504, 0.6670420169830322, -0.19505083560943604, 14.154937744140625, 3.0889663696289062, -2.798537254333496, -0.5369291305541992, 1.271759033203125, -10.232848167419434, 3.5001373291015625, 0.11607718467712402, -8.183692932128906, 0.519195556640625, -8.053060531616211, -3.616107940673828, -0.04849505424499512, 0.1678619384765625, -1.4842777252197266, 0.1881999969482422, -6.00093936920166, -3.058685779571533, 0.031244277954101562, 0.6652851104736328, 0.2565574645996094, 0.33368968963623047, 7.020478248596191, -0.25957202911376953, -3.047374725341797, -2.887042999267578, -0.315258264541626, -3.074432373046875, 1.8433728218078613], "custom_metrics": {}}}, "num_steps_sampled": 37296, "num_agent_steps_sampled": 111888, "num_steps_trained": 72608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 217824, "last_target_update_ts": 36848, "num_target_updates": 71}, "done": false, "episodes_total": 3728, "training_iteration": 37, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-47-20", "timestamp": 1648914440, "time_this_iter_s": 40.44938325881958, "time_total_s": 1466.1151359081268, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7d4710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7d4710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1466.1151359081268, "timesteps_since_restore": 1184, "iterations_since_restore": 37, "perf": {"cpu_util_percent": 52.03275862068965, "ram_util_percent": 65.36724137931033}}
{"episode_reward_max": 150.0, "episode_reward_min": -30.0, "episode_reward_mean": 74.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 24.8, "policy1": 24.8, "policy2": 24.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [0.0, 60.0, 60.0, 60.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 90.0, 90.0, 0.0, 60.0, 90.0, 90.0, 90.0, 120.0, 90.0, 150.0, 60.0, 60.0, 120.0, 60.0, 90.0, 30.0, 30.0, 120.0, 90.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 30.0, 60.0, 120.0, 90.0, 120.0, 120.0, 90.0, 60.0, 60.0, 90.0, 90.0, 90.0, 90.0, 90.0, 60.0, 120.0, 60.0, 90.0, 90.0, 60.0, 90.0, 60.0, 120.0, 60.0, 90.0, 90.0, -30.0, 90.0, 60.0, 90.0, 90.0, 90.0, 30.0, 30.0, 90.0, 60.0, 60.0, 90.0, 90.0, 90.0, 60.0, 90.0, 120.0, 0.0, 30.0, 30.0, 90.0, 90.0, 60.0, 90.0, 90.0, 60.0, 60.0, 0.0, 0.0, 60.0, 120.0, 120.0, 30.0, 150.0, 90.0, 60.0, 90.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, -10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 0.0, 0.0, 20.0, 40.0, 40.0, 10.0, 50.0, 30.0, 20.0, 30.0, 20.0, 20.0], "policy_policy1_reward": [0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, -10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 0.0, 0.0, 20.0, 40.0, 40.0, 10.0, 50.0, 30.0, 20.0, 30.0, 20.0, 20.0], "policy_policy2_reward": [0.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 10.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, -10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 10.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 0.0, 10.0, 10.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 0.0, 0.0, 20.0, 40.0, 40.0, 10.0, 50.0, 30.0, 20.0, 30.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.045377409830339, "mean_inference_ms": 26.028614925718312, "mean_action_processing_ms": 0.2474182269711877, "mean_env_wait_ms": 0.13915470774940253, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 38304, "timesteps_this_iter": 32, "agent_timesteps_total": 114912, "timers": {"load_time_ms": 0.648, "load_throughput": 49368.348, "learn_time_ms": 239.601, "learn_throughput": 133.555, "update_time_ms": 103.255}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.701059341430664, "min_q": 0.3832916021347046, "max_q": 28.845165252685547, "mean_td_error": 0.239002525806427, "model": {}}, "td_error": [1.722062349319458, 1.0395469665527344, -1.0241661071777344, 11.708961486816406, 12.28288459777832, 6.118605613708496, -1.1417560577392578, -0.5052390098571777, -6.464014053344727, 1.1501102447509766, -0.9025897979736328, 1.2672014236450195, -8.76403522491455, -1.6549873352050781, 0.12956207990646362, -0.32109057903289795, -7.296294689178467, 1.5890235900878906, -1.9102554321289062, -6.246851921081543, -1.0231695175170898, -2.79345703125, 2.5388240814208984, -1.6058340072631836, -1.2950458526611328, 2.8655128479003906, 1.435638427734375, 0.1992359161376953, 10.212263107299805, -6.1707024574279785, 3.3366641998291016, -0.8285274505615234], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.094883918762207, "min_q": -1.9496355056762695, "max_q": 26.1953182220459, "mean_td_error": -0.471315860748291, "model": {}}, "td_error": [-7.951619625091553, -4.068611145019531, -3.05084228515625, 13.54492473602295, -1.488774299621582, -0.5972472429275513, -6.290724754333496, -4.160954475402832, -1.725264549255371, -0.31061553955078125, 1.9722509384155273, 3.641477584838867, -1.9835710525512695, -0.5520199537277222, -6.641809940338135, 2.860605239868164, 2.127096176147461, 0.393585205078125, -1.2849979400634766, 1.1170644760131836, -5.7940874099731445, 0.10464119911193848, -1.0155162811279297, 8.533609390258789, 0.12981224060058594, -0.3187268078327179, -0.21505117416381836, 2.9673004150390625, 0.9094341993331909, -2.2666797637939453, -2.7013187408447266, -0.9654788970947266], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.414230346679688, "min_q": -0.5216189622879028, "max_q": 25.955707550048828, "mean_td_error": 0.23277485370635986, "model": {}}, "td_error": [0.5920810699462891, 0.40024566650390625, -0.925506591796875, -2.794886589050293, 2.945375442504883, 9.41486644744873, -1.280522346496582, -1.6979827880859375, 1.079054832458496, 0.33718442916870117, 0.3574542999267578, -0.20905590057373047, 0.8006905317306519, 3.4652099609375, 1.1791008710861206, 0.7779814600944519, -1.2837944030761719, -0.031114578247070312, -2.1379518508911133, -1.678492546081543, 0.23690414428710938, 0.04998779296875, -0.18988037109375, 0.013874053955078125, 1.1424427032470703, -0.7647132873535156, 0.7696743011474609, 0.10198402404785156, 5.683266639709473, 0.57414710521698, -8.519954681396484, -0.9588756561279297], "custom_metrics": {}}}, "num_steps_sampled": 38304, "num_agent_steps_sampled": 114912, "num_steps_trained": 74624, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 223872, "last_target_update_ts": 37872, "num_target_updates": 73}, "done": false, "episodes_total": 3828, "training_iteration": 38, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-48-01", "timestamp": 1648914481, "time_this_iter_s": 40.26297879219055, "time_total_s": 1506.3781147003174, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ecef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ecef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1506.3781147003174, "timesteps_since_restore": 1216, "iterations_since_restore": 38, "perf": {"cpu_util_percent": 51.966666666666676, "ram_util_percent": 65.21929824561404}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 69.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 23.3, "policy1": 23.3, "policy2": 23.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 60.0, 90.0, 120.0, 0.0, 90.0, 90.0, 60.0, 60.0, 30.0, 60.0, 60.0, 90.0, 60.0, 150.0, 30.0, 90.0, 90.0, 90.0, 60.0, 120.0, 30.0, 60.0, 120.0, 90.0, 30.0, 30.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 30.0, 60.0, 60.0, 60.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 60.0, 90.0, 60.0, 60.0, 90.0, 90.0, 90.0, 0.0, 0.0, 60.0, 60.0, 30.0, 60.0, 60.0, 60.0, 0.0, 120.0, 90.0, 120.0, 90.0, 60.0, 60.0, 60.0, 90.0, 0.0, 60.0, 120.0, 60.0, 90.0, 60.0, 60.0, 90.0, 90.0, 60.0, 60.0, 60.0, 90.0, 30.0, 90.0, 90.0, 90.0, 30.0, 60.0, 0.0, 120.0, 90.0, 60.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 0.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 20.0, 30.0, 40.0, 0.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 50.0, 10.0, 30.0, 30.0, 30.0, 20.0, 40.0, 10.0, 20.0, 40.0, 30.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 0.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 0.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 0.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 20.0, 30.0, 40.0, 0.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 50.0, 10.0, 30.0, 30.0, 30.0, 20.0, 40.0, 10.0, 20.0, 40.0, 30.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 0.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 0.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 0.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 20.0, 30.0, 40.0, 0.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 30.0, 20.0, 50.0, 10.0, 30.0, 30.0, 30.0, 20.0, 40.0, 10.0, 20.0, 40.0, 30.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 0.0, 0.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 40.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 0.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 20.0, 0.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 0.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0456336467551584, "mean_inference_ms": 26.032891553905365, "mean_action_processing_ms": 0.24750076483729316, "mean_env_wait_ms": 0.13922617750549166, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 39312, "timesteps_this_iter": 32, "agent_timesteps_total": 117936, "timers": {"load_time_ms": 0.646, "load_throughput": 49546.948, "learn_time_ms": 238.389, "learn_throughput": 134.234, "update_time_ms": 105.927}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.957181930541992, "min_q": -1.4335858821868896, "max_q": 30.060335159301758, "mean_td_error": 0.005301445722579956, "model": {}}, "td_error": [-2.1425743103027344, 1.5125144720077515, -1.0125112533569336, -2.7430543899536133, -1.3006210327148438, 2.22259521484375, 0.12497711181640625, 0.7833738327026367, -0.15720367431640625, -1.788574457168579, 3.691150665283203, 3.4681949615478516, 0.8705463409423828, 1.2218570709228516, -0.08960556983947754, -3.443418502807617, 3.912317991256714, 0.11353492736816406, -8.7727689743042, 1.5313234329223633, -1.9082517623901367, -1.8034000396728516, 0.9576911926269531, 1.635824203491211, -3.121774673461914, -0.6610394716262817, -0.3600902557373047, 3.5822534561157227, -2.8356456756591797, 5.0391435623168945, -0.43358588218688965, 2.076467514038086], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.611194610595703, "min_q": 1.2228944301605225, "max_q": 28.129528045654297, "mean_td_error": -0.10409514605998993, "model": {}}, "td_error": [1.3423404693603516, 1.896454930305481, -0.10687661170959473, -2.0653562545776367, -3.010563850402832, 0.6926989555358887, 1.4384956359863281, 4.824324607849121, -1.8163509368896484, 1.0265941619873047, 1.45855712890625, 0.5016384124755859, 7.4329833984375, -4.2105255126953125, -2.4490909576416016, -2.597733497619629, 2.217294692993164, 1.002716064453125, -3.5684523582458496, 2.0317840576171875, -0.0005002021789550781, 0.5038356781005859, -1.6312274932861328, 0.005794525146484375, 2.0611095428466797, -1.3722479343414307, 6.873171806335449, -3.6561660766601562, -0.4191474914550781, -3.032020092010498, -2.0744123458862305, -6.630167007446289], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.90166187286377, "min_q": -1.3556925058364868, "max_q": 27.707332611083984, "mean_td_error": 0.057830892503261566, "model": {}}, "td_error": [-1.4907629489898682, -0.2568016052246094, -1.149362564086914, 0.7643222808837891, 1.9717912673950195, 0.8550443649291992, -0.4627237319946289, -0.4627237319946289, 1.1059513092041016, 0.09670233726501465, -4.1707763671875, 0.2596015930175781, 1.230224609375, 0.8525161743164062, -1.1910343170166016, -8.87100601196289, 0.08067893981933594, 1.2648029327392578, -2.9796218872070312, -0.2518501281738281, -3.6182899475097656, -0.24069976806640625, -0.3556925058364868, 1.4744148254394531, 1.9754619598388672, 1.2642183303833008, -0.8379077911376953, 0.5505542755126953, -0.2052164077758789, 1.463571548461914, 13.64433479309082, -0.4591331481933594], "custom_metrics": {}}}, "num_steps_sampled": 39312, "num_agent_steps_sampled": 117936, "num_steps_trained": 76640, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 229920, "last_target_update_ts": 38896, "num_target_updates": 75}, "done": false, "episodes_total": 3928, "training_iteration": 39, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-48-41", "timestamp": 1648914521, "time_this_iter_s": 40.66757822036743, "time_total_s": 1547.0456929206848, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981e3830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1547.0456929206848, "timesteps_since_restore": 1248, "iterations_since_restore": 39, "perf": {"cpu_util_percent": 52.87586206896552, "ram_util_percent": 65.8}}
{"episode_reward_max": 120.0, "episode_reward_min": 30.0, "episode_reward_mean": 81.92307692307692, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 27.307692307692307, "policy1": 27.307692307692307, "policy2": 27.307692307692307}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 60.0, 120.0, 60.0, 30.0, 60.0, 90.0, 60.0, 30.0, 90.0, 90.0, 30.0, 90.0, 120.0, 120.0, 120.0, 120.0, 60.0, 120.0, 120.0, 120.0, 120.0, 60.0, 90.0, 120.0, 60.0, 60.0, 30.0, 90.0, 30.0, 60.0, 90.0, 90.0, 60.0, 120.0, 60.0, 90.0, 30.0, 60.0, 120.0, 120.0, 60.0, 60.0, 30.0, 90.0, 60.0, 30.0, 90.0, 120.0, 120.0, 90.0, 120.0, 60.0, 90.0, 60.0, 30.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 60.0, 90.0, 90.0, 120.0, 60.0, 120.0, 90.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0, 120.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 30.0, 120.0, 90.0, 90.0, 90.0, 60.0, 90.0, 30.0, 90.0, 90.0, 90.0, 60.0, 90.0, 120.0, 90.0, 120.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 20.0, 40.0, 20.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0], "policy_policy1_reward": [40.0, 20.0, 40.0, 20.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0], "policy_policy2_reward": [40.0, 20.0, 40.0, 20.0, 10.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 10.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 30.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 10.0, 30.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 30.0, 20.0, 10.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0453829889720352, "mean_inference_ms": 26.022778683363377, "mean_action_processing_ms": 0.2474044005722531, "mean_env_wait_ms": 0.13917577537488943, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 40320, "timesteps_this_iter": 32, "agent_timesteps_total": 120960, "timers": {"load_time_ms": 0.717, "load_throughput": 44636.579, "learn_time_ms": 233.145, "learn_throughput": 137.254, "update_time_ms": 102.132}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.77817153930664, "min_q": -2.6236917972564697, "max_q": 28.714372634887695, "mean_td_error": 0.2785935699939728, "model": {}}, "td_error": [-3.688434600830078, 1.838277816772461, -0.5192165374755859, -0.08067488670349121, -1.2330520153045654, 1.1046257019042969, -0.9060325622558594, 0.16735315322875977, -0.6893291473388672, -6.650623321533203, -3.441011428833008, 3.5501022338867188, 5.12711238861084, 0.7571945190429688, 0.5987462997436523, -0.5501632690429688, 0.7126865386962891, 2.823629379272461, 0.21141409873962402, 2.6043243408203125, -0.8919696807861328, 1.6702892780303955, 4.1207685470581055, 1.0517807006835938, 2.8637237548828125, 0.9168033599853516, -1.5442371368408203, 2.922086715698242, -1.2528877258300781, -0.8586139678955078, -1.3764877319335938, -0.4431896209716797], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.55252742767334, "min_q": -2.3487918376922607, "max_q": 26.179611206054688, "mean_td_error": 0.42326438426971436, "model": {}}, "td_error": [4.2066264152526855, 1.109262466430664, 2.0856943130493164, -0.9003276824951172, 2.1442718505859375, 7.116022109985352, 1.7856292724609375, 0.5340313911437988, 1.0043621063232422, -0.7795524597167969, -7.986825466156006, -1.0625967979431152, -4.23100471496582, 0.5736351013183594, 0.5992832183837891, -5.287901878356934, -6.373367786407471, 1.6780672073364258, 0.3641510009765625, -0.5319843292236328, 1.0486650466918945, 4.9065046310424805, -2.2315542697906494, 2.1510159969329834, 2.5357141494750977, 0.3456904888153076, 0.2550373077392578, 5.845235824584961, -1.9369397163391113, 3.7174196243286133, 0.8282699584960938, 0.031925201416015625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.758573532104492, "min_q": -1.936077356338501, "max_q": 27.013769149780273, "mean_td_error": -0.49769216775894165, "model": {}}, "td_error": [-8.054814338684082, 0.17374463379383087, -1.1079959869384766, 0.3950519561767578, -0.8411884307861328, -3.5050201416015625, -1.0782699584960938, -9.186760902404785, -3.757234573364258, -4.9420976638793945, 0.2877063751220703, -0.22545039653778076, -0.009491413831710815, 1.5424079895019531, 1.747232437133789, 0.001172482967376709, 2.0610485076904297, 26.815176010131836, -6.2155256271362305, 1.4198589324951172, 3.2264328002929688, 0.4313047528266907, 0.16431427001953125, 1.0373001098632812, -6.17221736907959, -7.73106575012207, 0.1103060245513916, -0.5865597724914551, -2.9132308959960938, 0.69794762134552, -1.4641742706298828, 1.7539424896240234], "custom_metrics": {}}}, "num_steps_sampled": 40320, "num_agent_steps_sampled": 120960, "num_steps_trained": 78656, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 235968, "last_target_update_ts": 39920, "num_target_updates": 77}, "done": false, "episodes_total": 4032, "training_iteration": 40, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-49-22", "timestamp": 1648914562, "time_this_iter_s": 39.97014284133911, "time_total_s": 1587.015835762024, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c44d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c44d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1587.015835762024, "timesteps_since_restore": 1280, "iterations_since_restore": 40, "perf": {"cpu_util_percent": 51.753571428571426, "ram_util_percent": 65.63035714285714}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 77.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 25.8, "policy1": 25.8, "policy2": 25.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 90.0, 90.0, 60.0, 60.0, 30.0, 60.0, 120.0, 30.0, 30.0, 90.0, 90.0, 60.0, 60.0, 120.0, 30.0, 30.0, 30.0, 60.0, 90.0, 60.0, 90.0, 90.0, 120.0, 60.0, 120.0, 120.0, 90.0, 30.0, 60.0, 90.0, 90.0, 60.0, 60.0, 120.0, 0.0, 60.0, 60.0, 120.0, 120.0, 150.0, 120.0, 60.0, 90.0, 90.0, 90.0, 90.0, 60.0, 90.0, 30.0, 90.0, 90.0, 60.0, 90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 90.0, 90.0, 90.0, 60.0, 30.0, 120.0, 90.0, 120.0, 60.0, 120.0, 120.0, 60.0, 90.0, 30.0, 120.0, 30.0, 0.0, 60.0, 90.0, 60.0, 30.0, 90.0, 120.0, 90.0, 90.0, 60.0, 60.0, 120.0, 60.0, 90.0, 30.0, 120.0, 60.0, 120.0, 120.0, 90.0, 90.0, 90.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 40.0, 0.0, 20.0, 20.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 10.0, 0.0, 20.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0], "policy_policy1_reward": [40.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 40.0, 0.0, 20.0, 20.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 10.0, 0.0, 20.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0], "policy_policy2_reward": [40.0, 30.0, 30.0, 20.0, 20.0, 10.0, 20.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 40.0, 0.0, 20.0, 20.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 10.0, 0.0, 20.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0452993804668052, "mean_inference_ms": 26.014984974980674, "mean_action_processing_ms": 0.24732053539453702, "mean_env_wait_ms": 0.13916523957499388, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 41328, "timesteps_this_iter": 32, "agent_timesteps_total": 123984, "timers": {"load_time_ms": 0.633, "load_throughput": 50549.009, "learn_time_ms": 235.054, "learn_throughput": 136.139, "update_time_ms": 104.262}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.218234062194824, "min_q": -0.746068000793457, "max_q": 31.51837921142578, "mean_td_error": 0.5410511493682861, "model": {}}, "td_error": [0.8705234527587891, -0.011812210083007812, 1.5837087631225586, -1.8528633117675781, -0.5239165425300598, 0.0751645565032959, -0.25189781188964844, 0.30133724212646484, -2.803072929382324, -4.92617130279541, 3.5590038299560547, -1.6815569400787354, -2.1243762969970703, -0.5759315490722656, 3.312723159790039, 0.25393199920654297, 2.5046072006225586, -1.2487621307373047, 1.6063728332519531, -0.6884174346923828, -7.425792694091797, -1.1825237274169922, -0.3370037078857422, 1.6557857990264893, -2.0927772521972656, -2.5556583404541016, -1.6121606826782227, 5.260270118713379, -1.3466300964355469, 18.32745933532715, 13.636432647705078, -2.3923592567443848], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.597694396972656, "min_q": -1.8413288593292236, "max_q": 27.4172306060791, "mean_td_error": 0.425136536359787, "model": {}}, "td_error": [2.287759780883789, -3.065387725830078, 12.626615524291992, 0.22368764877319336, -1.0435819625854492, -1.6039925813674927, -0.47658681869506836, -0.6896114349365234, 0.8198812007904053, 0.3285331726074219, 0.5821037292480469, -0.6400163173675537, -0.432525634765625, 2.991330146789551, 5.2090630531311035, 4.029491424560547, 3.8106632232666016, -0.8216915130615234, 2.0635993480682373, -1.2720375061035156, 0.7029361724853516, -2.9520044326782227, -8.313409805297852, 1.526031494140625, 0.2581758499145508, 1.390110969543457, -2.490692138671875, -0.22141265869140625, -0.17540264129638672, 2.680692672729492, -0.8413288593292236, -2.886625289916992], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.032936096191406, "min_q": -1.8678812980651855, "max_q": 26.920394897460938, "mean_td_error": 0.3576034903526306, "model": {}}, "td_error": [-2.1725988388061523, 0.14791202545166016, 10.609174728393555, 0.5230200290679932, -1.8154544830322266, -2.9175057411193848, -0.774324893951416, -8.440350532531738, 3.008395195007324, -0.5762672424316406, -2.1508216857910156, -0.06209564208984375, -5.703178405761719, -0.0011119842529296875, -3.636423110961914, -0.6496191024780273, 2.8550033569335938, -3.520963668823242, 19.39191246032715, 0.4775381088256836, 0.6000900268554688, -2.78033447265625, 1.3339672088623047, -0.028995513916015625, 0.04376792907714844, 1.7290973663330078, -4.9021501541137695, -3.284221649169922, 18.65577507019043, -3.401182174682617, -0.36373138427734375, -0.7510128021240234], "custom_metrics": {}}}, "num_steps_sampled": 41328, "num_agent_steps_sampled": 123984, "num_steps_trained": 80672, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 242016, "last_target_update_ts": 40944, "num_target_updates": 79}, "done": false, "episodes_total": 4132, "training_iteration": 41, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-50-02", "timestamp": 1648914602, "time_this_iter_s": 40.016671657562256, "time_total_s": 1627.0325074195862, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c48c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c48c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1627.0325074195862, "timesteps_since_restore": 1312, "iterations_since_restore": 41, "perf": {"cpu_util_percent": 51.833333333333336, "ram_util_percent": 65.60877192982457}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 74.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 24.9, "policy1": 24.9, "policy2": 24.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 120.0, 60.0, 90.0, 60.0, 30.0, 30.0, 90.0, 120.0, 30.0, 120.0, 60.0, 30.0, 90.0, 120.0, 120.0, 120.0, 30.0, 120.0, 60.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 90.0, 60.0, 120.0, 120.0, 90.0, 90.0, 120.0, 60.0, 120.0, 90.0, 60.0, 30.0, 90.0, 60.0, 90.0, 90.0, 60.0, 120.0, 60.0, 30.0, 0.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 30.0, 120.0, 90.0, 60.0, 30.0, 90.0, 0.0, 60.0, 120.0, 120.0, 90.0, 90.0, 60.0, 90.0, 30.0, 90.0, 60.0, 90.0, 60.0, 90.0, 120.0, 60.0, 30.0, 30.0, 30.0, 60.0, 30.0, 120.0, 90.0, 90.0, 30.0, 60.0, 60.0, 30.0, 90.0, 30.0, 90.0, 120.0, 30.0, 60.0, 120.0, 90.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 30.0, 40.0, 40.0, 40.0, 10.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 10.0, 30.0, 0.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 40.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 40.0, 10.0, 20.0, 40.0, 30.0, 20.0], "policy_policy1_reward": [20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 30.0, 40.0, 40.0, 40.0, 10.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 10.0, 30.0, 0.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 40.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 40.0, 10.0, 20.0, 40.0, 30.0, 20.0], "policy_policy2_reward": [20.0, 40.0, 20.0, 30.0, 20.0, 10.0, 10.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 30.0, 40.0, 40.0, 40.0, 10.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 20.0, 10.0, 0.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 10.0, 30.0, 0.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 20.0, 10.0, 10.0, 10.0, 20.0, 10.0, 40.0, 30.0, 30.0, 10.0, 20.0, 20.0, 10.0, 30.0, 10.0, 30.0, 40.0, 10.0, 20.0, 40.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0454151897313295, "mean_inference_ms": 26.01278689766922, "mean_action_processing_ms": 0.24743128003069514, "mean_env_wait_ms": 0.1392414730902714, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 42336, "timesteps_this_iter": 32, "agent_timesteps_total": 127008, "timers": {"load_time_ms": 0.74, "load_throughput": 43227.714, "learn_time_ms": 246.138, "learn_throughput": 130.008, "update_time_ms": 106.588}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.135855674743652, "min_q": -1.954643964767456, "max_q": 33.28886032104492, "mean_td_error": 0.826817512512207, "model": {}}, "td_error": [-1.8443565368652344, 0.02176380157470703, -1.9154396057128906, 4.154058456420898, -3.2963085174560547, -0.2675285339355469, 8.93415641784668, 4.188831329345703, -0.5969171524047852, -4.5030622482299805, -4.564304351806641, 0.6284124851226807, 2.6109366416931152, 1.7228622436523438, 3.6178970336914062, 0.21586036682128906, 0.8888435363769531, -1.5694265365600586, -0.3249073028564453, -1.2678241729736328, -0.1013031005859375, 0.21466922760009766, 0.35207128524780273, 11.255269050598145, 2.13875150680542, 3.1011390686035156, -9.644135475158691, -0.12546920776367188, 1.2239141464233398, -1.6714186668395996, 2.8760170936584473, 10.005109786987305], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.704347610473633, "min_q": -1.7741883993148804, "max_q": 27.403736114501953, "mean_td_error": 0.8639190196990967, "model": {}}, "td_error": [0.7420116662979126, 0.44330668449401855, 3.3975067138671875, -0.9070491790771484, -1.3042917251586914, -1.707463264465332, -2.951080322265625, 2.714362144470215, 2.4642491340637207, -0.5366706848144531, 13.663588523864746, 2.6339111328125, -2.1476707458496094, 0.2610311508178711, 3.324842929840088, 20.931184768676758, -1.0680761337280273, 0.3673248291015625, 2.171877861022949, 3.7196102142333984, 1.2161096334457397, 3.112081527709961, 0.5562248229980469, -0.46489715576171875, -8.95177936553955, -1.043259620666504, 2.780919075012207, -7.192954063415527, 2.2702724933624268, 0.18359756469726562, -3.61818790435791, -7.415224075317383], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.308016777038574, "min_q": -3.046358585357666, "max_q": 27.57183074951172, "mean_td_error": 0.11166435480117798, "model": {}}, "td_error": [0.3371715545654297, -3.1886444091796875, 1.5256462097167969, -0.6514053344726562, -4.843118667602539, 0.5679206848144531, 0.8883644938468933, 0.6556262969970703, -2.6043739318847656, 2.9112415313720703, 5.967278003692627, -1.0640983581542969, 0.219696044921875, 1.3334922790527344, -0.7108078002929688, -0.6188564300537109, -4.323751449584961, -7.365445137023926, 0.24429035186767578, 2.1546802520751953, -3.9054346084594727, -0.23946046829223633, 1.5755958557128906, -3.9442882537841797, 2.6190338134765625, 0.7327747344970703, 1.4468135833740234, -2.959169387817383, 18.896493911743164, -7.251850128173828, -0.6802387237548828, 5.848081588745117], "custom_metrics": {}}}, "num_steps_sampled": 42336, "num_agent_steps_sampled": 127008, "num_steps_trained": 82688, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 248064, "last_target_update_ts": 41968, "num_target_updates": 81}, "done": false, "episodes_total": 4232, "training_iteration": 42, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-50-41", "timestamp": 1648914641, "time_this_iter_s": 39.27129316329956, "time_total_s": 1666.3038005828857, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ecf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f54981ecf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1666.3038005828857, "timesteps_since_restore": 1344, "iterations_since_restore": 42, "perf": {"cpu_util_percent": 53.035714285714285, "ram_util_percent": 65.40535714285714}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 73.8, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 24.6, "policy1": 24.6, "policy2": 24.6}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 90.0, 90.0, 60.0, 60.0, 60.0, 90.0, 90.0, 0.0, 90.0, 60.0, 60.0, 30.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 120.0, 90.0, 30.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 30.0, 30.0, 60.0, 90.0, 120.0, 90.0, 90.0, 120.0, 60.0, 90.0, 90.0, 60.0, 60.0, 90.0, 90.0, 90.0, 60.0, 30.0, 90.0, 60.0, 90.0, 120.0, 90.0, 60.0, 60.0, 30.0, 30.0, 90.0, 60.0, 90.0, 30.0, 90.0, 60.0, 90.0, 30.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 30.0, 90.0, 30.0, 120.0, 90.0, 30.0, 90.0, 60.0, 60.0, 30.0, 60.0, 60.0, 60.0, 0.0, 90.0, 30.0, 30.0, 60.0, 120.0, 90.0, 120.0, 60.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 0.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 30.0, 10.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 30.0, 10.0, 10.0, 20.0, 40.0, 30.0, 40.0, 20.0, 20.0, 30.0], "policy_policy1_reward": [10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 0.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 30.0, 10.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 30.0, 10.0, 10.0, 20.0, 40.0, 30.0, 40.0, 20.0, 20.0, 30.0], "policy_policy2_reward": [10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 0.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 10.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 30.0, 10.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 20.0, 20.0, 20.0, 0.0, 30.0, 10.0, 10.0, 20.0, 40.0, 30.0, 40.0, 20.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0455060051388874, "mean_inference_ms": 26.025276771713326, "mean_action_processing_ms": 0.2475058316326432, "mean_env_wait_ms": 0.13929447080966476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 43344, "timesteps_this_iter": 32, "agent_timesteps_total": 130032, "timers": {"load_time_ms": 0.679, "load_throughput": 47107.163, "learn_time_ms": 229.472, "learn_throughput": 139.451, "update_time_ms": 96.321}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.105377197265625, "min_q": -1.3234529495239258, "max_q": 32.77702331542969, "mean_td_error": -0.008707672357559204, "model": {}}, "td_error": [0.42145442962646484, -0.10679042339324951, -6.974819660186768, -3.434244155883789, -1.1850919723510742, -0.346527099609375, 1.0217952728271484, 0.8516826629638672, -1.5853023529052734, -3.702442169189453, 3.727757215499878, 13.768229484558105, -0.43462181091308594, 0.2651348114013672, -2.0686683654785156, 0.3516426086425781, 0.6409263610839844, 1.1005306243896484, 0.2651348114013672, 1.3964729309082031, -1.6025924682617188, -1.0902423858642578, 3.2625961303710938, 0.7426362037658691, -0.7547731399536133, -0.06216621398925781, 1.3527164459228516, -1.522059440612793, -2.8841190338134766, -0.25809478759765625, -0.845245361328125, -0.5895538330078125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.198990821838379, "min_q": -4.8788862228393555, "max_q": 27.973125457763672, "mean_td_error": 0.6593795418739319, "model": {}}, "td_error": [-1.2686023712158203, 3.4204235076904297, -2.0592918395996094, -0.6371288299560547, -0.35627782344818115, -6.482948303222656, 0.7747993469238281, 1.4991188049316406, 1.8994817733764648, -1.8959407806396484, 3.0729904174804688, 5.762584686279297, 1.7228946685791016, -2.6825103759765625, 1.4775711297988892, 9.850635528564453, 1.3362865447998047, 2.156108856201172, 7.999398708343506, -0.16308975219726562, 0.9042743444442749, -1.1047899723052979, -4.675590515136719, -3.848997116088867, -1.193483829498291, 10.937030792236328, -3.592571258544922, 3.4157867431640625, 0.445035457611084, -3.177760124206543, 0.8376350402832031, -3.272928237915039], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.029582977294922, "min_q": -1.417056918144226, "max_q": 29.52341651916504, "mean_td_error": -1.101306438446045, "model": {}}, "td_error": [2.3812255859375, 4.512123107910156, -4.001983642578125, 0.7748889923095703, 1.605097770690918, 0.8521060943603516, -0.4146547317504883, -7.194060802459717, -9.460735321044922, -3.8661727905273438, 1.8714642524719238, -3.0175743103027344, 3.898275375366211, 0.13245177268981934, -5.854312896728516, 0.23352622985839844, -9.460735321044922, -1.5800971984863281, -9.508176803588867, 0.5875082015991211, 0.2916431427001953, -0.5588817596435547, 0.9597682952880859, -0.25661468505859375, 2.0759735107421875, 2.2436141967773438, 1.114654302597046, -2.653085708618164, -0.5126323699951172, 1.0033740997314453, -1.0227274894714355, -0.4170569181442261], "custom_metrics": {}}}, "num_steps_sampled": 43344, "num_agent_steps_sampled": 130032, "num_steps_trained": 84704, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 254112, "last_target_update_ts": 42992, "num_target_updates": 83}, "done": false, "episodes_total": 4332, "training_iteration": 43, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-51-22", "timestamp": 1648914682, "time_this_iter_s": 40.417250633239746, "time_total_s": 1706.7210512161255, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7940e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7940e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1706.7210512161255, "timesteps_since_restore": 1376, "iterations_since_restore": 43, "perf": {"cpu_util_percent": 51.791228070175436, "ram_util_percent": 65.92807017543859}}
{"episode_reward_max": 120.0, "episode_reward_min": 30.0, "episode_reward_mean": 80.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 26.9, "policy1": 26.9, "policy2": 26.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 60.0, 30.0, 90.0, 120.0, 60.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 120.0, 30.0, 30.0, 90.0, 30.0, 90.0, 90.0, 30.0, 120.0, 30.0, 120.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 30.0, 90.0, 60.0, 120.0, 30.0, 90.0, 60.0, 120.0, 60.0, 30.0, 90.0, 120.0, 30.0, 120.0, 90.0, 90.0, 60.0, 90.0, 90.0, 120.0, 120.0, 90.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 120.0, 30.0, 60.0, 30.0, 120.0, 30.0, 90.0, 90.0, 90.0, 30.0, 90.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 120.0, 120.0, 30.0, 90.0, 120.0, 60.0, 60.0, 90.0, 120.0, 90.0, 90.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 10.0, 40.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 20.0, 10.0, 40.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0], "policy_policy1_reward": [30.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 10.0, 40.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 20.0, 10.0, 40.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0], "policy_policy2_reward": [30.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 10.0, 10.0, 30.0, 10.0, 30.0, 30.0, 10.0, 40.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 40.0, 10.0, 30.0, 20.0, 40.0, 20.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 10.0, 20.0, 10.0, 40.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0459207630596081, "mean_inference_ms": 26.022631925955622, "mean_action_processing_ms": 0.24755200054854307, "mean_env_wait_ms": 0.13931319608025283, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 44352, "timesteps_this_iter": 32, "agent_timesteps_total": 133056, "timers": {"load_time_ms": 0.606, "load_throughput": 52827.067, "learn_time_ms": 229.64, "learn_throughput": 139.349, "update_time_ms": 98.752}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.949268341064453, "min_q": -2.5758121013641357, "max_q": 34.12379455566406, "mean_td_error": -0.16903097927570343, "model": {}}, "td_error": [-2.3168020248413086, 3.279600143432617, -1.3536663055419922, -2.634110450744629, -0.19159698486328125, -2.946840286254883, -3.105557441711426, 0.9144783020019531, 0.2574882507324219, -1.7756404876708984, 1.499685287475586, -0.8564577102661133, -3.1372499465942383, 1.6965255737304688, -3.0915298461914062, -2.781606674194336, 2.500619888305664, -3.051279067993164, 1.545557975769043, 3.989176034927368, 1.1309452056884766, 3.434978723526001, -3.713548421859741, -1.5758121013641357, -6.003352165222168, -7.85658073425293, 23.313125610351562, 0.9504060745239258, -5.039295196533203, -0.2558631896972656, -0.18483400344848633, 1.9500446319580078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.932205200195312, "min_q": -2.0269291400909424, "max_q": 27.196245193481445, "mean_td_error": -0.9059136509895325, "model": {}}, "td_error": [-4.505916595458984, 5.871335029602051, 0.511322021484375, -1.3734378814697266, -1.2134513854980469, 0.9311866760253906, -6.486342906951904, 0.25380516052246094, 0.9714317321777344, 4.065826416015625, -10.328704833984375, -4.524137496948242, 0.4278535842895508, 0.49952030181884766, 0.3242371082305908, 0.2403106689453125, 11.937447547912598, 1.0261554718017578, -9.585437774658203, -0.06206321716308594, -2.5919265747070312, -0.22643470764160156, 2.164740562438965, 1.9780292510986328, 0.16765403747558594, -1.0269291400909424, 0.5706825256347656, 0.7455234527587891, -0.16449928283691406, -15.49966812133789, -3.150419235229492, -0.9369282722473145], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 10.904045104980469, "min_q": -2.440326452255249, "max_q": 28.034164428710938, "mean_td_error": -1.181449055671692, "model": {}}, "td_error": [-0.23720788955688477, -0.3842421770095825, -4.391795635223389, 2.196868896484375, -0.19935953617095947, -6.793454170227051, -1.8561897277832031, -1.9281196594238281, -0.28100043535232544, 2.3468401432037354, 0.4018726348876953, -0.9441585540771484, -3.3569068908691406, -5.956193923950195, 0.5536116361618042, 0.2327413558959961, -0.15485191345214844, -0.2301807403564453, 0.9907407760620117, -0.41098976135253906, -5.463376998901367, 0.6629056930541992, -2.4772567749023438, -0.7788372039794922, 0.3743003010749817, 0.8199672698974609, 0.38324034214019775, -5.2640228271484375, -0.9829540252685547, -0.9059715270996094, 0.41846680641174316, -4.190854549407959], "custom_metrics": {}}}, "num_steps_sampled": 44352, "num_agent_steps_sampled": 133056, "num_steps_trained": 86720, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 260160, "last_target_update_ts": 44016, "num_target_updates": 85}, "done": false, "episodes_total": 4432, "training_iteration": 44, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-52-01", "timestamp": 1648914721, "time_this_iter_s": 39.70823645591736, "time_total_s": 1746.4292876720428, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1746.4292876720428, "timesteps_since_restore": 1408, "iterations_since_restore": 44, "perf": {"cpu_util_percent": 51.68771929824561, "ram_util_percent": 65.7701754385965}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 81.63461538461539, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 27.21153846153846, "policy1": 27.21153846153846, "policy2": 27.21153846153846}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 90.0, 60.0, 90.0, 60.0, 90.0, 120.0, 90.0, 30.0, 90.0, 60.0, 60.0, 30.0, 120.0, 90.0, 90.0, 0.0, 90.0, 90.0, 120.0, 120.0, 90.0, 30.0, 90.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 30.0, 120.0, 90.0, 60.0, 90.0, 120.0, 120.0, 90.0, 30.0, 120.0, 60.0, 90.0, 30.0, 90.0, 90.0, 90.0, 90.0, 150.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 0.0, 30.0, 90.0, 90.0, 60.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 120.0, 30.0, 120.0, 60.0, 60.0, 60.0, 0.0, 30.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0, 60.0, 90.0, 90.0, 120.0, 120.0, 60.0, 120.0, 90.0, 30.0, 90.0, 120.0, 120.0, 90.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 0.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 0.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0], "policy_policy1_reward": [30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 0.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 0.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0], "policy_policy2_reward": [30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 20.0, 20.0, 10.0, 40.0, 30.0, 30.0, 0.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 0.0, 10.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 40.0, 10.0, 40.0, 20.0, 20.0, 20.0, 0.0, 10.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0462310639820278, "mean_inference_ms": 26.03205339207072, "mean_action_processing_ms": 0.2476863314073013, "mean_env_wait_ms": 0.1393688091913467, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 45360, "timesteps_this_iter": 32, "agent_timesteps_total": 136080, "timers": {"load_time_ms": 0.77, "load_throughput": 41534.188, "learn_time_ms": 249.391, "learn_throughput": 128.313, "update_time_ms": 110.856}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.845999717712402, "min_q": -0.4909859895706177, "max_q": 35.74697494506836, "mean_td_error": -0.5249930620193481, "model": {}}, "td_error": [-2.068075180053711, -2.176759719848633, 1.6269092559814453, 1.3432159423828125, -0.3813580274581909, -0.7484269142150879, -4.481344223022461, 0.8034696578979492, 2.3352198600769043, -0.8472080230712891, -0.7481365203857422, -2.3158206939697266, 0.031056761741638184, -1.9720783233642578, -1.4845733642578125, -1.7925395965576172, -1.9643220901489258, -5.569819450378418, 7.812376499176025, -3.0170536041259766, -2.176759719848633, 7.493810653686523, 0.7718048095703125, -1.8469867706298828, 0.9382381439208984, 0.16458702087402344, 1.4083194732666016, -2.2651267051696777, -1.8307247161865234, -6.010162353515625, 3.494131088256836, -1.3256397247314453], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.82818603515625, "min_q": 1.467697024345398, "max_q": 29.092700958251953, "mean_td_error": 0.8772697448730469, "model": {}}, "td_error": [0.2886228561401367, 23.351308822631836, 4.242095947265625, -1.4087047576904297, -1.354034423828125, 0.5995960235595703, 1.231870174407959, -6.574631690979004, 0.917241096496582, 1.51019287109375, 1.1900444030761719, 0.19994163513183594, 4.360519886016846, 5.0006022453308105, 1.2119178771972656, 4.134950637817383, 2.6296873092651367, -0.6458625793457031, 0.3526191711425781, 2.7702674865722656, 0.8629531860351562, -10.318368911743164, -1.4981231689453125, 1.7866227626800537, -5.90396785736084, -1.432363510131836, 3.6787166595458984, -4.8799638748168945, 2.3294477462768555, 2.3157739639282227, -1.196817398071289, -1.6795220375061035], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.466691970825195, "min_q": -2.633457899093628, "max_q": 27.504819869995117, "mean_td_error": 1.068252682685852, "model": {}}, "td_error": [1.32288658618927, 0.7805325984954834, 0.5145249366760254, 1.733222484588623, 0.65733802318573, -6.423604965209961, -0.6156082153320312, 1.5710639953613281, -0.289318323135376, -5.365591049194336, 2.447340726852417, 0.4003944396972656, -1.3856048583984375, -2.6520767211914062, 12.161050796508789, 0.8851222991943359, -0.40471649169921875, -2.8621387481689453, 10.613482475280762, 4.152198314666748, 1.2836990356445312, 0.48299312591552734, 0.6779332160949707, 0.11415481567382812, 1.8101589679718018, 12.134956359863281, 0.6507358551025391, -0.10964488983154297, -0.5011749267578125, -6.57166862487793, 0.14396703243255615, 6.827479362487793], "custom_metrics": {}}}, "num_steps_sampled": 45360, "num_agent_steps_sampled": 136080, "num_steps_trained": 88736, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 266208, "last_target_update_ts": 45040, "num_target_updates": 87}, "done": false, "episodes_total": 4536, "training_iteration": 45, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-52-42", "timestamp": 1648914762, "time_this_iter_s": 40.88629126548767, "time_total_s": 1787.3155789375305, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e34d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7e34d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1787.3155789375305, "timesteps_since_restore": 1440, "iterations_since_restore": 45, "perf": {"cpu_util_percent": 52.865517241379315, "ram_util_percent": 65.9448275862069}}
{"episode_reward_max": 150.0, "episode_reward_min": -30.0, "episode_reward_mean": 76.5, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 25.5, "policy1": 25.5, "policy2": 25.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 60.0, 60.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 0.0, 120.0, 120.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 120.0, 60.0, 60.0, 90.0, 60.0, 60.0, 90.0, 120.0, 120.0, 60.0, 90.0, 60.0, 120.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 60.0, 30.0, 30.0, 120.0, 120.0, 90.0, 90.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 90.0, 90.0, 90.0, 90.0, -30.0, 30.0, 90.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 120.0, 30.0, 120.0, 60.0, 30.0, 60.0, 30.0, 90.0, 60.0, 150.0, 90.0, 60.0, 120.0, 60.0, 60.0, 120.0, 120.0, 120.0, 60.0, 60.0, 120.0, 60.0, 120.0, 30.0, 30.0, 60.0, 60.0, 60.0, 90.0, 30.0, 60.0, 120.0, -30.0, 150.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 0.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 40.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 50.0, 30.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 20.0, 40.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, -10.0, 50.0, 10.0], "policy_policy1_reward": [30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 0.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 40.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 50.0, 30.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 20.0, 40.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, -10.0, 50.0, 10.0], "policy_policy2_reward": [30.0, 20.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 0.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 30.0, 20.0, 20.0, 30.0, 40.0, 40.0, 20.0, 30.0, 20.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 20.0, 10.0, 10.0, 40.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 10.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 10.0, 40.0, 20.0, 10.0, 20.0, 10.0, 30.0, 20.0, 50.0, 30.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 20.0, 40.0, 10.0, 10.0, 20.0, 20.0, 20.0, 30.0, 10.0, 20.0, 40.0, -10.0, 50.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0468047666537343, "mean_inference_ms": 26.040039779832878, "mean_action_processing_ms": 0.2477731663991757, "mean_env_wait_ms": 0.1394771412882578, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 46368, "timesteps_this_iter": 32, "agent_timesteps_total": 139104, "timers": {"load_time_ms": 0.611, "load_throughput": 52336.802, "learn_time_ms": 229.528, "learn_throughput": 139.417, "update_time_ms": 96.306}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.048452377319336, "min_q": 0.3667732775211334, "max_q": 34.90868377685547, "mean_td_error": 0.5937243700027466, "model": {}}, "td_error": [3.31988525390625, -0.644505500793457, 1.021733283996582, 0.40633392333984375, 2.026958703994751, -2.422593116760254, 0.7251815795898438, -0.17984390258789062, -0.3099050521850586, 0.9522078037261963, -1.1248502731323242, -3.1622886657714844, 1.3053550720214844, 0.2710075378417969, -0.7391777038574219, 21.459705352783203, -0.5775960683822632, -1.4042701721191406, 1.714156150817871, 0.0001773834228515625, -6.475264549255371, -0.7162933349609375, 9.752791404724121, 1.216109275817871, -1.4740304946899414, -1.3729424476623535, -1.6590900421142578, -1.6093263626098633, -0.4793848991394043, -0.061374664306640625, -2.5259552001953125, 1.7662677764892578], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.004156112670898, "min_q": -3.723574638366699, "max_q": 28.82305145263672, "mean_td_error": 0.3956162929534912, "model": {}}, "td_error": [-0.2572460174560547, -1.462259292602539, 1.16282320022583, 1.9747028350830078, 0.9285707473754883, -1.448202133178711, 2.603670120239258, 1.3160936832427979, 3.1959152221679688, -0.3628406524658203, 14.021495819091797, 1.230574607849121, 0.4542703628540039, -9.096190452575684, 6.139725208282471, 0.7555656433105469, 1.5937252044677734, -0.6501007080078125, 0.7096881866455078, 1.4764137268066406, -2.496659278869629, -3.6395559310913086, -5.194042205810547, -14.068878173828125, 0.9509124755859375, -2.943574905395508, -0.5237827301025391, 7.663061618804932, 2.3217763900756836, -0.4252939224243164, 2.7423858642578125, 3.986978054046631], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.750334739685059, "min_q": -1.8960678577423096, "max_q": 28.206472396850586, "mean_td_error": -1.6407999992370605, "model": {}}, "td_error": [-0.8960678577423096, 2.0459442138671875, 3.6308212280273438, 2.9800052642822266, -8.837844848632812, -8.834102630615234, -6.197580337524414, -7.030054092407227, 0.622833251953125, -6.295372009277344, -4.255924224853516, -4.000859260559082, -0.08485603332519531, 1.2867240905761719, -0.5407161712646484, 1.1873397827148438, 9.277774810791016, 0.7907896041870117, -3.3961009979248047, -1.9852418899536133, -3.098773956298828, -0.3092641830444336, -4.75367546081543, -3.235361099243164, -3.697874069213867, -6.1526594161987305, -6.625801086425781, 4.690038681030273, -1.8800954818725586, 1.7781486511230469, 1.2086186408996582, 0.10359001159667969], "custom_metrics": {}}}, "num_steps_sampled": 46368, "num_agent_steps_sampled": 139104, "num_steps_trained": 90752, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 272256, "last_target_update_ts": 46064, "num_target_updates": 89}, "done": false, "episodes_total": 4636, "training_iteration": 46, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-53-23", "timestamp": 1648914803, "time_this_iter_s": 40.58325457572937, "time_total_s": 1827.89883351326, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b0440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b0440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1827.89883351326, "timesteps_since_restore": 1472, "iterations_since_restore": 46, "perf": {"cpu_util_percent": 51.66379310344828, "ram_util_percent": 66.12931034482757}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 78.0, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 26.0, "policy1": 26.0, "policy2": 26.0}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 90.0, 30.0, 90.0, 120.0, 90.0, 120.0, 120.0, 120.0, 60.0, 90.0, 90.0, 90.0, 120.0, 60.0, 150.0, 60.0, 90.0, 90.0, 90.0, 90.0, 120.0, 60.0, 60.0, 90.0, 60.0, 90.0, 0.0, 60.0, 30.0, 60.0, 90.0, 90.0, 60.0, 60.0, 60.0, 120.0, 90.0, 60.0, 60.0, 90.0, 60.0, 60.0, 120.0, 90.0, 90.0, 90.0, 90.0, 90.0, 90.0, 30.0, 120.0, 90.0, 60.0, 60.0, 90.0, 30.0, 90.0, 90.0, 90.0, 60.0, 0.0, 60.0, 60.0, 60.0, 60.0, 30.0, 30.0, 90.0, 60.0, 90.0, 90.0, 30.0, 90.0, 30.0, 60.0, 120.0, 90.0, 120.0, 90.0, 90.0, 60.0, 90.0, 120.0, 90.0, 90.0, 90.0, 90.0, 90.0, 120.0, 30.0, 90.0, 120.0, 90.0, 30.0, 90.0, 120.0, 60.0, 60.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 30.0, 10.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 20.0, 50.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 0.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 10.0, 30.0, 40.0, 30.0, 10.0, 30.0, 40.0, 20.0, 20.0, 10.0], "policy_policy1_reward": [10.0, 30.0, 10.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 20.0, 50.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 0.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 10.0, 30.0, 40.0, 30.0, 10.0, 30.0, 40.0, 20.0, 20.0, 10.0], "policy_policy2_reward": [10.0, 30.0, 10.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 20.0, 50.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 0.0, 20.0, 10.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 30.0, 10.0, 40.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 20.0, 10.0, 10.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 10.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 10.0, 30.0, 40.0, 30.0, 10.0, 30.0, 40.0, 20.0, 20.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0461573612845965, "mean_inference_ms": 26.01928418072128, "mean_action_processing_ms": 0.24772241378243137, "mean_env_wait_ms": 0.13959032918592704, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 47376, "timesteps_this_iter": 32, "agent_timesteps_total": 142128, "timers": {"load_time_ms": 0.724, "load_throughput": 44175.272, "learn_time_ms": 236.918, "learn_throughput": 135.068, "update_time_ms": 104.352}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.520414352416992, "min_q": 0.1204344630241394, "max_q": 35.4970703125, "mean_td_error": 0.5739845037460327, "model": {}}, "td_error": [2.114344835281372, -4.145768642425537, 0.22097015380859375, -0.5205525159835815, -2.177809715270996, 1.523667335510254, 0.6989141702651978, 1.4814224243164062, -1.6242408752441406, -0.3444347381591797, 20.292999267578125, -2.2547969818115234, -2.1352310180664062, 0.6474027633666992, 1.8169021606445312, 0.8208127021789551, -0.5940876007080078, 0.9625225067138672, 0.5272369384765625, -0.21483421325683594, 1.2381019592285156, -1.0455207824707031, -0.7886142730712891, -0.08221292495727539, 1.7704877853393555, -0.6221749782562256, 2.4511966705322266, -1.3891658782958984, 0.31865692138671875, 0.5566778182983398, 0.02280426025390625, -1.158172607421875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.780052185058594, "min_q": -1.1885398626327515, "max_q": 28.136648178100586, "mean_td_error": -0.40549778938293457, "model": {}}, "td_error": [3.2511532306671143, 0.2053183913230896, -2.2020483016967773, -5.89992618560791, -0.1869964599609375, -0.5898027420043945, 2.177450656890869, 1.4737567901611328, 1.8073997497558594, -4.838775634765625, 1.3972034454345703, 1.0779609680175781, 1.6277523040771484, -3.0104007720947266, 15.093632698059082, -12.269512176513672, 0.6587028503417969, -0.18853986263275146, 2.242969512939453, 0.0055332183837890625, -0.706787109375, -1.6704692840576172, -4.976076126098633, -2.2824325561523438, -5.02385139465332, -2.8407745361328125, 1.5748519897460938, 10.82824993133545, 0.035994529724121094, -6.344921112060547, 1.3124942779541016, -4.71504020690918], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.811174392700195, "min_q": -2.084596633911133, "max_q": 28.725914001464844, "mean_td_error": -1.4746649265289307, "model": {}}, "td_error": [-3.4228553771972656, 0.2916860580444336, -5.667118072509766, 0.47920918464660645, -0.15641212463378906, 0.7182350158691406, 1.2067623138427734, -8.681936264038086, 4.138910293579102, -3.5920257568359375, -2.0754337310791016, 1.2572532892227173, 0.6352767944335938, -1.8284573554992676, -1.7734651565551758, -5.455519676208496, -1.0351123809814453, -0.6792373657226562, -3.94345760345459, -1.0845966339111328, -7.997399806976318, 0.631443977355957, -5.171810150146484, -4.6339263916015625, -4.360489368438721, -3.7941389083862305, 0.995213508605957, 1.9316291809082031, 2.3561315536499023, 11.477540969848633, -7.885866165161133, -0.06931781768798828], "custom_metrics": {}}}, "num_steps_sampled": 47376, "num_agent_steps_sampled": 142128, "num_steps_trained": 92768, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 278304, "last_target_update_ts": 47088, "num_target_updates": 91}, "done": false, "episodes_total": 4736, "training_iteration": 47, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-54-02", "timestamp": 1648914842, "time_this_iter_s": 38.8914897441864, "time_total_s": 1866.7903232574463, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b0680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b0680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1866.7903232574463, "timesteps_since_restore": 1504, "iterations_since_restore": 47, "perf": {"cpu_util_percent": 52.07636363636364, "ram_util_percent": 65.62727272727273}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 84.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 28.3, "policy1": 28.3, "policy2": 28.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 90.0, 30.0, 60.0, 90.0, 90.0, 90.0, 150.0, 120.0, 60.0, 90.0, 90.0, 30.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 30.0, 30.0, 30.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 120.0, 150.0, 150.0, 60.0, 30.0, 60.0, 120.0, 90.0, 150.0, 90.0, 90.0, 120.0, 120.0, 60.0, 60.0, 120.0, 90.0, 60.0, 120.0, 90.0, 90.0, 60.0, 120.0, 120.0, 30.0, 120.0, 60.0, 120.0, 120.0, 90.0, 30.0, 90.0, 90.0, 120.0, 90.0, 150.0, 90.0, 90.0, 0.0, 60.0, 0.0, 120.0, 60.0, 90.0, 90.0, 60.0, 60.0, 30.0, 90.0, 60.0, 90.0, 90.0, 120.0, 60.0, 60.0, 90.0, 120.0, 90.0, 60.0, 90.0, 120.0, 90.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 30.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 30.0, 30.0, 50.0, 40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 50.0, 50.0, 20.0, 10.0, 20.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 0.0, 20.0, 0.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 10.0, 20.0, 30.0], "policy_policy1_reward": [20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 30.0, 30.0, 50.0, 40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 50.0, 50.0, 20.0, 10.0, 20.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 0.0, 20.0, 0.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 10.0, 20.0, 30.0], "policy_policy2_reward": [20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 30.0, 30.0, 50.0, 40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 40.0, 50.0, 50.0, 20.0, 10.0, 20.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 40.0, 10.0, 40.0, 20.0, 40.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 0.0, 20.0, 0.0, 40.0, 20.0, 30.0, 30.0, 20.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 10.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0463689894501587, "mean_inference_ms": 26.01806751566405, "mean_action_processing_ms": 0.2478014745820284, "mean_env_wait_ms": 0.13966364555835056, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 48384, "timesteps_this_iter": 32, "agent_timesteps_total": 145152, "timers": {"load_time_ms": 0.654, "load_throughput": 48914.949, "learn_time_ms": 235.409, "learn_throughput": 135.934, "update_time_ms": 102.543}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.72365379333496, "min_q": 0.8306416869163513, "max_q": 35.88533401489258, "mean_td_error": 1.188114881515503, "model": {}}, "td_error": [0.1573944091796875, -0.3451671600341797, -2.230304718017578, -1.487161636352539, -0.7409782409667969, 0.6116118431091309, 0.2336883544921875, 1.31549072265625, -6.515819549560547, 0.5711755752563477, -0.6246833801269531, 0.09831809997558594, 1.3234033584594727, 1.605072021484375, 1.3109283447265625, -3.4469032287597656, -1.2831459045410156, -1.4262256622314453, 1.2315726280212402, -2.2131614685058594, 1.091644287109375, -0.11259651184082031, 0.5945510864257812, 3.7925243377685547, 17.934547424316406, -3.6123428344726562, -0.3421974182128906, 15.10615062713623, 14.593052864074707, -0.8050804138183594, 1.1228599548339844, 0.5114574432373047], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.426358222961426, "min_q": 1.0148708820343018, "max_q": 31.00741958618164, "mean_td_error": 0.4753895401954651, "model": {}}, "td_error": [0.6468677520751953, 0.4723033905029297, 1.1610755920410156, -0.10061264038085938, 3.2094459533691406, 4.398176193237305, 3.6564197540283203, 0.8921031951904297, 1.273721694946289, 0.25026893615722656, 1.8173637390136719, 1.5745067596435547, -1.1048345565795898, -2.3174705505371094, 2.046389102935791, 9.584579467773438, -0.05186939239501953, -0.7089865207672119, 1.5383710861206055, -0.7255592346191406, 2.0685205459594727, -0.1953105926513672, -5.629291534423828, 2.4149208068847656, -7.0920610427856445, -3.8185787200927734, -0.743927001953125, -1.6816844940185547, 1.1851749420166016, 6.024874687194824, -0.942901611328125, -3.8895301818847656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.42520523071289, "min_q": -0.8245782852172852, "max_q": 27.19825553894043, "mean_td_error": -0.394708514213562, "model": {}}, "td_error": [0.5984869003295898, 7.496343612670898, -0.5424156188964844, -0.9478788375854492, 0.7363204956054688, -0.4088771343231201, 1.2073405981063843, -2.5139598846435547, -2.1999287605285645, -1.712554931640625, -1.3811416625976562, 1.4522556066513062, -4.429383277893066, -8.99815559387207, -7.154799461364746, 0.453008770942688, 0.4853353500366211, 1.4246654510498047, -2.247190475463867, -1.2970714569091797, 0.820220947265625, -0.8385848999023438, 19.546659469604492, 0.196039080619812, 0.37529945373535156, 0.17542171478271484, 3.4965896606445312, -7.9708356857299805, -3.1397705078125, -1.8549747467041016, 0.6731662750244141, -4.130302429199219], "custom_metrics": {}}}, "num_steps_sampled": 48384, "num_agent_steps_sampled": 145152, "num_steps_trained": 94784, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 284352, "last_target_update_ts": 48112, "num_target_updates": 93}, "done": false, "episodes_total": 4836, "training_iteration": 48, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-54-42", "timestamp": 1648914882, "time_this_iter_s": 39.934178590774536, "time_total_s": 1906.7245018482208, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1906.7245018482208, "timesteps_since_restore": 1536, "iterations_since_restore": 48, "perf": {"cpu_util_percent": 52.650877192982456, "ram_util_percent": 66.18245614035087}}
{"episode_reward_max": 150.0, "episode_reward_min": -30.0, "episode_reward_mean": 80.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 26.9, "policy1": 26.9, "policy2": 26.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 90.0, 60.0, 30.0, 60.0, 60.0, 90.0, 90.0, 60.0, 30.0, 90.0, 60.0, 120.0, 120.0, 90.0, 90.0, 120.0, 60.0, 60.0, 90.0, 90.0, 60.0, 90.0, 120.0, 60.0, 90.0, 120.0, 90.0, 30.0, 90.0, 90.0, 60.0, 0.0, 60.0, 60.0, 60.0, 90.0, 120.0, 60.0, 90.0, 90.0, 90.0, 120.0, 90.0, 90.0, 120.0, 60.0, 60.0, 60.0, 90.0, -30.0, 60.0, 90.0, 60.0, 120.0, 60.0, 120.0, 90.0, 90.0, 120.0, 150.0, 90.0, 90.0, 120.0, 60.0, 60.0, 150.0, 60.0, 60.0, 60.0, 90.0, 120.0, 120.0, 90.0, 0.0, 60.0, 60.0, 60.0, 120.0, 90.0, 90.0, 0.0, 60.0, 60.0, 90.0, 60.0, 60.0, 60.0, 120.0, 60.0, 60.0, 120.0, 120.0, 90.0, 90.0, 60.0, 60.0, 120.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 30.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 30.0, -10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 0.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 30.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 30.0, -10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 0.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 30.0, 20.0, 10.0, 20.0, 20.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 40.0, 30.0, 10.0, 30.0, 30.0, 20.0, 0.0, 20.0, 20.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0, 30.0, -10.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 0.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 0.0, 20.0, 20.0, 30.0, 20.0, 20.0, 20.0, 40.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0457649888543623, "mean_inference_ms": 25.998497662809523, "mean_action_processing_ms": 0.24766031088872664, "mean_env_wait_ms": 0.13960568139751736, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 49392, "timesteps_this_iter": 32, "agent_timesteps_total": 148176, "timers": {"load_time_ms": 0.646, "load_throughput": 49567.076, "learn_time_ms": 225.289, "learn_throughput": 142.04, "update_time_ms": 96.542}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.87618064880371, "min_q": -0.17577695846557617, "max_q": 36.32927703857422, "mean_td_error": 1.4870314598083496, "model": {}}, "td_error": [-0.1983318328857422, -4.881587028503418, -1.2201995849609375, 1.8212671279907227, 4.178581237792969, -0.5134391784667969, 7.290426254272461, -0.6114120483398438, -0.9478588104248047, -0.1667323112487793, -0.9890966415405273, -1.17498779296875, 1.1973962783813477, 0.149505615234375, -0.7930126190185547, 0.42513972520828247, 0.4474029541015625, -3.026355266571045, 3.6744487285614014, -2.266543388366699, -3.477916717529297, -0.3550605773925781, -0.6375744342803955, 2.400904655456543, 8.725564956665039, 17.111949920654297, -0.9099273681640625, -1.3031330108642578, 1.0474624633789062, 8.60519027709961, 14.125053405761719, -0.142120361328125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.463144302368164, "min_q": -2.029940128326416, "max_q": 28.334121704101562, "mean_td_error": 0.15413233637809753, "model": {}}, "td_error": [0.4227943420410156, 1.3496625423431396, 9.771051406860352, -3.6520423889160156, 1.3811016082763672, -0.5045309066772461, 0.9238867163658142, -0.581965446472168, -0.04586935043334961, -0.9273052215576172, 4.120014190673828, 2.4175915718078613, -3.8904924392700195, 4.200209617614746, 2.117645263671875, 1.7005805969238281, -1.722219467163086, -5.929540634155273, -2.0642757415771484, -1.276496410369873, -8.177719116210938, -4.450376510620117, -1.856886863708496, -0.8746356964111328, 0.8776558637619019, 2.4569969177246094, 1.0591082572937012, -1.5805721282958984, 0.689936637878418, -3.3260488510131836, 12.108160972595215, 0.19681453704833984], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 11.672996520996094, "min_q": -0.3772761821746826, "max_q": 28.366355895996094, "mean_td_error": 0.7649939656257629, "model": {}}, "td_error": [-8.476016998291016, -4.134326934814453, 1.8477001190185547, -0.09444904327392578, 1.1934242248535156, -0.29618263244628906, 7.60711669921875, 1.8456964492797852, 2.7101821899414062, 1.808283805847168, -0.8773574829101562, 0.15983200073242188, -7.900268077850342, 0.6098650097846985, 17.071544647216797, -3.690500259399414, -7.324027061462402, 0.8878157138824463, 3.6227364540100098, 3.474029064178467, 2.764542579650879, 0.05161571502685547, 1.1927776336669922, -7.287076950073242, 6.306049346923828, 1.4856624603271484, 1.4209377765655518, 0.7422306537628174, 3.3225955963134766, 1.4937405586242676, -2.24188232421875, 5.183515548706055], "custom_metrics": {}}}, "num_steps_sampled": 49392, "num_agent_steps_sampled": 148176, "num_steps_trained": 96800, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 290400, "last_target_update_ts": 49136, "num_target_updates": 95}, "done": false, "episodes_total": 4936, "training_iteration": 49, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-55-21", "timestamp": 1648914921, "time_this_iter_s": 38.695308685302734, "time_total_s": 1945.4198105335236, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c78be60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c78be60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1945.4198105335236, "timesteps_since_restore": 1568, "iterations_since_restore": 49, "perf": {"cpu_util_percent": 51.661111111111104, "ram_util_percent": 65.69444444444446}}
{"episode_reward_max": 120.0, "episode_reward_min": 0.0, "episode_reward_mean": 80.48076923076923, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_mean": {"policy0": 26.826923076923077, "policy1": 26.826923076923077, "policy2": 26.826923076923077}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 120.0, 90.0, 90.0, 60.0, 30.0, 120.0, 60.0, 120.0, 90.0, 60.0, 90.0, 60.0, 120.0, 120.0, 60.0, 90.0, 90.0, 30.0, 60.0, 90.0, 60.0, 90.0, 90.0, 60.0, 60.0, 60.0, 60.0, 120.0, 60.0, 90.0, 120.0, 60.0, 0.0, 60.0, 90.0, 30.0, 60.0, 120.0, 60.0, 60.0, 60.0, 90.0, 90.0, 120.0, 90.0, 60.0, 60.0, 60.0, 90.0, 90.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 60.0, 60.0, 120.0, 90.0, 30.0, 60.0, 120.0, 90.0, 90.0, 120.0, 60.0, 90.0, 30.0, 120.0, 0.0, 90.0, 60.0, 90.0, 60.0, 60.0, 120.0, 120.0, 60.0, 90.0, 120.0, 90.0, 60.0, 120.0, 90.0, 120.0, 60.0, 120.0, 120.0, 60.0, 120.0, 60.0, 60.0, 60.0, 90.0, 120.0, 90.0, 90.0, 90.0, 60.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 40.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 20.0, 30.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0], "policy_policy1_reward": [20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 40.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 20.0, 30.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0], "policy_policy2_reward": [20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 20.0, 30.0, 30.0, 10.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 0.0, 20.0, 30.0, 10.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 10.0, 20.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 10.0, 40.0, 0.0, 30.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 20.0, 30.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 20.0, 40.0, 40.0, 20.0, 40.0, 20.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 20.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0453679052461433, "mean_inference_ms": 25.986669068487473, "mean_action_processing_ms": 0.24756713288519627, "mean_env_wait_ms": 0.13957456618715364, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 50400, "timesteps_this_iter": 32, "agent_timesteps_total": 151200, "timers": {"load_time_ms": 0.617, "load_throughput": 51829.521, "learn_time_ms": 227.325, "learn_throughput": 140.768, "update_time_ms": 96.429}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.718870162963867, "min_q": -2.230781316757202, "max_q": 35.97511672973633, "mean_td_error": -0.3219999670982361, "model": {}}, "td_error": [2.6033782958984375, -0.24110031127929688, -5.818648338317871, -4.169093132019043, 0.3254432678222656, -1.2436747550964355, -2.9189796447753906, -1.9647407531738281, 2.4315032958984375, -1.1866798400878906, -0.45599365234375, -1.947662353515625, 0.32457733154296875, -0.36724853515625, 0.02896881103515625, 1.439596176147461, 1.1509857177734375, -1.2571697235107422, -0.23524093627929688, 1.2330760955810547, 1.9236412048339844, 0.6877646446228027, -2.1861000061035156, 0.5876331329345703, 1.2273712158203125, -2.497182846069336, 1.435739517211914, 0.2662785053253174, 1.2004871368408203, -1.3935165405273438, 2.005107879638672, -1.2925195693969727], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.925896644592285, "min_q": -0.3379693627357483, "max_q": 29.75581169128418, "mean_td_error": 0.6076094508171082, "model": {}}, "td_error": [-3.559725761413574, -6.545148849487305, 0.8303775787353516, -3.107166290283203, 1.6829757690429688, 0.35836219787597656, 0.6620306372642517, 1.2306861877441406, 0.4740865230560303, -5.217569351196289, 13.002439498901367, -0.8351602554321289, -3.6640987396240234, -0.935051441192627, -1.2256126403808594, -1.9865097999572754, 7.044993877410889, 2.9890222549438477, 0.858673095703125, 3.8980984687805176, 0.2662487030029297, 5.37956428527832, 1.0058937072753906, 0.40594911575317383, 1.9201443195343018, -5.723167419433594, 13.279953002929688, -2.6966638565063477, -0.8254051208496094, 1.5330525636672974, -1.5082149505615234, 0.45044517517089844], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 13.360466003417969, "min_q": -1.6382598876953125, "max_q": 30.277427673339844, "mean_td_error": 0.3177174925804138, "model": {}}, "td_error": [-1.0791292190551758, -3.611574172973633, 0.9183998107910156, -0.6878767013549805, -1.1001644134521484, 1.1617584228515625, -1.3354110717773438, 3.230226516723633, 0.9126071929931641, -0.9149370193481445, 0.4319171905517578, 3.235872268676758, 3.439912796020508, 1.327688217163086, 4.66229248046875, 1.6441243886947632, -0.6382598876953125, 1.0123004913330078, 2.2420835494995117, -3.631610870361328, -0.03906428813934326, -9.590348243713379, 11.468549728393555, -4.1958537101745605, 0.43534278869628906, 0.13231945037841797, 1.4567770957946777, -2.281747817993164, 5.072267532348633, -0.13133811950683594, -6.589069843292236, 3.208904266357422], "custom_metrics": {}}}, "num_steps_sampled": 50400, "num_agent_steps_sampled": 151200, "num_steps_trained": 98816, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 296448, "last_target_update_ts": 50160, "num_target_updates": 97}, "done": false, "episodes_total": 5040, "training_iteration": 50, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-56-00", "timestamp": 1648914960, "time_this_iter_s": 38.82775855064392, "time_total_s": 1984.2475690841675, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a8b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a8b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 1984.2475690841675, "timesteps_since_restore": 1600, "iterations_since_restore": 50, "perf": {"cpu_util_percent": 52.216363636363646, "ram_util_percent": 65.51818181818182}}
{"episode_reward_max": 150.0, "episode_reward_min": -30.0, "episode_reward_mean": 85.5, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": -10.0, "policy1": -10.0, "policy2": -10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 28.5, "policy1": 28.5, "policy2": 28.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 60.0, 120.0, 30.0, 150.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 90.0, 90.0, 120.0, 60.0, 90.0, 90.0, 90.0, 60.0, 30.0, 90.0, 60.0, 90.0, 90.0, 120.0, 90.0, 120.0, 90.0, 60.0, 90.0, 60.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 60.0, 90.0, 120.0, 30.0, 60.0, 60.0, 90.0, 90.0, 90.0, 90.0, -30.0, 90.0, 120.0, 150.0, 60.0, 60.0, 90.0, 120.0, 120.0, 150.0, 60.0, 90.0, 120.0, 60.0, 120.0, 30.0, 60.0, 60.0, 90.0, 60.0, 60.0, 120.0, 120.0, 90.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 90.0, 30.0, 60.0, 60.0, 60.0, 90.0, 120.0, 120.0, 120.0, 30.0, 150.0, 30.0, 90.0, 90.0, 60.0, 30.0, 60.0, 90.0, 120.0, 30.0, 120.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 30.0, 40.0, 50.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 30.0, 40.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 40.0, 10.0, 50.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 30.0, 40.0, 10.0, 40.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 30.0, 40.0, 50.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 30.0, 40.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 40.0, 10.0, 50.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 30.0, 40.0, 10.0, 40.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 30.0, 30.0, 20.0, 10.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 20.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 30.0, 30.0, 30.0, -10.0, 30.0, 40.0, 50.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 30.0, 40.0, 20.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 30.0, 10.0, 20.0, 20.0, 20.0, 30.0, 40.0, 40.0, 40.0, 10.0, 50.0, 10.0, 30.0, 30.0, 20.0, 10.0, 20.0, 30.0, 40.0, 10.0, 40.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0454042323468713, "mean_inference_ms": 25.98509011839574, "mean_action_processing_ms": 0.24755300366627167, "mean_env_wait_ms": 0.13955346361761434, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 51408, "timesteps_this_iter": 32, "agent_timesteps_total": 154224, "timers": {"load_time_ms": 0.633, "load_throughput": 50524.272, "learn_time_ms": 233.179, "learn_throughput": 137.234, "update_time_ms": 105.807}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.957061767578125, "min_q": -1.370826005935669, "max_q": 37.48704147338867, "mean_td_error": -0.7139841318130493, "model": {}}, "td_error": [-0.37082600593566895, -0.1676197052001953, -10.364858627319336, 2.762734889984131, 0.5185697078704834, -0.2398977279663086, 0.9183635711669922, 0.9348487854003906, 1.3066253662109375, -5.085023880004883, -4.0862250328063965, -2.356241226196289, -0.5538902282714844, 0.8706405162811279, 0.9191970825195312, 2.4587764739990234, 0.3126029968261719, -0.4259204864501953, -2.9078235626220703, -2.00299072265625, -0.8082036972045898, 0.8108158111572266, 0.7028179168701172, 0.9153366088867188, -1.8949470520019531, 0.5524406433105469, 0.7095813751220703, -0.014186859130859375, 0.9643778800964355, 1.2114639282226562, -12.580105781555176, 4.142074108123779], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.343486785888672, "min_q": -2.2087035179138184, "max_q": 31.833017349243164, "mean_td_error": 1.973151683807373, "model": {}}, "td_error": [14.098631858825684, 3.4568023681640625, 13.747132301330566, 3.8438377380371094, 0.5265440940856934, 2.545891046524048, -8.017061233520508, -1.0331382751464844, 0.17444705963134766, 21.085803985595703, -0.3413562774658203, 0.8818392753601074, 1.6074326038360596, -2.4481964111328125, 2.9703330993652344, -3.3327674865722656, -0.9699010848999023, -0.47078514099121094, -1.8202400207519531, -0.591110110282898, 0.4099388122558594, 5.635234832763672, 0.7417008876800537, -0.3449573516845703, -0.24057579040527344, 2.1190662384033203, -0.1285839080810547, 2.706913471221924, 3.014850616455078, 0.08408206701278687, 2.8194408416748047, 0.4096031188964844], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.599462509155273, "min_q": -1.8629229068756104, "max_q": 32.928558349609375, "mean_td_error": -0.4724363088607788, "model": {}}, "td_error": [0.6644802093505859, 0.8385906219482422, 0.21317291259765625, 2.253366470336914, 1.443835735321045, -4.532825469970703, 1.8583180904388428, -2.4344730377197266, -4.273366928100586, -6.987498760223389, -4.823657989501953, 11.182865142822266, -0.24935150146484375, 0.010730743408203125, 2.6686153411865234, 2.4029617309570312, 1.0484886169433594, -0.21341705322265625, -1.1454029083251953, -0.10742759704589844, 10.866795539855957, -7.525896072387695, -2.8598580360412598, -3.986827850341797, -3.249267578125, -1.6561412811279297, 3.1054744720458984, 3.398372173309326, -1.4143295288085938, -4.5032196044921875, -0.9263114929199219, -6.184758186340332], "custom_metrics": {}}}, "num_steps_sampled": 51408, "num_agent_steps_sampled": 154224, "num_steps_trained": 100832, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 302496, "last_target_update_ts": 51184, "num_target_updates": 99}, "done": false, "episodes_total": 5140, "training_iteration": 51, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-56-39", "timestamp": 1648914999, "time_this_iter_s": 38.93027091026306, "time_total_s": 2023.1778399944305, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a8ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a8ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2023.1778399944305, "timesteps_since_restore": 1632, "iterations_since_restore": 51, "perf": {"cpu_util_percent": 52.3018181818182, "ram_util_percent": 65.35454545454546}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 82.2, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 27.4, "policy1": 27.4, "policy2": 27.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 0.0, 120.0, 90.0, 90.0, 60.0, 30.0, 90.0, 120.0, 90.0, 30.0, 120.0, 120.0, 150.0, 120.0, 120.0, 90.0, 30.0, 30.0, 90.0, 120.0, 30.0, 0.0, 60.0, 60.0, 30.0, 90.0, 120.0, 120.0, 90.0, 120.0, 120.0, 60.0, 120.0, 150.0, 90.0, 150.0, 30.0, 90.0, 120.0, 120.0, 30.0, 90.0, 90.0, 60.0, 60.0, 60.0, 60.0, 90.0, 120.0, 30.0, 60.0, 60.0, 90.0, 60.0, 120.0, 120.0, 90.0, 60.0, 90.0, 90.0, 120.0, 90.0, 90.0, 30.0, 90.0, 60.0, 30.0, 120.0, 60.0, 120.0, 90.0, 30.0, 90.0, 60.0, 120.0, 120.0, 30.0, 60.0, 60.0, 60.0, 60.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 150.0, 90.0, 60.0, 30.0, 30.0, 90.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 10.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 10.0, 10.0, 30.0, 40.0, 10.0, 0.0, 20.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 40.0, 50.0, 30.0, 50.0, 10.0, 30.0, 40.0, 40.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0], "policy_policy1_reward": [30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 10.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 10.0, 10.0, 30.0, 40.0, 10.0, 0.0, 20.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 40.0, 50.0, 30.0, 50.0, 10.0, 30.0, 40.0, 40.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0], "policy_policy2_reward": [30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 0.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 40.0, 30.0, 10.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 10.0, 10.0, 30.0, 40.0, 10.0, 0.0, 20.0, 20.0, 10.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 40.0, 50.0, 30.0, 50.0, 10.0, 30.0, 40.0, 40.0, 10.0, 30.0, 30.0, 20.0, 20.0, 20.0, 20.0, 30.0, 40.0, 10.0, 20.0, 20.0, 30.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 20.0, 10.0, 40.0, 20.0, 40.0, 30.0, 10.0, 30.0, 20.0, 40.0, 40.0, 10.0, 20.0, 20.0, 20.0, 20.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 20.0, 10.0, 10.0, 30.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0449762473530277, "mean_inference_ms": 25.97290816901976, "mean_action_processing_ms": 0.24761299011771887, "mean_env_wait_ms": 0.13955307570817316, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 52416, "timesteps_this_iter": 32, "agent_timesteps_total": 157248, "timers": {"load_time_ms": 0.674, "load_throughput": 47468.692, "learn_time_ms": 231.722, "learn_throughput": 138.096, "update_time_ms": 95.998}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.246816635131836, "min_q": -0.9678818583488464, "max_q": 35.57124328613281, "mean_td_error": 0.19428811967372894, "model": {}}, "td_error": [-1.4572772979736328, 2.161585569381714, 1.1936883926391602, 2.1305294036865234, -0.6027641296386719, -5.87202262878418, 1.7269783020019531, -2.506317138671875, -0.11652183532714844, -0.8155689239501953, -1.662496566772461, 2.3849451541900635, 0.101898193359375, -1.0891685485839844, 0.39453125, 0.535088837146759, -4.255992889404297, -1.3720836639404297, -2.0704421997070312, -3.376911163330078, -2.584657669067383, 2.7938098907470703, -0.2259979248046875, 12.0244140625, -0.05545318126678467, -0.03819465637207031, -2.522418975830078, -0.3065834045410156, 14.068948745727539, -2.320049285888672, -1.1484265327453613, 1.1001510620117188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.104576110839844, "min_q": -2.3224387168884277, "max_q": 33.48417663574219, "mean_td_error": 1.3259739875793457, "model": {}}, "td_error": [-1.0336036682128906, 3.3835771083831787, -1.4376049041748047, -3.667755126953125, 11.082242012023926, 1.0365276336669922, 0.09899330139160156, 11.557915687561035, 3.4505844116210938, 2.109740734100342, 0.3313484191894531, -2.4370908737182617, 0.8129243850708008, -1.2529041767120361, -1.4861736297607422, 31.25135612487793, 1.0485477447509766, -3.6029891967773438, 1.6113224029541016, -1.7707812786102295, 1.3978761434555054, -1.5487719774246216, -1.3224387168884277, -2.0698299407958984, 1.8483831882476807, -0.7960186004638672, -4.304426193237305, 2.1273746490478516, 2.748279571533203, -2.4132728576660156, -3.00966215133667, -1.3125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.50808334350586, "min_q": -2.5483460426330566, "max_q": 34.596988677978516, "mean_td_error": -0.812899649143219, "model": {}}, "td_error": [-0.6892910003662109, -1.6105947494506836, -2.1343727111816406, 0.4639873504638672, -2.3484344482421875, -1.5283966064453125, -8.122544288635254, -3.6600711345672607, 1.7697715759277344, 3.007239580154419, -0.18053627014160156, -5.519796371459961, 0.011013031005859375, 2.4361114501953125, -1.5483460426330566, -1.9107301235198975, 9.824904441833496, -2.81524658203125, -5.672991752624512, -6.841225624084473, -1.797004222869873, 5.740268707275391, 2.5682477951049805, -1.526681900024414, 0.3702700138092041, -3.350531578063965, 0.9880447387695312, -1.8894658088684082, 0.7576770782470703, -1.113968849182129, 2.1677446365356445, -1.8578376770019531], "custom_metrics": {}}}, "num_steps_sampled": 52416, "num_agent_steps_sampled": 157248, "num_steps_trained": 102848, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 308544, "last_target_update_ts": 52208, "num_target_updates": 101}, "done": false, "episodes_total": 5240, "training_iteration": 52, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-57-18", "timestamp": 1648915038, "time_this_iter_s": 39.263644218444824, "time_total_s": 2062.4414842128754, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a5710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2062.4414842128754, "timesteps_since_restore": 1664, "iterations_since_restore": 52, "perf": {"cpu_util_percent": 52.1, "ram_util_percent": 65.06071428571428}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 89.7, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 29.9, "policy1": 29.9, "policy2": 29.9}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 90.0, 30.0, 60.0, 120.0, 90.0, 60.0, 60.0, 120.0, 60.0, 90.0, 120.0, 60.0, 60.0, 60.0, 120.0, 120.0, 60.0, 120.0, 120.0, 60.0, 60.0, 60.0, 90.0, 90.0, 60.0, 90.0, 120.0, 120.0, 60.0, 30.0, 90.0, 120.0, 60.0, 60.0, 90.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 30.0, 60.0, 120.0, 120.0, 180.0, 120.0, 120.0, 90.0, 120.0, 120.0, 30.0, 30.0, 90.0, 90.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 120.0, 120.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 90.0, 90.0, 60.0, 90.0, 60.0, 90.0, 60.0, 150.0, 120.0, 60.0, 30.0, 90.0, 120.0, 60.0, 90.0, 90.0, 60.0, 90.0, 120.0, 120.0, 120.0, 90.0, 60.0, 120.0, 90.0, 120.0, 90.0, 150.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 40.0, 40.0, 60.0, 40.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 50.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 30.0, 50.0, 30.0], "policy_policy1_reward": [30.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 40.0, 40.0, 60.0, 40.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 50.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 30.0, 50.0, 30.0], "policy_policy2_reward": [30.0, 30.0, 10.0, 20.0, 40.0, 30.0, 20.0, 20.0, 40.0, 20.0, 30.0, 40.0, 20.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 20.0, 20.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 20.0, 30.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 10.0, 20.0, 40.0, 40.0, 60.0, 40.0, 40.0, 30.0, 40.0, 40.0, 10.0, 10.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 50.0, 40.0, 20.0, 10.0, 30.0, 40.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 30.0, 40.0, 30.0, 50.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0449253906789202, "mean_inference_ms": 25.976895652346037, "mean_action_processing_ms": 0.2476211667658818, "mean_env_wait_ms": 0.13962674749605297, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 53424, "timesteps_this_iter": 32, "agent_timesteps_total": 160272, "timers": {"load_time_ms": 0.667, "load_throughput": 47989.748, "learn_time_ms": 236.562, "learn_throughput": 135.271, "update_time_ms": 102.248}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.749393463134766, "min_q": -2.0556955337524414, "max_q": 36.507843017578125, "mean_td_error": 0.678851842880249, "model": {}}, "td_error": [0.619720458984375, 1.2233524322509766, 1.4809989929199219, -0.4574241638183594, 1.551112174987793, 0.9519233703613281, -2.5982742309570312, 1.8564739227294922, -2.1395206451416016, -2.4860758781433105, 1.3990364074707031, -8.752458572387695, -1.7001972198486328, -0.8219680786132812, -2.2791213989257812, -0.22971343994140625, -0.06703758239746094, 1.820485234260559, -1.7484264373779297, -1.9259891510009766, 18.990741729736328, -3.2971153259277344, -1.1296443939208984, 1.268876075744629, 1.3738834857940674, 0.7715120315551758, 11.019041061401367, 4.995871543884277, 1.1100711822509766, -0.5467948913574219, 1.1263999938964844, 0.3435211181640625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.312944412231445, "min_q": -0.7927997708320618, "max_q": 32.88426208496094, "mean_td_error": 0.7858798503875732, "model": {}}, "td_error": [-1.77872633934021, -0.0820159912109375, -0.5872211456298828, -3.8804688453674316, 0.47101402282714844, 9.810079574584961, -1.3792402744293213, 11.920134544372559, -0.7861442565917969, 0.38772010803222656, 2.240899085998535, -3.103510856628418, -1.6304664611816406, 0.5146980285644531, 3.5883121490478516, 8.269828796386719, 2.3425683975219727, 1.7660226821899414, 1.8476506471633911, -11.378572463989258, 0.643585205078125, -1.7415504455566406, 0.2534148693084717, -0.37784576416015625, -7.211267471313477, 2.0599489212036133, 5.989503860473633, 1.7767467498779297, 0.20189666748046875, 0.1497478485107422, 4.374538421630859, 0.4768761396408081], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.989151000976562, "min_q": -1.5210931301116943, "max_q": 36.71292495727539, "mean_td_error": 1.5885818004608154, "model": {}}, "td_error": [21.533201217651367, 0.9795265197753906, 0.23256301879882812, 8.116549491882324, -2.526580810546875, -1.5980892181396484, 3.4992446899414062, 0.4163784980773926, -1.0939302444458008, -1.3518590927124023, 2.429511070251465, 0.4289817810058594, 4.916731834411621, -3.898594856262207, -0.7580108642578125, 1.4845809936523438, 0.6069869995117188, 0.5423965454101562, -2.526580810546875, 1.4694242477416992, 1.4349708557128906, 2.6834259033203125, -1.7018146514892578, 4.619112968444824, 2.323085308074951, -1.5220108032226562, -2.3656997680664062, 0.6819915771484375, 0.3527965545654297, 13.57097339630127, -1.006795883178711, -1.137847900390625], "custom_metrics": {}}}, "num_steps_sampled": 53424, "num_agent_steps_sampled": 160272, "num_steps_trained": 104864, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 314592, "last_target_update_ts": 53232, "num_target_updates": 103}, "done": false, "episodes_total": 5340, "training_iteration": 53, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-57-58", "timestamp": 1648915078, "time_this_iter_s": 40.10369563102722, "time_total_s": 2102.5451798439026, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cf560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7cf560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2102.5451798439026, "timesteps_since_restore": 1696, "iterations_since_restore": 53, "perf": {"cpu_util_percent": 51.715789473684204, "ram_util_percent": 65.3157894736842}}
{"episode_reward_max": 150.0, "episode_reward_min": 30.0, "episode_reward_mean": 89.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 29.8, "policy1": 29.8, "policy2": 29.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 60.0, 90.0, 90.0, 30.0, 120.0, 60.0, 90.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 60.0, 120.0, 90.0, 90.0, 60.0, 90.0, 90.0, 60.0, 90.0, 120.0, 150.0, 60.0, 90.0, 60.0, 90.0, 90.0, 60.0, 90.0, 30.0, 120.0, 90.0, 60.0, 90.0, 30.0, 90.0, 90.0, 150.0, 60.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 60.0, 60.0, 90.0, 120.0, 120.0, 90.0, 30.0, 90.0, 60.0, 90.0, 120.0, 30.0, 90.0, 60.0, 150.0, 90.0, 150.0, 120.0, 120.0, 60.0, 30.0, 150.0, 120.0, 120.0, 120.0, 90.0, 120.0, 90.0, 90.0, 30.0, 90.0, 90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 60.0, 60.0, 90.0, 90.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 120.0, 60.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 50.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 30.0, 20.0, 50.0, 30.0, 50.0, 40.0, 40.0, 20.0, 10.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0], "policy_policy1_reward": [40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 50.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 30.0, 20.0, 50.0, 30.0, 50.0, 40.0, 40.0, 20.0, 10.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0], "policy_policy2_reward": [40.0, 20.0, 30.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 40.0, 50.0, 20.0, 30.0, 20.0, 30.0, 30.0, 20.0, 30.0, 10.0, 40.0, 30.0, 20.0, 30.0, 10.0, 30.0, 30.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 10.0, 30.0, 20.0, 30.0, 40.0, 10.0, 30.0, 20.0, 50.0, 30.0, 50.0, 40.0, 40.0, 20.0, 10.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 10.0, 30.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0446248769987883, "mean_inference_ms": 25.974675431574934, "mean_action_processing_ms": 0.24753206315279908, "mean_env_wait_ms": 0.13964832621814136, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 54432, "timesteps_this_iter": 32, "agent_timesteps_total": 163296, "timers": {"load_time_ms": 0.613, "load_throughput": 52182.158, "learn_time_ms": 238.167, "learn_throughput": 134.359, "update_time_ms": 107.885}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.986373901367188, "min_q": -1.7291618585586548, "max_q": 35.605445861816406, "mean_td_error": 1.0928387641906738, "model": {}}, "td_error": [2.6527137756347656, -1.3468704223632812, 0.7900485992431641, 2.734351873397827, 2.6046142578125, -0.28011131286621094, 10.542438507080078, -0.079071044921875, 1.7367286682128906, 0.5090293884277344, 0.0949859619140625, 2.1637635231018066, -1.2615489959716797, -6.312216758728027, -0.7392158508300781, 2.808889627456665, 9.6528959274292, -0.5198850631713867, -2.4770164489746094, 2.900545120239258, 3.149637222290039, -1.0382356643676758, -1.1749874353408813, -1.166656494140625, -0.5086669921875, 3.4612979888916016, 0.5150527954101562, 0.6087279319763184, 4.550102233886719, -0.4227752685546875, 2.6046104431152344, -1.7823333740234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 12.998530387878418, "min_q": -0.38656675815582275, "max_q": 31.96745491027832, "mean_td_error": 0.07996392250061035, "model": {}}, "td_error": [-0.1775527000427246, -2.220487594604492, 0.9301776885986328, 4.110123634338379, -4.675816535949707, 0.743342399597168, 8.438987731933594, -0.5152196884155273, -3.2192678451538086, 0.1449451446533203, -1.0645751953125, -1.3828010559082031, 13.484769821166992, -2.7665843963623047, 1.2932376861572266, -4.754757881164551, 6.561545372009277, -2.124728202819824, -0.7726325988769531, -5.880395889282227, 2.060868740081787, 6.325743198394775, -3.4300289154052734, 0.18510520458221436, -0.9056186676025391, -0.9056186676025391, -0.17692184448242188, -4.06911563873291, -1.0009651184082031, 0.6134332418441772, 1.840734601020813, -4.131078720092773], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.960880279541016, "min_q": -1.0590075254440308, "max_q": 38.173118591308594, "mean_td_error": 1.0318562984466553, "model": {}}, "td_error": [0.7978973388671875, 1.5746383666992188, -0.07564544677734375, 0.6735420227050781, 0.31499481201171875, -0.9208115935325623, -0.6085634231567383, -1.8341131210327148, 1.7809104919433594, 1.9949569702148438, 5.880466461181641, -0.1287088394165039, -1.0472469329833984, -1.231938362121582, 1.8509235382080078, 0.7926349639892578, -0.47069549560546875, -2.457561492919922, 2.341245651245117, 2.2011938095092773, -2.7014288902282715, -1.2496299743652344, 2.049510955810547, -3.434380531311035, 1.0051651000976562, 1.6761054992675781, 0.19699394702911377, 1.2552032470703125, 1.575124740600586, 8.393826484680176, -2.5469131469726562, 15.371706008911133], "custom_metrics": {}}}, "num_steps_sampled": 54432, "num_agent_steps_sampled": 163296, "num_steps_trained": 106880, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 320640, "last_target_update_ts": 54256, "num_target_updates": 105}, "done": false, "episodes_total": 5440, "training_iteration": 54, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-58-40", "timestamp": 1648915120, "time_this_iter_s": 41.08441686630249, "time_total_s": 2143.629596710205, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b7290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2143.629596710205, "timesteps_since_restore": 1728, "iterations_since_restore": 54, "perf": {"cpu_util_percent": 52.115517241379315, "ram_util_percent": 65.6396551724138}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 94.90384615384616, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 31.634615384615383, "policy1": 31.634615384615383, "policy2": 31.634615384615383}, "custom_metrics": {}, "hist_stats": {"episode_reward": [30.0, 120.0, 90.0, 90.0, 60.0, 120.0, 90.0, 60.0, 60.0, 30.0, 90.0, 120.0, 60.0, 150.0, 150.0, 90.0, 120.0, 120.0, 90.0, 120.0, 30.0, 90.0, 90.0, 90.0, 60.0, 90.0, 120.0, 120.0, 60.0, 150.0, 120.0, 60.0, 30.0, 120.0, 120.0, 90.0, 90.0, 150.0, 0.0, 90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 90.0, 30.0, 150.0, 90.0, 120.0, 60.0, 120.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 90.0, 120.0, 150.0, 90.0, 120.0, 60.0, 120.0, 150.0, 90.0, 90.0, 90.0, 150.0, 90.0, 90.0, 120.0, 90.0, 90.0, 60.0, 90.0, 90.0, 30.0, 90.0, 90.0, 90.0, 150.0, 90.0, 90.0, 120.0, 90.0, 60.0, 90.0, 120.0, 90.0, 150.0, 90.0, 90.0, 90.0, 60.0, 90.0, 90.0, 150.0, 30.0, 150.0, 120.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 20.0, 10.0, 30.0, 40.0, 20.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 40.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 20.0, 10.0, 40.0, 40.0, 30.0, 30.0, 50.0, 0.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 50.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 20.0, 40.0, 50.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 50.0, 10.0, 50.0, 40.0, 30.0], "policy_policy1_reward": [10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 20.0, 10.0, 30.0, 40.0, 20.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 40.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 20.0, 10.0, 40.0, 40.0, 30.0, 30.0, 50.0, 0.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 50.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 20.0, 40.0, 50.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 50.0, 10.0, 50.0, 40.0, 30.0], "policy_policy2_reward": [10.0, 40.0, 30.0, 30.0, 20.0, 40.0, 30.0, 20.0, 20.0, 10.0, 30.0, 40.0, 20.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 40.0, 10.0, 30.0, 30.0, 30.0, 20.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 20.0, 10.0, 40.0, 40.0, 30.0, 30.0, 50.0, 0.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 10.0, 50.0, 30.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 20.0, 40.0, 50.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 30.0, 20.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 30.0, 30.0, 50.0, 10.0, 50.0, 40.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044548759298075, "mean_inference_ms": 25.959551811699882, "mean_action_processing_ms": 0.24741326444171896, "mean_env_wait_ms": 0.1396325946791624, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 55440, "timesteps_this_iter": 32, "agent_timesteps_total": 166320, "timers": {"load_time_ms": 0.682, "load_throughput": 46953.902, "learn_time_ms": 232.416, "learn_throughput": 137.684, "update_time_ms": 96.491}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.27541732788086, "min_q": -2.097565174102783, "max_q": 37.93821334838867, "mean_td_error": 2.446288824081421, "model": {}}, "td_error": [3.696949005126953, -1.3006315231323242, -1.5316238403320312, -0.18562841415405273, 1.9037647247314453, -1.6231575012207031, 0.35126304626464844, -0.33626556396484375, 0.23812448978424072, -0.009890556335449219, 2.230863571166992, 1.1627998352050781, 2.1040334701538086, -0.6179294586181641, -0.8824996948242188, -0.2549285888671875, 2.6446475982666016, -0.33468711376190186, -8.470381736755371, 4.666008949279785, 0.014179229736328125, -3.1512985229492188, 2.795893669128418, 22.417598724365234, 0.014179229736328125, 1.0004386901855469, 25.199020385742188, 2.0406532287597656, -6.080470085144043, 0.7531547546386719, 20.403945922851562, 9.423113822937012], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.78110122680664, "min_q": 0.8497216105461121, "max_q": 32.41415023803711, "mean_td_error": -0.6551940441131592, "model": {}}, "td_error": [-1.3545169830322266, 2.4991159439086914, 2.5305986404418945, 0.20536231994628906, 1.8497216701507568, 1.440164566040039, -5.10981559753418, 2.2271816730499268, 1.359262466430664, 1.8859272003173828, -1.314056396484375, -3.2443227767944336, 0.44695281982421875, -3.923447608947754, 0.019250869750976562, 3.0811195373535156, -1.1378421783447266, -2.3650054931640625, -0.193572998046875, -0.6935100555419922, -7.811518669128418, -2.26904296875, 0.8386440277099609, -0.6935100555419922, -8.160979270935059, -0.2583293914794922, -0.8043594360351562, 0.9323825836181641, -1.4720783233642578, 0.019250869750976562, 3.3035354614257812, -2.7987728118896484], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.622085571289062, "min_q": -2.192582845687866, "max_q": 35.68598175048828, "mean_td_error": 0.32579857110977173, "model": {}}, "td_error": [-1.7274036407470703, 10.632745742797852, 0.26573753356933594, -0.11186981201171875, -3.543924331665039, -5.045342445373535, 0.4622468948364258, 6.2454657554626465, -2.1879520416259766, -2.392005443572998, 1.8425712585449219, 1.984710693359375, 7.6391921043396, 0.4165527820587158, 1.956727385520935, 0.26079368591308594, -2.1902809143066406, 17.0534610748291, -0.11186981201171875, 0.2751350402832031, -2.063922882080078, 0.7837409973144531, -5.897150039672852, -0.4387779235839844, -11.54448127746582, 2.366455078125, -6.863005638122559, 4.319411754608154, -0.779902458190918, -1.0409584045410156, -0.3264188766479492, 0.18587493896484375], "custom_metrics": {}}}, "num_steps_sampled": 55440, "num_agent_steps_sampled": 166320, "num_steps_trained": 108896, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 326688, "last_target_update_ts": 55280, "num_target_updates": 107}, "done": false, "episodes_total": 5544, "training_iteration": 55, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-59-18", "timestamp": 1648915158, "time_this_iter_s": 38.84879660606384, "time_total_s": 2182.478393316269, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b79e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7b79e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2182.478393316269, "timesteps_since_restore": 1760, "iterations_since_restore": 55, "perf": {"cpu_util_percent": 52.370909090909095, "ram_util_percent": 65.40545454545455}}
{"episode_reward_max": 150.0, "episode_reward_min": 30.0, "episode_reward_mean": 87.9, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 29.3, "policy1": 29.3, "policy2": 29.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 90.0, 30.0, 90.0, 90.0, 90.0, 30.0, 120.0, 120.0, 90.0, 60.0, 90.0, 120.0, 60.0, 120.0, 90.0, 90.0, 60.0, 120.0, 30.0, 90.0, 90.0, 90.0, 120.0, 60.0, 60.0, 150.0, 90.0, 90.0, 90.0, 120.0, 90.0, 60.0, 90.0, 120.0, 60.0, 90.0, 90.0, 120.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 150.0, 90.0, 60.0, 90.0, 150.0, 90.0, 60.0, 150.0, 120.0, 120.0, 60.0, 90.0, 90.0, 60.0, 120.0, 120.0, 60.0, 120.0, 120.0, 30.0, 90.0, 120.0, 30.0, 120.0, 90.0, 90.0, 90.0, 60.0, 90.0, 60.0, 90.0, 60.0, 30.0, 30.0, 30.0, 120.0, 90.0, 30.0, 90.0, 90.0, 120.0, 60.0, 90.0, 60.0, 90.0, 60.0, 90.0, 90.0, 120.0, 150.0, 120.0, 30.0, 90.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 40.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 50.0, 30.0, 20.0, 30.0, 50.0, 30.0, 20.0, 50.0, 40.0, 40.0, 20.0, 30.0, 30.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 10.0, 30.0, 20.0, 20.0], "policy_policy1_reward": [30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 40.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 50.0, 30.0, 20.0, 30.0, 50.0, 30.0, 20.0, 50.0, 40.0, 40.0, 20.0, 30.0, 30.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 10.0, 30.0, 20.0, 20.0], "policy_policy2_reward": [30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 10.0, 40.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 40.0, 30.0, 30.0, 20.0, 40.0, 10.0, 30.0, 30.0, 30.0, 40.0, 20.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 50.0, 30.0, 20.0, 30.0, 50.0, 30.0, 20.0, 50.0, 40.0, 40.0, 20.0, 30.0, 30.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 10.0, 30.0, 40.0, 10.0, 40.0, 30.0, 30.0, 30.0, 20.0, 30.0, 20.0, 30.0, 20.0, 10.0, 10.0, 10.0, 40.0, 30.0, 10.0, 30.0, 30.0, 40.0, 20.0, 30.0, 20.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 10.0, 30.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0441412182742176, "mean_inference_ms": 25.957422984412514, "mean_action_processing_ms": 0.24739678793116354, "mean_env_wait_ms": 0.13964702665260997, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 56448, "timesteps_this_iter": 32, "agent_timesteps_total": 169344, "timers": {"load_time_ms": 0.611, "load_throughput": 52363.346, "learn_time_ms": 231.405, "learn_throughput": 138.286, "update_time_ms": 111.805}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.478649139404297, "min_q": -1.8348591327667236, "max_q": 37.79869079589844, "mean_td_error": -0.4631320536136627, "model": {}}, "td_error": [0.6533392667770386, 1.2201690673828125, 0.158782958984375, -0.145341157913208, -0.07058334350585938, 1.1561577320098877, -0.31177377700805664, -0.8208827972412109, -4.095180988311768, -0.7690010070800781, 0.8322181701660156, 3.3322200775146484, -0.11696243286132812, -9.157234191894531, -0.6968421936035156, -2.8310203552246094, -1.501382827758789, -0.29692554473876953, -2.0191173553466797, -6.245810508728027, -0.2283954620361328, -1.024099349975586, -3.2014389038085938, 0.26229095458984375, -0.01951885223388672, 2.122814178466797, 0.16956710815429688, 0.8871936798095703, -0.6779031753540039, 9.09520149230957, -1.0357742309570312, 0.5550079345703125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.381755828857422, "min_q": -0.13214069604873657, "max_q": 35.09077072143555, "mean_td_error": 0.38269731402397156, "model": {}}, "td_error": [9.760175704956055, -0.21080774068832397, 1.2566051483154297, 1.2481861114501953, 1.5716819763183594, 3.4108686447143555, 2.3071975708007812, -1.6821813583374023, 4.7658185958862305, -0.14942073822021484, -4.579624176025391, 1.4335784912109375, 2.8641717433929443, 2.398509979248047, 1.25543212890625, -4.45694637298584, 4.055402755737305, -2.225343704223633, -0.7182455062866211, -7.441012382507324, -2.320526599884033, 0.8373669385910034, 1.962188720703125, 0.0424652099609375, 2.149883270263672, -3.8113174438476562, 4.130326747894287, 4.038517951965332, -1.0978641510009766, 1.261270523071289, -5.000957489013672, -4.809087753295898], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.250591278076172, "min_q": -0.28123927116394043, "max_q": 38.334625244140625, "mean_td_error": -0.848432183265686, "model": {}}, "td_error": [-2.71036434173584, 0.13352394104003906, 0.4575631618499756, -4.919327735900879, 4.079031944274902, 2.3947067260742188, 3.503427028656006, -2.2458410263061523, -0.16375350952148438, -3.963836669921875, -2.80844783782959, -4.128347396850586, 0.35095691680908203, 2.2905044555664062, -4.919327735900879, 0.5824470520019531, 0.9741783142089844, 0.9960098266601562, 1.5061607360839844, 0.8036117553710938, -0.16802597045898438, -7.137005805969238, -5.27388858795166, 0.810699462890625, 0.08734440803527832, -2.306504726409912, 0.5861244201660156, -0.6941947937011719, 0.2833728790283203, -0.6763725280761719, -1.6760940551757812, -3.198162317276001], "custom_metrics": {}}}, "num_steps_sampled": 56448, "num_agent_steps_sampled": 169344, "num_steps_trained": 110912, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 332736, "last_target_update_ts": 56304, "num_target_updates": 109}, "done": false, "episodes_total": 5644, "training_iteration": 56, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_08-59-59", "timestamp": 1648915199, "time_this_iter_s": 40.16064429283142, "time_total_s": 2222.6390376091003, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a79e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a79e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2222.6390376091003, "timesteps_since_restore": 1792, "iterations_since_restore": 56, "perf": {"cpu_util_percent": 51.19827586206897, "ram_util_percent": 65.43965517241381}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 96.6, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 32.2, "policy1": 32.2, "policy2": 32.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 90.0, 150.0, 90.0, 60.0, 120.0, 90.0, 150.0, 60.0, 60.0, 120.0, 60.0, 90.0, 90.0, 120.0, 90.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 150.0, 150.0, 120.0, 120.0, 90.0, 90.0, 120.0, 90.0, 60.0, 150.0, 90.0, 60.0, 60.0, 90.0, 120.0, 150.0, 120.0, 60.0, 120.0, 60.0, 120.0, 90.0, 60.0, 90.0, 150.0, 60.0, 150.0, 150.0, 120.0, 120.0, 120.0, 90.0, 120.0, 60.0, 0.0, 120.0, 60.0, 60.0, 120.0, 120.0, 60.0, 120.0, 120.0, 90.0, 120.0, 120.0, 90.0, 60.0, 120.0, 150.0, 120.0, 60.0, 150.0, 120.0, 30.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 60.0, 90.0, 120.0, 30.0, 90.0, 90.0, 150.0, 90.0, 90.0, 60.0, 90.0, 30.0, 0.0, 60.0, 90.0, 90.0, 30.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 30.0, 50.0, 30.0, 20.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 20.0, 50.0, 30.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 50.0, 20.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 40.0, 50.0, 40.0, 20.0, 50.0, 40.0, 10.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 20.0, 30.0, 40.0, 10.0, 30.0, 30.0, 50.0, 30.0, 30.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 30.0, 10.0], "policy_policy1_reward": [40.0, 30.0, 50.0, 30.0, 20.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 20.0, 50.0, 30.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 50.0, 20.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 40.0, 50.0, 40.0, 20.0, 50.0, 40.0, 10.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 20.0, 30.0, 40.0, 10.0, 30.0, 30.0, 50.0, 30.0, 30.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 30.0, 10.0], "policy_policy2_reward": [40.0, 30.0, 50.0, 30.0, 20.0, 40.0, 30.0, 50.0, 20.0, 20.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 20.0, 50.0, 30.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 30.0, 20.0, 30.0, 50.0, 20.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 20.0, 0.0, 40.0, 20.0, 20.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 40.0, 50.0, 40.0, 20.0, 50.0, 40.0, 10.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 20.0, 30.0, 40.0, 10.0, 30.0, 30.0, 50.0, 30.0, 30.0, 20.0, 30.0, 10.0, 0.0, 20.0, 30.0, 30.0, 10.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0436287500532173, "mean_inference_ms": 25.93073769392472, "mean_action_processing_ms": 0.24721156086110085, "mean_env_wait_ms": 0.13958104512353742, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 57456, "timesteps_this_iter": 32, "agent_timesteps_total": 172368, "timers": {"load_time_ms": 0.667, "load_throughput": 48003.479, "learn_time_ms": 243.014, "learn_throughput": 131.679, "update_time_ms": 108.797}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.75305938720703, "min_q": 0.17292368412017822, "max_q": 38.21775817871094, "mean_td_error": 0.8768348097801208, "model": {}}, "td_error": [-3.1004886627197266, 0.8134241104125977, 1.7717113494873047, 0.994481086730957, 7.718524932861328, -0.9036350250244141, 10.344725608825684, 0.6391563415527344, -8.827075958251953, -1.2991180419921875, 0.9430046081542969, -0.8081169128417969, 0.062030792236328125, 2.485576629638672, 7.2750163078308105, -0.254302978515625, 2.705768585205078, -4.66063117980957, 2.0085930824279785, -0.3721904754638672, 2.842470169067383, -1.8572273254394531, 0.09623146057128906, -1.2991180419921875, 1.216238021850586, 0.4006080627441406, 8.174079895019531, 0.8029098510742188, 0.598048210144043, -2.4326133728027344, 1.4371871948242188, 0.5434474945068359], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.243247985839844, "min_q": -1.673351764678955, "max_q": 34.08118438720703, "mean_td_error": -0.55892413854599, "model": {}}, "td_error": [-1.0714645385742188, 2.9395389556884766, -0.08871841430664062, 3.7708396911621094, -0.2190380096435547, -9.89896011352539, -4.160455703735352, -1.9616718292236328, -0.6733517646789551, 1.069000244140625, -1.320810317993164, -2.476154327392578, -0.3562736511230469, -3.4476890563964844, -1.355377197265625, -0.7535829544067383, -1.7224464416503906, 12.100116729736328, -8.92612361907959, -0.012144088745117188, 1.3817110061645508, -1.8129234313964844, 2.5718917846679688, 1.79298996925354, 1.3542842864990234, 2.524017333984375, 0.12015771865844727, -3.4115467071533203, -1.8109397888183594, -1.6780649423599243, -0.9156646728515625, 0.5632801055908203], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.653947830200195, "min_q": -0.10900026559829712, "max_q": 38.19733428955078, "mean_td_error": -0.6646310687065125, "model": {}}, "td_error": [0.16573715209960938, -4.363475799560547, -0.44338321685791016, 0.36284637451171875, -9.109000205993652, -1.6438827514648438, 3.0158042907714844, -3.2584877014160156, 0.8392772674560547, -1.1420707702636719, -0.7795066833496094, -0.5216445922851562, 0.8030786514282227, 0.6207056045532227, -1.8856925964355469, -2.17633056640625, 1.0483531951904297, 0.9464111328125, 2.925607681274414, -1.3578662872314453, -0.7390861511230469, -0.9829254150390625, -1.574920654296875, 2.930593490600586, -2.4460620880126953, 3.037322998046875, -0.9074687957763672, 3.1651172637939453, 0.770599365234375, -0.15169620513916016, -1.2164459228515625, -7.199702262878418], "custom_metrics": {}}}, "num_steps_sampled": 57456, "num_agent_steps_sampled": 172368, "num_steps_trained": 112928, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 338784, "last_target_update_ts": 57328, "num_target_updates": 111}, "done": false, "episodes_total": 5744, "training_iteration": 57, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-00-39", "timestamp": 1648915239, "time_this_iter_s": 40.14414429664612, "time_total_s": 2262.7831819057465, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a7ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2262.7831819057465, "timesteps_since_restore": 1824, "iterations_since_restore": 57, "perf": {"cpu_util_percent": 51.33157894736843, "ram_util_percent": 64.98245614035088}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 99.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 33.1, "policy1": 33.1, "policy2": 33.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 90.0, 120.0, 90.0, 120.0, 90.0, 150.0, 60.0, 150.0, 120.0, 90.0, 90.0, 150.0, 60.0, 90.0, 30.0, 60.0, 90.0, 60.0, 120.0, 180.0, 90.0, 90.0, 120.0, 90.0, 60.0, 90.0, 90.0, 120.0, 120.0, 120.0, 120.0, 90.0, 120.0, 120.0, 90.0, 120.0, 150.0, 90.0, 120.0, 90.0, 120.0, 90.0, 90.0, 150.0, 150.0, 90.0, 60.0, 90.0, 90.0, 120.0, 150.0, 30.0, 120.0, 120.0, 120.0, 120.0, 30.0, 60.0, 30.0, 60.0, 120.0, 120.0, 60.0, 60.0, 120.0, 90.0, 150.0, 120.0, 90.0, 60.0, 90.0, 120.0, 90.0, 120.0, 60.0, 150.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 60.0, 90.0, 90.0, 120.0, 150.0, 150.0, 90.0, 60.0, 60.0, 60.0, 30.0, 120.0, 90.0, 150.0, 90.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 50.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 60.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 10.0, 40.0, 40.0, 40.0, 40.0, 10.0, 20.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 20.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 50.0, 50.0, 30.0, 20.0, 20.0, 20.0, 10.0, 40.0, 30.0, 50.0, 30.0, 30.0], "policy_policy1_reward": [20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 50.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 60.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 10.0, 40.0, 40.0, 40.0, 40.0, 10.0, 20.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 20.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 50.0, 50.0, 30.0, 20.0, 20.0, 20.0, 10.0, 40.0, 30.0, 50.0, 30.0, 30.0], "policy_policy2_reward": [20.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 50.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 20.0, 30.0, 10.0, 20.0, 30.0, 20.0, 40.0, 60.0, 30.0, 30.0, 40.0, 30.0, 20.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 20.0, 30.0, 30.0, 40.0, 50.0, 10.0, 40.0, 40.0, 40.0, 40.0, 10.0, 20.0, 10.0, 20.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 40.0, 30.0, 20.0, 30.0, 40.0, 30.0, 40.0, 20.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 50.0, 50.0, 30.0, 20.0, 20.0, 20.0, 10.0, 40.0, 30.0, 50.0, 30.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0439682946352264, "mean_inference_ms": 25.931332398759295, "mean_action_processing_ms": 0.24725688729589898, "mean_env_wait_ms": 0.13964104572480657, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 58464, "timesteps_this_iter": 32, "agent_timesteps_total": 175392, "timers": {"load_time_ms": 0.638, "load_throughput": 50184.232, "learn_time_ms": 229.919, "learn_throughput": 139.18, "update_time_ms": 114.03}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.72153091430664, "min_q": 0.26135075092315674, "max_q": 36.982826232910156, "mean_td_error": 2.7666568756103516, "model": {}}, "td_error": [2.0791234970092773, 0.8014583587646484, -1.2748394012451172, -8.738649368286133, 2.334911346435547, 5.415652751922607, 0.21691131591796875, -1.6345281600952148, 0.311065673828125, 3.051633834838867, 11.756354331970215, 18.38493537902832, -2.461864471435547, 0.8229804039001465, 0.35219573974609375, -2.797361373901367, 21.185941696166992, 0.9177494049072266, 6.224635124206543, 3.304086685180664, -0.050904273986816406, 3.223875045776367, 0.6113510131835938, 1.3646354675292969, 17.37017822265625, 0.9496707916259766, 0.5470545291900635, 2.5106945037841797, -2.490224838256836, -0.6279354095458984, 5.523286819458008, -0.6510496139526367], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.883792877197266, "min_q": 0.983612060546875, "max_q": 36.770790100097656, "mean_td_error": 1.8062293529510498, "model": {}}, "td_error": [1.6640090942382812, -0.16807937622070312, 1.9796504974365234, -3.106618881225586, 0.9190874099731445, 17.958030700683594, 2.2519545555114746, 12.439685821533203, 2.4594879150390625, -1.1061086654663086, -2.964122772216797, -3.033794403076172, -4.220729827880859, 0.2875099182128906, 10.210219383239746, 8.346914291381836, -5.066177845001221, -3.5117931365966797, 2.4565553665161133, 5.679468154907227, -0.4926900863647461, -2.566497802734375, -2.5747947692871094, 0.6643333435058594, 3.269275665283203, -0.7290725708007812, 11.957237243652344, 0.23022842407226562, 1.2969779968261719, 1.7211494445800781, -0.34375572204589844, 1.8918027877807617], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.60474395751953, "min_q": 0.07384836673736572, "max_q": 37.352149963378906, "mean_td_error": 1.079799771308899, "model": {}}, "td_error": [-1.043187141418457, -0.7443122863769531, -5.432889938354492, 3.4581899642944336, -0.1460275650024414, -0.28436851501464844, 3.5627670288085938, 0.8850460052490234, 1.1487445831298828, -4.251158237457275, -3.8806819915771484, -0.3179283142089844, -2.4374618530273438, 0.7379207611083984, 3.884812116622925, 22.03866195678711, -8.368568420410156, 1.7041206359863281, 0.6071643829345703, -0.7481498718261719, -0.5075702667236328, -8.926151275634766, -1.6147308349609375, 6.197829246520996, 0.9272632598876953, 4.44384241104126, -0.7595453262329102, 0.9425010681152344, 0.5964221954345703, 21.16016387939453, 1.0700225830078125, 0.6508522033691406], "custom_metrics": {}}}, "num_steps_sampled": 58464, "num_agent_steps_sampled": 175392, "num_steps_trained": 114944, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 344832, "last_target_update_ts": 58352, "num_target_updates": 113}, "done": false, "episodes_total": 5844, "training_iteration": 58, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-01-19", "timestamp": 1648915279, "time_this_iter_s": 40.39218831062317, "time_total_s": 2303.1753702163696, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c767dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c767dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2303.1753702163696, "timesteps_since_restore": 1856, "iterations_since_restore": 58, "perf": {"cpu_util_percent": 52.238596491228066, "ram_util_percent": 65.54385964912281}}
{"episode_reward_max": 150.0, "episode_reward_min": 0.0, "episode_reward_mean": 84.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 28.1, "policy1": 28.1, "policy2": 28.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 60.0, 90.0, 60.0, 60.0, 90.0, 150.0, 120.0, 120.0, 120.0, 90.0, 30.0, 120.0, 60.0, 90.0, 60.0, 90.0, 0.0, 120.0, 60.0, 60.0, 90.0, 120.0, 90.0, 150.0, 90.0, 120.0, 150.0, 60.0, 120.0, 120.0, 90.0, 90.0, 90.0, 60.0, 120.0, 0.0, 90.0, 120.0, 60.0, 60.0, 60.0, 60.0, 0.0, 60.0, 120.0, 120.0, 60.0, 90.0, 150.0, 60.0, 120.0, 120.0, 30.0, 30.0, 120.0, 60.0, 120.0, 60.0, 120.0, 120.0, 90.0, 60.0, 60.0, 150.0, 90.0, 30.0, 90.0, 60.0, 90.0, 90.0, 90.0, 90.0, 0.0, 60.0, 30.0, 90.0, 90.0, 150.0, 150.0, 60.0, 60.0, 120.0, 30.0, 30.0, 30.0, 120.0, 120.0, 60.0, 120.0, 60.0, 90.0, 60.0, 60.0, 90.0, 30.0, 90.0, 60.0, 150.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 30.0, 0.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 0.0, 30.0, 40.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 40.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 40.0, 10.0, 10.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 20.0, 50.0, 30.0, 10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 10.0, 30.0, 30.0, 50.0, 50.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 50.0, 30.0], "policy_policy1_reward": [40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 30.0, 0.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 0.0, 30.0, 40.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 40.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 40.0, 10.0, 10.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 20.0, 50.0, 30.0, 10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 10.0, 30.0, 30.0, 50.0, 50.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 50.0, 30.0], "policy_policy2_reward": [40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 20.0, 30.0, 20.0, 30.0, 0.0, 40.0, 20.0, 20.0, 30.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 20.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 0.0, 30.0, 40.0, 20.0, 20.0, 20.0, 20.0, 0.0, 20.0, 40.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 40.0, 10.0, 10.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 20.0, 50.0, 30.0, 10.0, 30.0, 20.0, 30.0, 30.0, 30.0, 30.0, 0.0, 20.0, 10.0, 30.0, 30.0, 50.0, 50.0, 20.0, 20.0, 40.0, 10.0, 10.0, 10.0, 40.0, 40.0, 20.0, 40.0, 20.0, 30.0, 20.0, 20.0, 30.0, 10.0, 30.0, 20.0, 50.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0432425596516952, "mean_inference_ms": 25.92013183122075, "mean_action_processing_ms": 0.2471608395326017, "mean_env_wait_ms": 0.13963286577953732, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 59472, "timesteps_this_iter": 32, "agent_timesteps_total": 178416, "timers": {"load_time_ms": 0.671, "load_throughput": 47674.396, "learn_time_ms": 235.672, "learn_throughput": 135.782, "update_time_ms": 110.847}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.664369583129883, "min_q": -0.8974522352218628, "max_q": 37.84927749633789, "mean_td_error": 1.4148743152618408, "model": {}}, "td_error": [-0.7416238784790039, 0.439602792263031, 1.9831295013427734, 4.465063095092773, 2.200728416442871, 0.08217620849609375, 1.4785346984863281, -2.222270965576172, -1.9474811553955078, 0.10915184020996094, -0.4977426528930664, -2.104022979736328, 2.260654926300049, -0.4624214172363281, -2.067350387573242, 0.46967315673828125, -1.7552032470703125, -6.785879135131836, -3.079960823059082, 4.099119663238525, -0.45235443115234375, 5.714754104614258, 0.10254776477813721, 0.33269309997558594, 1.66571044921875, 20.39390754699707, 1.31842041015625, 17.035646438598633, 2.605192184448242, -4.8175458908081055, -0.17907333374023438, 5.632201194763184], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.303544998168945, "min_q": -0.5325542092323303, "max_q": 34.3747444152832, "mean_td_error": -0.2474173605442047, "model": {}}, "td_error": [-3.1490840911865234, 1.9804458618164062, -0.39670753479003906, -2.603282928466797, -3.690927505493164, -0.1425933837890625, 0.7605247497558594, -0.6364002227783203, -1.3326911926269531, 0.9084072113037109, -2.34906005859375, 1.8187217712402344, 0.6603736877441406, -2.727686882019043, -1.3762989044189453, -0.6375923156738281, -2.4327526092529297, -1.944204330444336, -1.71492338180542, 1.1483898162841797, -2.5558300018310547, -0.24587059020996094, -3.9476356506347656, -0.9516382217407227, 1.2173348665237427, -3.3122425079345703, 2.320354461669922, -1.937448501586914, -0.2782459259033203, 0.9965439438819885, 0.045169830322265625, 18.589494705200195], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.92908477783203, "min_q": -2.856166124343872, "max_q": 38.28264617919922, "mean_td_error": 3.0033607482910156, "model": {}}, "td_error": [-1.2551403045654297, 17.588069915771484, -0.21296405792236328, 3.7381515502929688, 3.4163198471069336, 0.6173572540283203, 9.087139129638672, 3.14605712890625, -0.001392364501953125, 1.2097053527832031, 0.5596847534179688, 0.8055105209350586, 0.4371509552001953, 0.45543384552001953, 22.868873596191406, -0.7528762817382812, 3.0165252685546875, -2.369593620300293, -0.9748630523681641, 0.6282644271850586, 3.5072708129882812, 8.369032859802246, 0.13803863525390625, 0.7907180786132812, 3.6719398498535156, -0.5344314575195312, -3.73861026763916, -1.856166124343872, 0.3187255859375, -1.8011255264282227, 27.94428253173828, -2.709545135498047], "custom_metrics": {}}}, "num_steps_sampled": 59472, "num_agent_steps_sampled": 178416, "num_steps_trained": 116960, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 350880, "last_target_update_ts": 59376, "num_target_updates": 115}, "done": false, "episodes_total": 5944, "training_iteration": 59, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-02-00", "timestamp": 1648915320, "time_this_iter_s": 40.125436544418335, "time_total_s": 2343.300806760788, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ba0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ba0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2343.300806760788, "timesteps_since_restore": 1888, "iterations_since_restore": 59, "perf": {"cpu_util_percent": 50.76491228070175, "ram_util_percent": 65.24736842105263}}
{"episode_reward_max": 150.0, "episode_reward_min": 30.0, "episode_reward_mean": 96.92307692307692, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_mean": {"policy0": 32.30769230769231, "policy1": 32.30769230769231, "policy2": 32.30769230769231}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 120.0, 30.0, 90.0, 120.0, 120.0, 150.0, 120.0, 60.0, 90.0, 60.0, 30.0, 60.0, 120.0, 90.0, 60.0, 120.0, 120.0, 120.0, 120.0, 60.0, 60.0, 120.0, 90.0, 150.0, 90.0, 30.0, 90.0, 90.0, 90.0, 120.0, 150.0, 120.0, 60.0, 120.0, 120.0, 120.0, 150.0, 90.0, 90.0, 60.0, 150.0, 120.0, 90.0, 90.0, 150.0, 90.0, 90.0, 120.0, 120.0, 60.0, 90.0, 90.0, 120.0, 90.0, 60.0, 120.0, 60.0, 150.0, 60.0, 60.0, 90.0, 120.0, 90.0, 90.0, 60.0, 30.0, 90.0, 90.0, 90.0, 30.0, 90.0, 120.0, 120.0, 120.0, 120.0, 90.0, 90.0, 150.0, 120.0, 90.0, 120.0, 120.0, 60.0, 90.0, 120.0, 150.0, 150.0, 60.0, 60.0, 90.0, 120.0, 150.0, 120.0, 60.0, 90.0, 150.0, 30.0, 90.0, 60.0, 120.0, 120.0, 60.0, 60.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 40.0, 10.0, 30.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 30.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 40.0, 50.0, 50.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 30.0, 50.0, 10.0, 30.0, 20.0, 40.0, 40.0, 20.0, 20.0], "policy_policy1_reward": [30.0, 40.0, 10.0, 30.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 30.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 40.0, 50.0, 50.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 30.0, 50.0, 10.0, 30.0, 20.0, 40.0, 40.0, 20.0, 20.0], "policy_policy2_reward": [30.0, 40.0, 10.0, 30.0, 40.0, 40.0, 50.0, 40.0, 20.0, 30.0, 20.0, 10.0, 20.0, 40.0, 30.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 40.0, 30.0, 50.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 20.0, 20.0, 30.0, 40.0, 30.0, 30.0, 20.0, 10.0, 30.0, 30.0, 30.0, 10.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 50.0, 40.0, 30.0, 40.0, 40.0, 20.0, 30.0, 40.0, 50.0, 50.0, 20.0, 20.0, 30.0, 40.0, 50.0, 40.0, 20.0, 30.0, 50.0, 10.0, 30.0, 20.0, 40.0, 40.0, 20.0, 20.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.043189104867434, "mean_inference_ms": 25.92025549510636, "mean_action_processing_ms": 0.24714000278203216, "mean_env_wait_ms": 0.13965639469839738, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 60480, "timesteps_this_iter": 32, "agent_timesteps_total": 181440, "timers": {"load_time_ms": 0.808, "load_throughput": 39624.979, "learn_time_ms": 252.232, "learn_throughput": 126.867, "update_time_ms": 106.873}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.730260848999023, "min_q": -2.19465970993042, "max_q": 37.48325729370117, "mean_td_error": 1.6273653507232666, "model": {}}, "td_error": [-0.3281742334365845, 0.4837760925292969, 10.356550216674805, 3.238126754760742, -1.4342823028564453, -1.5230579376220703, 21.029687881469727, -1.8539519309997559, -9.306493759155273, 20.407194137573242, 0.5010097622871399, 0.2725067138671875, 11.25550651550293, -5.579314231872559, 2.8186988830566406, -1.19465970993042, -0.9487628936767578, 0.5529899597167969, 0.8172626495361328, -2.520627975463867, -0.0027256011962890625, -2.0346813201904297, 6.665221691131592, 0.18706893920898438, -0.8635079860687256, -1.9367027282714844, 13.025665283203125, 1.9096431732177734, -0.1805286407470703, -4.859704971313477, 1.2027950286865234, -8.080838203430176], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.41028594970703, "min_q": -1.8317530155181885, "max_q": 36.33146286010742, "mean_td_error": 1.8712339401245117, "model": {}}, "td_error": [-0.11546516418457031, 15.618967056274414, 3.4946231842041016, 2.0139942169189453, 0.3037686347961426, 1.4074164628982544, -1.2296409606933594, -1.1868515014648438, 18.2349853515625, -0.5539093017578125, -0.5843782424926758, -3.193301200866699, -2.644892692565918, -0.26143646240234375, 11.304664611816406, 2.7852745056152344, -1.637143611907959, 0.7972126007080078, 0.2514057159423828, 2.1758499145507812, -4.366493225097656, -1.0505180358886719, -2.760223388671875, 1.7578253746032715, 6.547635078430176, 1.5565261840820312, 18.35188865661621, -1.4814949035644531, -0.7203479409217834, -1.9121265411376953, -0.9918136596679688, -2.0325098037719727], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.191707611083984, "min_q": -1.8193519115447998, "max_q": 42.34037780761719, "mean_td_error": 2.6829283237457275, "model": {}}, "td_error": [1.8523216247558594, 22.49775505065918, 1.359609603881836, 2.4372386932373047, 0.00635528564453125, 2.947645664215088, -2.9221603870391846, 3.357870101928711, 0.8996448516845703, 3.4975204467773438, 0.7395095825195312, -1.8642683029174805, 1.1398773193359375, 0.5979630947113037, 1.698521375656128, 4.649932861328125, 0.10374069213867188, 1.6282103061676025, 19.68597412109375, 0.9521627426147461, -1.8683815002441406, 2.9306154251098633, 15.977779388427734, -1.1687521934509277, -0.8218879699707031, 0.10155296325683594, 3.683846950531006, -0.7153167724609375, 0.204803466796875, 0.3104116916656494, -1.2232208251953125, 3.1768321990966797], "custom_metrics": {}}}, "num_steps_sampled": 60480, "num_agent_steps_sampled": 181440, "num_steps_trained": 118976, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 356928, "last_target_update_ts": 60400, "num_target_updates": 117}, "done": false, "episodes_total": 6048, "training_iteration": 60, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-02-40", "timestamp": 1648915360, "time_this_iter_s": 40.18314790725708, "time_total_s": 2383.483954668045, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c783830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c783830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2383.483954668045, "timesteps_since_restore": 1920, "iterations_since_restore": 60, "perf": {"cpu_util_percent": 52.573684210526324, "ram_util_percent": 65.45438596491229}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 107.4, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 35.8, "policy1": 35.8, "policy2": 35.8}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 90.0, 120.0, 120.0, 120.0, 90.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 120.0, 90.0, 60.0, 60.0, 90.0, 60.0, 120.0, 90.0, 90.0, 120.0, 120.0, 90.0, 90.0, 150.0, 90.0, 90.0, 150.0, 120.0, 120.0, 150.0, 60.0, 90.0, 90.0, 60.0, 150.0, 60.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 90.0, 60.0, 120.0, 60.0, 120.0, 30.0, 120.0, 120.0, 150.0, 150.0, 120.0, 90.0, 90.0, 150.0, 90.0, 150.0, 180.0, 90.0, 150.0, 120.0, 120.0, 180.0, 120.0, 120.0, 150.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 90.0, 60.0, 90.0, 90.0, 90.0, 120.0, 120.0, 150.0, 90.0, 90.0, 150.0, 120.0, 120.0, 120.0, 120.0, 60.0, 120.0, 90.0, 120.0, 30.0, 90.0, 60.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 50.0, 20.0, 30.0, 30.0, 20.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 40.0, 10.0, 40.0, 40.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 60.0, 30.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 10.0, 30.0, 20.0, 20.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 50.0, 20.0, 30.0, 30.0, 20.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 40.0, 10.0, 40.0, 40.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 60.0, 30.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 10.0, 30.0, 20.0, 20.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 20.0, 30.0, 20.0, 40.0, 30.0, 30.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 50.0, 20.0, 30.0, 30.0, 20.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 40.0, 10.0, 40.0, 40.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 60.0, 30.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 30.0, 30.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 10.0, 30.0, 20.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0434910795571222, "mean_inference_ms": 25.929551816115364, "mean_action_processing_ms": 0.2472205446792053, "mean_env_wait_ms": 0.1397400363578938, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 61488, "timesteps_this_iter": 32, "agent_timesteps_total": 184464, "timers": {"load_time_ms": 0.668, "load_throughput": 47904.107, "learn_time_ms": 235.327, "learn_throughput": 135.981, "update_time_ms": 101.876}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 16.012104034423828, "min_q": -1.1150636672973633, "max_q": 38.54218673706055, "mean_td_error": 0.3094545304775238, "model": {}}, "td_error": [0.3959674835205078, -0.5996131896972656, -0.9182472229003906, 3.635099411010742, 10.083283424377441, -6.4886980056762695, 4.406848907470703, 0.6672735214233398, -4.506816864013672, -0.33841705322265625, 2.685138702392578, 15.333076477050781, 0.8994606733322144, -7.723232269287109, -7.605860710144043, 17.34223747253418, -8.062387466430664, 0.5382404327392578, 1.4970521926879883, -2.1790084838867188, -2.2241382598876953, -1.6745586395263672, 0.17461466789245605, 1.2023143768310547, 0.5355033874511719, -3.400881767272949, 2.1309728622436523, -2.769113063812256, 3.6116676330566406, -2.947307586669922, -0.6798543930053711, -3.118070602416992], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.073110580444336, "min_q": -2.2406675815582275, "max_q": 35.42793655395508, "mean_td_error": -1.2824032306671143, "model": {}}, "td_error": [-1.580352783203125, -3.663330554962158, 1.3948955535888672, 1.2772748470306396, -3.585947036743164, 1.128976821899414, -0.4964284896850586, 2.393045425415039, 1.6811714172363281, -3.663330554962158, -1.816136360168457, -2.920304298400879, -4.503302574157715, -1.2406675815582275, -0.7710685729980469, -7.331740856170654, -3.287796974182129, 3.873746871948242, -2.7296295166015625, -0.6320896148681641, 1.3123973608016968, 0.015339851379394531, -1.0259475708007812, -3.5459423065185547, 0.5795783996582031, -1.4094161987304688, -0.5203971862792969, -1.5881061553955078, -1.1844863891601562, -3.006209373474121, -1.9669532775878906, -2.2237472534179688], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.061674118041992, "min_q": -1.5733442306518555, "max_q": 40.51976776123047, "mean_td_error": -0.8264906406402588, "model": {}}, "td_error": [-3.0434513092041016, 0.004656791687011719, -1.249319076538086, -4.495101451873779, 1.4452037811279297, -0.5620384216308594, 1.2526521682739258, 1.363823413848877, -1.3387808799743652, -0.316192626953125, -0.23070812225341797, 0.7989158630371094, -0.13763999938964844, -1.3006811141967773, 0.24831771850585938, -2.878335952758789, 5.856453895568848, -0.6157684326171875, 0.5961380004882812, -1.3087005615234375, -7.481871604919434, -0.24053382873535156, -3.17633056640625, 0.18848562240600586, -2.949770927429199, -10.573344230651855, -0.27802276611328125, -1.1616592407226562, -0.314788818359375, 0.9164695739746094, 2.6527061462402344, 1.8815155029296875], "custom_metrics": {}}}, "num_steps_sampled": 61488, "num_agent_steps_sampled": 184464, "num_steps_trained": 120992, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 362976, "last_target_update_ts": 61424, "num_target_updates": 119}, "done": false, "episodes_total": 6148, "training_iteration": 61, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-03-21", "timestamp": 1648915401, "time_this_iter_s": 41.166486501693726, "time_total_s": 2424.6504411697388, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c73b560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c73b560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2424.6504411697388, "timesteps_since_restore": 1952, "iterations_since_restore": 61, "perf": {"cpu_util_percent": 51.963793103448275, "ram_util_percent": 65.83620689655173}}
{"episode_reward_max": 180.0, "episode_reward_min": 0.0, "episode_reward_mean": 99.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 33.1, "policy1": 33.1, "policy2": 33.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [60.0, 90.0, 30.0, 120.0, 120.0, 90.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 60.0, 90.0, 150.0, 90.0, 120.0, 120.0, 120.0, 90.0, 120.0, 120.0, 60.0, 150.0, 120.0, 0.0, 60.0, 90.0, 60.0, 120.0, 60.0, 120.0, 90.0, 150.0, 150.0, 90.0, 150.0, 90.0, 90.0, 120.0, 60.0, 120.0, 60.0, 30.0, 150.0, 60.0, 120.0, 120.0, 120.0, 120.0, 60.0, 90.0, 30.0, 120.0, 90.0, 120.0, 120.0, 60.0, 60.0, 90.0, 120.0, 120.0, 90.0, 120.0, 60.0, 120.0, 60.0, 0.0, 120.0, 120.0, 90.0, 150.0, 120.0, 120.0, 90.0, 120.0, 30.0, 150.0, 120.0, 120.0, 180.0, 30.0, 120.0, 90.0, 90.0, 60.0, 60.0, 120.0, 90.0, 90.0, 90.0, 60.0, 120.0, 120.0, 120.0, 60.0, 120.0, 120.0, 120.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [20.0, 30.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 0.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 50.0, 50.0, 30.0, 50.0, 30.0, 30.0, 40.0, 20.0, 40.0, 20.0, 10.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 40.0, 20.0, 0.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 50.0, 40.0, 40.0, 60.0, 10.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0], "policy_policy1_reward": [20.0, 30.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 0.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 50.0, 50.0, 30.0, 50.0, 30.0, 30.0, 40.0, 20.0, 40.0, 20.0, 10.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 40.0, 20.0, 0.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 50.0, 40.0, 40.0, 60.0, 10.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0], "policy_policy2_reward": [20.0, 30.0, 10.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 20.0, 50.0, 40.0, 0.0, 20.0, 30.0, 20.0, 40.0, 20.0, 40.0, 30.0, 50.0, 50.0, 30.0, 50.0, 30.0, 30.0, 40.0, 20.0, 40.0, 20.0, 10.0, 50.0, 20.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 10.0, 40.0, 30.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 30.0, 40.0, 20.0, 40.0, 20.0, 0.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 50.0, 40.0, 40.0, 60.0, 10.0, 40.0, 30.0, 30.0, 20.0, 20.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0433916015625002, "mean_inference_ms": 25.918251789093016, "mean_action_processing_ms": 0.2471796112060548, "mean_env_wait_ms": 0.13974709701538088, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 62496, "timesteps_this_iter": 32, "agent_timesteps_total": 187488, "timers": {"load_time_ms": 0.603, "load_throughput": 53031.62, "learn_time_ms": 229.772, "learn_throughput": 139.269, "update_time_ms": 98.881}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.309783935546875, "min_q": 0.02827325463294983, "max_q": 37.306671142578125, "mean_td_error": 1.0577514171600342, "model": {}}, "td_error": [1.5475692749023438, 1.9234352111816406, -0.7760353088378906, 4.962583541870117, -0.8169574737548828, 1.067068099975586, 5.150607109069824, 3.448118209838867, -0.07075166702270508, 2.913724422454834, -1.4526300430297852, -0.06143999099731445, 0.7590370178222656, 2.395662307739258, 5.317755222320557, 1.0903291702270508, 1.0282732248306274, -0.749117374420166, 0.13190460205078125, 0.6088671684265137, -2.5882930755615234, 2.2665061950683594, 0.12002944946289062, 3.1729164123535156, 1.1672992706298828, -2.141305923461914, -3.0819954872131348, 1.0920562744140625, 2.81912899017334, -0.5257816314697266, 0.6639747619628906, 2.4655075073242188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 14.302452087402344, "min_q": -2.4386160373687744, "max_q": 37.795860290527344, "mean_td_error": -1.1700106859207153, "model": {}}, "td_error": [-8.62229061126709, -1.9549436569213867, 2.720297336578369, 9.821369171142578, -4.014856338500977, -1.4405479431152344, -1.7450321912765503, 1.1533641815185547, -1.6677742004394531, -1.2324066162109375, -1.752854347229004, -7.284975051879883, -3.936429500579834, 0.49133825302124023, 1.4641742706298828, 3.1615991592407227, -3.455291748046875, -8.62229061126709, -2.0478262901306152, -6.069538116455078, 0.3835639953613281, -11.438615798950195, 9.592046737670898, 0.5347704887390137, 0.470794677734375, -1.8051109313964844, -2.0282812118530273, 1.650892734527588, 2.2180137634277344, 2.401987075805664, -0.23338079452514648, -4.152109146118164], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.577449798583984, "min_q": 1.3961503505706787, "max_q": 37.754058837890625, "mean_td_error": 1.4170398712158203, "model": {}}, "td_error": [-1.7668704986572266, -0.8593792915344238, 2.3907012939453125, 19.929426193237305, -6.673366546630859, 2.830078125, -0.2515125274658203, -1.0203361511230469, 1.8597736358642578, 20.753782272338867, 0.15845298767089844, -2.0041885375976562, 0.4084358215332031, 15.061846733093262, 0.27631378173828125, 0.9435653686523438, 0.5901260375976562, 0.4112663269042969, 1.3612529039382935, -0.19646930694580078, 2.0497264862060547, 1.4287524223327637, -0.7873039245605469, 0.3332700729370117, 2.3961503505706787, -0.9234237670898438, -1.9165172576904297, -7.846673965454102, -3.5509586334228516, -0.4864635467529297, -2.0654640197753906, 2.5112838745117188], "custom_metrics": {}}}, "num_steps_sampled": 62496, "num_agent_steps_sampled": 187488, "num_steps_trained": 123008, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 369024, "last_target_update_ts": 62448, "num_target_updates": 121}, "done": false, "episodes_total": 6248, "training_iteration": 62, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-04-00", "timestamp": 1648915440, "time_this_iter_s": 39.17352294921875, "time_total_s": 2463.8239641189575, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c767320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c767320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2463.8239641189575, "timesteps_since_restore": 1984, "iterations_since_restore": 62, "perf": {"cpu_util_percent": 51.853571428571435, "ram_util_percent": 65.35178571428571}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 105.6, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 35.2, "policy1": 35.2, "policy2": 35.2}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 120.0, 120.0, 90.0, 90.0, 90.0, 60.0, 120.0, 120.0, 120.0, 60.0, 30.0, 120.0, 90.0, 120.0, 90.0, 150.0, 120.0, 120.0, 120.0, 90.0, 120.0, 120.0, 90.0, 120.0, 120.0, 150.0, 90.0, 120.0, 120.0, 150.0, 60.0, 120.0, 30.0, 150.0, 120.0, 90.0, 90.0, 120.0, 120.0, 150.0, 120.0, 120.0, 180.0, 120.0, 60.0, 60.0, 90.0, 90.0, 90.0, 120.0, 90.0, 150.0, 60.0, 90.0, 60.0, 90.0, 120.0, 120.0, 120.0, 60.0, 120.0, 90.0, 120.0, 120.0, 90.0, 150.0, 150.0, 150.0, 120.0, 120.0, 90.0, 120.0, 30.0, 60.0, 90.0, 60.0, 90.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 120.0, 30.0, 90.0, 90.0, 90.0, 90.0, 90.0, 60.0, 120.0, 120.0, 150.0, 60.0, 150.0, 150.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 50.0, 20.0, 50.0, 50.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 50.0, 20.0, 50.0, 50.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 40.0, 20.0, 10.0, 40.0, 30.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 10.0, 50.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 20.0, 20.0, 30.0, 30.0, 30.0, 40.0, 30.0, 50.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 10.0, 20.0, 30.0, 20.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 30.0, 30.0, 30.0, 30.0, 30.0, 20.0, 40.0, 40.0, 50.0, 20.0, 50.0, 50.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0430280797508715, "mean_inference_ms": 25.895044621468013, "mean_action_processing_ms": 0.24700861940637986, "mean_env_wait_ms": 0.13969525616948483, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 63504, "timesteps_this_iter": 32, "agent_timesteps_total": 190512, "timers": {"load_time_ms": 0.649, "load_throughput": 49341.125, "learn_time_ms": 244.406, "learn_throughput": 130.93, "update_time_ms": 117.186}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.53722381591797, "min_q": -2.987337589263916, "max_q": 38.5080680847168, "mean_td_error": 0.291360080242157, "model": {}}, "td_error": [-1.5297250747680664, -3.316317081451416, -2.569772720336914, -0.6230316162109375, -1.5102653503417969, -0.1545119285583496, -1.1880664825439453, 2.0828170776367188, -3.019585609436035, 2.3319482803344727, -3.4857864379882812, -0.6709785461425781, -0.09825897216796875, 1.3531131744384766, 2.065267562866211, -1.0973329544067383, -2.4429359436035156, 3.3979263305664062, 12.263007164001465, -1.9124565124511719, 1.5870246887207031, 7.7535929679870605, -3.917562484741211, -8.157784461975098, -0.08872556686401367, -4.359807014465332, -0.4962787628173828, -1.987337589263916, 0.0289764404296875, 0.9271087646484375, 17.805513381958008, 0.3537473678588867], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.58334732055664, "min_q": 1.1894028186798096, "max_q": 36.71529006958008, "mean_td_error": 0.6289197206497192, "model": {}}, "td_error": [8.8297758102417, -0.8404321670532227, 2.3008480072021484, 1.7528228759765625, -1.4671077728271484, -1.098062515258789, -0.37427711486816406, -1.319540023803711, -1.7043743133544922, 2.598390579223633, -5.5327606201171875, 2.9576168060302734, 0.4015464782714844, -4.25445032119751, 11.330364227294922, 3.730832576751709, 0.33788299560546875, 3.229886054992676, -4.803522109985352, -4.713470458984375, 2.8664169311523438, 1.8077011108398438, 1.4991455078125, -1.622572898864746, -1.4324989318847656, 1.4472503662109375, -1.3860244750976562, 2.772106170654297, -0.06104731559753418, 2.4452457427978516, -1.7616643905639648, 2.1894028186798096], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.248004913330078, "min_q": 0.16192221641540527, "max_q": 40.68815612792969, "mean_td_error": 1.1203536987304688, "model": {}}, "td_error": [-0.3982505798339844, 0.04665565490722656, -3.2415084838867188, 0.7943878173828125, 0.6297550201416016, 15.932472229003906, 0.2231006622314453, -1.3034896850585938, 2.0365867614746094, -1.2168426513671875, 1.6417484283447266, -4.832122802734375, 0.7681655883789062, 1.7994117736816406, -0.9368743896484375, -0.6403350830078125, 12.420267105102539, 8.226703643798828, -1.0260915756225586, -1.1509246826171875, 0.45277976989746094, 12.765750885009766, -1.5891451835632324, -0.21117401123046875, -1.5801143646240234, 1.1619222164154053, -2.400665283203125, -0.4998626708984375, 1.4371728897094727, -0.4734382629394531, -2.299912452697754, -0.6848106384277344], "custom_metrics": {}}}, "num_steps_sampled": 63504, "num_agent_steps_sampled": 190512, "num_steps_trained": 125024, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 375072, "last_target_update_ts": 63472, "num_target_updates": 123}, "done": false, "episodes_total": 6348, "training_iteration": 63, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-04-41", "timestamp": 1648915481, "time_this_iter_s": 40.420125007629395, "time_total_s": 2504.244089126587, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c73ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c73ff80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2504.244089126587, "timesteps_since_restore": 2016, "iterations_since_restore": 63, "perf": {"cpu_util_percent": 51.89122807017544, "ram_util_percent": 65.14385964912282}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 116.1, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 38.7, "policy1": 38.7, "policy2": 38.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 150.0, 90.0, 120.0, 90.0, 150.0, 150.0, 150.0, 90.0, 120.0, 150.0, 120.0, 30.0, 120.0, 150.0, 120.0, 90.0, 120.0, 120.0, 150.0, 120.0, 150.0, 150.0, 120.0, 90.0, 120.0, 90.0, 90.0, 150.0, 150.0, 90.0, 90.0, 60.0, 150.0, 120.0, 150.0, 150.0, 90.0, 120.0, 90.0, 90.0, 150.0, 120.0, 120.0, 120.0, 180.0, 120.0, 90.0, 90.0, 120.0, 90.0, 150.0, 90.0, 90.0, 120.0, 120.0, 120.0, 120.0, 90.0, 150.0, 90.0, 120.0, 150.0, 120.0, 120.0, 60.0, 120.0, 90.0, 180.0, 150.0, 120.0, 150.0, 150.0, 90.0, 120.0, 150.0, 90.0, 90.0, 30.0, 90.0, 90.0, 90.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 150.0, 120.0, 90.0, 90.0, 120.0, 150.0, 90.0, 120.0, 150.0, 120.0, 120.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 50.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 40.0, 10.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 30.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 40.0], "policy_policy1_reward": [40.0, 50.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 40.0, 10.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 30.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 40.0], "policy_policy2_reward": [40.0, 50.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 40.0, 10.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 30.0, 50.0, 50.0, 30.0, 30.0, 20.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 30.0, 30.0, 40.0, 30.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 30.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 30.0, 30.0, 10.0, 30.0, 30.0, 30.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 30.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 40.0, 40.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.042574213563535, "mean_inference_ms": 25.88403102624171, "mean_action_processing_ms": 0.2468880410306445, "mean_env_wait_ms": 0.13963423701211874, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 64512, "timesteps_this_iter": 32, "agent_timesteps_total": 193536, "timers": {"load_time_ms": 0.593, "load_throughput": 53961.214, "learn_time_ms": 228.901, "learn_throughput": 139.798, "update_time_ms": 96.336}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.799210548400879, "min_q": -1.6581549644470215, "max_q": 37.52260208129883, "mean_td_error": -0.3092799484729767, "model": {}}, "td_error": [-0.6581549644470215, 0.5384511947631836, 0.3228491246700287, -1.6006193161010742, 14.189888000488281, -4.983921051025391, -0.501251220703125, -0.5886726379394531, -0.8898968696594238, 0.425872802734375, -1.0788421630859375, -0.1909646987915039, 0.065032958984375, -6.626463890075684, -6.970065116882324, -2.617569923400879, -1.589818000793457, 3.24820613861084, 4.239559650421143, -1.3226451873779297, -1.7198238372802734, 1.1904335021972656, -2.6364784240722656, 2.5004425048828125, 3.9486656188964844, 0.33144962787628174, -2.9106130599975586, 2.2606592178344727, 0.055756717920303345, -1.3656234741210938, -2.469048500061035, -2.493753433227539], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.630935668945312, "min_q": -0.7514971494674683, "max_q": 37.625911712646484, "mean_td_error": -0.0761806070804596, "model": {}}, "td_error": [1.1419181823730469, 0.21744310855865479, -7.487527847290039, -1.0263423919677734, 1.741241455078125, -5.527849197387695, -1.319777488708496, 17.78990936279297, 7.634390354156494, -0.38657188415527344, 0.49935150146484375, -2.1434593200683594, 2.0514755249023438, -3.909170150756836, -0.44492340087890625, -4.234796524047852, 9.693668365478516, -0.9444093704223633, -2.0943775177001953, -0.5764694213867188, 2.0057544708251953, 0.9465980529785156, 1.703470230102539, -1.025115966796875, -4.105045318603516, -2.5267467498779297, -4.356571197509766, 0.49935150146484375, -3.5188817977905273, -2.5052175521850586, -1.954854965209961, 1.7257575988769531], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.901273727416992, "min_q": 1.092724084854126, "max_q": 39.49307632446289, "mean_td_error": 1.1757930517196655, "model": {}}, "td_error": [-4.166906356811523, -1.5940513610839844, 1.0394153594970703, -0.8146247863769531, 0.5700774192810059, -1.4176297187805176, 0.0074443817138671875, -1.773233413696289, -0.8088474273681641, 0.7164695262908936, 1.7103166580200195, 1.5991134643554688, 1.1849021911621094, 1.2020988464355469, 0.6090974807739258, 0.6434497833251953, 16.475229263305664, 1.3833255767822266, 1.2648887634277344, 3.6200599670410156, -3.0831289291381836, -0.4624004364013672, -3.7855939865112305, -0.20044898986816406, 8.810066223144531, 1.7907733917236328, 18.183992385864258, -1.7535457611083984, 1.1226577758789062, 1.18914794921875, -3.4580039978027344, -2.1787338256835938], "custom_metrics": {}}}, "num_steps_sampled": 64512, "num_agent_steps_sampled": 193536, "num_steps_trained": 127040, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 381120, "last_target_update_ts": 64496, "num_target_updates": 125}, "done": false, "episodes_total": 6448, "training_iteration": 64, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-05-20", "timestamp": 1648915520, "time_this_iter_s": 38.99403238296509, "time_total_s": 2543.238121509552, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2543.238121509552, "timesteps_since_restore": 2048, "iterations_since_restore": 64, "perf": {"cpu_util_percent": 51.93454545454545, "ram_util_percent": 65.16545454545455}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 115.96153846153847, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 38.65384615384615, "policy1": 38.65384615384615, "policy2": 38.65384615384615}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 180.0, 90.0, 120.0, 90.0, 120.0, 150.0, 120.0, 120.0, 90.0, 150.0, 30.0, 180.0, 120.0, 120.0, 120.0, 120.0, 60.0, 90.0, 90.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 120.0, 120.0, 120.0, 180.0, 150.0, 90.0, 120.0, 90.0, 90.0, 120.0, 180.0, 60.0, 90.0, 90.0, 120.0, 150.0, 120.0, 120.0, 60.0, 60.0, 90.0, 120.0, 120.0, 150.0, 60.0, 120.0, 90.0, 120.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 150.0, 60.0, 150.0, 120.0, 120.0, 90.0, 90.0, 120.0, 90.0, 120.0, 90.0, 120.0, 150.0, 120.0, 150.0, 120.0, 60.0, 120.0, 90.0, 120.0, 120.0, 120.0, 90.0, 120.0, 150.0, 150.0, 150.0, 90.0, 90.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 90.0, 90.0, 120.0, 90.0, 90.0, 180.0, 90.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 60.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 40.0, 30.0, 50.0, 10.0, 60.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 40.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 20.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0, 60.0, 30.0, 30.0], "policy_policy1_reward": [40.0, 60.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 40.0, 30.0, 50.0, 10.0, 60.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 40.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 20.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0, 60.0, 30.0, 30.0], "policy_policy2_reward": [40.0, 60.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 40.0, 30.0, 50.0, 10.0, 60.0, 40.0, 40.0, 40.0, 40.0, 20.0, 30.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 40.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 20.0, 20.0, 30.0, 40.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 20.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 20.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0, 60.0, 30.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0420068862870329, "mean_inference_ms": 25.870258613395702, "mean_action_processing_ms": 0.24677025923237866, "mean_env_wait_ms": 0.13961986150288055, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 65520, "timesteps_this_iter": 32, "agent_timesteps_total": 196560, "timers": {"load_time_ms": 0.702, "load_throughput": 45557.764, "learn_time_ms": 231.722, "learn_throughput": 138.096, "update_time_ms": 98.697}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.9293212890625, "min_q": 2.3028483390808105, "max_q": 40.465118408203125, "mean_td_error": 0.3701050877571106, "model": {}}, "td_error": [-8.314085006713867, 10.198165893554688, 0.6753158569335938, 0.31243133544921875, -0.9092309474945068, 1.8174829483032227, -1.3357658386230469, -0.06513738632202148, 3.8882455825805664, -0.23118305206298828, -1.5373477935791016, 3.3028483390808105, -3.2012147903442383, 0.6931190490722656, 0.9206733703613281, 0.4679532051086426, 1.1672782897949219, 0.002185821533203125, 1.281494140625, 0.1306610107421875, -0.85064697265625, 5.0962724685668945, -0.5303821563720703, 0.5144186019897461, 2.288869857788086, -3.993178367614746, -1.8718791007995605, 2.1485958099365234, -1.3357658386230469, 4.977245330810547, -1.93182373046875, -1.9322528839111328], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.642112731933594, "min_q": -0.5742377042770386, "max_q": 39.45741271972656, "mean_td_error": 2.5224435329437256, "model": {}}, "td_error": [-0.9653949737548828, -1.2731399536132812, 18.649578094482422, -0.41433238983154297, 0.0070285797119140625, 0.8779239654541016, 16.045326232910156, 0.5064115524291992, -9.574237823486328, 3.9334850311279297, 1.8850631713867188, -0.2536907196044922, -0.9986400604248047, 1.3111686706542969, 3.658100128173828, -0.8525943756103516, 8.358306884765625, -8.557661056518555, -0.6644515991210938, 2.69952392578125, 21.601261138916016, -0.5568742752075195, -0.1518411636352539, 6.321010589599609, 2.020313262939453, 0.005948066711425781, 12.174396514892578, 0.03256797790527344, -6.003223419189453, 0.00710296630859375, -0.2536888122558594, 11.143445014953613], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 23.57341194152832, "min_q": -1.5554752349853516, "max_q": 43.11555099487305, "mean_td_error": 1.6074650287628174, "model": {}}, "td_error": [-4.015451431274414, 0.19649505615234375, -1.520782470703125, 0.3699378967285156, 3.9925994873046875, 4.985727310180664, -1.7171001434326172, 1.8782882690429688, -0.7477836608886719, -0.9543876647949219, -3.523763656616211, 5.852985382080078, 2.7371253967285156, 2.66259765625, 5.106003761291504, 9.02894401550293, 2.2420034408569336, -1.4456214904785156, -0.5554752349853516, -5.129194259643555, 5.283866882324219, -0.8621997833251953, 0.03896331787109375, -1.1353797912597656, 22.28923988342285, -1.8386350870132446, -1.192230224609375, -2.0567779541015625, 5.823476791381836, 3.115678310394287, 0.9918575286865234, 1.537872314453125], "custom_metrics": {}}}, "num_steps_sampled": 65520, "num_agent_steps_sampled": 196560, "num_steps_trained": 129056, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 387168, "last_target_update_ts": 65520, "num_target_updates": 127}, "done": false, "episodes_total": 6552, "training_iteration": 65, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-05-59", "timestamp": 1648915559, "time_this_iter_s": 38.85793375968933, "time_total_s": 2582.0960552692413, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c748c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c748c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2582.0960552692413, "timesteps_since_restore": 2080, "iterations_since_restore": 65, "perf": {"cpu_util_percent": 51.9909090909091, "ram_util_percent": 65.19636363636364}}
{"episode_reward_max": 180.0, "episode_reward_min": 30.0, "episode_reward_mean": 105.3, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 35.1, "policy1": 35.1, "policy2": 35.1}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 120.0, 120.0, 90.0, 90.0, 120.0, 150.0, 60.0, 60.0, 150.0, 60.0, 90.0, 150.0, 120.0, 60.0, 90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 60.0, 120.0, 120.0, 90.0, 60.0, 90.0, 60.0, 120.0, 120.0, 180.0, 120.0, 150.0, 60.0, 90.0, 120.0, 150.0, 90.0, 90.0, 60.0, 30.0, 120.0, 60.0, 90.0, 150.0, 60.0, 120.0, 90.0, 120.0, 60.0, 150.0, 90.0, 150.0, 150.0, 120.0, 90.0, 120.0, 120.0, 150.0, 120.0, 120.0, 60.0, 120.0, 120.0, 150.0, 90.0, 90.0, 120.0, 90.0, 120.0, 150.0, 60.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 90.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 30.0, 60.0, 60.0, 120.0, 120.0, 120.0, 120.0, 120.0, 90.0, 150.0, 120.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 50.0, 20.0, 20.0, 50.0, 20.0, 30.0, 50.0, 40.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 60.0, 40.0, 50.0, 20.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 30.0, 40.0, 20.0, 50.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 50.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0], "policy_policy1_reward": [50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 50.0, 20.0, 20.0, 50.0, 20.0, 30.0, 50.0, 40.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 60.0, 40.0, 50.0, 20.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 30.0, 40.0, 20.0, 50.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 50.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0], "policy_policy2_reward": [50.0, 40.0, 40.0, 30.0, 30.0, 40.0, 50.0, 20.0, 20.0, 50.0, 20.0, 30.0, 50.0, 40.0, 20.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 20.0, 40.0, 40.0, 30.0, 20.0, 30.0, 20.0, 40.0, 40.0, 60.0, 40.0, 50.0, 20.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 10.0, 40.0, 20.0, 30.0, 50.0, 20.0, 40.0, 30.0, 40.0, 20.0, 50.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 50.0, 30.0, 30.0, 40.0, 30.0, 40.0, 50.0, 20.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 10.0, 20.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0422170502635075, "mean_inference_ms": 25.87915025528272, "mean_action_processing_ms": 0.24671592335703, "mean_env_wait_ms": 0.13964873745473974, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 66528, "timesteps_this_iter": 32, "agent_timesteps_total": 199584, "timers": {"load_time_ms": 0.681, "load_throughput": 47019.698, "learn_time_ms": 259.413, "learn_throughput": 123.355, "update_time_ms": 107.405}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.48953628540039, "min_q": -1.3559210300445557, "max_q": 40.912479400634766, "mean_td_error": 0.8636438846588135, "model": {}}, "td_error": [-1.6116790771484375, 0.11402368545532227, -0.412811279296875, 6.005164623260498, -0.2314929962158203, 0.5074803829193115, -1.6171321868896484, -1.7731914520263672, 0.39251708984375, 4.5731730461120605, -0.5756683349609375, 0.9761247634887695, -1.1591148376464844, 0.8056755065917969, 1.3843536376953125, -0.025077342987060547, 4.5731730461120605, 0.29857635498046875, 1.9347114562988281, 1.5648473501205444, -0.6662864685058594, 1.4373550415039062, -1.1007804870605469, 1.890380859375, 0.17604446411132812, -2.1266536712646484, 0.1708230972290039, -0.6540412902832031, 2.234996795654297, -0.24773406982421875, 11.147163391113281, -0.3483161926269531], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 15.93905258178711, "min_q": -2.3391666412353516, "max_q": 38.909976959228516, "mean_td_error": 0.5378178358078003, "model": {}}, "td_error": [-0.8822097778320312, 0.2809574604034424, 0.9832315444946289, -2.4037322998046875, -1.0270614624023438, -0.11680984497070312, 1.4634387493133545, -2.042041778564453, -1.0491504669189453, 4.608613014221191, -1.4318523406982422, 4.315488815307617, -2.5491867065429688, -0.5983066558837891, 3.6412436962127686, 20.023406982421875, 17.227386474609375, 2.8155555725097656, 0.18709886074066162, -3.6952993869781494, -3.5218734741210938, -2.5176925659179688, -2.4047775268554688, -2.709583282470703, 5.338781833648682, -0.485076904296875, -7.60898494720459, -0.7180881500244141, -3.8641557693481445, -1.3413177728652954, -1.657273530960083, -1.0505561828613281], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.697607040405273, "min_q": -1.5858858823776245, "max_q": 43.48046875, "mean_td_error": 0.2890130579471588, "model": {}}, "td_error": [-2.140148162841797, 19.337602615356445, -0.7158651351928711, -0.5858858823776245, -3.7104263305664062, -1.162313461303711, -0.24175381660461426, 1.9005699157714844, -0.6308727264404297, 4.204242706298828, -1.8439788818359375, -0.43146324157714844, 0.6704025268554688, -3.5839614868164062, 3.8714351654052734, -1.8505187034606934, -0.05668067932128906, -1.9100608825683594, -2.373058319091797, -1.178053855895996, -0.6878585815429688, 1.4341583251953125, -1.104365348815918, -0.2382359504699707, -1.3773956298828125, 1.200357437133789, -8.417899131774902, -6.530675888061523, 21.946626663208008, -1.5818290710449219, -2.140148162841797, -0.8235282897949219], "custom_metrics": {}}}, "num_steps_sampled": 66528, "num_agent_steps_sampled": 199584, "num_steps_trained": 131072, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 393216, "last_target_update_ts": 66032, "num_target_updates": 128}, "done": false, "episodes_total": 6652, "training_iteration": 66, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-06-40", "timestamp": 1648915600, "time_this_iter_s": 40.830952405929565, "time_total_s": 2622.927007675171, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c748f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c748f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2622.927007675171, "timesteps_since_restore": 2112, "iterations_since_restore": 66, "perf": {"cpu_util_percent": 52.091379310344834, "ram_util_percent": 65.60172413793103}}
{"episode_reward_max": 180.0, "episode_reward_min": 0.0, "episode_reward_mean": 106.5, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 35.5, "policy1": 35.5, "policy2": 35.5}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 90.0, 90.0, 150.0, 90.0, 90.0, 90.0, 60.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 30.0, 90.0, 150.0, 120.0, 120.0, 120.0, 60.0, 90.0, 120.0, 120.0, 150.0, 90.0, 150.0, 90.0, 120.0, 0.0, 150.0, 120.0, 60.0, 180.0, 120.0, 30.0, 60.0, 120.0, 120.0, 90.0, 90.0, 150.0, 90.0, 90.0, 120.0, 150.0, 90.0, 90.0, 60.0, 90.0, 120.0, 90.0, 30.0, 150.0, 60.0, 90.0, 120.0, 90.0, 120.0, 150.0, 150.0, 90.0, 120.0, 90.0, 120.0, 90.0, 90.0, 90.0, 120.0, 150.0, 150.0, 180.0, 90.0, 120.0, 90.0, 150.0, 150.0, 150.0, 60.0, 60.0, 120.0, 120.0, 150.0, 90.0, 30.0, 60.0, 150.0, 120.0, 150.0, 150.0, 150.0, 90.0, 120.0, 120.0, 90.0, 90.0, 120.0, 90.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 10.0, 30.0, 50.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 0.0, 50.0, 40.0, 20.0, 60.0, 40.0, 10.0, 20.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 50.0, 20.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 50.0, 50.0, 60.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 40.0, 40.0, 50.0, 30.0, 10.0, 20.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0], "policy_policy1_reward": [40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 10.0, 30.0, 50.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 0.0, 50.0, 40.0, 20.0, 60.0, 40.0, 10.0, 20.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 50.0, 20.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 50.0, 50.0, 60.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 40.0, 40.0, 50.0, 30.0, 10.0, 20.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0], "policy_policy2_reward": [40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 10.0, 30.0, 50.0, 40.0, 40.0, 40.0, 20.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 0.0, 50.0, 40.0, 20.0, 60.0, 40.0, 10.0, 20.0, 40.0, 40.0, 30.0, 30.0, 50.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 20.0, 30.0, 40.0, 30.0, 10.0, 50.0, 20.0, 30.0, 40.0, 30.0, 40.0, 50.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 30.0, 30.0, 40.0, 50.0, 50.0, 60.0, 30.0, 40.0, 30.0, 50.0, 50.0, 50.0, 20.0, 20.0, 40.0, 40.0, 50.0, 30.0, 10.0, 20.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 30.0, 30.0, 40.0, 30.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0421772027178067, "mean_inference_ms": 25.879866271319734, "mean_action_processing_ms": 0.2466742477721987, "mean_env_wait_ms": 0.13966595311118257, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 67536, "timesteps_this_iter": 32, "agent_timesteps_total": 202608, "timers": {"load_time_ms": 0.733, "load_throughput": 43670.765, "learn_time_ms": 244.088, "learn_throughput": 131.1, "update_time_ms": 105.011}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.55312728881836, "min_q": 1.0626243352890015, "max_q": 42.023799896240234, "mean_td_error": 1.0893877744674683, "model": {}}, "td_error": [-0.5835781097412109, 1.795989990234375, -3.7900171279907227, 2.5265884399414062, 0.23919224739074707, -1.2830371856689453, 1.3853416442871094, -0.36525726318359375, 4.505937576293945, -3.273904800415039, -0.9440746307373047, -0.5343093872070312, 12.598503112792969, 1.4341506958007812, -1.017038345336914, 0.3663291931152344, 3.0761709213256836, -0.29492950439453125, -0.4506874084472656, 3.016935348510742, -1.3175640106201172, 2.971919059753418, -2.3577346801757812, 2.4982290267944336, 4.6557111740112305, 0.43981170654296875, -1.8202018737792969, 5.561072826385498, 2.062624454498291, -1.8176689147949219, 4.547548294067383, 1.0283546447753906], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.79792594909668, "min_q": 2.0078470706939697, "max_q": 39.44865417480469, "mean_td_error": 2.932096481323242, "model": {}}, "td_error": [3.405162811279297, 0.3402214050292969, 0.3422994613647461, 3.4756898880004883, 1.8676986694335938, 3.24674129486084, 24.634784698486328, -0.8320560455322266, -2.170034408569336, 10.901006698608398, -0.18547821044921875, -1.5933723449707031, 1.5902976989746094, 23.577417373657227, -3.117115020751953, 0.9735183715820312, -1.361433982849121, 11.678960800170898, -1.3842525482177734, -0.41618919372558594, -6.992153167724609, 2.2192859649658203, 0.26442718505859375, 3.116619110107422, 2.916828155517578, 0.7967061996459961, 3.114849090576172, 3.4527928829193115, -0.4345054626464844, 4.549690246582031, 0.16357135772705078, 5.685110569000244], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.64936065673828, "min_q": 2.342656373977661, "max_q": 45.12602233886719, "mean_td_error": 0.2415969967842102, "model": {}}, "td_error": [-1.4786911010742188, 0.04893755912780762, -1.1452770233154297, 0.8745880126953125, 3.9200496673583984, 2.4194869995117188, 1.9893150329589844, -0.9236335754394531, -1.51910400390625, -0.8762550354003906, -1.5210380554199219, -0.2905254364013672, 0.8961343765258789, 0.40256500244140625, 2.146808624267578, -2.670989990234375, -0.7082023620605469, 1.765869140625, 1.8302974700927734, -5.048617362976074, -0.46179771423339844, -0.6350898742675781, 3.049999237060547, 3.392639636993408, 1.0192546844482422, 2.155731201171875, 3.9943923950195312, -1.5106391906738281, -0.4906425476074219, 1.8790245056152344, -1.9575881958007812, -2.815898895263672], "custom_metrics": {}}}, "num_steps_sampled": 67536, "num_agent_steps_sampled": 202608, "num_steps_trained": 133088, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 399264, "last_target_update_ts": 67056, "num_target_updates": 130}, "done": false, "episodes_total": 6752, "training_iteration": 67, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-07-21", "timestamp": 1648915641, "time_this_iter_s": 40.999351263046265, "time_total_s": 2663.926358938217, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7bacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7bacb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2663.926358938217, "timesteps_since_restore": 2144, "iterations_since_restore": 67, "perf": {"cpu_util_percent": 51.94827586206897, "ram_util_percent": 65.55862068965517}}
{"episode_reward_max": 180.0, "episode_reward_min": 60.0, "episode_reward_mean": 116.1, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 38.7, "policy1": 38.7, "policy2": 38.7}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 90.0, 120.0, 150.0, 120.0, 120.0, 180.0, 120.0, 120.0, 150.0, 90.0, 60.0, 60.0, 120.0, 120.0, 90.0, 120.0, 90.0, 120.0, 150.0, 90.0, 120.0, 150.0, 180.0, 120.0, 60.0, 150.0, 120.0, 150.0, 60.0, 90.0, 150.0, 120.0, 150.0, 60.0, 90.0, 90.0, 120.0, 150.0, 90.0, 90.0, 90.0, 90.0, 90.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 120.0, 120.0, 90.0, 90.0, 150.0, 150.0, 60.0, 150.0, 90.0, 90.0, 90.0, 60.0, 120.0, 60.0, 150.0, 90.0, 120.0, 60.0, 150.0, 90.0, 120.0, 120.0, 150.0, 180.0, 150.0, 150.0, 150.0, 120.0, 150.0, 150.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 120.0, 120.0, 90.0, 90.0, 120.0, 60.0, 90.0, 150.0, 90.0, 150.0, 150.0, 120.0, 120.0, 180.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 20.0, 50.0, 40.0, 50.0, 20.0, 30.0, 50.0, 40.0, 50.0, 20.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 50.0, 50.0, 20.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 50.0, 30.0, 40.0, 20.0, 50.0, 30.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 40.0, 60.0], "policy_policy1_reward": [30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 20.0, 50.0, 40.0, 50.0, 20.0, 30.0, 50.0, 40.0, 50.0, 20.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 50.0, 50.0, 20.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 50.0, 30.0, 40.0, 20.0, 50.0, 30.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 40.0, 60.0], "policy_policy2_reward": [30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 40.0, 50.0, 30.0, 20.0, 20.0, 40.0, 40.0, 30.0, 40.0, 30.0, 40.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 20.0, 50.0, 40.0, 50.0, 20.0, 30.0, 50.0, 40.0, 50.0, 20.0, 30.0, 30.0, 40.0, 50.0, 30.0, 30.0, 30.0, 30.0, 30.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 30.0, 30.0, 50.0, 50.0, 20.0, 50.0, 30.0, 30.0, 30.0, 20.0, 40.0, 20.0, 50.0, 30.0, 40.0, 20.0, 50.0, 30.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 30.0, 30.0, 40.0, 20.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 40.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0422939158462619, "mean_inference_ms": 25.881076384962462, "mean_action_processing_ms": 0.24669471028847653, "mean_env_wait_ms": 0.13968331286389232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 68544, "timesteps_this_iter": 32, "agent_timesteps_total": 205632, "timers": {"load_time_ms": 0.699, "load_throughput": 45806.535, "learn_time_ms": 246.364, "learn_throughput": 129.889, "update_time_ms": 105.707}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.199310302734375, "min_q": -1.425102710723877, "max_q": 40.272560119628906, "mean_td_error": 0.9672342538833618, "model": {}}, "td_error": [-1.9887027740478516, -2.881092071533203, 2.8353843688964844, -0.1968839168548584, -2.907970428466797, 0.6780815124511719, -2.5734786987304688, -1.026571273803711, -0.5819091796875, -1.9674630165100098, -0.2547569274902344, 2.336793899536133, -0.8783760070800781, 24.991331100463867, -0.40709495544433594, 9.434797286987305, 0.2808036804199219, -0.07366561889648438, -2.881092071533203, -4.731691360473633, 1.8301925659179688, -5.080658912658691, -2.5332107543945312, 6.38203763961792, -1.3235721588134766, -4.799491882324219, -1.04541015625, -2.5716075897216797, -1.464888334274292, 11.410309791564941, 0.5847053527832031, 12.356647491455078], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.755212783813477, "min_q": -2.0573689937591553, "max_q": 39.601470947265625, "mean_td_error": 1.0967216491699219, "model": {}}, "td_error": [-0.32853269577026367, -1.9779882431030273, -7.280547142028809, 10.290994644165039, 13.287003517150879, 0.1609344482421875, 1.0914344787597656, 0.3864014148712158, -2.373140335083008, -6.600388526916504, 4.196725368499756, 5.388177871704102, -2.3223133087158203, -5.955052375793457, 2.881124496459961, -0.9650154113769531, 0.5622386932373047, 1.2106590270996094, 23.56180763244629, -0.7195281982421875, -2.8553504943847656, 2.2680397033691406, -0.22449684143066406, -1.552947998046875, 3.0648155212402344, 0.2821919918060303, -0.07995986938476562, -4.908088207244873, 1.6173219680786133, 3.382640838623047, -2.193718910217285, 1.799652099609375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.210908889770508, "min_q": -1.478196382522583, "max_q": 45.58580017089844, "mean_td_error": 0.717490553855896, "model": {}}, "td_error": [-3.2388534545898438, -0.0015048980712890625, -0.7836360931396484, 0.8487434387207031, -3.1466121673583984, -0.8449287414550781, 2.977144956588745, 4.631762504577637, 2.4490203857421875, 1.3813972473144531, -0.0083465576171875, 2.1610031127929688, 7.3453369140625, -1.0404243469238281, 14.538948059082031, -0.4141578674316406, -0.9603424072265625, 1.858284592628479, 0.5281305313110352, -0.5906896591186523, -0.1472311019897461, -2.3702468872070312, -4.74888801574707, -9.824275016784668, -9.118976593017578, 1.2275900840759277, -1.7831649780273438, -1.8761053085327148, 25.8635311126709, -0.478196382522583, -2.9323959350585938, 1.4577805995941162], "custom_metrics": {}}}, "num_steps_sampled": 68544, "num_agent_steps_sampled": 205632, "num_steps_trained": 135104, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 405312, "last_target_update_ts": 68080, "num_target_updates": 132}, "done": false, "episodes_total": 6852, "training_iteration": 68, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-08-01", "timestamp": 1648915681, "time_this_iter_s": 39.967822551727295, "time_total_s": 2703.8941814899445, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c1dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c1dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2703.8941814899445, "timesteps_since_restore": 2176, "iterations_since_restore": 68, "perf": {"cpu_util_percent": 51.53508771929825, "ram_util_percent": 65.11754385964912}}
{"episode_reward_max": 186.0, "episode_reward_min": 0.0, "episode_reward_mean": 117.98019801980197, "episode_len_mean": 9.98019801980198, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 39.32673267326733, "policy1": 39.32673267326733, "policy2": 39.32673267326733}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 120.0, 150.0, 30.0, 0.0, 120.0, 120.0, 120.0, 120.0, 60.0, 150.0, 90.0, 90.0, 90.0, 120.0, 150.0, 90.0, 180.0, 30.0, 120.0, 120.0, 120.0, 120.0, 90.0, 30.0, 120.0, 150.0, 180.0, 120.0, 120.0, 120.0, 150.0, 120.0, 150.0, 150.0, 90.0, 150.0, 150.0, 180.0, 120.0, 150.0, 30.0, 90.0, 186.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 150.0, 150.0, 120.0, 60.0, 120.0, 60.0, 120.0, 60.0, 120.0, 120.0, 150.0, 120.0, 90.0, 90.0, 90.0, 120.0, 120.0, 120.0, 150.0, 90.0, 120.0, 120.0, 150.0, 90.0, 150.0, 120.0, 90.0, 150.0, 150.0, 150.0, 150.0, 150.0, 90.0, 150.0, 90.0, 150.0, 150.0, 120.0, 150.0, 150.0, 150.0, 120.0, 120.0, 90.0, 120.0, 120.0, 90.0, 60.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 40.0, 50.0, 10.0, 0.0, 40.0, 40.0, 40.0, 40.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 60.0, 10.0, 40.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 60.0, 40.0, 50.0, 10.0, 30.0, 62.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0], "policy_policy1_reward": [30.0, 40.0, 50.0, 10.0, 0.0, 40.0, 40.0, 40.0, 40.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 60.0, 10.0, 40.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 60.0, 40.0, 50.0, 10.0, 30.0, 62.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0], "policy_policy2_reward": [30.0, 40.0, 50.0, 10.0, 0.0, 40.0, 40.0, 40.0, 40.0, 20.0, 50.0, 30.0, 30.0, 30.0, 40.0, 50.0, 30.0, 60.0, 10.0, 40.0, 40.0, 40.0, 40.0, 30.0, 10.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 60.0, 40.0, 50.0, 10.0, 30.0, 62.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 20.0, 40.0, 20.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 30.0, 40.0, 40.0, 40.0, 50.0, 30.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 30.0, 40.0, 40.0, 30.0, 20.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0432820741857212, "mean_inference_ms": 25.927142637883406, "mean_action_processing_ms": 0.2469727416026212, "mean_env_wait_ms": 0.139888223041846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 69552, "timesteps_this_iter": 32, "agent_timesteps_total": 208656, "timers": {"load_time_ms": 0.721, "load_throughput": 44401.789, "learn_time_ms": 251.509, "learn_throughput": 127.232, "update_time_ms": 103.966}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.244091033935547, "min_q": -0.3348073959350586, "max_q": 43.886817932128906, "mean_td_error": 0.39446887373924255, "model": {}}, "td_error": [-2.6414737701416016, 2.907560348510742, 0.5555381774902344, 3.0618648529052734, -1.6161727905273438, 22.72910499572754, 0.6764297485351562, 0.4417552947998047, 2.248889923095703, 4.170955657958984, -1.6051292419433594, 16.267963409423828, -3.9159255027770996, 1.756683349609375, -2.6966187953948975, 1.145303726196289, 1.1199750900268555, -7.66380500793457, 3.781888484954834, -0.42864227294921875, 0.7854404449462891, -4.020812511444092, -3.243885040283203, 1.3555717468261719, -1.9610977172851562, -2.177186965942383, -0.046955108642578125, -8.091449737548828, -0.5197296142578125, -4.869536876678467, -5.086641311645508, 0.2031412124633789], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.09290885925293, "min_q": -3.3246450424194336, "max_q": 42.017364501953125, "mean_td_error": 0.34209662675857544, "model": {}}, "td_error": [-0.7051925659179688, 0.9030342102050781, -0.4204845428466797, -2.3246450424194336, 1.4818344116210938, 0.7499866485595703, -2.9734573364257812, -1.4618489742279053, 2.076000213623047, -0.3021754026412964, -2.743356227874756, 1.1939232349395752, -3.815472364425659, 4.677233695983887, 0.6642208099365234, 1.8578071594238281, 1.63848876953125, 1.7021007537841797, 2.0543689727783203, 2.5871143341064453, -1.242645263671875, -0.7615947723388672, 0.4401054382324219, 2.4663867950439453, 2.811779022216797, 0.9588966369628906, -2.9734573364257812, 4.63363790512085, 0.6543552875518799, -0.95672607421875, -0.7751731872558594, -1.1479530334472656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.718475341796875, "min_q": 1.8347337245941162, "max_q": 44.13038635253906, "mean_td_error": -0.4049402177333832, "model": {}}, "td_error": [4.038978576660156, -5.743508338928223, 1.7453575134277344, -0.5133304595947266, 1.0261993408203125, 2.030101776123047, -1.073099136352539, 1.4602527618408203, -0.60638427734375, 0.8048763275146484, -1.5807924270629883, 0.3812417984008789, -1.0544090270996094, -0.3605804443359375, 0.28423500061035156, -1.2465629577636719, -0.5380401611328125, 4.287565231323242, -1.4120864868164062, -0.5498123168945312, -2.872303009033203, -0.8764114379882812, -2.377134323120117, -0.1988849639892578, -2.0170364379882812, -0.685943603515625, -0.685943603515625, -2.0170364379882812, -0.8892173767089844, -2.1913223266601562, -0.5993919372558594, 1.072336196899414], "custom_metrics": {}}}, "num_steps_sampled": 69552, "num_agent_steps_sampled": 208656, "num_steps_trained": 137120, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 411360, "last_target_update_ts": 69104, "num_target_updates": 134}, "done": false, "episodes_total": 6953, "training_iteration": 69, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-08-42", "timestamp": 1648915722, "time_this_iter_s": 40.81256628036499, "time_total_s": 2744.7067477703094, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7f3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7f3c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2744.7067477703094, "timesteps_since_restore": 2208, "iterations_since_restore": 69, "perf": {"cpu_util_percent": 52.6051724137931, "ram_util_percent": 65.54827586206895}}
{"episode_reward_max": 186.0, "episode_reward_min": 30.0, "episode_reward_mean": 129.23300970873785, "episode_len_mean": 9.932038834951456, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 43.077669902912625, "policy1": 43.077669902912625, "policy2": 43.077669902912625}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 150.0, 120.0, 180.0, 150.0, 180.0, 150.0, 120.0, 150.0, 150.0, 90.0, 90.0, 120.0, 180.0, 150.0, 150.0, 90.0, 90.0, 150.0, 30.0, 90.0, 120.0, 90.0, 150.0, 120.0, 60.0, 120.0, 120.0, 120.0, 120.0, 120.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 186.0, 120.0, 120.0, 180.0, 120.0, 120.0, 120.0, 120.0, 150.0, 120.0, 150.0, 120.0, 120.0, 180.0, 150.0, 150.0, 120.0, 150.0, 90.0, 150.0, 150.0, 90.0, 180.0, 150.0, 150.0, 60.0, 120.0, 150.0, 90.0, 120.0, 150.0, 90.0, 150.0, 90.0, 120.0, 120.0, 120.0, 150.0, 150.0, 150.0, 60.0, 120.0, 180.0, 150.0, 120.0, 183.0, 90.0, 150.0, 150.0, 120.0, 120.0, 150.0, 120.0, 90.0, 186.0, 150.0, 150.0, 120.0, 90.0, 90.0, 150.0, 186.0, 150.0, 30.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 40.0, 60.0, 50.0, 50.0, 30.0, 30.0, 50.0, 10.0, 30.0, 40.0, 30.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 62.0, 40.0, 40.0, 60.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 30.0, 50.0, 50.0, 30.0, 60.0, 50.0, 50.0, 20.0, 40.0, 50.0, 30.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 40.0, 60.0, 50.0, 40.0, 61.0, 30.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 30.0, 62.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 62.0, 50.0, 10.0, 40.0], "policy_policy1_reward": [40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 40.0, 60.0, 50.0, 50.0, 30.0, 30.0, 50.0, 10.0, 30.0, 40.0, 30.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 62.0, 40.0, 40.0, 60.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 30.0, 50.0, 50.0, 30.0, 60.0, 50.0, 50.0, 20.0, 40.0, 50.0, 30.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 40.0, 60.0, 50.0, 40.0, 61.0, 30.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 30.0, 62.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 62.0, 50.0, 10.0, 40.0], "policy_policy2_reward": [40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 40.0, 60.0, 50.0, 50.0, 30.0, 30.0, 50.0, 10.0, 30.0, 40.0, 30.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 62.0, 40.0, 40.0, 60.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 30.0, 50.0, 50.0, 30.0, 60.0, 50.0, 50.0, 20.0, 40.0, 50.0, 30.0, 40.0, 50.0, 30.0, 50.0, 30.0, 40.0, 40.0, 40.0, 50.0, 50.0, 50.0, 20.0, 40.0, 60.0, 50.0, 40.0, 61.0, 30.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 30.0, 62.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 62.0, 50.0, 10.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0412273187655847, "mean_inference_ms": 25.841912148058352, "mean_action_processing_ms": 0.246275305035429, "mean_env_wait_ms": 0.13951227771116567, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 70560, "timesteps_this_iter": 32, "agent_timesteps_total": 211680, "timers": {"load_time_ms": 0.622, "load_throughput": 51457.934, "learn_time_ms": 235.036, "learn_throughput": 136.149, "update_time_ms": 106.988}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.845855712890625, "min_q": 2.15887188911438, "max_q": 42.93656539916992, "mean_td_error": 0.3701741397380829, "model": {}}, "td_error": [-2.514741897583008, -1.9940357208251953, -0.4118976593017578, 14.75789737701416, 0.6977691650390625, -0.7468986511230469, 1.0373802185058594, 1.3264141082763672, -1.054229736328125, 0.9112982749938965, -1.2232475280761719, -1.663482666015625, -2.130361318588257, -3.615245819091797, 2.8088436126708984, -0.037853240966796875, 3.264209032058716, -1.0755972862243652, 0.213531494140625, -0.7861080169677734, 0.3749885559082031, -1.8170661926269531, -1.8123035430908203, 0.6777725219726562, -2.8877034187316895, 2.140789031982422, 1.8060150146484375, -0.45993804931640625, 2.842813491821289, -5.000434398651123, 0.2795829772949219, 7.937413215637207], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.03350830078125, "min_q": -0.6964399814605713, "max_q": 40.41472244262695, "mean_td_error": 0.5904499888420105, "model": {}}, "td_error": [0.2264251708984375, -1.279022216796875, 0.03648567199707031, -3.6809654235839844, 9.41328239440918, -1.839944839477539, -0.8599300384521484, -0.6932449340820312, -0.8685283660888672, 4.543249130249023, -5.309492111206055, 1.863729476928711, -3.808163642883301, 23.65946388244629, -2.4988059997558594, 4.162240028381348, -1.4547920227050781, 7.61632776260376, -0.6799411773681641, -2.7334060668945312, -3.1668143272399902, -2.089710235595703, -0.07880496978759766, 2.060333251953125, -5.366336822509766, 2.3842506408691406, 0.3679962158203125, 1.4206409454345703, 0.03611135482788086, -1.1750847101211548, 0.43412017822265625, -1.7472686767578125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.2777042388916, "min_q": 2.2009925842285156, "max_q": 46.940147399902344, "mean_td_error": -1.0282299518585205, "model": {}}, "td_error": [0.7253074645996094, -2.363668441772461, -3.9249496459960938, 2.865215301513672, -1.5581855773925781, 0.14744186401367188, -6.3393778800964355, -1.0081596374511719, 1.2193069458007812, -14.479341506958008, -4.6298933029174805, 2.4168968200683594, 3.2009925842285156, -2.1725921630859375, 1.2193069458007812, -0.743804931640625, -0.057933807373046875, -1.0095443725585938, 0.1470165252685547, 0.9527454376220703, 0.4990577697753906, -1.3443145751953125, -4.869176864624023, -0.0251007080078125, -1.1511993408203125, -1.069864273071289, -0.7890129089355469, -0.9741630554199219, 0.6439213752746582, 4.29840087890625, -0.9289464950561523, -1.7997398376464844], "custom_metrics": {}}}, "num_steps_sampled": 70560, "num_agent_steps_sampled": 211680, "num_steps_trained": 139136, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 417408, "last_target_update_ts": 70128, "num_target_updates": 136}, "done": false, "episodes_total": 7056, "training_iteration": 70, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-09-22", "timestamp": 1648915762, "time_this_iter_s": 40.03841209411621, "time_total_s": 2784.7451598644257, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ea70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ea70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2784.7451598644257, "timesteps_since_restore": 2240, "iterations_since_restore": 70, "perf": {"cpu_util_percent": 51.65087719298245, "ram_util_percent": 65.6}}
{"episode_reward_max": 186.0, "episode_reward_min": 30.0, "episode_reward_mean": 124.59, "episode_len_mean": 9.97, "episode_media": {}, "episodes_this_iter": 100, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 41.53, "policy1": 41.53, "policy2": 41.53}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 150.0, 120.0, 120.0, 120.0, 30.0, 120.0, 120.0, 150.0, 90.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 180.0, 120.0, 150.0, 90.0, 120.0, 90.0, 120.0, 120.0, 90.0, 120.0, 150.0, 120.0, 180.0, 90.0, 60.0, 120.0, 90.0, 90.0, 150.0, 90.0, 150.0, 120.0, 150.0, 120.0, 120.0, 120.0, 90.0, 120.0, 120.0, 120.0, 120.0, 120.0, 60.0, 60.0, 150.0, 120.0, 120.0, 120.0, 180.0, 120.0, 183.0, 60.0, 90.0, 150.0, 150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 180.0, 186.0, 150.0, 90.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 150.0, 90.0, 120.0, 180.0, 60.0, 90.0, 120.0, 180.0, 150.0, 120.0, 150.0, 90.0, 120.0, 90.0, 120.0, 90.0, 120.0, 120.0, 120.0, 150.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 60.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 40.0, 60.0, 30.0, 20.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 61.0, 20.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 60.0, 20.0, 30.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0], "policy_policy1_reward": [40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 60.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 40.0, 60.0, 30.0, 20.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 61.0, 20.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 60.0, 20.0, 30.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0], "policy_policy2_reward": [40.0, 50.0, 40.0, 40.0, 40.0, 10.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 60.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 40.0, 30.0, 40.0, 50.0, 40.0, 60.0, 30.0, 20.0, 40.0, 30.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 30.0, 40.0, 40.0, 40.0, 40.0, 40.0, 20.0, 20.0, 50.0, 40.0, 40.0, 40.0, 60.0, 40.0, 61.0, 20.0, 30.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 60.0, 20.0, 30.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 40.0, 30.0, 40.0, 30.0, 40.0, 40.0, 40.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0422071542880043, "mean_inference_ms": 25.877579454538086, "mean_action_processing_ms": 0.24649606944662827, "mean_env_wait_ms": 0.13967171433799017, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 71568, "timesteps_this_iter": 32, "agent_timesteps_total": 214704, "timers": {"load_time_ms": 0.617, "load_throughput": 51879.606, "learn_time_ms": 231.053, "learn_throughput": 138.497, "update_time_ms": 98.901}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 23.512939453125, "min_q": 1.951147437095642, "max_q": 44.324161529541016, "mean_td_error": -0.7975500822067261, "model": {}}, "td_error": [0.5154094696044922, -0.6009273529052734, -1.1392135620117188, -0.5448970794677734, -0.5937175750732422, -3.9525928497314453, 5.551384449005127, -2.797184944152832, -1.766016960144043, 1.7010211944580078, -0.19272994995117188, 0.24953079223632812, -0.182220458984375, -1.4105339050292969, -1.3083953857421875, -1.1845321655273438, -0.011041641235351562, -1.9138107299804688, -1.9395294189453125, -0.05057525634765625, 0.1371440887451172, -2.230900764465332, -1.3512821197509766, 6.012953758239746, -7.048852443695068, 4.4652605056762695, -3.091876983642578, -5.324766159057617, -0.24948501586914062, -4.945610523223877, -0.7790641784667969, 0.45545196533203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.66299819946289, "min_q": 3.335549831390381, "max_q": 41.49790573120117, "mean_td_error": -0.4896579086780548, "model": {}}, "td_error": [0.5924186706542969, -2.1834816932678223, -1.5106830596923828, -2.9573211669921875, -5.664450168609619, -4.637524127960205, 1.4126949310302734, -4.469779014587402, -2.9573211669921875, -1.126739501953125, -1.307478427886963, 11.123183250427246, 1.86236572265625, 2.8354625701904297, -1.4873771667480469, 1.0546379089355469, -2.8418540954589844, -0.4914264678955078, 0.7667083740234375, -2.941343307495117, -2.5679893493652344, -1.0526809692382812, 13.733626365661621, -3.0586814880371094, 4.644167423248291, -2.6949195861816406, -1.163536787033081, -3.2864646911621094, -1.5539970397949219, -6.26483154296875, -0.46825122833251953, 2.99381160736084], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.171663284301758, "min_q": 0.16971158981323242, "max_q": 47.55609893798828, "mean_td_error": -0.01269008219242096, "model": {}}, "td_error": [-1.5004043579101562, 0.9485149383544922, 0.285491943359375, 0.9462707042694092, -2.0089073181152344, -0.8051671981811523, -4.122278690338135, -3.0738980770111084, 1.2139935493469238, -1.4631576538085938, -1.4586334228515625, -0.37099266052246094, 1.6806755065917969, 1.2091059684753418, 0.586411714553833, 1.8173103332519531, 3.0831069946289062, 3.576221466064453, 3.2494401931762695, -1.0347175598144531, 3.47745418548584, -3.33394718170166, 0.1456298828125, 0.8055324554443359, -1.2131900787353516, 0.23880958557128906, -2.30096435546875, -1.4267501831054688, 1.1697115898132324, -0.2595863342285156, -0.9866485595703125, 0.5194797515869141], "custom_metrics": {}}}, "num_steps_sampled": 71568, "num_agent_steps_sampled": 214704, "num_steps_trained": 141152, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 423456, "last_target_update_ts": 71152, "num_target_updates": 138}, "done": false, "episodes_total": 7156, "training_iteration": 71, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-10-02", "timestamp": 1648915802, "time_this_iter_s": 39.854979515075684, "time_total_s": 2824.6001393795013, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ab950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7ab950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2824.6001393795013, "timesteps_since_restore": 2272, "iterations_since_restore": 71, "perf": {"cpu_util_percent": 51.3, "ram_util_percent": 65.14035087719299}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 126.29702970297029, "episode_len_mean": 9.98019801980198, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 42.0990099009901, "policy1": 42.0990099009901, "policy2": 42.0990099009901}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 90.0, 90.0, 150.0, 120.0, 150.0, 120.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 90.0, 150.0, 150.0, 150.0, 120.0, 90.0, 90.0, 150.0, 150.0, 150.0, 120.0, 120.0, 60.0, 120.0, 120.0, 120.0, 120.0, 150.0, 120.0, 90.0, 90.0, 150.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 90.0, 180.0, 150.0, 120.0, 90.0, 120.0, 120.0, 90.0, 150.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 120.0, 120.0, 150.0, 120.0, 150.0, 150.0, 150.0, 120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 150.0, 90.0, 150.0, 90.0, 150.0, 90.0, 90.0, 60.0, 120.0, 150.0, 60.0, 150.0, 150.0, 150.0, 120.0, 120.0, 120.0, 90.0, 186.0, 150.0, 150.0, 150.0, 90.0, 90.0, 150.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 50.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 30.0, 30.0, 20.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 62.0, 50.0, 50.0, 50.0, 30.0, 30.0, 50.0, 40.0], "policy_policy1_reward": [40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 50.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 30.0, 30.0, 20.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 62.0, 50.0, 50.0, 50.0, 30.0, 30.0, 50.0, 40.0], "policy_policy2_reward": [40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 50.0, 40.0, 40.0, 20.0, 40.0, 40.0, 40.0, 40.0, 50.0, 40.0, 30.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 50.0, 40.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 50.0, 30.0, 50.0, 30.0, 30.0, 20.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 30.0, 62.0, 50.0, 50.0, 50.0, 30.0, 30.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.043727272903582, "mean_inference_ms": 25.91190237323884, "mean_action_processing_ms": 0.24672199799300285, "mean_env_wait_ms": 0.13979611489508503, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 72576, "timesteps_this_iter": 32, "agent_timesteps_total": 217728, "timers": {"load_time_ms": 0.676, "load_throughput": 47343.114, "learn_time_ms": 235.132, "learn_throughput": 136.094, "update_time_ms": 97.675}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.720056533813477, "min_q": -0.6769076585769653, "max_q": 44.360469818115234, "mean_td_error": 0.5870753526687622, "model": {}}, "td_error": [1.9350810050964355, -2.614971160888672, 6.982069492340088, -2.2452564239501953, -1.7029800415039062, -0.3553009033203125, -0.6731542944908142, -7.015900611877441, -1.5590152740478516, -2.2853012084960938, -0.11733245849609375, 1.1521068811416626, 1.333932876586914, 1.2997589111328125, -1.5465927124023438, -1.7691459655761719, 1.0877752304077148, -0.7284927368164062, -0.38924407958984375, 2.4854583740234375, 1.6777324676513672, 0.20055294036865234, -2.5639963150024414, -0.346771240234375, -2.4154014587402344, 0.010715484619140625, 1.044820785522461, 2.6049747467041016, 19.101558685302734, 0.0328216552734375, -1.7029762268066406, 7.868884563446045], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.21124839782715, "min_q": -0.30783921480178833, "max_q": 44.37946319580078, "mean_td_error": 0.8601269125938416, "model": {}}, "td_error": [-2.8664777278900146, -0.9932422637939453, 3.6774253845214844, -0.10655784606933594, -0.62060546875, -1.8811073303222656, -0.8643054962158203, 3.5598983764648438, 4.610706329345703, 1.2229347229003906, 12.80632495880127, 0.5821533203125, -1.7138442993164062, -2.9576635360717773, -0.9444160461425781, 1.1239147186279297, -1.3851423263549805, -0.9608917236328125, 2.2579405307769775, -1.2284889221191406, 1.9779139757156372, 5.8479719161987305, -0.5371627807617188, 2.020587921142578, -0.3393077850341797, 1.4422378540039062, 2.640472412109375, -2.1433868408203125, 3.3305301666259766, 1.4419803619384766, -1.0694313049316406, -0.40689849853515625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.846330642700195, "min_q": 1.9150148630142212, "max_q": 44.4532470703125, "mean_td_error": 1.744370460510254, "model": {}}, "td_error": [1.1840744018554688, 2.330453872680664, -1.8231534957885742, -1.5354633331298828, -0.15042591094970703, -0.6997222900390625, -4.777379035949707, 17.965723037719727, 1.0984916687011719, 0.42055511474609375, -0.5335788726806641, -0.7941341400146484, 20.909059524536133, 6.185529708862305, 0.24845123291015625, -0.4413013458251953, 24.079654693603516, 0.5309104919433594, 0.2512969970703125, 0.48681640625, 2.034076690673828, 1.5919113159179688, -1.692474365234375, -0.35528564453125, -1.3966541290283203, -0.15598297119140625, -0.4429149627685547, -1.8951988220214844, 0.44658660888671875, -0.20942401885986328, 0.044342041015625, -7.084985256195068], "custom_metrics": {}}}, "num_steps_sampled": 72576, "num_agent_steps_sampled": 217728, "num_steps_trained": 143168, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 429504, "last_target_update_ts": 72176, "num_target_updates": 140}, "done": false, "episodes_total": 7257, "training_iteration": 72, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-10-43", "timestamp": 1648915843, "time_this_iter_s": 40.536962032318115, "time_total_s": 2865.1371014118195, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7abef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7abef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2865.1371014118195, "timesteps_since_restore": 2304, "iterations_since_restore": 72, "perf": {"cpu_util_percent": 52.3298245614035, "ram_util_percent": 65.53508771929823}}
{"episode_reward_max": 180.0, "episode_reward_min": 60.0, "episode_reward_mean": 128.31683168316832, "episode_len_mean": 10.0, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_mean": {"policy0": 42.772277227722775, "policy1": 42.772277227722775, "policy2": 42.772277227722775}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 120.0, 120.0, 150.0, 120.0, 120.0, 180.0, 120.0, 90.0, 120.0, 120.0, 150.0, 150.0, 150.0, 120.0, 60.0, 120.0, 120.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 150.0, 120.0, 150.0, 120.0, 90.0, 120.0, 120.0, 120.0, 90.0, 150.0, 120.0, 150.0, 150.0, 90.0, 150.0, 120.0, 90.0, 150.0, 150.0, 120.0, 90.0, 120.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 90.0, 120.0, 150.0, 150.0, 90.0, 150.0, 120.0, 120.0, 90.0, 60.0, 120.0, 60.0, 150.0, 150.0, 120.0, 150.0, 120.0, 90.0, 90.0, 180.0, 180.0, 120.0, 150.0, 150.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 120.0, 180.0, 120.0, 120.0, 180.0, 150.0, 150.0, 150.0, 120.0, 90.0, 150.0, 90.0, 150.0, 120.0, 150.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 30.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 40.0, 60.0, 50.0, 50.0, 50.0, 40.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0], "policy_policy1_reward": [40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 30.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 40.0, 60.0, 50.0, 50.0, 50.0, 40.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0], "policy_policy2_reward": [40.0, 40.0, 40.0, 50.0, 40.0, 40.0, 60.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 40.0, 20.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 40.0, 40.0, 40.0, 30.0, 50.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 30.0, 50.0, 50.0, 40.0, 30.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 40.0, 50.0, 50.0, 30.0, 50.0, 40.0, 40.0, 30.0, 20.0, 40.0, 20.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 30.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 40.0, 60.0, 50.0, 50.0, 50.0, 40.0, 30.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0436056266780978, "mean_inference_ms": 25.9078761250235, "mean_action_processing_ms": 0.24661320518972038, "mean_env_wait_ms": 0.13975215063266688, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 73584, "timesteps_this_iter": 32, "agent_timesteps_total": 220752, "timers": {"load_time_ms": 0.64, "load_throughput": 50023.379, "learn_time_ms": 233.256, "learn_throughput": 137.188, "update_time_ms": 105.617}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 23.701425552368164, "min_q": 0.38022172451019287, "max_q": 45.21920394897461, "mean_td_error": -0.961350679397583, "model": {}}, "td_error": [1.8166942596435547, 0.9848098754882812, 2.3944787979125977, 0.4543037414550781, -1.7273178100585938, -2.4943675994873047, -1.0130548477172852, -0.058406829833984375, -1.4932136535644531, -13.316581726074219, -2.067890167236328, 0.40411376953125, -0.9449119567871094, -2.0268917083740234, -1.2613658905029297, 1.6392183303833008, -0.6125221252441406, -0.019756317138671875, 4.039941787719727, -1.671647071838379, -1.222529411315918, -1.2019805908203125, 1.4157484769821167, -1.1939868927001953, -0.6466064453125, -2.8606796264648438, -2.1729679107666016, -1.6881561279296875, -1.3378257751464844, -2.107393264770508, 1.7049198150634766, -2.4773988723754883], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 23.1467342376709, "min_q": 0.388615220785141, "max_q": 46.01498794555664, "mean_td_error": 1.6799492835998535, "model": {}}, "td_error": [-0.18968963623046875, -0.20338058471679688, 1.2310028076171875, 4.391420364379883, 6.063825607299805, -1.386545181274414, 9.405023574829102, 3.6889595985412598, -1.5942554473876953, 2.4466168880462646, -2.1108779907226562, -0.06686782836914062, 0.5919303894042969, -1.2851104736328125, -0.10784149169921875, 1.1928901672363281, -2.8112239837646484, 18.029937744140625, 0.471649169921875, -0.06112861633300781, 3.7772674560546875, -2.5220565795898438, 18.92190933227539, 0.10238838195800781, 1.9606781005859375, -0.3545522689819336, 0.7865962982177734, 3.2795028686523438, -1.9193916320800781, -7.185633659362793, 1.3886152505874634, -2.1732826232910156], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 25.845409393310547, "min_q": 3.847634792327881, "max_q": 47.730865478515625, "mean_td_error": 2.350325584411621, "model": {}}, "td_error": [-2.743915557861328, 1.3929901123046875, -1.4238319396972656, 0.025966644287109375, 0.546478271484375, 0.623199462890625, 0.623199462890625, 1.3462200164794922, 4.847634792327881, 9.468216896057129, -1.1979990005493164, 22.121475219726562, 5.395871162414551, 0.1657543182373047, -1.4590320587158203, 1.1171550750732422, -2.0024681091308594, 1.3895206451416016, -0.43662548065185547, -1.3570518493652344, -0.5121707916259766, 25.9311580657959, -0.24253082275390625, -1.9943962097167969, 3.6770687103271484, -2.4774818420410156, -0.24034500122070312, 16.227188110351562, -1.1662712097167969, -1.101827621459961, -0.21588897705078125, -1.1168365478515625], "custom_metrics": {}}}, "num_steps_sampled": 73584, "num_agent_steps_sampled": 220752, "num_steps_trained": 145184, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 435552, "last_target_update_ts": 73200, "num_target_updates": 142}, "done": false, "episodes_total": 7358, "training_iteration": 73, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-11-23", "timestamp": 1648915883, "time_this_iter_s": 40.03079605102539, "time_total_s": 2905.167897462845, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c782d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c782d40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2905.167897462845, "timesteps_since_restore": 2336, "iterations_since_restore": 73, "perf": {"cpu_util_percent": 51.400000000000006, "ram_util_percent": 65.21578947368421}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 130.7058823529412, "episode_len_mean": 9.96078431372549, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 43.568627450980394, "policy1": 43.568627450980394, "policy2": 43.568627450980394}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 183.0, 120.0, 150.0, 90.0, 90.0, 120.0, 120.0, 120.0, 90.0, 120.0, 180.0, 120.0, 120.0, 120.0, 150.0, 90.0, 90.0, 150.0, 150.0, 183.0, 150.0, 150.0, 60.0, 186.0, 120.0, 120.0, 150.0, 90.0, 150.0, 60.0, 120.0, 150.0, 150.0, 180.0, 60.0, 120.0, 150.0, 150.0, 150.0, 120.0, 120.0, 150.0, 120.0, 120.0, 150.0, 90.0, 150.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 150.0, 180.0, 150.0, 150.0, 120.0, 150.0, 150.0, 90.0, 90.0, 150.0, 150.0, 180.0, 120.0, 90.0, 180.0, 90.0, 150.0, 150.0, 90.0, 120.0, 90.0, 90.0, 150.0, 120.0, 120.0, 120.0, 150.0, 150.0, 60.0, 150.0, 90.0, 150.0, 150.0, 180.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 90.0, 180.0, 90.0, 150.0, 150.0, 120.0], "episode_lengths": [10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [50.0, 61.0, 40.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 60.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 50.0, 61.0, 50.0, 50.0, 20.0, 62.0, 40.0, 40.0, 50.0, 30.0, 50.0, 20.0, 40.0, 50.0, 50.0, 60.0, 20.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 50.0, 50.0, 60.0, 40.0, 30.0, 60.0, 30.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 20.0, 50.0, 30.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 30.0, 50.0, 50.0, 40.0], "policy_policy1_reward": [50.0, 61.0, 40.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 60.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 50.0, 61.0, 50.0, 50.0, 20.0, 62.0, 40.0, 40.0, 50.0, 30.0, 50.0, 20.0, 40.0, 50.0, 50.0, 60.0, 20.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 50.0, 50.0, 60.0, 40.0, 30.0, 60.0, 30.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 20.0, 50.0, 30.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 30.0, 50.0, 50.0, 40.0], "policy_policy2_reward": [50.0, 61.0, 40.0, 50.0, 30.0, 30.0, 40.0, 40.0, 40.0, 30.0, 40.0, 60.0, 40.0, 40.0, 40.0, 50.0, 30.0, 30.0, 50.0, 50.0, 61.0, 50.0, 50.0, 20.0, 62.0, 40.0, 40.0, 50.0, 30.0, 50.0, 20.0, 40.0, 50.0, 50.0, 60.0, 20.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 30.0, 30.0, 50.0, 50.0, 60.0, 40.0, 30.0, 60.0, 30.0, 50.0, 50.0, 30.0, 40.0, 30.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 20.0, 50.0, 30.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 30.0, 60.0, 30.0, 50.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0409570365959966, "mean_inference_ms": 25.786441991130587, "mean_action_processing_ms": 0.24557866994310049, "mean_env_wait_ms": 0.13919349432162795, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 74592, "timesteps_this_iter": 32, "agent_timesteps_total": 223776, "timers": {"load_time_ms": 0.744, "load_throughput": 43022.639, "learn_time_ms": 239.294, "learn_throughput": 133.727, "update_time_ms": 105.586}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 23.428556442260742, "min_q": -1.1878106594085693, "max_q": 45.938255310058594, "mean_td_error": -0.2040262222290039, "model": {}}, "td_error": [10.396757125854492, 0.2206401824951172, 0.11841201782226562, -0.5089702606201172, 0.7074837684631348, -4.484347343444824, -1.0821666717529297, -1.6922855377197266, 1.4389762878417969, 0.9708647727966309, -1.7334823608398438, -1.970311164855957, 1.2116374969482422, -2.656818389892578, -0.18781065940856934, -0.7503814697265625, 1.8723983764648438, -0.8105659484863281, 1.3947982788085938, -3.890085220336914, 2.964583396911621, -1.1945686340332031, -5.1556267738342285, -2.046833038330078, -0.6865196228027344, 2.3189125061035156, -0.3687934875488281, -2.9770445823669434, 2.137094497680664, 0.4249897003173828, -0.4360809326171875, -0.07369613647460938], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.15060043334961, "min_q": 3.1566972732543945, "max_q": 44.91059494018555, "mean_td_error": -0.06428179144859314, "model": {}}, "td_error": [-1.8027057647705078, 1.4482355117797852, 2.064655303955078, 0.18693065643310547, -2.5877437591552734, 0.8628730773925781, -1.8265266418457031, -1.2529945373535156, -2.3253173828125, -1.3672142028808594, -2.537992477416992, 6.016850471496582, -0.7333641052246094, -1.2229690551757812, 0.49126434326171875, 1.5107746124267578, -2.1792545318603516, -1.5437812805175781, -0.27845001220703125, -1.166015625, 1.7120742797851562, 2.9759912490844727, 0.5387840270996094, 0.9263877868652344, 17.01380729675293, -5.4993672370910645, -4.279297828674316, -1.4787960052490234, -1.6572685241699219, -4.562464714050293, 1.0418415069580078, -0.5459632873535156], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.729190826416016, "min_q": 2.5214102268218994, "max_q": 49.44950485229492, "mean_td_error": 1.1983370780944824, "model": {}}, "td_error": [14.041645050048828, 1.9396400451660156, -0.7588691711425781, 4.411491394042969, -0.4266090393066406, -0.4266090393066406, 0.09311676025390625, -0.24610137939453125, -0.7607383728027344, -0.9423942565917969, 0.11641311645507812, -0.4915351867675781, -0.8014450073242188, 0.03626441955566406, -0.9423942565917969, 1.9596443176269531, -1.1053581237792969, 0.03508949279785156, 1.5666847229003906, 0.45819091796875, -1.1685256958007812, 2.4288101196289062, 3.5214102268218994, -0.961338996887207, -1.3030281066894531, 1.3807144165039062, -0.2817955017089844, 12.580995559692383, -0.6363182067871094, 1.5642776489257812, -0.4928169250488281, 3.9582748413085938], "custom_metrics": {}}}, "num_steps_sampled": 74592, "num_agent_steps_sampled": 223776, "num_steps_trained": 147200, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 441600, "last_target_update_ts": 74224, "num_target_updates": 144}, "done": false, "episodes_total": 7460, "training_iteration": 74, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-12-03", "timestamp": 1648915923, "time_this_iter_s": 39.916131019592285, "time_total_s": 2945.084028482437, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c79fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c79fb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2945.084028482437, "timesteps_since_restore": 2368, "iterations_since_restore": 74, "perf": {"cpu_util_percent": 51.6, "ram_util_percent": 65.39824561403509}}
{"episode_reward_max": 186.0, "episode_reward_min": 0.0, "episode_reward_mean": 134.64356435643563, "episode_len_mean": 9.871287128712872, "episode_media": {}, "episodes_this_iter": 101, "policy_reward_min": {"policy0": 0.0, "policy1": 0.0, "policy2": 0.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 44.881188118811885, "policy1": 44.881188118811885, "policy2": 44.881188118811885}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 180.0, 150.0, 180.0, 150.0, 150.0, 120.0, 150.0, 60.0, 60.0, 150.0, 120.0, 120.0, 183.0, 90.0, 90.0, 120.0, 180.0, 60.0, 90.0, 150.0, 120.0, 90.0, 90.0, 150.0, 120.0, 150.0, 150.0, 150.0, 90.0, 180.0, 90.0, 90.0, 183.0, 120.0, 183.0, 150.0, 186.0, 120.0, 150.0, 180.0, 150.0, 120.0, 120.0, 150.0, 150.0, 150.0, 150.0, 120.0, 150.0, 120.0, 183.0, 150.0, 150.0, 120.0, 150.0, 180.0, 186.0, 120.0, 120.0, 150.0, 90.0, 120.0, 180.0, 150.0, 180.0, 186.0, 90.0, 150.0, 150.0, 183.0, 120.0, 120.0, 90.0, 120.0, 120.0, 150.0, 150.0, 150.0, 90.0, 180.0, 150.0, 90.0, 120.0, 120.0, 90.0, 150.0, 150.0, 120.0, 0.0, 120.0, 150.0, 186.0, 120.0, 150.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 9, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10], "policy_policy0_reward": [50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 20.0, 20.0, 50.0, 40.0, 40.0, 61.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 50.0, 40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 30.0, 30.0, 61.0, 40.0, 61.0, 50.0, 62.0, 40.0, 50.0, 60.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 40.0, 40.0, 50.0, 30.0, 40.0, 60.0, 50.0, 60.0, 62.0, 30.0, 50.0, 50.0, 61.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 50.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 0.0, 40.0, 50.0, 62.0, 40.0, 50.0, 30.0], "policy_policy1_reward": [50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 20.0, 20.0, 50.0, 40.0, 40.0, 61.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 50.0, 40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 30.0, 30.0, 61.0, 40.0, 61.0, 50.0, 62.0, 40.0, 50.0, 60.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 40.0, 40.0, 50.0, 30.0, 40.0, 60.0, 50.0, 60.0, 62.0, 30.0, 50.0, 50.0, 61.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 50.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 0.0, 40.0, 50.0, 62.0, 40.0, 50.0, 30.0], "policy_policy2_reward": [50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 20.0, 20.0, 50.0, 40.0, 40.0, 61.0, 30.0, 30.0, 40.0, 60.0, 20.0, 30.0, 50.0, 40.0, 30.0, 30.0, 50.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 30.0, 30.0, 61.0, 40.0, 61.0, 50.0, 62.0, 40.0, 50.0, 60.0, 50.0, 40.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 50.0, 60.0, 62.0, 40.0, 40.0, 50.0, 30.0, 40.0, 60.0, 50.0, 60.0, 62.0, 30.0, 50.0, 50.0, 61.0, 40.0, 40.0, 30.0, 40.0, 40.0, 50.0, 50.0, 50.0, 30.0, 60.0, 50.0, 30.0, 40.0, 40.0, 30.0, 50.0, 50.0, 40.0, 0.0, 40.0, 50.0, 62.0, 40.0, 50.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044234555595995, "mean_inference_ms": 25.903075938155474, "mean_action_processing_ms": 0.2464447521471229, "mean_env_wait_ms": 0.1396569061974295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 75600, "timesteps_this_iter": 32, "agent_timesteps_total": 226800, "timers": {"load_time_ms": 0.736, "load_throughput": 43476.962, "learn_time_ms": 234.872, "learn_throughput": 136.245, "update_time_ms": 101.82}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.640214920043945, "min_q": 0.05967104434967041, "max_q": 43.13819885253906, "mean_td_error": -0.9170539975166321, "model": {}}, "td_error": [-0.36431884765625, -0.831024169921875, -1.2522602081298828, -1.1801490783691406, -4.373453140258789, 1.3655166625976562, -0.7011756896972656, 0.9768257141113281, -6.435415267944336, -0.7647781372070312, -5.924501419067383, 2.4381370544433594, -1.9139289855957031, 0.056232452392578125, -6.796041488647461, -4.50252628326416, -1.3390388488769531, -0.4145317077636719, -0.5647430419921875, 1.0596710443496704, 0.3241233825683594, -1.9139289855957031, -2.644092559814453, -0.9122276306152344, 3.109039306640625, -1.7586803436279297, 2.3413658142089844, 1.42919921875, -0.8659954071044922, 3.368673324584961, 1.1733875274658203, -1.5350875854492188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.039941787719727, "min_q": -2.4788780212402344, "max_q": 47.26566696166992, "mean_td_error": 0.19440552592277527, "model": {}}, "td_error": [-0.7044181823730469, -2.1012039184570312, 3.4774816036224365, 9.015743255615234, 0.4625205993652344, 5.730411529541016, 4.635146141052246, -1.8151493072509766, -2.2213497161865234, -1.0251426696777344, 1.6259212493896484, 0.7696514129638672, -1.4172592163085938, 1.051279067993164, -1.0126218795776367, 3.4930992126464844, -2.8048152923583984, -0.8477210998535156, 0.7722690105438232, 2.023609161376953, -0.17875289916992188, -1.494532585144043, 0.8723220825195312, -1.4788780212402344, -1.5690383911132812, -1.7451324462890625, -4.062112808227539, -0.6890907287597656, 3.236635446548462, 1.137115478515625, -4.813809394836426, -2.1012001037597656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.116573333740234, "min_q": -0.8947896361351013, "max_q": 51.153865814208984, "mean_td_error": 2.2728638648986816, "model": {}}, "td_error": [4.637882232666016, 0.10521036386489868, -0.42218780517578125, 2.3885984420776367, -0.97137451171875, 0.6986865997314453, -2.566779136657715, -0.8928890228271484, 0.04931068420410156, 11.533681869506836, 14.306538581848145, 14.122590065002441, 1.2341327667236328, -2.4942216873168945, 1.9862117767333984, -1.1885032653808594, 14.896944046020508, 1.24725341796875, -2.3008766174316406, 4.637882232666016, -1.4841537475585938, -0.1611328125, -1.5253963470458984, 2.002469301223755, 4.204353332519531, 0.36872196197509766, -0.97137451171875, 11.500444412231445, -1.4159164428710938, 1.02142333984375, -1.0000762939453125, -0.8158073425292969], "custom_metrics": {}}}, "num_steps_sampled": 75600, "num_agent_steps_sampled": 226800, "num_steps_trained": 149216, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 447648, "last_target_update_ts": 75248, "num_target_updates": 146}, "done": false, "episodes_total": 7561, "training_iteration": 75, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-12-44", "timestamp": 1648915964, "time_this_iter_s": 41.022581815719604, "time_total_s": 2986.1066102981567, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75b710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75b710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 2986.1066102981567, "timesteps_since_restore": 2400, "iterations_since_restore": 75, "perf": {"cpu_util_percent": 52.59137931034482, "ram_util_percent": 65.55862068965517}}
{"episode_reward_max": 186.0, "episode_reward_min": 30.0, "episode_reward_mean": 136.2058823529412, "episode_len_mean": 9.892156862745098, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 45.40196078431372, "policy1": 45.40196078431372, "policy2": 45.40196078431372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 150.0, 120.0, 180.0, 150.0, 90.0, 180.0, 150.0, 150.0, 90.0, 150.0, 150.0, 150.0, 120.0, 150.0, 183.0, 150.0, 150.0, 90.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 150.0, 150.0, 150.0, 150.0, 120.0, 150.0, 120.0, 90.0, 150.0, 120.0, 120.0, 120.0, 30.0, 60.0, 120.0, 60.0, 120.0, 150.0, 150.0, 150.0, 150.0, 150.0, 60.0, 186.0, 186.0, 150.0, 120.0, 180.0, 120.0, 180.0, 90.0, 180.0, 183.0, 180.0, 150.0, 120.0, 150.0, 90.0, 150.0, 120.0, 120.0, 120.0, 150.0, 150.0, 90.0, 120.0, 150.0, 180.0, 120.0, 186.0, 120.0, 183.0, 180.0, 150.0, 120.0, 150.0, 180.0, 120.0, 120.0, 120.0, 186.0, 120.0, 150.0, 150.0, 150.0, 120.0, 120.0, 150.0, 150.0, 120.0, 150.0, 120.0, 120.0, 90.0, 60.0, 90.0, 150.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 8, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [60.0, 50.0, 40.0, 60.0, 50.0, 30.0, 60.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 10.0, 20.0, 40.0, 20.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 62.0, 62.0, 50.0, 40.0, 60.0, 40.0, 60.0, 30.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 62.0, 40.0, 61.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 62.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 50.0], "policy_policy1_reward": [60.0, 50.0, 40.0, 60.0, 50.0, 30.0, 60.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 10.0, 20.0, 40.0, 20.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 62.0, 62.0, 50.0, 40.0, 60.0, 40.0, 60.0, 30.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 62.0, 40.0, 61.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 62.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 50.0], "policy_policy2_reward": [60.0, 50.0, 40.0, 60.0, 50.0, 30.0, 60.0, 50.0, 50.0, 30.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 30.0, 50.0, 40.0, 40.0, 40.0, 10.0, 20.0, 40.0, 20.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 20.0, 62.0, 62.0, 50.0, 40.0, 60.0, 40.0, 60.0, 30.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 30.0, 50.0, 40.0, 40.0, 40.0, 50.0, 50.0, 30.0, 40.0, 50.0, 60.0, 40.0, 62.0, 40.0, 61.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 62.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 30.0, 20.0, 30.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0427745047502524, "mean_inference_ms": 25.85360939592246, "mean_action_processing_ms": 0.2460580359740755, "mean_env_wait_ms": 0.13950597830050887, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 76608, "timesteps_this_iter": 32, "agent_timesteps_total": 229824, "timers": {"load_time_ms": 0.724, "load_throughput": 44226.219, "learn_time_ms": 232.47, "learn_throughput": 137.652, "update_time_ms": 97.596}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 17.862117767333984, "min_q": -2.180514097213745, "max_q": 47.247840881347656, "mean_td_error": 1.2769193649291992, "model": {}}, "td_error": [-4.565861701965332, 2.195484161376953, -0.30377197265625, 0.9601364135742188, 0.22588062286376953, 2.827874183654785, -0.12945938110351562, -0.40071678161621094, 3.9113831520080566, 11.852554321289062, 3.224910259246826, -0.06488418579101562, -0.6897649765014648, -1.8595094680786133, -5.251954555511475, -1.354233980178833, 9.661081314086914, 0.8602123260498047, -1.0510330200195312, 2.8955700397491455, -3.5052871704101562, 3.9874305725097656, -0.8482742309570312, 0.11136817932128906, -3.6466541290283203, -0.25421714782714844, 1.7145309448242188, 20.765626907348633, 7.529690265655518, -3.6466541290283203, -5.136913299560547, 0.8468780517578125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.613460540771484, "min_q": -0.304777592420578, "max_q": 48.2686882019043, "mean_td_error": 0.5467772483825684, "model": {}}, "td_error": [3.0367507934570312, -0.9422941207885742, -1.9254684448242188, 1.2378239631652832, 2.9075145721435547, -0.03294944763183594, 3.065591812133789, -1.0715045928955078, -0.2842578887939453, -0.06118202209472656, -1.2982101440429688, -0.0009555816650390625, -0.976252555847168, -2.2997055053710938, -1.036046028137207, 1.753133773803711, -0.6066818237304688, -0.6315326690673828, 2.1217384338378906, 7.526762008666992, 9.669114112854004, 2.2296810150146484, 1.778676986694336, -1.6318740844726562, 0.6952223777770996, -1.5030632019042969, 3.7662487030029297, -2.5041065216064453, -0.7637786865234375, -0.27107810974121094, -2.6330771446228027, -1.8173694610595703], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.48569679260254, "min_q": 0.7200249433517456, "max_q": 51.44772720336914, "mean_td_error": 0.762866199016571, "model": {}}, "td_error": [16.404361724853516, 6.318394660949707, -0.49260711669921875, -1.419748306274414, 1.3276176452636719, 0.15837383270263672, -0.28682148456573486, -0.4767723083496094, -1.097747802734375, -1.0558357238769531, -6.03386116027832, 1.8667488098144531, -0.16913223266601562, 0.19480323791503906, 2.192464590072632, -0.4657173156738281, -2.3499298095703125, 2.013004779815674, -1.0753250122070312, -1.097747802734375, 2.7277603149414062, -1.2144355773925781, -0.4405021667480469, 1.6752599477767944, 6.2300214767456055, -0.40174102783203125, -0.8037714958190918, 1.5135841369628906, -0.5498428344726562, -0.24991416931152344, 1.7788467407226562, -0.3080711364746094], "custom_metrics": {}}}, "num_steps_sampled": 76608, "num_agent_steps_sampled": 229824, "num_steps_trained": 151232, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 453696, "last_target_update_ts": 76272, "num_target_updates": 148}, "done": false, "episodes_total": 7663, "training_iteration": 76, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-13-24", "timestamp": 1648916004, "time_this_iter_s": 39.85204577445984, "time_total_s": 3025.9586560726166, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72e7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72e7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3025.9586560726166, "timesteps_since_restore": 2432, "iterations_since_restore": 76, "perf": {"cpu_util_percent": 51.60877192982456, "ram_util_percent": 65.2894736842105}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 142.88235294117646, "episode_len_mean": 9.92156862745098, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 47.627450980392155, "policy1": 47.627450980392155, "policy2": 47.627450980392155}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 150.0, 150.0, 120.0, 150.0, 120.0, 120.0, 150.0, 120.0, 180.0, 150.0, 150.0, 180.0, 150.0, 150.0, 150.0, 150.0, 120.0, 150.0, 150.0, 150.0, 120.0, 150.0, 60.0, 180.0, 90.0, 120.0, 150.0, 150.0, 150.0, 150.0, 120.0, 150.0, 183.0, 150.0, 150.0, 150.0, 120.0, 150.0, 120.0, 150.0, 120.0, 150.0, 183.0, 120.0, 120.0, 120.0, 150.0, 150.0, 120.0, 180.0, 120.0, 150.0, 183.0, 120.0, 120.0, 150.0, 120.0, 180.0, 120.0, 150.0, 150.0, 90.0, 180.0, 120.0, 120.0, 150.0, 150.0, 90.0, 150.0, 150.0, 120.0, 180.0, 183.0, 150.0, 150.0, 186.0, 150.0, 120.0, 120.0, 180.0, 120.0, 150.0, 183.0, 120.0, 150.0, 120.0, 180.0, 150.0, 120.0, 150.0, 150.0, 120.0, 120.0, 150.0, 90.0, 150.0, 120.0, 180.0, 183.0, 150.0, 180.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 8, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10], "policy_policy0_reward": [50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 20.0, 60.0, 30.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 61.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 50.0, 50.0, 30.0, 60.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 40.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 60.0, 61.0, 50.0, 60.0], "policy_policy1_reward": [50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 20.0, 60.0, 30.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 61.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 50.0, 50.0, 30.0, 60.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 40.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 60.0, 61.0, 50.0, 60.0], "policy_policy2_reward": [50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 40.0, 50.0, 20.0, 60.0, 30.0, 40.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 61.0, 50.0, 50.0, 50.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 61.0, 40.0, 40.0, 40.0, 50.0, 50.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 40.0, 50.0, 40.0, 60.0, 40.0, 50.0, 50.0, 30.0, 60.0, 40.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 40.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 61.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 50.0, 30.0, 50.0, 40.0, 60.0, 61.0, 50.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0410778401951741, "mean_inference_ms": 25.767245225859014, "mean_action_processing_ms": 0.24535962425926647, "mean_env_wait_ms": 0.13915609247023866, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 77616, "timesteps_this_iter": 32, "agent_timesteps_total": 232848, "timers": {"load_time_ms": 0.64, "load_throughput": 50038.298, "learn_time_ms": 232.169, "learn_throughput": 137.831, "update_time_ms": 100.534}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.46214485168457, "min_q": -2.2835769653320312, "max_q": 47.27927780151367, "mean_td_error": 1.3375440835952759, "model": {}}, "td_error": [9.8383207321167, 1.7309341430664062, 7.682136535644531, -0.2724733352661133, -0.3175163269042969, 8.135546684265137, 24.264392852783203, -1.801483154296875, -0.2571372985839844, -3.817708969116211, -1.0891094207763672, -1.0806617736816406, -2.2266244888305664, -1.0162773132324219, 3.945549726486206, -0.3722267150878906, -3.181722640991211, -0.5818710327148438, -0.06566238403320312, -0.8548717498779297, -2.2547264099121094, -2.2904233932495117, -8.987332344055176, -1.2835769653320312, 12.4568452835083, 10.52944564819336, 1.3283538818359375, -0.39234352111816406, 1.2163658142089844, -1.3467040061950684, -3.208106756210327, -1.6279220581054688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.188129425048828, "min_q": 2.331937551498413, "max_q": 47.85218048095703, "mean_td_error": -0.1339593529701233, "model": {}}, "td_error": [-0.15748977661132812, 3.2470703125, 1.4377641677856445, 1.57574462890625, -1.7838859558105469, 1.381174087524414, 1.6198043823242188, 0.6195459365844727, 0.0054759979248046875, -4.458963394165039, -1.0928049087524414, -1.4978790283203125, -0.15748977661132812, -1.1906299591064453, -1.019360065460205, 2.641143798828125, 2.6425180435180664, -9.16314697265625, -0.5765094757080078, -0.39258766174316406, 4.8461174964904785, 0.8370304107666016, 3.055644989013672, 1.7999420166015625, -0.9331474304199219, -2.7253799438476562, -1.6245956420898438, -0.4689674377441406, -4.208723068237305, 0.7125167846679688, -0.5001792907714844, 1.2435474395751953], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.07082748413086, "min_q": -0.5767725706100464, "max_q": 51.16522979736328, "mean_td_error": 1.531622052192688, "model": {}}, "td_error": [1.4763374328613281, -0.48110198974609375, 0.6329565048217773, -0.7434768676757812, -1.0770950317382812, -1.2306394577026367, -0.7132265567779541, -0.13077163696289062, -0.7060909271240234, -0.5488395690917969, 1.3550949096679688, -0.5880966186523438, -1.1722393035888672, 15.764280319213867, 0.4232274293899536, 1.3242225646972656, -0.9186573028564453, 6.559181213378906, -0.33485984802246094, 0.2591285705566406, -0.6879615783691406, -0.5488395690917969, 19.947519302368164, 4.5393476486206055, 1.679168701171875, 1.12322998046875, 1.7712593078613281, 2.0262107849121094, 1.1353622674942017, -0.5488395690917969, -0.7084903717041016, 0.13460350036621094], "custom_metrics": {}}}, "num_steps_sampled": 77616, "num_agent_steps_sampled": 232848, "num_steps_trained": 153248, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 459744, "last_target_update_ts": 77296, "num_target_updates": 150}, "done": false, "episodes_total": 7765, "training_iteration": 77, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-14-03", "timestamp": 1648916043, "time_this_iter_s": 38.97731328010559, "time_total_s": 3064.935969352722, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c71e3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c71e3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3064.935969352722, "timesteps_since_restore": 2464, "iterations_since_restore": 77, "perf": {"cpu_util_percent": 51.643636363636375, "ram_util_percent": 65.23818181818183}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 143.7058823529412, "episode_len_mean": 9.843137254901961, "episode_media": {}, "episodes_this_iter": 102, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 47.90196078431372, "policy1": 47.90196078431372, "policy2": 47.90196078431372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [90.0, 180.0, 180.0, 186.0, 90.0, 186.0, 150.0, 150.0, 120.0, 150.0, 120.0, 180.0, 150.0, 120.0, 150.0, 180.0, 120.0, 150.0, 150.0, 186.0, 120.0, 150.0, 120.0, 180.0, 150.0, 150.0, 120.0, 150.0, 183.0, 180.0, 150.0, 120.0, 120.0, 150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 150.0, 120.0, 120.0, 180.0, 150.0, 150.0, 180.0, 150.0, 150.0, 180.0, 186.0, 120.0, 90.0, 90.0, 120.0, 120.0, 150.0, 150.0, 120.0, 120.0, 180.0, 120.0, 150.0, 180.0, 180.0, 120.0, 60.0, 120.0, 180.0, 90.0, 90.0, 183.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 90.0, 120.0, 120.0, 186.0, 90.0, 186.0, 150.0, 180.0, 120.0, 120.0, 150.0, 120.0, 120.0, 186.0, 150.0, 150.0, 180.0, 150.0, 150.0, 150.0, 150.0, 120.0, 180.0, 150.0, 120.0], "episode_lengths": [10, 10, 10, 8, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 8, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [30.0, 60.0, 60.0, 62.0, 30.0, 62.0, 50.0, 50.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 61.0, 60.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 60.0, 62.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 60.0, 40.0, 20.0, 40.0, 60.0, 30.0, 30.0, 61.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 62.0, 30.0, 62.0, 50.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 62.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 50.0, 40.0], "policy_policy1_reward": [30.0, 60.0, 60.0, 62.0, 30.0, 62.0, 50.0, 50.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 61.0, 60.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 60.0, 62.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 60.0, 40.0, 20.0, 40.0, 60.0, 30.0, 30.0, 61.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 62.0, 30.0, 62.0, 50.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 62.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 50.0, 40.0], "policy_policy2_reward": [30.0, 60.0, 60.0, 62.0, 30.0, 62.0, 50.0, 50.0, 40.0, 50.0, 40.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0, 60.0, 50.0, 50.0, 40.0, 50.0, 61.0, 60.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 60.0, 62.0, 40.0, 30.0, 30.0, 40.0, 40.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 60.0, 40.0, 20.0, 40.0, 60.0, 30.0, 30.0, 61.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 30.0, 40.0, 40.0, 62.0, 30.0, 62.0, 50.0, 60.0, 40.0, 40.0, 50.0, 40.0, 40.0, 62.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0452421874608986, "mean_inference_ms": 25.910400647432244, "mean_action_processing_ms": 0.24647603473332075, "mean_env_wait_ms": 0.13978591259404932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 78624, "timesteps_this_iter": 32, "agent_timesteps_total": 235872, "timers": {"load_time_ms": 0.707, "load_throughput": 45267.362, "learn_time_ms": 240.31, "learn_throughput": 133.162, "update_time_ms": 106.344}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.989559173583984, "min_q": 4.2115797996521, "max_q": 50.05312728881836, "mean_td_error": 0.7597165703773499, "model": {}}, "td_error": [14.14577865600586, -4.268194198608398, -0.9068794250488281, 0.1345233917236328, -0.5326404571533203, -0.16539764404296875, 1.3320541381835938, -4.7884202003479, -2.8966827392578125, 7.284201622009277, -0.5707340240478516, -0.5915069580078125, 0.3710765838623047, 2.4668922424316406, -1.1812629699707031, 3.215390682220459, -1.6599998474121094, 3.174386501312256, -2.3657264709472656, -1.7779178619384766, 1.3699703216552734, -1.1026020050048828, -0.8270406723022461, 0.9059715270996094, -0.8268947601318359, -2.323427200317383, 4.955404758453369, 4.387886047363281, -0.619659423828125, 0.6465244293212891, -0.10418319702148438, 7.4300384521484375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.133609771728516, "min_q": 6.313371658325195, "max_q": 49.15632247924805, "mean_td_error": -0.20626115798950195, "model": {}}, "td_error": [0.143463134765625, -1.5842475891113281, 1.6464385986328125, -1.9788312911987305, -1.4353561401367188, 0.023799896240234375, 2.0537548065185547, 1.6877517700195312, 0.2568359375, 2.938169479370117, -0.3699016571044922, -1.331441879272461, -0.4545249938964844, -0.22739410400390625, -2.874673843383789, -2.2982606887817383, 1.7552261352539062, -1.6273918151855469, -1.5842475891113281, 1.1357688903808594, 2.5507774353027344, 4.134364128112793, -1.8542366027832031, -1.1195526123046875, -1.1264238357543945, -0.24760055541992188, -1.0215797424316406, -2.084914207458496, -0.5975189208984375, -1.9346933364868164, 1.8823661804199219, -1.0562820434570312], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.424182891845703, "min_q": 1.6174356937408447, "max_q": 52.19099807739258, "mean_td_error": 0.3234725594520569, "model": {}}, "td_error": [1.962647795677185, 2.6393051147460938, -3.1453704833984375, 0.36693382263183594, 0.6638965606689453, 0.9062995910644531, -0.01691436767578125, 2.770021677017212, -0.6256637573242188, -2.8210248947143555, 0.45786285400390625, 1.0126800537109375, -0.13558387756347656, 2.5763587951660156, -0.931647777557373, -0.3397178649902344, -1.0609493255615234, 19.677154541015625, 0.027971267700195312, -1.566542625427246, -2.4267401695251465, 0.7147183418273926, 0.20455360412597656, -1.1114606857299805, 0.700264573097229, -3.0046944618225098, -1.06146240234375, -0.19935989379882812, 2.3217811584472656, -0.05356597900390625, -0.7680635452270508, -7.382564544677734], "custom_metrics": {}}}, "num_steps_sampled": 78624, "num_agent_steps_sampled": 235872, "num_steps_trained": 155264, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 465792, "last_target_update_ts": 78320, "num_target_updates": 152}, "done": false, "episodes_total": 7867, "training_iteration": 78, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-14-43", "timestamp": 1648916083, "time_this_iter_s": 39.50982141494751, "time_total_s": 3104.4457907676697, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72e0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72e0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3104.4457907676697, "timesteps_since_restore": 2496, "iterations_since_restore": 78, "perf": {"cpu_util_percent": 52.737500000000004, "ram_util_percent": 65.19464285714285}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 146.27884615384616, "episode_len_mean": 9.798076923076923, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 48.75961538461539, "policy1": 48.75961538461539, "policy2": 48.75961538461539}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 150.0, 120.0, 90.0, 120.0, 120.0, 183.0, 120.0, 150.0, 150.0, 150.0, 90.0, 120.0, 150.0, 150.0, 180.0, 120.0, 120.0, 150.0, 150.0, 120.0, 150.0, 60.0, 150.0, 150.0, 150.0, 120.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 180.0, 180.0, 180.0, 120.0, 120.0, 186.0, 150.0, 120.0, 180.0, 120.0, 90.0, 180.0, 186.0, 180.0, 150.0, 186.0, 180.0, 120.0, 150.0, 150.0, 120.0, 150.0, 186.0, 150.0, 120.0, 180.0, 186.0, 150.0, 150.0, 180.0, 183.0, 183.0, 90.0, 180.0, 120.0, 150.0, 180.0, 180.0, 186.0, 183.0, 120.0, 150.0, 120.0, 150.0, 120.0, 150.0, 180.0, 150.0, 183.0, 90.0, 120.0, 120.0, 183.0, 90.0, 120.0, 150.0, 60.0, 180.0, 150.0, 150.0, 150.0, 90.0, 150.0, 186.0, 183.0, 180.0, 120.0, 150.0, 120.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 8, 10, 10, 10, 9, 9, 10, 10, 10, 10, 10, 10, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 9, 10, 10, 10, 10], "policy_policy0_reward": [50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 61.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 50.0, 60.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 30.0, 60.0, 62.0, 60.0, 50.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 40.0, 60.0, 62.0, 50.0, 50.0, 60.0, 61.0, 61.0, 30.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 61.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 60.0, 50.0, 61.0, 30.0, 40.0, 40.0, 61.0, 30.0, 40.0, 50.0, 20.0, 60.0, 50.0, 50.0, 50.0, 30.0, 50.0, 62.0, 61.0, 60.0, 40.0, 50.0, 40.0], "policy_policy1_reward": [50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 61.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 50.0, 60.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 30.0, 60.0, 62.0, 60.0, 50.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 40.0, 60.0, 62.0, 50.0, 50.0, 60.0, 61.0, 61.0, 30.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 61.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 60.0, 50.0, 61.0, 30.0, 40.0, 40.0, 61.0, 30.0, 40.0, 50.0, 20.0, 60.0, 50.0, 50.0, 50.0, 30.0, 50.0, 62.0, 61.0, 60.0, 40.0, 50.0, 40.0], "policy_policy2_reward": [50.0, 50.0, 40.0, 30.0, 40.0, 40.0, 61.0, 40.0, 50.0, 50.0, 50.0, 30.0, 40.0, 50.0, 50.0, 60.0, 40.0, 40.0, 50.0, 50.0, 40.0, 50.0, 20.0, 50.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 30.0, 60.0, 62.0, 60.0, 50.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 40.0, 60.0, 62.0, 50.0, 50.0, 60.0, 61.0, 61.0, 30.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 61.0, 40.0, 50.0, 40.0, 50.0, 40.0, 50.0, 60.0, 50.0, 61.0, 30.0, 40.0, 40.0, 61.0, 30.0, 40.0, 50.0, 20.0, 60.0, 50.0, 50.0, 50.0, 30.0, 50.0, 62.0, 61.0, 60.0, 40.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0435450495597713, "mean_inference_ms": 25.832156811314235, "mean_action_processing_ms": 0.2457964030518777, "mean_env_wait_ms": 0.13942162008226602, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 79632, "timesteps_this_iter": 32, "agent_timesteps_total": 238896, "timers": {"load_time_ms": 0.679, "load_throughput": 47127.011, "learn_time_ms": 225.656, "learn_throughput": 141.809, "update_time_ms": 105.144}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.34963035583496, "min_q": -5.1691412925720215, "max_q": 49.414669036865234, "mean_td_error": 0.5052177309989929, "model": {}}, "td_error": [2.068147659301758, 1.1586542129516602, 0.25459861755371094, 8.040446281433105, 1.5893630981445312, 1.8870582580566406, -5.9136528968811035, -0.5786876678466797, -3.0759811401367188, -1.4817771911621094, -4.458640098571777, -1.6614761352539062, -1.3610858917236328, -0.5764198303222656, -0.4799156188964844, 2.026620864868164, -2.0755786895751953, 3.5348215103149414, 1.4059982299804688, 0.6695518493652344, -1.8862724304199219, 1.7176055908203125, -1.6382484436035156, -1.3648452758789062, 4.7044830322265625, 0.7208442687988281, -2.1667609214782715, 3.617919921875, -0.7066628932952881, 14.273534774780273, -1.233412265777588, -0.8432636260986328], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.444486618041992, "min_q": 1.0445115566253662, "max_q": 49.845706939697266, "mean_td_error": 1.1742920875549316, "model": {}}, "td_error": [0.10095691680908203, 13.07286548614502, 1.2995338439941406, 1.1514549255371094, 3.3769779205322266, 2.03948974609375, -0.9939193725585938, 0.5439529418945312, 0.39247703552246094, 0.13527488708496094, -3.614032745361328, -1.110687255859375, 4.866596221923828, -0.8911590576171875, -1.0092706680297852, -0.306121826171875, -2.8801345825195312, -0.8831710815429688, -6.738555908203125, 3.419178009033203, -2.2828352451324463, -0.784210205078125, -0.3841972351074219, 2.1387314796447754, -1.0499496459960938, 1.9979209899902344, 2.2237892150878906, -1.4971466064453125, 1.9457082748413086, 20.055564880371094, -0.48366355895996094, 3.7259273529052734], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.72634506225586, "min_q": -1.2565877437591553, "max_q": 52.027706146240234, "mean_td_error": 0.26075148582458496, "model": {}}, "td_error": [-2.083303451538086, 0.2999725341796875, 0.20431900024414062, 0.3670463562011719, -0.9250831604003906, -0.3153618574142456, -1.911057472229004, 0.8316497802734375, 5.782032012939453, 0.08163213729858398, 0.8239974975585938, -0.03675079345703125, 1.8293228149414062, 2.968120574951172, -3.749089241027832, 0.8649234771728516, 0.7624588012695312, 1.7338542938232422, 2.2787094116210938, -1.3076057434082031, -3.0297508239746094, -0.20224761962890625, 0.097747802734375, -0.2037506103515625, -1.328782081604004, 0.8492431640625, 1.0171356201171875, 0.069427490234375, 1.9313697814941406, 0.21102523803710938, 0.6894302368164062, -0.2565877437591553], "custom_metrics": {}}}, "num_steps_sampled": 79632, "num_agent_steps_sampled": 238896, "num_steps_trained": 157280, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 471840, "last_target_update_ts": 79344, "num_target_updates": 154}, "done": false, "episodes_total": 7971, "training_iteration": 79, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-15-22", "timestamp": 1648916122, "time_this_iter_s": 39.830463886260986, "time_total_s": 3144.2762546539307, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c771560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c771560>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3144.2762546539307, "timesteps_since_restore": 2528, "iterations_since_restore": 79, "perf": {"cpu_util_percent": 51.778571428571425, "ram_util_percent": 65.17142857142856}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 152.50485436893203, "episode_len_mean": 9.74757281553398, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 50.83495145631068, "policy1": 50.83495145631068, "policy2": 50.83495145631068}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 180.0, 120.0, 150.0, 90.0, 150.0, 150.0, 150.0, 180.0, 150.0, 120.0, 150.0, 150.0, 120.0, 150.0, 180.0, 150.0, 120.0, 150.0, 186.0, 180.0, 150.0, 120.0, 150.0, 180.0, 120.0, 120.0, 186.0, 150.0, 120.0, 180.0, 120.0, 150.0, 120.0, 120.0, 150.0, 120.0, 150.0, 180.0, 180.0, 120.0, 183.0, 186.0, 180.0, 150.0, 186.0, 150.0, 180.0, 150.0, 150.0, 150.0, 150.0, 150.0, 120.0, 120.0, 186.0, 90.0, 183.0, 183.0, 180.0, 120.0, 180.0, 150.0, 180.0, 180.0, 150.0, 90.0, 150.0, 186.0, 120.0, 180.0, 183.0, 150.0, 150.0, 120.0, 180.0, 150.0, 150.0, 183.0, 183.0, 150.0, 186.0, 183.0, 180.0, 120.0, 120.0, 150.0, 180.0, 150.0, 150.0, 186.0, 150.0, 150.0, 150.0, 183.0, 150.0, 120.0, 120.0, 150.0, 150.0, 120.0, 186.0, 150.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 9, 10, 10, 10, 10, 10, 10, 9, 9, 10, 8, 9, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 8, 10], "policy_policy0_reward": [50.0, 60.0, 40.0, 50.0, 30.0, 50.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 40.0, 50.0, 62.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 60.0, 60.0, 40.0, 61.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 62.0, 30.0, 61.0, 61.0, 60.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 50.0, 62.0, 40.0, 60.0, 61.0, 50.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 61.0, 50.0, 62.0, 61.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 62.0, 50.0], "policy_policy1_reward": [50.0, 60.0, 40.0, 50.0, 30.0, 50.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 40.0, 50.0, 62.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 60.0, 60.0, 40.0, 61.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 62.0, 30.0, 61.0, 61.0, 60.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 50.0, 62.0, 40.0, 60.0, 61.0, 50.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 61.0, 50.0, 62.0, 61.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 62.0, 50.0], "policy_policy2_reward": [50.0, 60.0, 40.0, 50.0, 30.0, 50.0, 50.0, 50.0, 60.0, 50.0, 40.0, 50.0, 50.0, 40.0, 50.0, 60.0, 50.0, 40.0, 50.0, 62.0, 60.0, 50.0, 40.0, 50.0, 60.0, 40.0, 40.0, 62.0, 50.0, 40.0, 60.0, 40.0, 50.0, 40.0, 40.0, 50.0, 40.0, 50.0, 60.0, 60.0, 40.0, 61.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 40.0, 62.0, 30.0, 61.0, 61.0, 60.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 50.0, 62.0, 40.0, 60.0, 61.0, 50.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 61.0, 50.0, 62.0, 61.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 50.0, 40.0, 40.0, 50.0, 50.0, 40.0, 62.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.044637467325558, "mean_inference_ms": 25.856463998105077, "mean_action_processing_ms": 0.2459976538810017, "mean_env_wait_ms": 0.1395386862787417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 80640, "timesteps_this_iter": 32, "agent_timesteps_total": 241920, "timers": {"load_time_ms": 0.648, "load_throughput": 49379.246, "learn_time_ms": 242.185, "learn_throughput": 132.13, "update_time_ms": 105.813}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 19.956256866455078, "min_q": -0.05103583633899689, "max_q": 47.34633255004883, "mean_td_error": 0.4642973244190216, "model": {}}, "td_error": [0.27547693252563477, 3.02545166015625, 4.822776794433594, -0.946502685546875, 2.1807193756103516, -0.6826705932617188, -2.9531898498535156, -2.1034393310546875, 1.9943819046020508, -1.0131034851074219, -1.4349250793457031, 3.117624282836914, 1.2190074920654297, -0.8937225341796875, -3.097414970397949, -0.6724891662597656, -2.073653221130371, 2.3585853576660156, 0.4741942882537842, -0.12807083129882812, 2.3820037841796875, -0.07723045349121094, -1.6839218139648438, 1.5869903564453125, -6.757778644561768, 2.9781131744384766, 1.679534912109375, 1.2954254150390625, 4.012694358825684, 9.887445449829102, -2.3664398193359375, -1.5483589172363281], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.656307220458984, "min_q": 1.90790593624115, "max_q": 49.77040100097656, "mean_td_error": 0.7750198841094971, "model": {}}, "td_error": [-1.8508892059326172, -6.040732383728027, -0.24860000610351562, -0.728607177734375, -0.38048362731933594, -1.231435775756836, -0.79150390625, 4.507803916931152, -0.1736602783203125, 9.996299743652344, -0.6425514221191406, -0.9556236267089844, 3.649061918258667, -2.246633529663086, 1.7281723022460938, 4.113664627075195, -0.9542598724365234, -0.24860000610351562, 12.062511444091797, -0.8807258605957031, 0.9043121337890625, -2.9533939361572266, 2.6916842460632324, -0.1736602783203125, -1.0661048889160156, 0.18511676788330078, -0.1900310516357422, -1.0164031982421875, 12.829734802246094, -2.236116409301758, -5.765615463256836, 2.9079060554504395], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.96334457397461, "min_q": 1.5774210691452026, "max_q": 50.940574645996094, "mean_td_error": 1.421761393547058, "model": {}}, "td_error": [-4.987339496612549, 0.34641122817993164, -2.470099449157715, 2.577421188354492, -1.3904552459716797, -0.8897686004638672, -0.6646766662597656, -3.928068161010742, 1.2029666900634766, 1.6026763916015625, 5.741575241088867, 0.649897575378418, 0.7887763977050781, -2.817704200744629, 9.331853866577148, -0.4362602233886719, 0.07574653625488281, -0.10181045532226562, -3.9685840606689453, 21.059356689453125, 0.34515953063964844, -2.134200096130371, 0.04010009765625, 10.043478965759277, -0.8910293579101562, -0.4562339782714844, -0.09531784057617188, 0.9864044189453125, 2.4320430755615234, 1.3485851287841797, -3.4146556854248047, 15.570114135742188], "custom_metrics": {}}}, "num_steps_sampled": 80640, "num_agent_steps_sampled": 241920, "num_steps_trained": 159296, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 477888, "last_target_update_ts": 80368, "num_target_updates": 156}, "done": false, "episodes_total": 8074, "training_iteration": 80, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-16-03", "timestamp": 1648916163, "time_this_iter_s": 40.25562334060669, "time_total_s": 3184.5318779945374, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c727290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c727290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3184.5318779945374, "timesteps_since_restore": 2560, "iterations_since_restore": 80, "perf": {"cpu_util_percent": 51.320689655172416, "ram_util_percent": 65.41206896551725}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 154.04854368932038, "episode_len_mean": 9.718446601941748, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 51.349514563106794, "policy1": 51.349514563106794, "policy2": 51.349514563106794}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 180.0, 186.0, 180.0, 150.0, 120.0, 90.0, 120.0, 150.0, 183.0, 150.0, 180.0, 180.0, 180.0, 90.0, 150.0, 180.0, 186.0, 120.0, 186.0, 150.0, 150.0, 150.0, 60.0, 180.0, 150.0, 120.0, 183.0, 150.0, 150.0, 150.0, 180.0, 150.0, 150.0, 120.0, 183.0, 150.0, 150.0, 120.0, 180.0, 180.0, 180.0, 183.0, 183.0, 180.0, 150.0, 150.0, 150.0, 186.0, 180.0, 120.0, 90.0, 150.0, 186.0, 186.0, 150.0, 150.0, 150.0, 150.0, 150.0, 120.0, 150.0, 186.0, 150.0, 150.0, 183.0, 150.0, 150.0, 183.0, 150.0, 90.0, 150.0, 183.0, 150.0, 180.0, 186.0, 150.0, 186.0, 60.0, 150.0, 150.0, 180.0, 180.0, 150.0, 120.0, 180.0, 150.0, 150.0, 183.0, 180.0, 150.0, 90.0, 120.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 186.0, 120.0, 150.0, 120.0], "episode_lengths": [10, 10, 8, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 8, 10, 8, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 9, 9, 10, 10, 10, 10, 8, 10, 10, 10, 10, 8, 8, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 9, 10, 10, 9, 10, 10, 10, 9, 10, 10, 8, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10], "policy_policy0_reward": [50.0, 60.0, 62.0, 60.0, 50.0, 40.0, 30.0, 40.0, 50.0, 61.0, 50.0, 60.0, 60.0, 60.0, 30.0, 50.0, 60.0, 62.0, 40.0, 62.0, 50.0, 50.0, 50.0, 20.0, 60.0, 50.0, 40.0, 61.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 60.0, 61.0, 61.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 40.0, 30.0, 50.0, 62.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0, 50.0, 61.0, 50.0, 60.0, 62.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 60.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 60.0, 50.0, 30.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0], "policy_policy1_reward": [50.0, 60.0, 62.0, 60.0, 50.0, 40.0, 30.0, 40.0, 50.0, 61.0, 50.0, 60.0, 60.0, 60.0, 30.0, 50.0, 60.0, 62.0, 40.0, 62.0, 50.0, 50.0, 50.0, 20.0, 60.0, 50.0, 40.0, 61.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 60.0, 61.0, 61.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 40.0, 30.0, 50.0, 62.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0, 50.0, 61.0, 50.0, 60.0, 62.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 60.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 60.0, 50.0, 30.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0], "policy_policy2_reward": [50.0, 60.0, 62.0, 60.0, 50.0, 40.0, 30.0, 40.0, 50.0, 61.0, 50.0, 60.0, 60.0, 60.0, 30.0, 50.0, 60.0, 62.0, 40.0, 62.0, 50.0, 50.0, 50.0, 20.0, 60.0, 50.0, 40.0, 61.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 60.0, 61.0, 61.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 40.0, 30.0, 50.0, 62.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0, 50.0, 61.0, 50.0, 60.0, 62.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 60.0, 50.0, 40.0, 60.0, 50.0, 50.0, 61.0, 60.0, 50.0, 30.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 40.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.043220023599187, "mean_inference_ms": 25.79957237677567, "mean_action_processing_ms": 0.24544005495382507, "mean_env_wait_ms": 0.13923495552848775, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 81648, "timesteps_this_iter": 32, "agent_timesteps_total": 244944, "timers": {"load_time_ms": 0.646, "load_throughput": 49565.245, "learn_time_ms": 247.331, "learn_throughput": 129.381, "update_time_ms": 100.433}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 21.329986572265625, "min_q": 0.7044873237609863, "max_q": 51.620235443115234, "mean_td_error": -0.22499237954616547, "model": {}}, "td_error": [1.7827720642089844, -0.177337646484375, 0.9240341186523438, 1.212712287902832, -1.2474441528320312, -2.3740415573120117, -0.2675600051879883, 0.14649200439453125, 0.32049560546875, -2.3740415573120117, -3.822786331176758, -3.188169479370117, 0.661278247833252, 1.2552566528320312, 1.7044873237609863, 0.8482894897460938, 1.7388496398925781, -0.9781761169433594, -1.8774032592773438, 0.09899139404296875, -0.8477153778076172, -4.19091796875, 1.8464279174804688, 0.72808837890625, -0.22592544555664062, -3.599994659423828, -2.625520706176758, 2.307950973510742, 2.105689525604248, 1.7827720642089844, 0.6012458801269531, 0.5314445495605469], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.236909866333008, "min_q": -0.11919543147087097, "max_q": 52.02769088745117, "mean_td_error": 1.1118100881576538, "model": {}}, "td_error": [-0.4019432067871094, 1.9371185302734375, -1.2784042358398438, -3.540618896484375, 1.464691162109375, 1.6685256958007812, -0.03045177459716797, 3.4757537841796875, -1.1180667877197266, 22.59132194519043, 5.534889221191406, -0.6935501098632812, 1.0864543914794922, 2.6098060607910156, -2.7482051849365234, 1.6575660705566406, -0.812225341796875, 0.24564361572265625, -1.1774234771728516, -1.0398712158203125, -1.0065765380859375, 1.9241409301757812, -0.5537223815917969, -0.9951667785644531, 8.249902725219727, 4.055201053619385, -1.0406646728515625, -1.5004043579101562, -2.1167068481445312, 0.8858871459960938, -1.3215255737304688, -0.43345165252685547], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 18.248779296875, "min_q": 0.7013595104217529, "max_q": 50.34590530395508, "mean_td_error": 1.2427654266357422, "model": {}}, "td_error": [-0.1292552947998047, -0.4663105010986328, 5.010777950286865, 9.50749683380127, 0.08820343017578125, 1.7687492370605469, -3.5919923782348633, 3.3335959911346436, 3.414764881134033, -0.8246669769287109, 4.968303680419922, 2.6971683502197266, 0.5117533206939697, 5.505898475646973, 1.6654548645019531, 0.2708892822265625, -0.6147651672363281, 4.33683967590332, -0.7395439147949219, -0.039699554443359375, 0.9574384689331055, 0.7571687698364258, 9.692482948303223, -0.023662567138671875, 0.7583904266357422, 1.701359510421753, -0.7929706573486328, 0.9460926055908203, -2.0026473999023438, -1.9051055908203125, -7.7261786460876465, 0.7324657440185547], "custom_metrics": {}}}, "num_steps_sampled": 81648, "num_agent_steps_sampled": 244944, "num_steps_trained": 161312, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 483936, "last_target_update_ts": 81392, "num_target_updates": 158}, "done": false, "episodes_total": 8177, "training_iteration": 81, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-16-44", "timestamp": 1648916204, "time_this_iter_s": 41.13259482383728, "time_total_s": 3225.6644728183746, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c727b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c727b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3225.6644728183746, "timesteps_since_restore": 2592, "iterations_since_restore": 81, "perf": {"cpu_util_percent": 52.60689655172414, "ram_util_percent": 65.56034482758622}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 155.18446601941747, "episode_len_mean": 9.728155339805825, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 51.728155339805824, "policy1": 51.728155339805824, "policy2": 51.728155339805824}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 180.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 120.0, 180.0, 120.0, 90.0, 186.0, 150.0, 150.0, 180.0, 90.0, 180.0, 120.0, 90.0, 150.0, 120.0, 150.0, 180.0, 120.0, 150.0, 120.0, 120.0, 180.0, 186.0, 90.0, 150.0, 180.0, 180.0, 150.0, 183.0, 180.0, 180.0, 180.0, 183.0, 120.0, 150.0, 120.0, 120.0, 180.0, 183.0, 150.0, 120.0, 120.0, 186.0, 120.0, 180.0, 186.0, 150.0, 150.0, 150.0, 180.0, 150.0, 150.0, 120.0, 150.0, 150.0, 150.0, 150.0, 150.0, 120.0, 180.0, 183.0, 186.0, 150.0, 186.0, 180.0, 180.0, 150.0, 180.0, 150.0, 180.0, 120.0, 180.0, 90.0, 186.0, 150.0, 180.0, 186.0, 183.0, 150.0, 180.0, 180.0, 186.0, 180.0, 183.0, 120.0, 150.0, 150.0, 180.0, 186.0, 150.0, 183.0, 150.0, 150.0, 183.0, 150.0, 90.0], "episode_lengths": [10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 10, 9, 10, 10, 10, 10, 10, 9, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 8, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 8, 9, 10, 10, 10, 8, 10, 9, 10, 10, 10, 10, 8, 10, 9, 10, 10, 9, 10, 10], "policy_policy0_reward": [40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 60.0, 40.0, 30.0, 62.0, 50.0, 50.0, 60.0, 30.0, 60.0, 40.0, 30.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 40.0, 40.0, 60.0, 62.0, 30.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 60.0, 61.0, 40.0, 50.0, 40.0, 40.0, 60.0, 61.0, 50.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 62.0, 50.0, 62.0, 60.0, 60.0, 50.0, 60.0, 50.0, 60.0, 40.0, 60.0, 30.0, 62.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 40.0, 50.0, 50.0, 60.0, 62.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0], "policy_policy1_reward": [40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 60.0, 40.0, 30.0, 62.0, 50.0, 50.0, 60.0, 30.0, 60.0, 40.0, 30.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 40.0, 40.0, 60.0, 62.0, 30.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 60.0, 61.0, 40.0, 50.0, 40.0, 40.0, 60.0, 61.0, 50.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 62.0, 50.0, 62.0, 60.0, 60.0, 50.0, 60.0, 50.0, 60.0, 40.0, 60.0, 30.0, 62.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 40.0, 50.0, 50.0, 60.0, 62.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0], "policy_policy2_reward": [40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 40.0, 60.0, 40.0, 30.0, 62.0, 50.0, 50.0, 60.0, 30.0, 60.0, 40.0, 30.0, 50.0, 40.0, 50.0, 60.0, 40.0, 50.0, 40.0, 40.0, 60.0, 62.0, 30.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 60.0, 61.0, 40.0, 50.0, 40.0, 40.0, 60.0, 61.0, 50.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 62.0, 50.0, 62.0, 60.0, 60.0, 50.0, 60.0, 50.0, 60.0, 40.0, 60.0, 30.0, 62.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 40.0, 50.0, 50.0, 60.0, 62.0, 50.0, 61.0, 50.0, 50.0, 61.0, 50.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0445725313815408, "mean_inference_ms": 25.86553987423822, "mean_action_processing_ms": 0.24589681533851793, "mean_env_wait_ms": 0.13952226327331294, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 82656, "timesteps_this_iter": 32, "agent_timesteps_total": 247968, "timers": {"load_time_ms": 0.603, "load_throughput": 53037.907, "learn_time_ms": 238.917, "learn_throughput": 133.938, "update_time_ms": 99.028}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 25.922893524169922, "min_q": -2.690751314163208, "max_q": 54.914146423339844, "mean_td_error": 0.07384353876113892, "model": {}}, "td_error": [0.4781532287597656, -1.8029556274414062, 2.317451238632202, 0.5856122970581055, 0.806915283203125, -6.479780197143555, -1.8029556274414062, -6.479780197143555, -1.5615291595458984, -1.8029556274414062, -1.08648681640625, 0.5876243114471436, -2.118485450744629, 0.2794342041015625, -0.3708992004394531, 19.967222213745117, -5.578813552856445, 7.72938346862793, 4.660045623779297, -0.6384315490722656, 2.188490867614746, -0.3228302001953125, 0.5074234008789062, -2.335108757019043, -2.0479888916015625, -1.1457195281982422, -0.39272308349609375, -3.4440250396728516, -0.2303466796875, 1.9314727783203125, -6.203632354736328, 6.169212341308594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.094074249267578, "min_q": 4.3584136962890625, "max_q": 53.332191467285156, "mean_td_error": 2.6249964237213135, "model": {}}, "td_error": [-0.6184577941894531, 0.00432586669921875, 0.20611572265625, 2.457042694091797, 6.55299186706543, -0.6659622192382812, 0.18299484252929688, -1.0718307495117188, 0.8373756408691406, -2.0573081970214844, 1.7546615600585938, -1.701777458190918, 3.73577880859375, -0.1150970458984375, 1.3753318786621094, 4.640739440917969, 3.5920639038085938, 3.359233856201172, -0.10743522644042969, 4.99713134765625, 26.594099044799805, 3.7254600524902344, -0.03771495819091797, 3.187723159790039, -0.5506076812744141, 8.664798736572266, 1.2939262390136719, 0.16274261474609375, -0.3721046447753906, 6.150371551513672, 5.046571731567383, 2.776700973510742], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 20.8885498046875, "min_q": -2.1402335166931152, "max_q": 53.16729736328125, "mean_td_error": 0.5028443336486816, "model": {}}, "td_error": [2.4175796508789062, -0.9236297607421875, -1.1402335166931152, -1.0137271881103516, -0.14768600463867188, -0.2697944641113281, -1.513972282409668, 0.7802162170410156, -0.7430419921875, 2.4604568481445312, -1.8840484619140625, 1.9802207946777344, 0.4981422424316406, 3.5545778274536133, -0.19881057739257812, -1.425827980041504, 1.8441886901855469, 1.1129741668701172, -5.276534080505371, 11.762829780578613, -0.2697944641113281, 1.5224857330322266, 0.301971435546875, -0.9909114837646484, 2.1808252334594727, 1.55757474899292, 0.4981422424316406, -2.5704431533813477, 2.025188446044922, -0.02429962158203125, -0.6367568969726562, 0.6231569051742554], "custom_metrics": {}}}, "num_steps_sampled": 82656, "num_agent_steps_sampled": 247968, "num_steps_trained": 163328, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 489984, "last_target_update_ts": 82416, "num_target_updates": 160}, "done": false, "episodes_total": 8280, "training_iteration": 82, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-17-23", "timestamp": 1648916243, "time_this_iter_s": 39.15774583816528, "time_total_s": 3264.82221865654, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c1680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7c1680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3264.82221865654, "timesteps_since_restore": 2624, "iterations_since_restore": 82, "perf": {"cpu_util_percent": 51.887499999999996, "ram_util_percent": 65.23214285714286}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 154.67307692307693, "episode_len_mean": 9.692307692307692, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 51.55769230769231, "policy1": 51.55769230769231, "policy2": 51.55769230769231}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 150.0, 120.0, 90.0, 180.0, 186.0, 150.0, 150.0, 186.0, 60.0, 150.0, 150.0, 180.0, 186.0, 150.0, 150.0, 90.0, 150.0, 183.0, 180.0, 150.0, 150.0, 183.0, 180.0, 180.0, 180.0, 186.0, 186.0, 150.0, 150.0, 183.0, 180.0, 90.0, 180.0, 150.0, 150.0, 183.0, 180.0, 120.0, 90.0, 180.0, 183.0, 150.0, 150.0, 180.0, 180.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 150.0, 150.0, 150.0, 120.0, 90.0, 180.0, 186.0, 186.0, 183.0, 120.0, 180.0, 180.0, 180.0, 150.0, 150.0, 150.0, 150.0, 120.0, 180.0, 183.0, 120.0, 180.0, 120.0, 150.0, 150.0, 180.0, 90.0, 186.0, 150.0, 150.0, 120.0, 186.0, 150.0, 120.0, 150.0, 180.0, 150.0, 150.0, 90.0, 150.0, 120.0, 150.0, 186.0, 183.0, 150.0, 186.0, 120.0, 90.0, 180.0, 180.0, 186.0, 150.0], "episode_lengths": [10, 10, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 8, 10, 10, 10, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 8, 10, 10, 9, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 9, 10, 8, 10, 10, 10, 10, 8, 10], "policy_policy0_reward": [40.0, 50.0, 40.0, 30.0, 60.0, 62.0, 50.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 62.0, 50.0, 50.0, 30.0, 50.0, 61.0, 60.0, 50.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 50.0, 50.0, 61.0, 60.0, 30.0, 60.0, 50.0, 50.0, 61.0, 60.0, 40.0, 30.0, 60.0, 61.0, 50.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 30.0, 60.0, 62.0, 62.0, 61.0, 40.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 40.0, 60.0, 40.0, 50.0, 50.0, 60.0, 30.0, 62.0, 50.0, 50.0, 40.0, 62.0, 50.0, 40.0, 50.0, 60.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 62.0, 61.0, 50.0, 62.0, 40.0, 30.0, 60.0, 60.0, 62.0, 50.0], "policy_policy1_reward": [40.0, 50.0, 40.0, 30.0, 60.0, 62.0, 50.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 62.0, 50.0, 50.0, 30.0, 50.0, 61.0, 60.0, 50.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 50.0, 50.0, 61.0, 60.0, 30.0, 60.0, 50.0, 50.0, 61.0, 60.0, 40.0, 30.0, 60.0, 61.0, 50.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 30.0, 60.0, 62.0, 62.0, 61.0, 40.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 40.0, 60.0, 40.0, 50.0, 50.0, 60.0, 30.0, 62.0, 50.0, 50.0, 40.0, 62.0, 50.0, 40.0, 50.0, 60.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 62.0, 61.0, 50.0, 62.0, 40.0, 30.0, 60.0, 60.0, 62.0, 50.0], "policy_policy2_reward": [40.0, 50.0, 40.0, 30.0, 60.0, 62.0, 50.0, 50.0, 62.0, 20.0, 50.0, 50.0, 60.0, 62.0, 50.0, 50.0, 30.0, 50.0, 61.0, 60.0, 50.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 50.0, 50.0, 61.0, 60.0, 30.0, 60.0, 50.0, 50.0, 61.0, 60.0, 40.0, 30.0, 60.0, 61.0, 50.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 50.0, 50.0, 40.0, 30.0, 60.0, 62.0, 62.0, 61.0, 40.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 40.0, 60.0, 61.0, 40.0, 60.0, 40.0, 50.0, 50.0, 60.0, 30.0, 62.0, 50.0, 50.0, 40.0, 62.0, 50.0, 40.0, 50.0, 60.0, 50.0, 50.0, 30.0, 50.0, 40.0, 50.0, 62.0, 61.0, 50.0, 62.0, 40.0, 30.0, 60.0, 60.0, 62.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0437859930146145, "mean_inference_ms": 25.823714414882794, "mean_action_processing_ms": 0.24556695899173706, "mean_env_wait_ms": 0.13938742374241986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 83664, "timesteps_this_iter": 32, "agent_timesteps_total": 250992, "timers": {"load_time_ms": 0.604, "load_throughput": 52958.384, "learn_time_ms": 231.394, "learn_throughput": 138.292, "update_time_ms": 105.645}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.733959197998047, "min_q": 0.731468677520752, "max_q": 54.62302780151367, "mean_td_error": 0.6624374985694885, "model": {}}, "td_error": [1.2563676834106445, 10.617940902709961, 0.49828338623046875, -6.003242492675781, -0.6334075927734375, -0.5788211822509766, 0.5716323852539062, 0.5538558959960938, -2.435056686401367, -0.5842151641845703, 2.3850345611572266, 0.2651023864746094, -1.2115135192871094, -0.0390625, 1.8763885498046875, 0.708709716796875, 9.321769714355469, -1.4719371795654297, 2.5572052001953125, -2.8678975105285645, 9.45910930633545, 0.5132274627685547, 1.6470870971679688, -0.5744519233703613, 0.2299346923828125, 2.336894989013672, -1.9240913391113281, 1.0473442077636719, -2.376194953918457, -0.9957313537597656, 1.731468677520752, -4.683734893798828], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.485031127929688, "min_q": 0.17613744735717773, "max_q": 53.63998031616211, "mean_td_error": 2.117046594619751, "model": {}}, "td_error": [1.1761374473571777, 1.267603874206543, -1.2302837371826172, 0.3218345642089844, -0.1104888916015625, 6.723291397094727, 2.7010421752929688, 3.5888290405273438, 0.4398174285888672, -0.39573097229003906, 2.4165525436401367, 3.6413421630859375, -0.7015743255615234, 3.318256378173828, 1.1923065185546875, 2.035449981689453, -1.86981201171875, 19.170955657958984, 0.6668853759765625, -2.051654815673828, 5.394283294677734, -0.8961582183837891, 10.729321479797363, 5.1177978515625, 5.789979934692383, -1.7260246276855469, 2.2350234985351562, -1.195587158203125, 0.328582763671875, 1.9977493286132812, -0.7270584106445312, -1.6031804084777832], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.014156341552734, "min_q": 3.3243284225463867, "max_q": 53.717708587646484, "mean_td_error": 1.1068832874298096, "model": {}}, "td_error": [-2.3283119201660156, 3.4837989807128906, 0.43675994873046875, 1.6346321105957031, 20.254547119140625, -5.200918197631836, -0.4297599792480469, 1.6575355529785156, 1.9243927001953125, 0.5382862091064453, 1.4705524444580078, 3.4912166595458984, 9.178865432739258, 1.3512744903564453, 0.9952678680419922, -0.45134735107421875, 0.41045379638671875, 2.5477066040039062, 1.299764633178711, 0.8938636779785156, 4.324328422546387, -0.25091552734375, -5.258512496948242, 1.24151611328125, -2.8711986541748047, -3.053152084350586, 2.8663196563720703, -2.161130428314209, -0.4108543395996094, -0.4556465148925781, -0.19367599487304688, -1.5153923034667969], "custom_metrics": {}}}, "num_steps_sampled": 83664, "num_agent_steps_sampled": 250992, "num_steps_trained": 165344, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 496032, "last_target_update_ts": 83440, "num_target_updates": 162}, "done": false, "episodes_total": 8384, "training_iteration": 83, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-18-03", "timestamp": 1648916283, "time_this_iter_s": 39.41403007507324, "time_total_s": 3304.236248731613, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c74a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c74a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3304.236248731613, "timesteps_since_restore": 2656, "iterations_since_restore": 83, "perf": {"cpu_util_percent": 51.88035714285714, "ram_util_percent": 65.19821428571427}}
{"episode_reward_max": 186.0, "episode_reward_min": 30.0, "episode_reward_mean": 147.11428571428573, "episode_len_mean": 9.723809523809523, "episode_media": {}, "episodes_this_iter": 105, "policy_reward_min": {"policy0": 10.0, "policy1": 10.0, "policy2": 10.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 49.03809523809524, "policy1": 49.03809523809524, "policy2": 49.03809523809524}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 30.0, 90.0, 186.0, 120.0, 150.0, 186.0, 183.0, 183.0, 186.0, 150.0, 186.0, 120.0, 183.0, 120.0, 150.0, 186.0, 183.0, 90.0, 180.0, 120.0, 150.0, 150.0, 90.0, 150.0, 150.0, 30.0, 180.0, 186.0, 120.0, 120.0, 180.0, 180.0, 180.0, 150.0, 183.0, 90.0, 150.0, 180.0, 150.0, 120.0, 90.0, 150.0, 120.0, 180.0, 180.0, 183.0, 120.0, 180.0, 150.0, 186.0, 120.0, 150.0, 150.0, 150.0, 150.0, 180.0, 90.0, 150.0, 180.0, 180.0, 150.0, 150.0, 180.0, 150.0, 150.0, 120.0, 120.0, 180.0, 120.0, 150.0, 180.0, 120.0, 120.0, 120.0, 150.0, 180.0, 180.0, 60.0, 180.0, 180.0, 120.0, 90.0, 150.0, 90.0, 186.0, 180.0, 150.0, 60.0, 186.0, 150.0, 150.0, 186.0, 150.0, 90.0, 150.0, 90.0, 183.0, 120.0, 186.0, 150.0, 150.0, 180.0, 180.0, 120.0], "episode_lengths": [10, 10, 10, 8, 10, 10, 8, 9, 9, 8, 10, 8, 10, 9, 10, 10, 8, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 9, 10, 8, 10, 10, 10, 10, 10], "policy_policy0_reward": [50.0, 10.0, 30.0, 62.0, 40.0, 50.0, 62.0, 61.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 40.0, 50.0, 62.0, 61.0, 30.0, 60.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 10.0, 60.0, 62.0, 40.0, 40.0, 60.0, 60.0, 60.0, 50.0, 61.0, 30.0, 50.0, 60.0, 50.0, 40.0, 30.0, 50.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 50.0, 62.0, 40.0, 50.0, 50.0, 50.0, 50.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 60.0, 60.0, 20.0, 60.0, 60.0, 40.0, 30.0, 50.0, 30.0, 62.0, 60.0, 50.0, 20.0, 62.0, 50.0, 50.0, 62.0, 50.0, 30.0, 50.0, 30.0, 61.0, 40.0, 62.0, 50.0, 50.0, 60.0, 60.0, 40.0], "policy_policy1_reward": [50.0, 10.0, 30.0, 62.0, 40.0, 50.0, 62.0, 61.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 40.0, 50.0, 62.0, 61.0, 30.0, 60.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 10.0, 60.0, 62.0, 40.0, 40.0, 60.0, 60.0, 60.0, 50.0, 61.0, 30.0, 50.0, 60.0, 50.0, 40.0, 30.0, 50.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 50.0, 62.0, 40.0, 50.0, 50.0, 50.0, 50.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 60.0, 60.0, 20.0, 60.0, 60.0, 40.0, 30.0, 50.0, 30.0, 62.0, 60.0, 50.0, 20.0, 62.0, 50.0, 50.0, 62.0, 50.0, 30.0, 50.0, 30.0, 61.0, 40.0, 62.0, 50.0, 50.0, 60.0, 60.0, 40.0], "policy_policy2_reward": [50.0, 10.0, 30.0, 62.0, 40.0, 50.0, 62.0, 61.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 40.0, 50.0, 62.0, 61.0, 30.0, 60.0, 40.0, 50.0, 50.0, 30.0, 50.0, 50.0, 10.0, 60.0, 62.0, 40.0, 40.0, 60.0, 60.0, 60.0, 50.0, 61.0, 30.0, 50.0, 60.0, 50.0, 40.0, 30.0, 50.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 50.0, 62.0, 40.0, 50.0, 50.0, 50.0, 50.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 50.0, 60.0, 50.0, 50.0, 40.0, 40.0, 60.0, 40.0, 50.0, 60.0, 40.0, 40.0, 40.0, 50.0, 60.0, 60.0, 20.0, 60.0, 60.0, 40.0, 30.0, 50.0, 30.0, 62.0, 60.0, 50.0, 20.0, 62.0, 50.0, 50.0, 62.0, 50.0, 30.0, 50.0, 30.0, 61.0, 40.0, 62.0, 50.0, 50.0, 60.0, 60.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0458539345735276, "mean_inference_ms": 25.880580278699185, "mean_action_processing_ms": 0.24604512740573903, "mean_env_wait_ms": 0.13965870061189767, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 84672, "timesteps_this_iter": 32, "agent_timesteps_total": 254016, "timers": {"load_time_ms": 0.657, "load_throughput": 48719.637, "learn_time_ms": 243.858, "learn_throughput": 131.224, "update_time_ms": 114.244}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.788694381713867, "min_q": -3.699100971221924, "max_q": 53.28771209716797, "mean_td_error": 1.071487307548523, "model": {}}, "td_error": [-0.5598945617675781, -5.190524101257324, -0.6111831665039062, -1.3458728790283203, 2.3798751831054688, 11.710798263549805, 0.4962291717529297, -1.4842071533203125, 0.9134407043457031, 3.3319053649902344, 2.357992172241211, -1.6274070739746094, 0.6483879089355469, -0.9050941467285156, 0.6824455261230469, -0.8280391693115234, 2.824443817138672, 0.4652099609375, -2.699100971221924, 13.36460018157959, -1.0640220642089844, 2.408721923828125, -0.4844512939453125, 0.7670841217041016, 0.9217529296875, 11.176557540893555, -1.0682334899902344, -2.7607479095458984, -0.6111831665039062, 3.372425079345703, -1.5897178649902344, -0.704594612121582], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.191688537597656, "min_q": -0.6845381855964661, "max_q": 54.8424072265625, "mean_td_error": 0.9944857358932495, "model": {}}, "td_error": [0.18217086791992188, 2.1482696533203125, 0.23928451538085938, -2.048246383666992, 0.7502021789550781, -1.0192794799804688, 0.1286773681640625, -1.687089443206787, -0.17580413818359375, 4.130889892578125, 4.223625183105469, 3.585047721862793, -1.117197036743164, 0.7891845703125, 11.265342712402344, -1.1063289642333984, -0.8259429931640625, 2.072990655899048, -0.7863922119140625, -0.7193336486816406, -2.4640650749206543, 10.064066886901855, 5.6736741065979, -2.9260921478271484, 1.0508360862731934, -1.0464706420898438, -1.7696552276611328, 4.130889892578125, -0.7693424224853516, -0.9699897766113281, 1.5408515930175781, -0.7212303280830383], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.5498046875, "min_q": 3.507784843444824, "max_q": 52.02119445800781, "mean_td_error": 1.107380747795105, "model": {}}, "td_error": [5.016831398010254, 0.09349441528320312, -0.5721855163574219, 1.5935144424438477, -1.1540756225585938, 0.14725494384765625, 0.45696258544921875, 0.7103614807128906, 4.507784843444824, 1.3875846862792969, -0.4104461669921875, -3.589038848876953, -0.5805549621582031, -3.235177993774414, 1.5750312805175781, 0.6857624053955078, -0.7975502014160156, -0.6054229736328125, -1.3659043312072754, 1.0589790344238281, -0.9841461181640625, 1.7779464721679688, 0.10260772705078125, 0.39871978759765625, 4.661455154418945, -2.1548519134521484, 25.08914566040039, -0.062267303466796875, 1.128265380859375, -0.7975502014160156, 0.7077312469482422, 0.6459255218505859], "custom_metrics": {}}}, "num_steps_sampled": 84672, "num_agent_steps_sampled": 254016, "num_steps_trained": 167360, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 502080, "last_target_update_ts": 84464, "num_target_updates": 164}, "done": false, "episodes_total": 8489, "training_iteration": 84, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-18-44", "timestamp": 1648916324, "time_this_iter_s": 41.26872992515564, "time_total_s": 3345.504978656769, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f9290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f9290>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3345.504978656769, "timesteps_since_restore": 2688, "iterations_since_restore": 84, "perf": {"cpu_util_percent": 52.5293103448276, "ram_util_percent": 65.58793103448275}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 152.88349514563106, "episode_len_mean": 9.718446601941748, "episode_media": {}, "episodes_this_iter": 103, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 50.96116504854369, "policy1": 50.96116504854369, "policy2": 50.96116504854369}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 150.0, 90.0, 180.0, 120.0, 150.0, 186.0, 180.0, 150.0, 180.0, 180.0, 120.0, 180.0, 150.0, 180.0, 183.0, 183.0, 150.0, 150.0, 90.0, 150.0, 180.0, 120.0, 183.0, 180.0, 150.0, 150.0, 180.0, 183.0, 120.0, 60.0, 186.0, 180.0, 180.0, 186.0, 180.0, 120.0, 120.0, 150.0, 186.0, 120.0, 180.0, 150.0, 180.0, 120.0, 180.0, 183.0, 180.0, 150.0, 120.0, 150.0, 186.0, 90.0, 150.0, 150.0, 150.0, 150.0, 180.0, 180.0, 180.0, 120.0, 150.0, 150.0, 150.0, 120.0, 120.0, 120.0, 186.0, 150.0, 186.0, 90.0, 186.0, 150.0, 150.0, 150.0, 150.0, 150.0, 183.0, 120.0, 120.0, 180.0, 180.0, 186.0, 150.0, 120.0, 180.0, 180.0, 150.0, 90.0, 120.0, 90.0, 90.0, 186.0, 120.0, 183.0, 180.0, 180.0, 120.0, 150.0, 180.0, 150.0, 150.0, 120.0], "episode_lengths": [8, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 9, 9, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 9, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 8, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [62.0, 50.0, 30.0, 60.0, 40.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 40.0, 60.0, 50.0, 60.0, 61.0, 61.0, 50.0, 50.0, 30.0, 50.0, 60.0, 40.0, 61.0, 60.0, 50.0, 50.0, 60.0, 61.0, 40.0, 20.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 40.0, 50.0, 62.0, 40.0, 60.0, 50.0, 60.0, 40.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 62.0, 30.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 62.0, 50.0, 62.0, 30.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 60.0, 60.0, 62.0, 50.0, 40.0, 60.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 62.0, 40.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 50.0, 50.0, 40.0], "policy_policy1_reward": [62.0, 50.0, 30.0, 60.0, 40.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 40.0, 60.0, 50.0, 60.0, 61.0, 61.0, 50.0, 50.0, 30.0, 50.0, 60.0, 40.0, 61.0, 60.0, 50.0, 50.0, 60.0, 61.0, 40.0, 20.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 40.0, 50.0, 62.0, 40.0, 60.0, 50.0, 60.0, 40.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 62.0, 30.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 62.0, 50.0, 62.0, 30.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 60.0, 60.0, 62.0, 50.0, 40.0, 60.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 62.0, 40.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 50.0, 50.0, 40.0], "policy_policy2_reward": [62.0, 50.0, 30.0, 60.0, 40.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 40.0, 60.0, 50.0, 60.0, 61.0, 61.0, 50.0, 50.0, 30.0, 50.0, 60.0, 40.0, 61.0, 60.0, 50.0, 50.0, 60.0, 61.0, 40.0, 20.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 40.0, 50.0, 62.0, 40.0, 60.0, 50.0, 60.0, 40.0, 60.0, 61.0, 60.0, 50.0, 40.0, 50.0, 62.0, 30.0, 50.0, 50.0, 50.0, 50.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 50.0, 40.0, 40.0, 40.0, 62.0, 50.0, 62.0, 30.0, 62.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 60.0, 60.0, 62.0, 50.0, 40.0, 60.0, 60.0, 50.0, 30.0, 40.0, 30.0, 30.0, 62.0, 40.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 50.0, 50.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0438138689237293, "mean_inference_ms": 25.796718715127856, "mean_action_processing_ms": 0.24535059364553088, "mean_env_wait_ms": 0.13930581383255733, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 85680, "timesteps_this_iter": 32, "agent_timesteps_total": 257040, "timers": {"load_time_ms": 0.747, "load_throughput": 42842.737, "learn_time_ms": 235.735, "learn_throughput": 135.745, "update_time_ms": 101.902}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.254478454589844, "min_q": -1.2445285320281982, "max_q": 54.669273376464844, "mean_td_error": 0.7838628888130188, "model": {}}, "td_error": [1.8464832305908203, -1.8864326477050781, 0.7570610046386719, -2.6053504943847656, -0.6557540893554688, 0.5810775756835938, -1.6026859283447266, 6.707442283630371, -1.7283592224121094, 4.0996479988098145, -0.2439422607421875, -0.027984619140625, -1.3772602081298828, -5.087345123291016, 0.6143267154693604, -0.8903617858886719, -1.1593799591064453, 3.8279075622558594, 0.08442878723144531, 12.947486877441406, 14.769279479980469, -0.8005905151367188, 4.773014068603516, 0.24602890014648438, 2.0916500091552734, -6.891142845153809, 0.8130302429199219, -0.4684906005859375, -0.6557540893554688, -1.7906208038330078, 3.8279037475585938, -5.03170108795166], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.55115509033203, "min_q": 0.5681484937667847, "max_q": 57.27368927001953, "mean_td_error": 0.6199865341186523, "model": {}}, "td_error": [3.53216552734375, 0.6787300109863281, 1.2014408111572266, -0.5548477172851562, -0.16266632080078125, 0.013641357421875, 0.2873115539550781, 2.718189239501953, 4.86939811706543, 0.14052200317382812, 0.4025115966796875, 2.0188026428222656, 0.24364089965820312, 0.24364089965820312, 0.20638656616210938, 0.34203338623046875, 0.5988273620605469, -0.3491363525390625, -0.04669189453125, -0.18271255493164062, 1.2009391784667969, 1.4439029693603516, 0.8662567138671875, -0.5872726440429688, 0.7139358520507812, -4.730100154876709, 1.0961475372314453, 3.114948272705078, 2.1398658752441406, 0.46476781368255615, 0.17986738681793213, -2.2648773193359375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.917705535888672, "min_q": 1.8522377014160156, "max_q": 50.656864166259766, "mean_td_error": 1.2343206405639648, "model": {}}, "td_error": [-1.6274070739746094, -1.025033950805664, 3.2925987243652344, 4.748527526855469, -2.4249095916748047, -0.3181419372558594, 0.635711669921875, -3.013336181640625, 0.2728004455566406, 1.469625473022461, -1.2056961059570312, 2.0577354431152344, 1.8798761367797852, -2.3687782287597656, -1.3261375427246094, 2.873270034790039, 1.5239629745483398, -1.7739906311035156, 0.18667888641357422, 1.230825424194336, -1.5068931579589844, 0.22994422912597656, 3.762579917907715, -1.4834136962890625, -1.1940765380859375, -2.5653162002563477, 4.625278472900391, -3.5421791076660156, 0.4478759765625, 0.03359794616699219, 2.8522377014160156, 32.75044250488281], "custom_metrics": {}}}, "num_steps_sampled": 85680, "num_agent_steps_sampled": 257040, "num_steps_trained": 169376, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 508128, "last_target_update_ts": 85488, "num_target_updates": 166}, "done": false, "episodes_total": 8592, "training_iteration": 85, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-19-25", "timestamp": 1648916365, "time_this_iter_s": 40.30274677276611, "time_total_s": 3385.807725429535, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f9680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f9680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3385.807725429535, "timesteps_since_restore": 2720, "iterations_since_restore": 85, "perf": {"cpu_util_percent": 51.540350877192985, "ram_util_percent": 65.37894736842105}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 160.9811320754717, "episode_len_mean": 9.547169811320755, "episode_media": {}, "episodes_this_iter": 106, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 53.660377358490564, "policy1": 53.660377358490564, "policy2": 53.660377358490564}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 180.0, 186.0, 120.0, 180.0, 150.0, 150.0, 150.0, 183.0, 120.0, 120.0, 186.0, 120.0, 180.0, 186.0, 183.0, 180.0, 150.0, 186.0, 150.0, 183.0, 183.0, 180.0, 186.0, 150.0, 150.0, 180.0, 150.0, 186.0, 150.0, 180.0, 186.0, 150.0, 180.0, 180.0, 183.0, 183.0, 120.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 186.0, 150.0, 120.0, 183.0, 180.0, 150.0, 150.0, 120.0, 183.0, 186.0, 186.0, 180.0, 120.0, 120.0, 90.0, 120.0, 150.0, 150.0, 150.0, 180.0, 183.0, 150.0, 183.0, 150.0, 180.0, 183.0, 180.0, 186.0, 120.0, 150.0, 120.0, 150.0, 186.0, 150.0, 150.0, 150.0, 150.0, 186.0, 180.0, 180.0, 180.0, 120.0, 150.0, 186.0, 150.0, 183.0, 150.0, 150.0, 120.0, 180.0, 180.0, 150.0, 186.0, 186.0, 180.0, 180.0, 90.0, 186.0, 120.0, 120.0, 150.0], "episode_lengths": [8, 10, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 8, 10, 10, 8, 9, 10, 10, 8, 10, 9, 9, 10, 8, 10, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 9, 9, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 9, 10, 10, 10, 10, 9, 8, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 9, 10, 10, 9, 10, 8, 10, 10, 10, 10, 8, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 10, 10, 10, 10, 8, 8, 10, 10, 10, 8, 10, 10, 10], "policy_policy0_reward": [62.0, 60.0, 60.0, 62.0, 40.0, 60.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 61.0, 60.0, 62.0, 50.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 61.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 40.0, 61.0, 60.0, 50.0, 50.0, 40.0, 61.0, 62.0, 62.0, 60.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 60.0, 61.0, 50.0, 61.0, 50.0, 60.0, 61.0, 60.0, 62.0, 40.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 62.0, 50.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 62.0, 62.0, 60.0, 60.0, 30.0, 62.0, 40.0, 40.0, 50.0], "policy_policy1_reward": [62.0, 60.0, 60.0, 62.0, 40.0, 60.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 61.0, 60.0, 62.0, 50.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 61.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 40.0, 61.0, 60.0, 50.0, 50.0, 40.0, 61.0, 62.0, 62.0, 60.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 60.0, 61.0, 50.0, 61.0, 50.0, 60.0, 61.0, 60.0, 62.0, 40.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 62.0, 50.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 62.0, 62.0, 60.0, 60.0, 30.0, 62.0, 40.0, 40.0, 50.0], "policy_policy2_reward": [62.0, 60.0, 60.0, 62.0, 40.0, 60.0, 50.0, 50.0, 50.0, 61.0, 40.0, 40.0, 62.0, 40.0, 60.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 61.0, 60.0, 62.0, 50.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 61.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 40.0, 61.0, 60.0, 50.0, 50.0, 40.0, 61.0, 62.0, 62.0, 60.0, 40.0, 40.0, 30.0, 40.0, 50.0, 50.0, 50.0, 60.0, 61.0, 50.0, 61.0, 50.0, 60.0, 61.0, 60.0, 62.0, 40.0, 50.0, 40.0, 50.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 62.0, 50.0, 61.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 62.0, 62.0, 60.0, 60.0, 30.0, 62.0, 40.0, 40.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0453686371933772, "mean_inference_ms": 25.836420750028488, "mean_action_processing_ms": 0.24566415014678672, "mean_env_wait_ms": 0.1394407632250838, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 86688, "timesteps_this_iter": 32, "agent_timesteps_total": 260064, "timers": {"load_time_ms": 0.697, "load_throughput": 45938.23, "learn_time_ms": 231.014, "learn_throughput": 138.52, "update_time_ms": 101.215}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.33935546875, "min_q": 2.183129072189331, "max_q": 55.33646011352539, "mean_td_error": 0.051066964864730835, "model": {}}, "td_error": [6.780942916870117, -0.6149959564208984, -0.5064153671264648, -3.5553932189941406, 2.6285438537597656, -0.9635887145996094, -2.804004669189453, -0.42476654052734375, -3.384876251220703, -1.74017333984375, 20.920215606689453, -1.9170246124267578, -1.1912651062011719, -2.0560264587402344, 2.099771499633789, 1.2872276306152344, -3.8648176193237305, 2.7761001586914062, -2.6138248443603516, 1.6320819854736328, -2.196807861328125, -2.120311737060547, -2.014911651611328, -0.13805770874023438, 0.06796455383300781, -1.4488499164581299, 3.307708740234375, -2.6138248443603516, -0.6149959564208984, -1.3591995239257812, -0.09130668640136719, -1.6309738159179688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.75128746032715, "min_q": 3.315763473510742, "max_q": 56.07802963256836, "mean_td_error": 1.7169255018234253, "model": {}}, "td_error": [5.638141632080078, 1.9724464416503906, -1.5474777221679688, 1.9806089401245117, 0.4688987731933594, -0.5157203674316406, 0.5488510131835938, -0.2513465881347656, 4.315763473510742, 0.43442249298095703, 3.2050628662109375, -0.8917961120605469, 0.5564765930175781, -1.1705141067504883, 0.7820644378662109, -0.10434722900390625, -1.378509521484375, -1.8310813903808594, 23.099830627441406, 5.60334587097168, 0.44443511962890625, 4.40392541885376, 1.3138904571533203, -0.10552597045898438, 1.772632122039795, -0.7418441772460938, 0.17293262481689453, 3.409536361694336, -0.30151939392089844, 1.5290946960449219, 1.7930517196655273, 0.33588600158691406], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.86351203918457, "min_q": 2.091066837310791, "max_q": 56.813507080078125, "mean_td_error": 0.5977154970169067, "model": {}}, "td_error": [0.97882080078125, -0.14882946014404297, -6.908933162689209, -1.8281288146972656, 0.8706626892089844, -3.070037841796875, -1.4780006408691406, 0.22436904907226562, -0.03403663635253906, 0.69000244140625, 1.5737895965576172, 2.3294448852539062, 0.9982223510742188, 1.9504108428955078, 0.4314842224121094, 8.8455810546875, -0.9906158447265625, 1.465287685394287, -0.28072547912597656, 3.972829818725586, 0.31583213806152344, -1.0858840942382812, 0.21119117736816406, -0.7371635437011719, -0.7371635437011719, 9.089313507080078, 0.18062973022460938, -0.15312957763671875, 8.13931655883789, -3.1997203826904297, -1.21429443359375, -1.2736282348632812], "custom_metrics": {}}}, "num_steps_sampled": 86688, "num_agent_steps_sampled": 260064, "num_steps_trained": 171392, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 514176, "last_target_update_ts": 86512, "num_target_updates": 168}, "done": false, "episodes_total": 8698, "training_iteration": 86, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-20-05", "timestamp": 1648916405, "time_this_iter_s": 40.17678999900818, "time_total_s": 3425.984515428543, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3425.984515428543, "timesteps_since_restore": 2752, "iterations_since_restore": 86, "perf": {"cpu_util_percent": 51.824137931034485, "ram_util_percent": 65.2051724137931}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 157.47115384615384, "episode_len_mean": 9.721153846153847, "episode_media": {}, "episodes_this_iter": 104, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 52.49038461538461, "policy1": 52.49038461538461, "policy2": 52.49038461538461}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 150.0, 180.0, 150.0, 150.0, 120.0, 150.0, 180.0, 180.0, 180.0, 120.0, 186.0, 186.0, 183.0, 183.0, 150.0, 150.0, 186.0, 150.0, 120.0, 180.0, 150.0, 183.0, 90.0, 180.0, 180.0, 180.0, 150.0, 180.0, 180.0, 180.0, 180.0, 150.0, 150.0, 186.0, 180.0, 120.0, 186.0, 120.0, 180.0, 186.0, 180.0, 120.0, 150.0, 180.0, 180.0, 150.0, 180.0, 186.0, 150.0, 60.0, 180.0, 180.0, 150.0, 186.0, 180.0, 150.0, 150.0, 150.0, 150.0, 186.0, 180.0, 183.0, 180.0, 180.0, 150.0, 150.0, 183.0, 150.0, 150.0, 180.0, 150.0, 150.0, 150.0, 186.0, 180.0, 150.0, 120.0, 186.0, 150.0, 150.0, 150.0, 120.0, 180.0, 180.0, 150.0, 150.0, 90.0, 120.0, 120.0, 150.0, 150.0, 180.0, 150.0, 120.0, 183.0, 120.0, 180.0, 150.0, 120.0, 150.0, 90.0, 90.0, 120.0], "episode_lengths": [9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 8, 9, 9, 10, 10, 8, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10], "policy_policy0_reward": [61.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 60.0, 60.0, 60.0, 40.0, 62.0, 62.0, 61.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 60.0, 50.0, 61.0, 30.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 62.0, 60.0, 40.0, 62.0, 40.0, 60.0, 62.0, 60.0, 40.0, 50.0, 60.0, 60.0, 50.0, 60.0, 62.0, 50.0, 20.0, 60.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 61.0, 60.0, 60.0, 50.0, 50.0, 61.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 40.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 50.0, 30.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 40.0, 61.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 30.0, 40.0], "policy_policy1_reward": [61.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 60.0, 60.0, 60.0, 40.0, 62.0, 62.0, 61.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 60.0, 50.0, 61.0, 30.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 62.0, 60.0, 40.0, 62.0, 40.0, 60.0, 62.0, 60.0, 40.0, 50.0, 60.0, 60.0, 50.0, 60.0, 62.0, 50.0, 20.0, 60.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 61.0, 60.0, 60.0, 50.0, 50.0, 61.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 40.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 50.0, 30.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 40.0, 61.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 30.0, 40.0], "policy_policy2_reward": [61.0, 50.0, 60.0, 50.0, 50.0, 40.0, 50.0, 60.0, 60.0, 60.0, 40.0, 62.0, 62.0, 61.0, 61.0, 50.0, 50.0, 62.0, 50.0, 40.0, 60.0, 50.0, 61.0, 30.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 50.0, 50.0, 62.0, 60.0, 40.0, 62.0, 40.0, 60.0, 62.0, 60.0, 40.0, 50.0, 60.0, 60.0, 50.0, 60.0, 62.0, 50.0, 20.0, 60.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 61.0, 60.0, 60.0, 50.0, 50.0, 61.0, 50.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 40.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 50.0, 50.0, 30.0, 40.0, 40.0, 50.0, 50.0, 60.0, 50.0, 40.0, 61.0, 40.0, 60.0, 50.0, 40.0, 50.0, 30.0, 30.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0432393891112282, "mean_inference_ms": 25.75145789598459, "mean_action_processing_ms": 0.24493931322889934, "mean_env_wait_ms": 0.1391088407339313, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 87696, "timesteps_this_iter": 32, "agent_timesteps_total": 263088, "timers": {"load_time_ms": 0.698, "load_throughput": 45869.153, "learn_time_ms": 232.715, "learn_throughput": 137.507, "update_time_ms": 97.42}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.669692993164062, "min_q": -4.314617156982422, "max_q": 54.97785949707031, "mean_td_error": 1.0561540126800537, "model": {}}, "td_error": [13.236915588378906, -1.6092891693115234, 0.23482513427734375, 1.2788734436035156, 5.171669006347656, -2.9905364513397217, 1.1168403625488281, 0.31513214111328125, -1.1298713684082031, 0.3745079040527344, 1.1412410736083984, 4.067527770996094, -0.4280433654785156, 0.131011962890625, 0.31513214111328125, -1.5444698333740234, -1.0337762832641602, 23.40628433227539, 0.3934059143066406, 1.0397987365722656, -1.0286312103271484, -8.091129302978516, -1.485870361328125, 2.4443962574005127, -0.9803733825683594, 3.429065704345703, -1.6609649658203125, 0.5135812759399414, 0.6151809692382812, -0.9803733825683594, 0.8482704162597656, -3.313401222229004], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.932640075683594, "min_q": 0.4869301915168762, "max_q": 54.7159538269043, "mean_td_error": 0.8539590835571289, "model": {}}, "td_error": [-0.9149169921875, -1.1161956787109375, 1.341592788696289, -1.2614402770996094, -0.002780914306640625, 0.37548065185546875, 1.9989509582519531, 1.3319091796875, -0.7666015625, -0.04279327392578125, -1.6851379871368408, 4.496273040771484, 1.1085052490234375, 0.3037281036376953, -0.457550048828125, 2.3161067962646484, 1.4077110290527344, -1.46832275390625, 9.82192611694336, 1.5680770874023438, 0.45038604736328125, 4.4080963134765625, -0.2047576904296875, 1.116567611694336, 1.0082817077636719, 0.3682117462158203, 1.6093406677246094, 2.455617904663086, 0.12592315673828125, 0.8653755187988281, -7.727148056030273, 4.496273040771484], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.36199951171875, "min_q": 1.9188086986541748, "max_q": 58.72157669067383, "mean_td_error": 0.2134973108768463, "model": {}}, "td_error": [1.5258617401123047, -1.2456989288330078, -0.7570419311523438, -1.401153564453125, 0.5357704162597656, -0.49653053283691406, 1.3573379516601562, -2.1928138732910156, -0.16009521484375, -1.2491769790649414, -0.4189949035644531, -0.07691574096679688, -1.3417110443115234, 4.893780708312988, 1.8778076171875, -0.12129402160644531, 0.1908721923828125, 4.482982635498047, 0.03700065612792969, -2.123828887939453, 2.5252685546875, 2.399763822555542, -0.050586700439453125, 2.2768077850341797, 0.17987823486328125, 1.7026138305664062, -2.6522483825683594, -2.1928138732910156, -0.26979827880859375, -1.9131507873535156, 1.3301467895507812, 0.17987442016601562], "custom_metrics": {}}}, "num_steps_sampled": 87696, "num_agent_steps_sampled": 263088, "num_steps_trained": 173408, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 520224, "last_target_update_ts": 87536, "num_target_updates": 170}, "done": false, "episodes_total": 8802, "training_iteration": 87, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-20-45", "timestamp": 1648916445, "time_this_iter_s": 39.960878133773804, "time_total_s": 3465.945393562317, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3465.945393562317, "timesteps_since_restore": 2784, "iterations_since_restore": 87, "perf": {"cpu_util_percent": 52.573214285714286, "ram_util_percent": 65.45357142857144}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 158.42857142857142, "episode_len_mean": 9.571428571428571, "episode_media": {}, "episodes_this_iter": 105, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 52.80952380952381, "policy1": 52.80952380952381, "policy2": 52.80952380952381}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 150.0, 150.0, 150.0, 180.0, 186.0, 180.0, 183.0, 150.0, 150.0, 186.0, 150.0, 180.0, 90.0, 150.0, 183.0, 150.0, 150.0, 150.0, 186.0, 150.0, 180.0, 150.0, 120.0, 120.0, 180.0, 150.0, 180.0, 180.0, 150.0, 180.0, 150.0, 186.0, 150.0, 180.0, 180.0, 180.0, 150.0, 183.0, 120.0, 180.0, 90.0, 150.0, 180.0, 180.0, 150.0, 180.0, 180.0, 186.0, 150.0, 180.0, 186.0, 120.0, 150.0, 180.0, 120.0, 120.0, 150.0, 180.0, 150.0, 186.0, 180.0, 180.0, 90.0, 183.0, 120.0, 150.0, 183.0, 186.0, 180.0, 120.0, 186.0, 150.0, 120.0, 186.0, 180.0, 120.0, 186.0, 150.0, 186.0, 150.0, 186.0, 90.0, 183.0, 180.0, 150.0, 150.0, 186.0, 186.0, 186.0, 186.0, 120.0, 90.0, 186.0, 150.0, 90.0, 150.0, 150.0, 150.0, 150.0, 150.0, 183.0, 186.0, 120.0, 150.0], "episode_lengths": [10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 8, 10, 10, 10, 10, 9, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 9, 10, 10, 9, 8, 10, 10, 8, 10, 10, 8, 10, 10, 8, 10, 8, 10, 8, 10, 9, 10, 10, 10, 8, 8, 8, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 9, 8, 10, 10], "policy_policy0_reward": [40.0, 50.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 60.0, 30.0, 50.0, 61.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0, 50.0, 40.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 60.0, 60.0, 50.0, 61.0, 40.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 62.0, 50.0, 60.0, 62.0, 40.0, 50.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 62.0, 60.0, 60.0, 30.0, 61.0, 40.0, 50.0, 61.0, 62.0, 60.0, 40.0, 62.0, 50.0, 40.0, 62.0, 60.0, 40.0, 62.0, 50.0, 62.0, 50.0, 62.0, 30.0, 61.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 40.0, 30.0, 62.0, 50.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 62.0, 40.0, 50.0], "policy_policy1_reward": [40.0, 50.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 60.0, 30.0, 50.0, 61.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0, 50.0, 40.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 60.0, 60.0, 50.0, 61.0, 40.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 62.0, 50.0, 60.0, 62.0, 40.0, 50.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 62.0, 60.0, 60.0, 30.0, 61.0, 40.0, 50.0, 61.0, 62.0, 60.0, 40.0, 62.0, 50.0, 40.0, 62.0, 60.0, 40.0, 62.0, 50.0, 62.0, 50.0, 62.0, 30.0, 61.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 40.0, 30.0, 62.0, 50.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 62.0, 40.0, 50.0], "policy_policy2_reward": [40.0, 50.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 62.0, 50.0, 60.0, 30.0, 50.0, 61.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0, 50.0, 40.0, 40.0, 60.0, 50.0, 60.0, 60.0, 50.0, 60.0, 50.0, 62.0, 50.0, 60.0, 60.0, 60.0, 50.0, 61.0, 40.0, 60.0, 30.0, 50.0, 60.0, 60.0, 50.0, 60.0, 60.0, 62.0, 50.0, 60.0, 62.0, 40.0, 50.0, 60.0, 40.0, 40.0, 50.0, 60.0, 50.0, 62.0, 60.0, 60.0, 30.0, 61.0, 40.0, 50.0, 61.0, 62.0, 60.0, 40.0, 62.0, 50.0, 40.0, 62.0, 60.0, 40.0, 62.0, 50.0, 62.0, 50.0, 62.0, 30.0, 61.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 40.0, 30.0, 62.0, 50.0, 30.0, 50.0, 50.0, 50.0, 50.0, 50.0, 61.0, 62.0, 40.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0465576560776442, "mean_inference_ms": 25.86015924503336, "mean_action_processing_ms": 0.2457729897260634, "mean_env_wait_ms": 0.13954847512319626, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 88704, "timesteps_this_iter": 32, "agent_timesteps_total": 266112, "timers": {"load_time_ms": 0.606, "load_throughput": 52764.763, "learn_time_ms": 235.363, "learn_throughput": 135.96, "update_time_ms": 98.314}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.119304656982422, "min_q": 4.540191173553467, "max_q": 55.53385543823242, "mean_td_error": 2.3808138370513916, "model": {}}, "td_error": [3.8557186126708984, 5.281676292419434, 11.799301147460938, -2.0462465286254883, 1.0181999206542969, -1.6256542205810547, 2.604839324951172, -0.4119224548339844, -4.459808826446533, -0.4119224548339844, -4.420609474182129, -1.0728378295898438, -0.3939247131347656, 33.380165100097656, -1.0764999389648438, 13.541242599487305, 4.960811614990234, -2.760396957397461, 2.709888458251953, 2.3628387451171875, -1.4527931213378906, 2.665189743041992, -1.0764999389648438, 1.3519668579101562, 1.7830562591552734, 1.87542724609375, -1.1903018951416016, 1.1674690246582031, -0.8844413757324219, -0.5826759338378906, -0.7428016662597656, 10.437589645385742], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.028377532958984, "min_q": -2.305490732192993, "max_q": 55.886573791503906, "mean_td_error": 0.6857375502586365, "model": {}}, "td_error": [-0.3887176513671875, -0.8951988220214844, -0.23030853271484375, 1.1977615356445312, -1.111948013305664, 1.7290611267089844, -0.7529945373535156, 3.1321678161621094, 1.4388427734375, -2.5191545486450195, 14.296453475952148, 0.21718597412109375, 3.4148406982421875, -0.5689506530761719, -0.41033172607421875, 0.25250244140625, -1.0071125030517578, -2.0387325286865234, -0.8447723388671875, 0.2608757019042969, 4.067176818847656, 0.42905235290527344, -1.3054907321929932, -5.7966179847717285, 0.2678508758544922, -0.022806167602539062, -2.3465404510498047, 0.4274406433105469, 0.8912239074707031, 11.558403015136719, -0.819671630859375, -0.5778884887695312], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.807292938232422, "min_q": 3.3501617908477783, "max_q": 54.937843322753906, "mean_td_error": 0.17117446660995483, "model": {}}, "td_error": [22.629032135009766, 0.13785934448242188, -0.7679481506347656, 1.8266944885253906, -0.6653671264648438, -0.04502677917480469, 1.12310791015625, -2.488262176513672, -3.314223289489746, 0.2058544158935547, -2.0427932739257812, -0.11470794677734375, -0.6804695129394531, -1.8180060386657715, 0.7628059387207031, -0.7683639526367188, -0.6653671264648438, -0.5823974609375, -5.649838447570801, -1.4472541809082031, 0.6991348266601562, -1.489234209060669, -0.18837356567382812, -0.6578292846679688, 0.5535926818847656, 1.5487442016601562, 2.030031204223633, -0.05485725402832031, -0.7523651123046875, -0.5009994506835938, -2.0386276245117188, 0.6930389404296875], "custom_metrics": {}}}, "num_steps_sampled": 88704, "num_agent_steps_sampled": 266112, "num_steps_trained": 175424, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 526272, "last_target_update_ts": 88560, "num_target_updates": 172}, "done": false, "episodes_total": 8907, "training_iteration": 88, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-21-25", "timestamp": 1648916485, "time_this_iter_s": 40.11263298988342, "time_total_s": 3506.0580265522003, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3506.0580265522003, "timesteps_since_restore": 2816, "iterations_since_restore": 88, "perf": {"cpu_util_percent": 51.46140350877193, "ram_util_percent": 65.33508771929824}}
{"episode_reward_max": 186.0, "episode_reward_min": 60.0, "episode_reward_mean": 164.11428571428573, "episode_len_mean": 9.58095238095238, "episode_media": {}, "episodes_this_iter": 105, "policy_reward_min": {"policy0": 20.0, "policy1": 20.0, "policy2": 20.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 54.7047619047619, "policy1": 54.7047619047619, "policy2": 54.7047619047619}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 183.0, 150.0, 183.0, 120.0, 180.0, 150.0, 186.0, 186.0, 180.0, 150.0, 180.0, 186.0, 150.0, 150.0, 180.0, 120.0, 180.0, 183.0, 120.0, 180.0, 183.0, 180.0, 186.0, 150.0, 150.0, 150.0, 180.0, 186.0, 183.0, 150.0, 120.0, 150.0, 180.0, 180.0, 150.0, 183.0, 180.0, 180.0, 120.0, 150.0, 180.0, 180.0, 186.0, 150.0, 120.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 150.0, 186.0, 180.0, 180.0, 180.0, 120.0, 150.0, 150.0, 120.0, 180.0, 186.0, 120.0, 180.0, 180.0, 180.0, 150.0, 120.0, 186.0, 150.0, 186.0, 150.0, 150.0, 150.0, 183.0, 180.0, 150.0, 120.0, 183.0, 186.0, 180.0, 180.0, 60.0, 180.0, 186.0, 180.0, 180.0, 183.0, 150.0, 186.0, 183.0, 180.0, 180.0, 186.0, 150.0, 186.0, 180.0, 180.0, 186.0, 180.0, 180.0, 90.0, 90.0], "episode_lengths": [8, 10, 9, 10, 9, 10, 10, 10, 8, 8, 10, 10, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 9, 10, 8, 10, 10, 10, 10, 8, 9, 10, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 8, 10, 10, 10, 9, 10, 10, 10, 9, 8, 10, 10, 10, 10, 8, 10, 10, 9, 10, 8, 9, 10, 10, 8, 10, 8, 10, 10, 8, 10, 10, 10, 10], "policy_policy0_reward": [62.0, 60.0, 61.0, 50.0, 61.0, 40.0, 60.0, 50.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 50.0, 50.0, 60.0, 40.0, 60.0, 61.0, 40.0, 60.0, 61.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 62.0, 61.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 40.0, 60.0, 60.0, 60.0, 50.0, 40.0, 62.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 60.0, 50.0, 40.0, 61.0, 62.0, 60.0, 60.0, 20.0, 60.0, 62.0, 60.0, 60.0, 61.0, 50.0, 62.0, 61.0, 60.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 30.0, 30.0], "policy_policy1_reward": [62.0, 60.0, 61.0, 50.0, 61.0, 40.0, 60.0, 50.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 50.0, 50.0, 60.0, 40.0, 60.0, 61.0, 40.0, 60.0, 61.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 62.0, 61.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 40.0, 60.0, 60.0, 60.0, 50.0, 40.0, 62.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 60.0, 50.0, 40.0, 61.0, 62.0, 60.0, 60.0, 20.0, 60.0, 62.0, 60.0, 60.0, 61.0, 50.0, 62.0, 61.0, 60.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 30.0, 30.0], "policy_policy2_reward": [62.0, 60.0, 61.0, 50.0, 61.0, 40.0, 60.0, 50.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 50.0, 50.0, 60.0, 40.0, 60.0, 61.0, 40.0, 60.0, 61.0, 60.0, 62.0, 50.0, 50.0, 50.0, 60.0, 62.0, 61.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 61.0, 60.0, 60.0, 40.0, 50.0, 60.0, 60.0, 62.0, 50.0, 40.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 40.0, 60.0, 60.0, 60.0, 50.0, 40.0, 62.0, 50.0, 62.0, 50.0, 50.0, 50.0, 61.0, 60.0, 50.0, 40.0, 61.0, 62.0, 60.0, 60.0, 20.0, 60.0, 62.0, 60.0, 60.0, 61.0, 50.0, 62.0, 61.0, 60.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 30.0, 30.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.04661658905959, "mean_inference_ms": 25.859540382432343, "mean_action_processing_ms": 0.2457211435410237, "mean_env_wait_ms": 0.13954962721193087, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 89712, "timesteps_this_iter": 32, "agent_timesteps_total": 269136, "timers": {"load_time_ms": 0.668, "load_throughput": 47919.5, "learn_time_ms": 234.704, "learn_throughput": 136.342, "update_time_ms": 99.843}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.120471954345703, "min_q": 1.6643785238265991, "max_q": 55.97798156738281, "mean_td_error": 0.5686779022216797, "model": {}}, "td_error": [-1.2625312805175781, -6.208496570587158, -0.20317840576171875, 2.257274627685547, -0.3416271209716797, 0.21610069274902344, 24.843448638916016, -0.05242919921875, -2.8850650787353516, 2.00201416015625, 4.668512344360352, 0.3896293640136719, -1.2223434448242188, -2.74554443359375, 0.19097137451171875, -1.1204948425292969, -2.0477776527404785, -1.5611648559570312, -1.0803871154785156, -1.1119461059570312, 3.2022571563720703, -2.078256607055664, 1.7827138900756836, -1.0077247619628906, 1.4869728088378906, 1.6163616180419922, 2.7330589294433594, -0.9364204406738281, -0.5814971923828125, -0.20317840576171875, 0.9694042205810547, -1.510965347290039], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.389850616455078, "min_q": 0.3696196675300598, "max_q": 58.893226623535156, "mean_td_error": 0.8907877802848816, "model": {}}, "td_error": [-0.9635953903198242, -0.5325508117675781, 0.3187713623046875, 7.790317535400391, -0.11762237548828125, -1.15875244140625, -2.5687522888183594, 0.34798431396484375, 4.353205680847168, -1.2584648132324219, 1.2691497802734375, 3.251495361328125, 0.2975730895996094, -2.5005435943603516, 7.242284774780273, 1.369619607925415, 0.7028961181640625, 5.200481414794922, 0.8409957885742188, -2.8154163360595703, -0.028560638427734375, -0.9183769226074219, -1.0086898803710938, 1.6684761047363281, 1.50115966796875, 1.7329177856445312, -1.9539527893066406, 3.751466751098633, 2.918161392211914, 1.5932226181030273, -0.9488391876220703, -0.8708534240722656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.89777374267578, "min_q": -1.7162370681762695, "max_q": 56.479557037353516, "mean_td_error": 0.460409015417099, "model": {}}, "td_error": [5.351932525634766, 1.5276718139648438, -1.5557928085327148, -1.4329700469970703, -0.8014926910400391, 0.5165901184082031, -0.45336151123046875, -0.5993537902832031, 0.6389923095703125, -3.124480962753296, -1.414581298828125, -0.23436546325683594, -0.48062896728515625, -0.9253520965576172, 3.3280696868896484, -1.3060545921325684, 0.7049655914306641, -3.240846633911133, -0.3883781433105469, -1.1490345001220703, -0.22312164306640625, 0.9335212707519531, 0.014997482299804688, 15.82322883605957, 0.02099609375, 0.7524185180664062, 3.071369171142578, -0.6113166809082031, -0.3883781433105469, -1.3543243408203125, -0.4847412109375, 2.2169113159179688], "custom_metrics": {}}}, "num_steps_sampled": 89712, "num_agent_steps_sampled": 269136, "num_steps_trained": 177440, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 532320, "last_target_update_ts": 89584, "num_target_updates": 174}, "done": false, "episodes_total": 9012, "training_iteration": 89, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-22-05", "timestamp": 1648916525, "time_this_iter_s": 40.156163692474365, "time_total_s": 3546.2141902446747, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d7c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d7c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3546.2141902446747, "timesteps_since_restore": 2848, "iterations_since_restore": 89, "perf": {"cpu_util_percent": 51.74035087719299, "ram_util_percent": 65.30877192982457}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 169.5566037735849, "episode_len_mean": 9.518867924528301, "episode_media": {}, "episodes_this_iter": 106, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 56.5188679245283, "policy1": 56.5188679245283, "policy2": 56.5188679245283}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 90.0, 180.0, 183.0, 180.0, 150.0, 183.0, 186.0, 186.0, 183.0, 150.0, 180.0, 186.0, 186.0, 183.0, 183.0, 180.0, 120.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 150.0, 183.0, 186.0, 150.0, 150.0, 186.0, 150.0, 150.0, 150.0, 180.0, 180.0, 183.0, 180.0, 150.0, 180.0, 150.0, 180.0, 150.0, 180.0, 180.0, 180.0, 180.0, 180.0, 183.0, 120.0, 183.0, 180.0, 186.0, 150.0, 183.0, 150.0, 186.0, 150.0, 150.0, 180.0, 186.0, 180.0, 183.0, 183.0, 183.0, 180.0, 150.0, 180.0, 150.0, 180.0, 90.0, 180.0, 180.0, 180.0, 180.0, 150.0, 180.0, 180.0, 150.0, 150.0, 150.0, 186.0, 180.0, 150.0, 180.0, 180.0, 150.0, 90.0, 186.0, 180.0, 180.0, 150.0, 183.0, 150.0, 180.0, 180.0, 183.0, 180.0, 150.0, 150.0, 186.0, 183.0, 186.0, 183.0, 180.0, 150.0, 186.0], "episode_lengths": [10, 10, 10, 9, 10, 10, 9, 8, 8, 9, 10, 10, 8, 8, 9, 9, 10, 10, 8, 8, 10, 10, 8, 10, 10, 9, 8, 10, 10, 8, 10, 10, 10, 10, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 9, 10, 9, 10, 8, 10, 9, 10, 8, 10, 10, 10, 8, 10, 9, 9, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 9, 10, 10, 10, 9, 10, 10, 10, 8, 9, 8, 9, 10, 10, 8], "policy_policy0_reward": [50.0, 30.0, 60.0, 61.0, 60.0, 50.0, 61.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 40.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 62.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 40.0, 61.0, 60.0, 62.0, 50.0, 61.0, 50.0, 62.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 61.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 30.0, 60.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 62.0, 60.0, 60.0, 50.0, 61.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0], "policy_policy1_reward": [50.0, 30.0, 60.0, 61.0, 60.0, 50.0, 61.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 40.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 62.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 40.0, 61.0, 60.0, 62.0, 50.0, 61.0, 50.0, 62.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 61.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 30.0, 60.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 62.0, 60.0, 60.0, 50.0, 61.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0], "policy_policy2_reward": [50.0, 30.0, 60.0, 61.0, 60.0, 50.0, 61.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 40.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 62.0, 50.0, 50.0, 62.0, 50.0, 50.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 40.0, 61.0, 60.0, 62.0, 50.0, 61.0, 50.0, 62.0, 50.0, 50.0, 60.0, 62.0, 60.0, 61.0, 61.0, 61.0, 60.0, 50.0, 60.0, 50.0, 60.0, 30.0, 60.0, 60.0, 60.0, 60.0, 50.0, 60.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 50.0, 60.0, 60.0, 50.0, 30.0, 62.0, 60.0, 60.0, 50.0, 61.0, 50.0, 60.0, 60.0, 61.0, 60.0, 50.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0441998425187378, "mean_inference_ms": 25.756311155932856, "mean_action_processing_ms": 0.24488143893734304, "mean_env_wait_ms": 0.13918405194825986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 90720, "timesteps_this_iter": 32, "agent_timesteps_total": 272160, "timers": {"load_time_ms": 0.625, "load_throughput": 51181.257, "learn_time_ms": 229.757, "learn_throughput": 139.278, "update_time_ms": 96.215}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.96322250366211, "min_q": 5.050450325012207, "max_q": 59.067298889160156, "mean_td_error": 2.3678781986236572, "model": {}}, "td_error": [23.232114791870117, 2.795574188232422, -0.1418628692626953, -0.9119548797607422, -0.813385009765625, 1.2345657348632812, 0.8628616333007812, 4.196269989013672, 2.8687400817871094, 1.0157241821289062, 0.4342384338378906, 2.9516468048095703, 0.4342384338378906, 0.7385711669921875, 1.0964317321777344, 1.5199699401855469, 0.31311988830566406, 2.7439231872558594, 1.7319717407226562, -0.2960052490234375, 0.4621620178222656, -0.628509521484375, 0.8195858001708984, -0.9255142211914062, -2.735598564147949, 22.286968231201172, 3.5205421447753906, 4.5723419189453125, 0.4621620178222656, 0.4621620178222656, 1.8194694519042969, -0.3504199981689453], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.718017578125, "min_q": 8.680290222167969, "max_q": 56.786415100097656, "mean_td_error": 1.110908031463623, "model": {}}, "td_error": [-1.4959964752197266, -1.2332534790039062, -2.2014503479003906, 0.31421852111816406, 4.855646133422852, -0.6023101806640625, 0.039493560791015625, -0.12420272827148438, 15.033172607421875, -0.6396980285644531, 2.013113021850586, -0.5062904357910156, 14.891382217407227, -0.5295944213867188, 0.41534423828125, -2.473285675048828, -0.31970977783203125, -0.6884250640869141, 3.2142486572265625, 4.531917572021484, -1.4148292541503906, -0.7975578308105469, 2.332551956176758, -2.3910560607910156, 5.88142204284668, -0.18697738647460938, 1.7069244384765625, -0.2176971435546875, -1.0877208709716797, -1.6433734893798828, 0.4823780059814453, -1.6093254089355469], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 22.846118927001953, "min_q": 1.9449832439422607, "max_q": 57.04070281982422, "mean_td_error": 1.118131160736084, "model": {}}, "td_error": [-0.3720111846923828, -0.7606887817382812, -0.01480865478515625, -0.011661529541015625, -0.13750457763671875, -0.6387271881103516, -2.0801143646240234, 4.455402374267578, 0.3060722351074219, 0.4401741027832031, -0.8619575500488281, 3.593503475189209, -1.9270315170288086, -1.6300888061523438, 10.890666007995605, -0.9201841354370117, -0.1402435302734375, 0.7878036499023438, -1.447159767150879, 1.6417417526245117, 3.288407802581787, -3.2166309356689453, -5.4663496017456055, 1.6374664306640625, 2.795825958251953, 0.2523918151855469, -0.3544769287109375, 2.9449832439422607, -0.6387271881103516, 12.780647277832031, 4.763031005859375, 5.820446014404297], "custom_metrics": {}}}, "num_steps_sampled": 90720, "num_agent_steps_sampled": 272160, "num_steps_trained": 179456, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 538368, "last_target_update_ts": 90608, "num_target_updates": 176}, "done": false, "episodes_total": 9118, "training_iteration": 90, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-22-46", "timestamp": 1648916566, "time_this_iter_s": 40.44717717170715, "time_total_s": 3586.661367416382, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d7dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d7dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3586.661367416382, "timesteps_since_restore": 2880, "iterations_since_restore": 90, "perf": {"cpu_util_percent": 52.68421052631579, "ram_util_percent": 65.6719298245614}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 168.91666666666666, "episode_len_mean": 9.342592592592593, "episode_media": {}, "episodes_this_iter": 108, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 56.30555555555556, "policy1": 56.30555555555556, "policy2": 56.30555555555556}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 180.0, 186.0, 186.0, 180.0, 150.0, 186.0, 180.0, 186.0, 186.0, 180.0, 150.0, 186.0, 183.0, 180.0, 183.0, 186.0, 150.0, 150.0, 150.0, 120.0, 180.0, 180.0, 186.0, 180.0, 183.0, 150.0, 150.0, 180.0, 186.0, 180.0, 90.0, 150.0, 150.0, 183.0, 180.0, 186.0, 120.0, 183.0, 186.0, 180.0, 150.0, 150.0, 183.0, 183.0, 186.0, 180.0, 183.0, 183.0, 150.0, 183.0, 150.0, 120.0, 186.0, 186.0, 183.0, 150.0, 150.0, 186.0, 186.0, 186.0, 150.0, 186.0, 150.0, 183.0, 186.0, 180.0, 186.0, 183.0, 183.0, 180.0, 183.0, 180.0, 186.0, 150.0, 180.0, 180.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 150.0, 183.0, 150.0, 180.0, 180.0, 120.0, 150.0, 150.0, 180.0, 150.0, 180.0, 150.0, 90.0, 150.0, 186.0, 150.0, 90.0, 180.0, 150.0, 150.0, 150.0, 186.0, 150.0, 180.0], "episode_lengths": [10, 10, 8, 8, 10, 10, 8, 10, 8, 8, 10, 10, 8, 9, 10, 9, 8, 10, 10, 10, 10, 10, 10, 8, 10, 9, 10, 10, 10, 8, 10, 10, 10, 10, 9, 10, 8, 10, 9, 8, 10, 10, 10, 9, 9, 8, 10, 9, 9, 10, 9, 10, 10, 8, 8, 9, 10, 10, 8, 8, 8, 10, 8, 10, 9, 8, 10, 8, 9, 9, 10, 9, 10, 8, 10, 10, 10, 8, 10, 9, 8, 10, 8, 8, 10, 9, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10], "policy_policy0_reward": [60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 60.0, 61.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 60.0, 62.0, 60.0, 30.0, 50.0, 50.0, 61.0, 60.0, 62.0, 40.0, 61.0, 62.0, 60.0, 50.0, 50.0, 61.0, 61.0, 62.0, 60.0, 61.0, 61.0, 50.0, 61.0, 50.0, 40.0, 62.0, 62.0, 61.0, 50.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 61.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 61.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 61.0, 50.0, 60.0, 60.0, 40.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 30.0, 50.0, 62.0, 50.0, 30.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0], "policy_policy1_reward": [60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 60.0, 61.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 60.0, 62.0, 60.0, 30.0, 50.0, 50.0, 61.0, 60.0, 62.0, 40.0, 61.0, 62.0, 60.0, 50.0, 50.0, 61.0, 61.0, 62.0, 60.0, 61.0, 61.0, 50.0, 61.0, 50.0, 40.0, 62.0, 62.0, 61.0, 50.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 61.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 61.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 61.0, 50.0, 60.0, 60.0, 40.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 30.0, 50.0, 62.0, 50.0, 30.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0], "policy_policy2_reward": [60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 60.0, 61.0, 62.0, 50.0, 50.0, 50.0, 40.0, 60.0, 60.0, 62.0, 60.0, 61.0, 50.0, 50.0, 60.0, 62.0, 60.0, 30.0, 50.0, 50.0, 61.0, 60.0, 62.0, 40.0, 61.0, 62.0, 60.0, 50.0, 50.0, 61.0, 61.0, 62.0, 60.0, 61.0, 61.0, 50.0, 61.0, 50.0, 40.0, 62.0, 62.0, 61.0, 50.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 61.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 61.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 61.0, 50.0, 60.0, 60.0, 40.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 30.0, 50.0, 62.0, 50.0, 30.0, 60.0, 50.0, 50.0, 50.0, 62.0, 50.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0441116099762358, "mean_inference_ms": 25.746955414641107, "mean_action_processing_ms": 0.24473916184532912, "mean_env_wait_ms": 0.13911569214434596, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 91728, "timesteps_this_iter": 32, "agent_timesteps_total": 275184, "timers": {"load_time_ms": 0.614, "load_throughput": 52155.797, "learn_time_ms": 245.46, "learn_throughput": 130.367, "update_time_ms": 103.206}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.62788009643555, "min_q": -2.194689989089966, "max_q": 57.49156951904297, "mean_td_error": 0.4049898087978363, "model": {}}, "td_error": [-0.44679832458496094, 5.542612075805664, -0.25029754638671875, 1.7519493103027344, -1.1704368591308594, -0.6870346069335938, -0.9520187377929688, -1.7429637908935547, 5.858835220336914, -2.461801052093506, -0.4644927978515625, -0.17535018920898438, -1.1946899890899658, 3.2468833923339844, 0.21950149536132812, -0.5737648010253906, -0.7759437561035156, 2.099079132080078, 2.3914718627929688, -0.5317916870117188, -1.9191703796386719, 0.23472213745117188, 1.9026448726654053, -1.7429637908935547, 0.06461334228515625, 1.5399551391601562, 0.6816482543945312, -0.2613487243652344, -0.9581661224365234, -0.39591407775878906, -0.123809814453125, 4.254514694213867], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.75447082519531, "min_q": 6.487536430358887, "max_q": 60.11033630371094, "mean_td_error": 0.436032772064209, "model": {}}, "td_error": [-1.1561412811279297, 0.4301872253417969, -0.3207378387451172, -0.2574443817138672, 1.2801380157470703, -0.4898834228515625, -0.3149433135986328, 21.03848648071289, -2.4904308319091797, -3.023221969604492, -0.153656005859375, -0.0902252197265625, -2.429475784301758, -1.1222000122070312, 5.159038543701172, 2.645956039428711, 1.0761299133300781, 1.0761299133300781, 0.19926834106445312, -1.6363887786865234, 1.3970603942871094, -2.5124635696411133, -0.0902252197265625, -2.036039352416992, 1.3202743530273438, 0.19602584838867188, -2.1550140380859375, 0.3057403564453125, -0.8141899108886719, -1.061378002166748, 0.1380786895751953, -0.15540695190429688], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.006103515625, "min_q": 8.875724792480469, "max_q": 57.373714447021484, "mean_td_error": 2.435964584350586, "model": {}}, "td_error": [7.320301055908203, 7.2325897216796875, -0.7469730377197266, -0.7068195343017578, -1.0455894470214844, -0.8234710693359375, 0.270843505859375, 2.195821762084961, 16.875755310058594, -0.8327217102050781, -1.0843582153320312, 29.32243537902832, 3.401865005493164, 0.24248123168945312, 4.241996765136719, -0.2053813934326172, -0.12427520751953125, -1.1240787506103516, -0.2053813934326172, -0.2053813934326172, -0.7826805114746094, -0.3524208068847656, 0.20759201049804688, -0.5739450454711914, -3.1894073486328125, -1.0797901153564453, 0.7153568267822266, 17.697959899902344, 1.9131317138671875, 0.1754150390625, 0.22077178955078125, -1.0007781982421875], "custom_metrics": {}}}, "num_steps_sampled": 91728, "num_agent_steps_sampled": 275184, "num_steps_trained": 181472, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 544416, "last_target_update_ts": 91632, "num_target_updates": 178}, "done": false, "episodes_total": 9226, "training_iteration": 91, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-23-27", "timestamp": 1648916607, "time_this_iter_s": 41.0162832736969, "time_total_s": 3627.6776506900787, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d07a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6d07a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3627.6776506900787, "timesteps_since_restore": 2912, "iterations_since_restore": 91, "perf": {"cpu_util_percent": 51.459322033898296, "ram_util_percent": 65.61864406779661}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 170.88785046728972, "episode_len_mean": 9.392523364485982, "episode_media": {}, "episodes_this_iter": 107, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 56.96261682242991, "policy1": 56.96261682242991, "policy2": 56.96261682242991}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 183.0, 180.0, 90.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 183.0, 183.0, 150.0, 150.0, 180.0, 180.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 120.0, 180.0, 150.0, 186.0, 183.0, 186.0, 183.0, 180.0, 150.0, 186.0, 150.0, 183.0, 186.0, 150.0, 180.0, 186.0, 180.0, 186.0, 90.0, 186.0, 180.0, 180.0, 183.0, 180.0, 180.0, 180.0, 186.0, 186.0, 180.0, 150.0, 186.0, 180.0, 150.0, 186.0, 180.0, 150.0, 150.0, 180.0, 180.0, 180.0, 150.0, 150.0, 150.0, 180.0, 150.0, 180.0, 150.0, 180.0, 186.0, 186.0, 180.0, 120.0, 150.0, 150.0, 120.0, 180.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 150.0, 183.0, 180.0, 180.0, 180.0, 186.0, 180.0, 150.0, 180.0, 186.0, 183.0, 150.0, 180.0, 120.0, 180.0, 180.0, 183.0, 120.0, 180.0, 120.0], "episode_lengths": [10, 9, 10, 10, 10, 8, 8, 9, 8, 8, 8, 10, 9, 9, 10, 10, 10, 10, 10, 8, 10, 10, 8, 8, 10, 10, 10, 10, 8, 9, 8, 9, 10, 10, 8, 10, 9, 8, 10, 10, 8, 10, 8, 10, 8, 10, 10, 9, 10, 10, 10, 8, 8, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 8, 8, 10, 10, 10, 10, 10, 10, 8, 8, 9, 9, 10, 8, 10, 9, 10, 10, 10, 8, 10, 10, 10, 8, 9, 10, 10, 10, 10, 10, 9, 10, 10, 10], "policy_policy0_reward": [50.0, 61.0, 60.0, 30.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 50.0, 50.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 40.0, 60.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 62.0, 60.0, 62.0, 30.0, 62.0, 60.0, 60.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 62.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 40.0], "policy_policy1_reward": [50.0, 61.0, 60.0, 30.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 50.0, 50.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 40.0, 60.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 62.0, 60.0, 62.0, 30.0, 62.0, 60.0, 60.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 62.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 40.0], "policy_policy2_reward": [50.0, 61.0, 60.0, 30.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 50.0, 50.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 40.0, 60.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 50.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 62.0, 60.0, 62.0, 30.0, 62.0, 60.0, 60.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 62.0, 60.0, 50.0, 50.0, 60.0, 60.0, 60.0, 50.0, 50.0, 50.0, 60.0, 50.0, 60.0, 50.0, 60.0, 62.0, 62.0, 60.0, 40.0, 50.0, 50.0, 40.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 50.0, 61.0, 60.0, 60.0, 60.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 50.0, 60.0, 40.0, 60.0, 60.0, 61.0, 40.0, 60.0, 40.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0477892249344671, "mean_inference_ms": 25.866283744802985, "mean_action_processing_ms": 0.24570576789641932, "mean_env_wait_ms": 0.13966881971936715, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 92736, "timesteps_this_iter": 32, "agent_timesteps_total": 278208, "timers": {"load_time_ms": 0.696, "load_throughput": 45964.975, "learn_time_ms": 241.115, "learn_throughput": 132.717, "update_time_ms": 99.722}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.458457946777344, "min_q": 6.48070764541626, "max_q": 56.72599792480469, "mean_td_error": -0.32093167304992676, "model": {}}, "td_error": [-2.3763999938964844, 0.8912200927734375, 0.3698158264160156, 1.4485149383544922, -0.018459320068359375, 2.123607635498047, -9.1552734375e-05, 0.5693187713623047, 4.666259765625, 0.9708404541015625, -1.8748512268066406, 0.04468536376953125, -0.3281364440917969, -1.0017929077148438, -1.7901296615600586, -0.3384437561035156, -2.529188632965088, 0.04468536376953125, -0.11968612670898438, -1.5726490020751953, 1.9064903259277344, -1.1141319274902344, 0.4510688781738281, -4.086578369140625, -0.8791484832763672, 0.8936424255371094, -4.7651519775390625, -2.2670650482177734, -1.0017929077148438, -0.7452201843261719, 0.0108795166015625, 2.1480751037597656], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.416549682617188, "min_q": 1.12624192237854, "max_q": 62.429893493652344, "mean_td_error": 0.9623777270317078, "model": {}}, "td_error": [-0.7570209503173828, 0.9889297485351562, -0.5101184844970703, -0.0185699462890625, 0.3411588668823242, 0.17514801025390625, 0.07658767700195312, -2.228057861328125, -0.07197952270507812, 0.476806640625, 0.0701904296875, 2.716917037963867, 0.5824203491210938, -0.7273120880126953, 1.4034843444824219, 1.5238380432128906, -0.9804420471191406, 0.14228057861328125, 0.9889297485351562, 3.3443336486816406, 1.4731674194335938, 1.7492866516113281, 2.2785816192626953, 3.5219879150390625, -0.6749172210693359, -0.02796149253845215, 9.184341430664062, -1.6110610961914062, 0.9893112182617188, 1.628448486328125, 5.46699857711792, -0.7196221351623535], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 24.74761962890625, "min_q": -0.39392077922821045, "max_q": 56.13571548461914, "mean_td_error": 1.4728314876556396, "model": {}}, "td_error": [1.6750316619873047, -0.845703125, -0.10983085632324219, -3.6777963638305664, -0.4188270568847656, 0.3212928771972656, -1.1656599044799805, 0.45412540435791016, 1.0343379974365234, 0.38796234130859375, 0.27117919921875, -0.9624118804931641, 6.105504035949707, 10.684806823730469, 0.2918281555175781, -1.4435672760009766, 2.874561309814453, -0.388641357421875, 21.161386489868164, -0.9209537506103516, -0.08617019653320312, 0.12077522277832031, -1.540750503540039, 0.12502706050872803, 0.8467063903808594, 4.310205459594727, 1.5326175689697266, 3.1356372833251953, 5.4829888343811035, -1.1441631317138672, -0.5582847595214844, -0.422607421875], "custom_metrics": {}}}, "num_steps_sampled": 92736, "num_agent_steps_sampled": 278208, "num_steps_trained": 183488, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 550464, "last_target_update_ts": 92656, "num_target_updates": 180}, "done": false, "episodes_total": 9333, "training_iteration": 92, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-24-08", "timestamp": 1648916648, "time_this_iter_s": 40.74427914619446, "time_total_s": 3668.421929836273, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6e4ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6e4ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3668.421929836273, "timesteps_since_restore": 2944, "iterations_since_restore": 92, "perf": {"cpu_util_percent": 51.253448275862056, "ram_util_percent": 66.07758620689654}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 173.8909090909091, "episode_len_mean": 9.218181818181819, "episode_media": {}, "episodes_this_iter": 110, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 57.96363636363636, "policy1": 57.96363636363636, "policy2": 57.96363636363636}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 150.0, 180.0, 186.0, 150.0, 180.0, 180.0, 186.0, 180.0, 150.0, 183.0, 150.0, 186.0, 150.0, 186.0, 180.0, 183.0, 183.0, 180.0, 180.0, 150.0, 183.0, 150.0, 150.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 186.0, 150.0, 150.0, 186.0, 183.0, 150.0, 180.0, 180.0, 186.0, 180.0, 180.0, 180.0, 180.0, 180.0, 180.0, 186.0, 150.0, 183.0, 186.0, 150.0, 180.0, 180.0, 186.0, 186.0, 150.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 150.0, 183.0, 150.0, 186.0, 186.0, 120.0, 183.0, 150.0, 186.0, 120.0, 186.0, 180.0, 186.0, 180.0, 180.0, 180.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 120.0, 150.0, 180.0, 150.0, 150.0, 150.0, 186.0, 180.0, 180.0, 186.0, 183.0, 180.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 120.0, 180.0, 183.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0], "episode_lengths": [10, 10, 10, 8, 10, 10, 10, 8, 10, 10, 9, 10, 8, 10, 8, 10, 9, 9, 10, 10, 10, 9, 10, 10, 8, 10, 8, 8, 10, 9, 8, 10, 10, 8, 9, 10, 10, 10, 8, 10, 10, 10, 10, 10, 10, 8, 10, 9, 8, 10, 10, 10, 8, 8, 10, 8, 10, 10, 8, 8, 8, 10, 9, 10, 8, 8, 10, 9, 10, 8, 10, 8, 10, 8, 10, 10, 10, 8, 9, 8, 10, 8, 8, 10, 10, 10, 10, 10, 10, 8, 10, 10, 8, 9, 10, 8, 10, 9, 8, 10, 8, 10, 10, 9, 10, 8, 8, 8, 9, 8], "policy_policy0_reward": [60.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 60.0, 60.0, 50.0, 61.0, 50.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 50.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 50.0, 61.0, 50.0, 62.0, 62.0, 40.0, 61.0, 50.0, 62.0, 40.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 40.0, 60.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy1_reward": [60.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 60.0, 60.0, 50.0, 61.0, 50.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 50.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 50.0, 61.0, 50.0, 62.0, 62.0, 40.0, 61.0, 50.0, 62.0, 40.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 40.0, 60.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy2_reward": [60.0, 50.0, 60.0, 62.0, 50.0, 60.0, 60.0, 62.0, 60.0, 50.0, 61.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 60.0, 60.0, 50.0, 61.0, 50.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 50.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 50.0, 61.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 50.0, 61.0, 50.0, 62.0, 62.0, 40.0, 61.0, 50.0, 62.0, 40.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 40.0, 50.0, 60.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 40.0, 60.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.046847187550311, "mean_inference_ms": 25.813300369225196, "mean_action_processing_ms": 0.24527534306977142, "mean_env_wait_ms": 0.1394077607605972, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 93744, "timesteps_this_iter": 32, "agent_timesteps_total": 281232, "timers": {"load_time_ms": 0.612, "load_throughput": 52302.131, "learn_time_ms": 226.448, "learn_throughput": 141.313, "update_time_ms": 97.931}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.08051681518555, "min_q": 9.909460067749023, "max_q": 58.500240325927734, "mean_td_error": -0.21184107661247253, "model": {}}, "td_error": [-0.301605224609375, 4.871395111083984, 0.9094600677490234, -0.43152618408203125, 0.712066650390625, -2.297125816345215, -3.199920654296875, 3.1851844787597656, -0.9253120422363281, 1.030324935913086, -0.7931480407714844, -0.30081939697265625, -0.3401451110839844, -1.3348369598388672, -0.2037334442138672, 0.37847900390625, 0.9554538726806641, 0.7087821960449219, -0.7827110290527344, -1.9670963287353516, 2.1498146057128906, 0.41921043395996094, -1.5770950317382812, -2.6702651977539062, -1.144765853881836, 0.41921043395996094, -0.43152618408203125, -1.0855751037597656, -1.9604415893554688, 1.4175453186035156, 0.42340087890625, -2.611593246459961], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.14781379699707, "min_q": 11.017276763916016, "max_q": 58.26046371459961, "mean_td_error": 0.9686664342880249, "model": {}}, "td_error": [0.75531005859375, 1.8884506225585938, 0.21894454956054688, -3.3867664337158203, 0.25980377197265625, -2.2059497833251953, -1.0129547119140625, -1.682302474975586, 1.5840606689453125, 3.610051155090332, 1.3099651336669922, 17.931659698486328, -0.42148399353027344, 0.3606300354003906, 0.7403526306152344, -0.7275733947753906, 0.043430328369140625, 1.1254348754882812, 1.3345355987548828, -0.42879295349121094, 9.71866226196289, 0.21894454956054688, -1.1015357971191406, -3.7090539932250977, 1.2711830139160156, -1.0767993927001953, 0.762786865234375, -0.1419219970703125, 2.986520767211914, -0.2813377380371094, -0.6530075073242188, 1.7060794830322266], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.176305770874023, "min_q": -4.1262993812561035, "max_q": 58.191978454589844, "mean_td_error": 0.5958163142204285, "model": {}}, "td_error": [0.2533836364746094, 0.4148674011230469, 1.735808253288269, -0.003513336181640625, -0.35875701904296875, 0.07523536682128906, 2.2484798431396484, -0.19063758850097656, -0.9657478332519531, 11.335615158081055, 3.077113151550293, 2.2469444274902344, 1.5467357635498047, -0.03751945495605469, -1.1948375701904297, 0.965545654296875, 0.3247871398925781, 3.746000289916992, -2.2096939086914062, -0.3604927062988281, -0.3302955627441406, 0.3468608856201172, -0.5546188354492188, -0.949406623840332, -3.1262993812561035, -0.6726264953613281, -0.03751945495605469, -0.7562580108642578, 0.6412525177001953, 0.13637161254882812, 2.2771873474121094, -0.5578422546386719], "custom_metrics": {}}}, "num_steps_sampled": 93744, "num_agent_steps_sampled": 281232, "num_steps_trained": 185504, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 556512, "last_target_update_ts": 93680, "num_target_updates": 182}, "done": false, "episodes_total": 9443, "training_iteration": 93, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-24-48", "timestamp": 1648916688, "time_this_iter_s": 40.37739706039429, "time_total_s": 3708.7993268966675, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75ec20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3708.7993268966675, "timesteps_since_restore": 2976, "iterations_since_restore": 93, "perf": {"cpu_util_percent": 52.37017543859649, "ram_util_percent": 65.96842105263157}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 175.86486486486487, "episode_len_mean": 9.036036036036036, "episode_media": {}, "episodes_this_iter": 111, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 58.62162162162162, "policy1": 58.62162162162162, "policy2": 58.62162162162162}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 183.0, 186.0, 186.0, 186.0, 150.0, 150.0, 150.0, 186.0, 180.0, 180.0, 186.0, 180.0, 120.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 120.0, 150.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 150.0, 186.0, 150.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 180.0, 183.0, 183.0, 90.0, 180.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 150.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 180.0, 120.0, 186.0, 180.0, 180.0, 186.0, 150.0, 150.0, 150.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 180.0, 180.0, 186.0, 180.0, 186.0, 120.0, 150.0, 180.0], "episode_lengths": [10, 9, 10, 8, 8, 10, 8, 10, 9, 9, 8, 8, 8, 10, 10, 10, 8, 10, 10, 8, 10, 10, 8, 10, 8, 8, 8, 8, 9, 10, 8, 10, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 10, 10, 10, 10, 8, 10, 8, 8, 8, 8, 10, 8, 10, 10, 8, 10, 10, 8, 8, 10, 8, 10, 9, 10, 9, 9, 10, 10, 9, 8, 8, 10, 8, 10, 10, 8, 10, 10, 8, 8, 8, 10, 10, 8, 10, 10, 8, 10, 10, 10, 10, 8, 8, 8, 8, 8, 10, 8, 8, 10, 9, 10, 10, 8, 10, 8, 10, 10, 10], "policy_policy0_reward": [60.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 40.0, 50.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 61.0, 30.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 60.0, 60.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 40.0, 50.0, 60.0], "policy_policy1_reward": [60.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 40.0, 50.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 61.0, 30.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 60.0, 60.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 40.0, 50.0, 60.0], "policy_policy2_reward": [60.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 50.0, 50.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 40.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 40.0, 50.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 61.0, 30.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 50.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 60.0, 60.0, 62.0, 50.0, 50.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 40.0, 50.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0484085378799728, "mean_inference_ms": 25.854808715204474, "mean_action_processing_ms": 0.24557626203897318, "mean_env_wait_ms": 0.13967634002169677, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 94752, "timesteps_this_iter": 32, "agent_timesteps_total": 284256, "timers": {"load_time_ms": 0.618, "load_throughput": 51755.573, "learn_time_ms": 228.413, "learn_throughput": 140.097, "update_time_ms": 105.527}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.54639434814453, "min_q": -3.083582878112793, "max_q": 58.23899459838867, "mean_td_error": 0.20114785432815552, "model": {}}, "td_error": [-0.8757591247558594, -0.01155853271484375, -2.0852088928222656, -1.2711524963378906, -1.8032341003417969, -1.7637710571289062, 3.704343795776367, -1.7066593170166016, -1.0950736999511719, 3.546405792236328, 4.073884963989258, 5.620718002319336, -0.3432464599609375, 0.10379409790039062, 0.22788619995117188, -0.5721244812011719, -1.076869010925293, -1.2681999206542969, -0.015794754028320312, -0.8458251953125, 8.214069366455078, -0.9452896118164062, -1.7624397277832031, 1.1328277587890625, -0.9452896118164062, -0.2715339660644531, -1.2681999206542969, 1.775848388671875, 0.214752197265625, -0.18924331665039062, 0.022256851196289062, -2.083582878112793], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.067140579223633, "min_q": 8.980202674865723, "max_q": 58.99359893798828, "mean_td_error": 2.3748676776885986, "model": {}}, "td_error": [14.530860900878906, 16.24027442932129, -0.4837150573730469, -0.08133697509765625, 5.366697311401367, 1.0672588348388672, 0.3221569061279297, 5.929384231567383, -0.04742431640625, 0.6330718994140625, 26.046653747558594, 0.3942375183105469, -0.030309677124023438, 2.137481689453125, 1.8236408233642578, -4.448825836181641, 0.013132095336914062, -0.04742431640625, 2.039743423461914, -0.6039695739746094, 1.1310062408447266, -1.6171512603759766, 1.0680503845214844, 0.5708847045898438, 0.24525070190429688, -0.04742431640625, 0.5318336486816406, 3.6421070098876953, 1.1310062408447266, -0.019797325134277344, -1.6356964111328125, 0.1941089630126953], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.72417449951172, "min_q": 4.5306525230407715, "max_q": 58.36853790283203, "mean_td_error": 0.5996850728988647, "model": {}}, "td_error": [0.9636077880859375, -0.3425865173339844, -1.984489917755127, 1.183298110961914, -0.2950286865234375, 0.49332332611083984, -0.6730384826660156, -2.267033576965332, 0.7481174468994141, -0.022754669189453125, -1.1836872100830078, 0.11292457580566406, -0.5631313323974609, -0.0031175613403320312, 1.3010063171386719, -0.9836521148681641, -0.5890407562255859, -1.6288719177246094, 2.0857391357421875, -0.1378173828125, 0.4219684600830078, -2.194967269897461, -0.5213508605957031, -0.5890407562255859, -0.16379165649414062, -0.11126708984375, -0.21893692016601562, 22.255212783813477, -0.08353424072265625, -0.5307693481445312, 4.464101791381836, 0.24853134155273438], "custom_metrics": {}}}, "num_steps_sampled": 94752, "num_agent_steps_sampled": 284256, "num_steps_trained": 187520, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 562560, "last_target_update_ts": 94704, "num_target_updates": 184}, "done": false, "episodes_total": 9554, "training_iteration": 94, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-25-27", "timestamp": 1648916727, "time_this_iter_s": 38.99397587776184, "time_total_s": 3747.7933027744293, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c782e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c782e60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3747.7933027744293, "timesteps_since_restore": 3008, "iterations_since_restore": 94, "perf": {"cpu_util_percent": 51.594545454545454, "ram_util_percent": 65.51636363636364}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 175.8053097345133, "episode_len_mean": 8.920353982300885, "episode_media": {}, "episodes_this_iter": 113, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 58.60176991150443, "policy1": 58.60176991150443, "policy2": 58.60176991150443}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 150.0, 186.0, 180.0, 150.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 150.0, 180.0, 90.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 180.0, 150.0, 180.0, 90.0, 186.0, 186.0, 186.0, 186.0, 150.0, 180.0, 183.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 180.0, 150.0, 150.0, 186.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 150.0, 150.0, 186.0, 186.0, 150.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 186.0, 150.0, 186.0, 183.0, 150.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 150.0, 150.0], "episode_lengths": [8, 8, 10, 8, 10, 10, 10, 8, 8, 8, 8, 10, 9, 8, 8, 10, 10, 10, 8, 8, 10, 8, 8, 10, 10, 10, 10, 10, 8, 8, 8, 8, 10, 10, 9, 10, 8, 10, 10, 8, 8, 10, 8, 10, 8, 10, 8, 10, 10, 10, 10, 8, 10, 8, 8, 8, 9, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 10, 9, 8, 8, 8, 8, 10, 8, 8, 8, 10, 10, 10, 8, 8, 10, 8, 8, 10, 8, 10, 8, 8, 10, 10, 8, 8, 10, 8, 8, 9, 8, 10, 8, 9, 10, 10, 10, 8, 8, 8, 8, 10, 10, 10, 10], "policy_policy0_reward": [62.0, 62.0, 50.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 50.0, 60.0, 30.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 60.0, 50.0, 60.0, 30.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 50.0, 50.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 50.0], "policy_policy1_reward": [62.0, 62.0, 50.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 50.0, 60.0, 30.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 60.0, 50.0, 60.0, 30.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 50.0, 50.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 50.0], "policy_policy2_reward": [62.0, 62.0, 50.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 50.0, 60.0, 30.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 60.0, 50.0, 60.0, 30.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 50.0, 50.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 50.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0462390631288858, "mean_inference_ms": 25.766185512509086, "mean_action_processing_ms": 0.24480257003093472, "mean_env_wait_ms": 0.13922589294530066, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 95760, "timesteps_this_iter": 32, "agent_timesteps_total": 287280, "timers": {"load_time_ms": 0.635, "load_throughput": 50399.057, "learn_time_ms": 235.944, "learn_throughput": 135.625, "update_time_ms": 107.319}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.94236946105957, "min_q": 1.519025444984436, "max_q": 59.38996124267578, "mean_td_error": 1.460587501525879, "model": {}}, "td_error": [15.687433242797852, 1.9498424530029297, 0.2860935926437378, 3.7810821533203125, -3.5484437942504883, 1.1099395751953125, 0.4782524108886719, 4.835029602050781, 11.218448638916016, -0.405792236328125, 0.6022167205810547, -0.4652128219604492, -1.699228286743164, -0.6340522766113281, -0.3394126892089844, -2.330324172973633, -0.5291957855224609, 10.589954376220703, -0.15472984313964844, -1.5217151641845703, -0.4378166198730469, -0.22626113891601562, 3.8795337677001953, 0.4574575424194336, -0.5478782653808594, 4.773614883422852, -0.055233001708984375, -0.8536472320556641, 0.4916419982910156, -0.2990264892578125, 0.7063217163085938, -0.060092926025390625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.776477813720703, "min_q": 5.318652629852295, "max_q": 60.763214111328125, "mean_td_error": 2.1685895919799805, "model": {}}, "td_error": [-0.06517887115478516, 1.6391220092773438, 4.443458557128906, -0.08365631103515625, 1.354909896850586, 0.4700736999511719, 1.7819976806640625, 9.096874237060547, 2.9819908142089844, -0.6267318725585938, 3.631485939025879, 0.8206901550292969, 0.3063812255859375, -2.9728431701660156, 0.19661712646484375, -0.091064453125, 2.599306106567383, -3.681347370147705, -1.588369369506836, 0.6661815643310547, -0.25023651123046875, -0.233856201171875, 0.21385955810546875, 0.8939857482910156, -0.6096725463867188, 25.048660278320312, -0.6974334716796875, 0.2638568878173828, 4.31614875793457, -1.4616551399230957, 0.6570892333984375, 20.374223709106445], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.376846313476562, "min_q": 5.671046733856201, "max_q": 59.56318664550781, "mean_td_error": -0.15315498411655426, "model": {}}, "td_error": [-0.6606712341308594, -0.4526996612548828, -0.6606712341308594, -0.3183479309082031, 0.9819908142089844, -0.3615131378173828, -1.298004150390625, -0.1614360809326172, 0.7522144317626953, -0.47194385528564453, 0.6831512451171875, -0.3921318054199219, 1.4744415283203125, -0.22977256774902344, -1.248382568359375, -0.0376739501953125, 0.030010223388671875, 0.2731208801269531, -1.096491813659668, -0.6224174499511719, -2.9610977172851562, -1.8613476753234863, 2.4676589965820312, 0.6243858337402344, -0.6606712341308594, -0.6470832824707031, -4.741977691650391, 0.7338409423828125, 2.1755104064941406, 0.8206787109375, 3.627035140991211, -0.6606636047363281], "custom_metrics": {}}}, "num_steps_sampled": 95760, "num_agent_steps_sampled": 287280, "num_steps_trained": 189536, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 568608, "last_target_update_ts": 95728, "num_target_updates": 186}, "done": false, "episodes_total": 9667, "training_iteration": 95, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-26-07", "timestamp": 1648916767, "time_this_iter_s": 39.073235511779785, "time_total_s": 3786.866538286209, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6ac050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6ac050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3786.866538286209, "timesteps_since_restore": 3040, "iterations_since_restore": 95, "perf": {"cpu_util_percent": 51.59642857142857, "ram_util_percent": 65.3875}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 179.28947368421052, "episode_len_mean": 8.921052631578947, "episode_media": {}, "episodes_this_iter": 114, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 59.76315789473684, "policy1": 59.76315789473684, "policy2": 59.76315789473684}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 186.0, 180.0, 90.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 90.0, 186.0, 183.0, 150.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 150.0, 186.0, 183.0, 150.0, 180.0, 150.0, 186.0, 183.0, 186.0, 150.0, 186.0, 120.0, 183.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 180.0, 180.0, 150.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 183.0, 186.0, 183.0, 180.0, 186.0, 180.0, 180.0, 180.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0], "episode_lengths": [10, 8, 8, 10, 10, 8, 10, 8, 10, 8, 10, 8, 10, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 10, 8, 10, 8, 10, 10, 8, 9, 10, 8, 10, 10, 8, 8, 8, 10, 10, 8, 10, 8, 10, 8, 9, 10, 10, 10, 8, 9, 8, 10, 8, 10, 9, 10, 8, 8, 10, 10, 8, 8, 9, 10, 8, 8, 10, 8, 8, 9, 8, 8, 10, 8, 10, 10, 10, 10, 10, 8, 8, 10, 8, 8, 10, 9, 8, 9, 10, 8, 10, 10, 10, 8, 10, 10, 10, 8, 8], "policy_policy0_reward": [60.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 30.0, 62.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 30.0, 62.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 30.0, 62.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 60.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 40.0, 61.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 60.0, 50.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0457089286993095, "mean_inference_ms": 25.727818961625164, "mean_action_processing_ms": 0.24447347887949103, "mean_env_wait_ms": 0.13908765567119943, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 96768, "timesteps_this_iter": 32, "agent_timesteps_total": 290304, "timers": {"load_time_ms": 0.611, "load_throughput": 52385.827, "learn_time_ms": 232.188, "learn_throughput": 137.819, "update_time_ms": 104.748}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.54815101623535, "min_q": 3.761178493499756, "max_q": 58.54396438598633, "mean_td_error": 0.7360461950302124, "model": {}}, "td_error": [15.816295623779297, -1.4073066711425781, 2.5553646087646484, -4.472037315368652, 0.9346046447753906, -0.012424468994140625, 6.642980575561523, -0.6725893020629883, 4.761178493499756, 2.6998291015625, -0.05837440490722656, -1.4073066711425781, 1.5260696411132812, -1.0775318145751953, -0.7195529937744141, -2.668825149536133, -0.6682243347167969, -0.3198966979980469, 4.66082763671875, -0.8403263092041016, 0.829742431640625, -0.6682243347167969, -0.016971588134765625, -1.8687171936035156, -1.9743385314941406, -0.2470569610595703, 0.13552474975585938, 1.0962848663330078, 0.0387115478515625, -1.8134641647338867, 2.299785614013672, 0.46944427490234375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.269039154052734, "min_q": 1.8180632591247559, "max_q": 58.95701217651367, "mean_td_error": 0.29214537143707275, "model": {}}, "td_error": [-1.0158424377441406, 0.5243148803710938, -1.0824623107910156, 0.052883148193359375, -1.0824623107910156, -1.53125, 1.3278846740722656, 1.349578857421875, 0.052883148193359375, -0.8358345031738281, -0.09050750732421875, 0.3893146514892578, -1.1745071411132812, -0.47063446044921875, -1.0158424377441406, 0.5365371704101562, 2.280364990234375, 0.9488296508789062, -0.3639945983886719, -0.59228515625, 2.818063259124756, -0.17891311645507812, 0.052883148193359375, 1.6244239807128906, 0.8722114562988281, 0.453857421875, 0.052883148193359375, -0.2738628387451172, -0.5012645721435547, -0.24576187133789062, 6.48321533203125, -0.01605224609375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.767921447753906, "min_q": 8.859630584716797, "max_q": 59.925270080566406, "mean_td_error": 1.6859016418457031, "model": {}}, "td_error": [0.4860115051269531, 11.203547477722168, -1.196401596069336, -1.0105972290039062, -0.6529254913330078, 0.5937767028808594, 15.834735870361328, -0.22914505004882812, -0.0767822265625, -0.3628692626953125, 1.8017845153808594, 1.875, 0.7199420928955078, 0.044612884521484375, 0.4167594909667969, -0.3851280212402344, 1.2325172424316406, 1.1708297729492188, 0.4351482391357422, -3.529336929321289, 21.419395446777344, 1.1708297729492188, -0.3851280212402344, 0.3813743591308594, -0.6319084167480469, -0.5748519897460938, 2.1346540451049805, -1.0508346557617188, -0.14036941528320312, -0.9740943908691406, 4.368675231933594, -0.14036941528320312], "custom_metrics": {}}}, "num_steps_sampled": 96768, "num_agent_steps_sampled": 290304, "num_steps_trained": 191552, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 574656, "last_target_update_ts": 96752, "num_target_updates": 188}, "done": false, "episodes_total": 9781, "training_iteration": 96, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-26-46", "timestamp": 1648916806, "time_this_iter_s": 39.35368633270264, "time_total_s": 3826.2202246189117, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6acf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6acf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3826.2202246189117, "timesteps_since_restore": 3072, "iterations_since_restore": 96, "perf": {"cpu_util_percent": 52.665454545454544, "ram_util_percent": 65.40727272727273}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 181.72173913043477, "episode_len_mean": 8.643478260869566, "episode_media": {}, "episodes_this_iter": 115, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.573913043478264, "policy1": 60.573913043478264, "policy2": 60.573913043478264}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 90.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 180.0, 180.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0], "episode_lengths": [8, 9, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 10, 8, 10, 8, 10, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 9, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 10, 8, 10, 8, 8, 10, 8, 9, 8, 10, 9, 8, 8, 8, 10, 8, 8, 9, 9, 8, 8, 10, 9, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 9, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 10, 10, 10, 9, 10, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8], "policy_policy0_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 30.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 30.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 30.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0465132123126564, "mean_inference_ms": 25.741510629639095, "mean_action_processing_ms": 0.24460464153289627, "mean_env_wait_ms": 0.1392047465691964, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 97776, "timesteps_this_iter": 32, "agent_timesteps_total": 293328, "timers": {"load_time_ms": 0.706, "load_throughput": 45299.446, "learn_time_ms": 227.026, "learn_throughput": 140.953, "update_time_ms": 112.563}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.45206069946289, "min_q": 1.9825787544250488, "max_q": 58.76558303833008, "mean_td_error": 1.9722727537155151, "model": {}}, "td_error": [-1.7350502014160156, 1.7376823425292969, 25.15662956237793, -0.39078521728515625, 6.792760848999023, -0.17121124267578125, -0.7548446655273438, -0.5078487396240234, 5.155220985412598, 0.011010169982910156, -0.6299362182617188, -0.5889720916748047, -0.3177299499511719, -0.4918088912963867, -0.4677543640136719, 2.982578754425049, 0.002480030059814453, -0.37389373779296875, 3.6829617023468018, -0.39078521728515625, -0.3177299499511719, 0.07738304138183594, 3.7381134033203125, 1.75885009765625, -0.4791984558105469, 4.502159118652344, -1.5696563720703125, -2.428333282470703, -0.3576240539550781, 2.7913589477539062, -0.17438507080078125, 16.87108612060547], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.95217514038086, "min_q": 7.767888069152832, "max_q": 55.91902160644531, "mean_td_error": 0.03623688220977783, "model": {}}, "td_error": [-0.9511909484863281, -0.15902328491210938, -1.1779289245605469, -0.22743606567382812, -0.6568336486816406, 2.0463905334472656, -0.15902328491210938, -1.2956085205078125, -0.8800086975097656, -0.8068885803222656, 1.9192752838134766, 3.0477962493896484, -0.3755035400390625, -0.9922866821289062, 2.3325748443603516, -0.9511909484863281, -1.232111930847168, -0.6568336486816406, -0.29625606536865234, -0.8068885803222656, -0.6051082611083984, -0.24559783935546875, 0.7416400909423828, 5.42503547668457, -0.6348075866699219, -0.44287681579589844, 3.3953399658203125, -0.21254539489746094, -2.9742813110351562, 1.8715438842773438, -2.6432876586914062, -0.2364978790283203], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.719301223754883, "min_q": 4.786691665649414, "max_q": 57.982818603515625, "mean_td_error": -0.09973891079425812, "model": {}}, "td_error": [-0.5155143737792969, -0.22410202026367188, 5.5072784423828125, 3.531879425048828, -0.7983818054199219, -0.08138847351074219, -0.6492233276367188, -0.2685394287109375, -1.7067880630493164, -1.7837886810302734, -0.29671478271484375, 0.07564163208007812, 0.019367218017578125, 1.1254768371582031, -0.3464775085449219, -0.5276641845703125, -1.291295051574707, -0.2982006072998047, -0.8935050964355469, -0.3748207092285156, -1.0240740776062012, -0.3464775085449219, -0.27675437927246094, -0.3748207092285156, 3.1813364028930664, 0.9963111877441406, -0.95635986328125, -0.5276641845703125, -1.1886634826660156, -0.4212303161621094, -0.95635986328125, -1.5001277923583984], "custom_metrics": {}}}, "num_steps_sampled": 97776, "num_agent_steps_sampled": 293328, "num_steps_trained": 193568, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 580704, "last_target_update_ts": 97776, "num_target_updates": 190}, "done": false, "episodes_total": 9896, "training_iteration": 97, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-27-27", "timestamp": 1648916847, "time_this_iter_s": 41.0430269241333, "time_total_s": 3867.263251543045, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f98c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6f98c0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3867.263251543045, "timesteps_since_restore": 3104, "iterations_since_restore": 97, "perf": {"cpu_util_percent": 49.983050847457626, "ram_util_percent": 65.35932203389831}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.57983193277312, "episode_len_mean": 8.554621848739496, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.19327731092437, "policy1": 61.19327731092437, "policy2": 61.19327731092437}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 180.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 180.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0], "episode_lengths": [8, 10, 10, 8, 8, 10, 8, 9, 8, 10, 10, 8, 10, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 8, 10, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 10, 10, 9, 8, 8, 8, 10, 8, 10, 8, 9, 8, 8, 9, 10, 8, 10, 8, 10, 8, 8, 8, 9], "policy_policy0_reward": [62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0], "policy_policy1_reward": [62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0], "policy_policy2_reward": [62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0482801200106038, "mean_inference_ms": 25.79576684086196, "mean_action_processing_ms": 0.24500129082235877, "mean_env_wait_ms": 0.1394504296254125, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 98784, "timesteps_this_iter": 32, "agent_timesteps_total": 296352, "timers": {"load_time_ms": 0.626, "load_throughput": 51087.747, "learn_time_ms": 231.498, "learn_throughput": 138.23, "update_time_ms": 106.78}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.821487426757812, "min_q": 2.062732219696045, "max_q": 60.21287536621094, "mean_td_error": 0.8865959644317627, "model": {}}, "td_error": [-0.8564949035644531, 0.1469879150390625, -1.2964630126953125, 7.669221878051758, -0.5371742248535156, -0.2778587341308594, -0.16061019897460938, -0.3003063201904297, -0.24272537231445312, 0.07427597045898438, -0.16061019897460938, -0.16061019897460938, -0.09216690063476562, -0.10738754272460938, 3.58935546875, 0.22161293029785156, -0.4949760437011719, -1.0536079406738281, -0.737342357635498, 1.0695075988769531, 1.704864501953125, 4.670930862426758, 8.559926986694336, -0.4772682189941406, 0.1469879150390625, 3.062732219696045, -0.17684555053710938, 1.1831417083740234, -0.6844940185546875, -0.5101652145385742, -0.3345832824707031, 4.933216094970703], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.98158264160156, "min_q": 8.018306732177734, "max_q": 60.25019454956055, "mean_td_error": 3.12337589263916, "model": {}}, "td_error": [8.79861831665039, 0.10013198852539062, 0.3839073181152344, 0.23357391357421875, -0.13449478149414062, -0.09600067138671875, 0.4670600891113281, -0.06572341918945312, -0.3116340637207031, 24.158864974975586, 1.5083885192871094, -0.06572341918945312, 1.5708808898925781, -0.5620231628417969, 24.863271713256836, 0.10832977294921875, 0.07241439819335938, 0.33349609375, -0.5269145965576172, 0.38028526306152344, -0.2799034118652344, 2.568359375, -0.1782379150390625, 22.580095291137695, 2.9283008575439453, 0.19475936889648438, 2.442525863647461, 0.07241439819335938, 0.20610427856445312, 9.018306732177734, -0.09599685668945312, -0.7254104614257812], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 25.898162841796875, "min_q": 1.6889797449111938, "max_q": 58.68928909301758, "mean_td_error": 2.222480058670044, "model": {}}, "td_error": [-0.010023117065429688, 6.114903450012207, -0.09937763214111328, -0.6462440490722656, 0.7107210159301758, 1.1657638549804688, 0.8308429718017578, 1.2260513305664062, 0.8175048828125, 0.32538509368896484, -1.1166019439697266, 27.415348052978516, 23.975997924804688, 3.148866653442383, 0.21168899536132812, 0.3097190856933594, 0.6022491455078125, -0.18580245971679688, 0.6478185653686523, 0.6255912780761719, 0.2923698425292969, 0.3697853088378906, 1.5987052917480469, 2.6889796257019043, -0.8750853538513184, 3.71282958984375, 3.9643611907958984, -3.221097946166992, -0.18580245971679688, -0.6223068237304688, -0.8327198028564453, -1.8410539627075195], "custom_metrics": {}}}, "num_steps_sampled": 98784, "num_agent_steps_sampled": 296352, "num_steps_trained": 195584, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 586752, "last_target_update_ts": 98288, "num_target_updates": 191}, "done": false, "episodes_total": 10015, "training_iteration": 98, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-28-07", "timestamp": 1648916887, "time_this_iter_s": 40.19721055030823, "time_total_s": 3907.4604620933533, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7323b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7323b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3907.4604620933533, "timesteps_since_restore": 3136, "iterations_since_restore": 98, "perf": {"cpu_util_percent": 50.871929824561406, "ram_util_percent": 65.28947368421053}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 182.89743589743588, "episode_len_mean": 8.521367521367521, "episode_media": {}, "episodes_this_iter": 117, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.965811965811966, "policy1": 60.965811965811966, "policy2": 60.965811965811966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [120.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 90.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 9, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 10, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 10, 9, 10, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 10, 8, 10, 9, 8, 8, 8, 8, 10, 10, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8], "policy_policy0_reward": [40.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 30.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [40.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 30.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [40.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 30.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0474244107330153, "mean_inference_ms": 25.732114501728358, "mean_action_processing_ms": 0.2445038695270525, "mean_env_wait_ms": 0.13921591816898232, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 99792, "timesteps_this_iter": 32, "agent_timesteps_total": 299376, "timers": {"load_time_ms": 0.608, "load_throughput": 52640.596, "learn_time_ms": 228.943, "learn_throughput": 139.773, "update_time_ms": 95.853}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.2469425201416, "min_q": 7.250079154968262, "max_q": 60.0538330078125, "mean_td_error": 0.0670166015625, "model": {}}, "td_error": [-0.13198471069335938, -0.09714508056640625, -0.5447158813476562, -2.9828224182128906, 0.6957836151123047, -0.4799919128417969, 0.04975318908691406, -0.15563201904296875, 0.2674732208251953, -1.6897821426391602, -0.09714508056640625, -0.41227149963378906, -0.2118701934814453, -0.3999137878417969, 8.489139556884766, 0.908447265625, 0.14274978637695312, -0.187286376953125, 0.3358802795410156, 0.002025604248046875, 1.7922496795654297, -0.24643707275390625, -0.35915565490722656, -1.156386375427246, 0.38372802734375, -0.15563201904296875, -1.120138168334961, -0.20780563354492188, 0.3811779022216797, -0.09986114501953125, -0.15563201904296875, -0.41226768493652344], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.20012664794922, "min_q": 6.409207344055176, "max_q": 60.2020378112793, "mean_td_error": 0.4068222939968109, "model": {}}, "td_error": [-2.1666479110717773, -0.4189281463623047, 0.44637298583984375, -0.4390525817871094, 0.15824651718139648, -0.5797042846679688, 0.9678134918212891, 0.150604248046875, 0.42555999755859375, 2.689638137817383, 18.633447647094727, -0.2117757797241211, -0.3311500549316406, -0.9276561737060547, 0.40148162841796875, -0.05341339111328125, -0.9939308166503906, -2.379436492919922, 1.3879194259643555, 0.23808670043945312, 0.33776092529296875, -0.7323837280273438, -0.5636138916015625, 0.08535003662109375, 0.14755630493164062, 0.3292064666748047, -0.2870950698852539, -0.6589508056640625, -0.23138046264648438, -0.3900299072265625, -1.7191333770751953, -0.29644775390625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.8787727355957, "min_q": 7.747251987457275, "max_q": 62.28317642211914, "mean_td_error": 1.0358480215072632, "model": {}}, "td_error": [-0.38544464111328125, 9.960325241088867, -0.32697296142578125, -0.07098007202148438, -0.07817459106445312, 1.0949783325195312, -0.34222412109375, -0.9777870178222656, 27.44986343383789, -0.4614543914794922, -0.3431129455566406, -0.8538360595703125, -0.20284271240234375, 1.9383773803710938, -0.79095458984375, -0.03967475891113281, 0.06867790222167969, 0.3087043762207031, 0.06974172592163086, -0.05534172058105469, 1.2684240341186523, -0.3043060302734375, -1.142526626586914, 0.2726926803588867, -0.3043060302734375, -0.7275791168212891, -0.13655662536621094, -0.45084190368652344, -0.180877685546875, -0.3080406188964844, -0.20284652709960938, -0.5979652404785156], "custom_metrics": {}}}, "num_steps_sampled": 99792, "num_agent_steps_sampled": 299376, "num_steps_trained": 197600, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 592800, "last_target_update_ts": 99312, "num_target_updates": 193}, "done": false, "episodes_total": 10132, "training_iteration": 99, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-28-46", "timestamp": 1648916926, "time_this_iter_s": 38.779736280441284, "time_total_s": 3946.2401983737946, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c732f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c732f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3946.2401983737946, "timesteps_since_restore": 3168, "iterations_since_restore": 99, "perf": {"cpu_util_percent": 52.93636363636365, "ram_util_percent": 65.08909090909094}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.91735537190084, "episode_len_mean": 8.446280991735538, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.30578512396694, "policy1": 61.30578512396694, "policy2": 61.30578512396694}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 180.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 10, 10, 10, 8, 8, 9, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 10, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 10, 10, 10, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 10, 8, 8, 10, 10, 8, 8, 8], "policy_policy0_reward": [62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0490299755215757, "mean_inference_ms": 25.792215145266844, "mean_action_processing_ms": 0.24489627314668028, "mean_env_wait_ms": 0.13947667294941327, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 100800, "timesteps_this_iter": 32, "agent_timesteps_total": 302400, "timers": {"load_time_ms": 0.661, "load_throughput": 48399.887, "learn_time_ms": 229.772, "learn_throughput": 139.268, "update_time_ms": 103.787}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.484071731567383, "min_q": 5.420530796051025, "max_q": 59.48344039916992, "mean_td_error": 1.0804531574249268, "model": {}}, "td_error": [3.1828384399414062, 5.9106903076171875, -0.8055915832519531, 6.420530796051025, -0.40419578552246094, -0.22541427612304688, -0.021595001220703125, 17.368274688720703, -0.12246322631835938, 3.7684326171875, -0.3700981140136719, 0.07938003540039062, -0.13534927368164062, -0.13534927368164062, -0.5750465393066406, 1.5544071197509766, -0.5288276672363281, -0.10147476196289062, -0.5391883850097656, 1.6132011413574219, -0.6650886535644531, -0.67333984375, 1.832275390625, -0.2341785430908203, -2.0082435607910156, -0.13230133056640625, 0.13552093505859375, -0.40419578552246094, -0.26634788513183594, 0.49460506439208984, 0.5401248931884766, 0.0225067138671875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.53472900390625, "min_q": 9.008417129516602, "max_q": 60.687747955322266, "mean_td_error": -0.005196660757064819, "model": {}}, "td_error": [-0.1523571014404297, 0.008417129516601562, 0.40344810485839844, 0.12875843048095703, -0.7538909912109375, -0.6050643920898438, -0.29949188232421875, -0.09400558471679688, -0.032436370849609375, -0.032436370849609375, -0.29002952575683594, 2.707674026489258, 1.3091239929199219, -0.06925010681152344, -0.032436370849609375, -1.8962249755859375, 0.3817901611328125, -0.4682197570800781, -0.4146900177001953, -0.6016807556152344, 0.03223228454589844, 0.3906517028808594, -0.008525848388671875, 2.262218475341797, -1.9647216796875, 0.03223228454589844, 0.6385822296142578, -0.18993186950683594, -0.1665802001953125, 0.5848979949951172, -0.1523571014404297, -0.8219890594482422], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.259441375732422, "min_q": 6.2551045417785645, "max_q": 62.323551177978516, "mean_td_error": 2.6009082794189453, "model": {}}, "td_error": [-0.3697967529296875, -1.3401870727539062, 0.13796615600585938, 0.062427520751953125, 8.189050674438477, 0.2962627410888672, 26.825735092163086, 0.5127677917480469, -2.6894102096557617, -1.1712303161621094, -0.011617660522460938, -0.10334014892578125, 16.339553833007812, 0.2589225769042969, -0.23401641845703125, -0.4337120056152344, -0.5584049224853516, -0.28160667419433594, 7.2551045417785645, -0.45717430114746094, 0.13796615600585938, 0.1675586700439453, -0.16198158264160156, 0.3492612838745117, 16.339553833007812, -0.028995513916015625, 1.2685317993164062, 2.8837890625, 8.189050674438477, 2.469409942626953, -0.6007461547851562, -0.01161956787109375], "custom_metrics": {}}}, "num_steps_sampled": 100800, "num_agent_steps_sampled": 302400, "num_steps_trained": 199616, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 598848, "last_target_update_ts": 100336, "num_target_updates": 195}, "done": false, "episodes_total": 10253, "training_iteration": 100, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-29-26", "timestamp": 1648916966, "time_this_iter_s": 39.2215461730957, "time_total_s": 3985.4617445468903, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c27a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c27a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 3985.4617445468903, "timesteps_since_restore": 3200, "iterations_since_restore": 100, "perf": {"cpu_util_percent": 51.44909090909091, "ram_util_percent": 65.27818181818182}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.88235294117646, "episode_len_mean": 8.369747899159664, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.294117647058826, "policy1": 61.294117647058826, "policy2": 61.294117647058826}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 180.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 183.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 9, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 9, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0490101597244041, "mean_inference_ms": 25.78614542513091, "mean_action_processing_ms": 0.2447952579808783, "mean_env_wait_ms": 0.13943788717780728, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 101808, "timesteps_this_iter": 32, "agent_timesteps_total": 305424, "timers": {"load_time_ms": 0.603, "load_throughput": 53071.462, "learn_time_ms": 236.579, "learn_throughput": 135.261, "update_time_ms": 112.297}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.68495178222656, "min_q": 4.787158012390137, "max_q": 60.75197982788086, "mean_td_error": 0.8565568923950195, "model": {}}, "td_error": [-0.10154914855957031, -0.06586074829101562, -0.12841033935546875, 17.425947189331055, -0.16170883178710938, -0.16209030151367188, -0.11882400512695312, 2.9978981018066406, 0.6145343780517578, 0.46064090728759766, -0.0867156982421875, -0.15024566650390625, -0.021268844604492188, -0.08295440673828125, -0.3883953094482422, -0.4351682662963867, -0.18067550659179688, 1.4873390197753906, -0.6903705596923828, 1.5031204223632812, -0.11882400512695312, -0.3190727233886719, -0.18283843994140625, 2.0458507537841797, 0.02625274658203125, 3.3637771606445312, -0.17095565795898438, 0.02625274658203125, 0.02625274658203125, 1.485635757446289, -0.32566261291503906, -0.16209030151367188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.168609619140625, "min_q": 7.2844462394714355, "max_q": 61.509159088134766, "mean_td_error": 0.11227492988109589, "model": {}}, "td_error": [-0.336212158203125, 0.4819183349609375, -0.5818672180175781, 0.0374908447265625, 9.054079055786133, -0.08261299133300781, -0.2501029968261719, -0.5128097534179688, -2.791614532470703, -0.4753589630126953, -0.24753475189208984, -0.5818672180175781, -0.34239959716796875, 0.0374908447265625, 0.17319488525390625, 0.0374908447265625, 0.0374908447265625, -0.3665046691894531, -0.26912689208984375, -0.4753589630126953, -0.17432212829589844, -0.5581903457641602, -0.22328948974609375, 2.182159423828125, -0.255828857421875, 0.2722206115722656, -0.25069427490234375, -0.813408374786377, 1.806833267211914, -0.25069427490234375, -0.38541221618652344, -0.30236053466796875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.628387451171875, "min_q": 7.790465354919434, "max_q": 61.38942337036133, "mean_td_error": 0.7126266956329346, "model": {}}, "td_error": [-0.5004501342773438, 1.3077659606933594, 0.6265783309936523, -0.08181381225585938, 0.018833160400390625, 2.129608154296875, 9.77515697479248, 0.13004302978515625, -0.16855621337890625, 0.1910839080810547, 0.065216064453125, -0.41277313232421875, -0.8105373382568359, -0.4767026901245117, 0.127105712890625, -0.046871185302734375, 0.127105712890625, 0.018833160400390625, 2.676271438598633, 0.11314964294433594, -0.044506072998046875, 0.0445709228515625, 0.00258636474609375, -0.05059814453125, 0.00751495361328125, 2.6842117309570312, 0.127105712890625, -1.0780525207519531, -0.1671905517578125, 7.626659393310547, -0.3558197021484375, -0.8014755249023438], "custom_metrics": {}}}, "num_steps_sampled": 101808, "num_agent_steps_sampled": 305424, "num_steps_trained": 201632, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 604896, "last_target_update_ts": 101360, "num_target_updates": 197}, "done": false, "episodes_total": 10372, "training_iteration": 101, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-30-06", "timestamp": 1648917006, "time_this_iter_s": 40.351746559143066, "time_total_s": 4025.8134911060333, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7145f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7145f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4025.8134911060333, "timesteps_since_restore": 3232, "iterations_since_restore": 101, "perf": {"cpu_util_percent": 51.04310344827586, "ram_util_percent": 65.57758620689656}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.0327868852459, "episode_len_mean": 8.327868852459016, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.34426229508197, "policy1": 61.34426229508197, "policy2": 61.34426229508197}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 10, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0486474172907394, "mean_inference_ms": 25.743650243526215, "mean_action_processing_ms": 0.24447329920519922, "mean_env_wait_ms": 0.13927868785818798, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 102816, "timesteps_this_iter": 32, "agent_timesteps_total": 308448, "timers": {"load_time_ms": 0.691, "load_throughput": 46331.502, "learn_time_ms": 228.945, "learn_throughput": 139.772, "update_time_ms": 102.382}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.27261734008789, "min_q": 6.7890119552612305, "max_q": 61.16204833984375, "mean_td_error": -0.07002902030944824, "model": {}}, "td_error": [0.0750131607055664, -0.7376842498779297, -0.5099878311157227, -0.03569793701171875, -0.057399749755859375, -0.26825904846191406, -0.003711700439453125, -0.10553359985351562, -0.003711700439453125, 0.3652381896972656, -0.3689308166503906, 0.3073387145996094, 0.2117633819580078, 0.2117633819580078, 0.2899188995361328, 0.2117633819580078, -0.14526748657226562, 0.002674102783203125, -0.10553359985351562, -1.056199073791504, -0.10598373413085938, -0.11122989654541016, -0.148162841796875, 0.1072235107421875, 0.048755645751953125, 0.18693923950195312, 0.048755645751953125, -0.3194122314453125, -0.14526748657226562, -0.1683349609375, -0.04002189636230469, 0.12825393676757812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.159183502197266, "min_q": 9.030838966369629, "max_q": 60.890602111816406, "mean_td_error": -0.005919039249420166, "model": {}}, "td_error": [0.035800933837890625, 0.22467422485351562, -0.0173187255859375, 0.06785774230957031, 0.11365127563476562, 0.11365127563476562, -0.041721343994140625, -0.00759124755859375, 0.030838966369628906, 0.05640411376953125, 0.08077621459960938, 0.1530780792236328, -0.08994674682617188, -0.41327667236328125, -2.375774383544922, -0.6855983734130859, 1.3050270080566406, -0.08994674682617188, 0.16701126098632812, -0.14453697204589844, 0.13852310180664062, 0.11365127563476562, -0.07275772094726562, -0.5417499542236328, 0.16794586181640625, -0.5768337249755859, -0.11724090576171875, 0.3116645812988281, 0.05640411376953125, 0.10817718505859375, 1.7198495864868164, 0.0198974609375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 40.91999053955078, "min_q": 7.881579875946045, "max_q": 61.086517333984375, "mean_td_error": 0.03170095384120941, "model": {}}, "td_error": [-0.07086181640625, -0.4456596374511719, -0.23017501831054688, -0.23017501831054688, 0.12969017028808594, -0.009798049926757812, 3.4551315307617188, -0.3875694274902344, 1.6415634155273438, 0.021945953369140625, -0.11798095703125, -0.11565017700195312, -0.5611667633056641, -0.009798049926757812, -0.13816070556640625, -0.12468338012695312, -0.3314323425292969, 0.1839580535888672, -0.3867034912109375, -0.12192535400390625, 0.3018951416015625, -0.3314323425292969, -0.11798095703125, -0.16014480590820312, -0.3314323425292969, -0.10793733596801758, -0.13816070556640625, -0.13816070556640625, -0.07086181640625, 0.01641082763671875, -0.09291648864746094, 0.034603118896484375], "custom_metrics": {}}}, "num_steps_sampled": 102816, "num_agent_steps_sampled": 308448, "num_steps_trained": 203648, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 610944, "last_target_update_ts": 102384, "num_target_updates": 199}, "done": false, "episodes_total": 10494, "training_iteration": 102, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-30-47", "timestamp": 1648917047, "time_this_iter_s": 40.503143072128296, "time_total_s": 4066.3166341781616, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c714830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4066.3166341781616, "timesteps_since_restore": 3264, "iterations_since_restore": 102, "perf": {"cpu_util_percent": 52.087719298245624, "ram_util_percent": 65.41754385964911}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.375, "episode_len_mean": 8.375, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.458333333333336, "policy1": 61.458333333333336, "policy2": 61.458333333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 180.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 10, 10, 10, 9, 9, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0481724644651507, "mean_inference_ms": 25.733777172150198, "mean_action_processing_ms": 0.24432612800972903, "mean_env_wait_ms": 0.13921984576543345, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 103824, "timesteps_this_iter": 32, "agent_timesteps_total": 311472, "timers": {"load_time_ms": 0.646, "load_throughput": 49525.009, "learn_time_ms": 223.228, "learn_throughput": 143.351, "update_time_ms": 111.235}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.980445861816406, "min_q": 8.23664379119873, "max_q": 61.3964958190918, "mean_td_error": 0.45190954208374023, "model": {}}, "td_error": [-0.2379608154296875, 0.5457143783569336, 0.2919120788574219, 2.5937538146972656, 0.03458404541015625, 0.03458404541015625, -0.11298370361328125, 0.1942157745361328, 0.2635383605957031, -0.024869918823242188, 0.3803596496582031, 0.5046443939208984, 0.010835647583007812, 6.513360023498535, 1.7097492218017578, 0.009283065795898438, 0.3767375946044922, -0.22298431396484375, 0.00695037841796875, -0.2897911071777344, -0.014835357666015625, -0.22298431396484375, -0.34214019775390625, 2.592559814453125, -0.024869918823242188, -0.272674560546875, 0.19956398010253906, -0.2379608154296875, -0.024869918823242188, 0.006649017333984375, 0.18645095825195312, 0.03458404541015625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.895347595214844, "min_q": 8.812165260314941, "max_q": 60.325923919677734, "mean_td_error": 0.12635281682014465, "model": {}}, "td_error": [-0.12291145324707031, 0.08805465698242188, -0.1878347396850586, 0.08805465698242188, 0.15108489990234375, 0.08805465698242188, -0.14875221252441406, -0.12291145324707031, 0.14494895935058594, 0.010049819946289062, -0.1510467529296875, -0.025325775146484375, 3.085308074951172, 0.08805465698242188, -0.0058135986328125, -0.2728614807128906, 0.01807403564453125, -0.14875221252441406, -0.12291145324707031, 0.017131805419921875, -0.1878347396850586, -0.027252197265625, 0.14863967895507812, -0.1878347396850586, 0.08805465698242188, -0.032527923583984375, 0.08805465698242188, 2.1362667083740234, -0.3977069854736328, 0.14258575439453125, -0.045803070068359375, -0.1510467529296875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.673038482666016, "min_q": 2.656466007232666, "max_q": 60.79191589355469, "mean_td_error": 0.838188648223877, "model": {}}, "td_error": [2.9194068908691406, -0.22152137756347656, -0.15976524353027344, 26.871658325195312, -0.06056976318359375, -0.06056976318359375, -0.29810523986816406, -0.3408622741699219, -0.07372474670410156, -0.4877195358276367, -0.15976524353027344, -0.8556137084960938, -1.1700716018676758, -0.16439247131347656, -0.4117259979248047, -0.07372474670410156, 0.043010711669921875, -0.38474464416503906, -1.5671300888061523, 2.3721275329589844, -0.29810523986816406, -0.10987091064453125, -0.06056976318359375, -0.23074722290039062, -0.6893386840820312, -0.35761356353759766, -0.19460296630859375, -0.10224533081054688, -0.1734619140625, -0.158966064453125, -0.1586151123046875, 3.6399757862091064], "custom_metrics": {}}}, "num_steps_sampled": 103824, "num_agent_steps_sampled": 311472, "num_steps_trained": 205664, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 616992, "last_target_update_ts": 103408, "num_target_updates": 201}, "done": false, "episodes_total": 10614, "training_iteration": 103, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-31-26", "timestamp": 1648917086, "time_this_iter_s": 38.99059200286865, "time_total_s": 4105.30722618103, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6efb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6efb90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4105.30722618103, "timesteps_since_restore": 3296, "iterations_since_restore": 103, "perf": {"cpu_util_percent": 51.238181818181815, "ram_util_percent": 64.88}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 184.0909090909091, "episode_len_mean": 8.388429752066116, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.36363636363637, "policy1": 61.36363636363637, "policy2": 61.36363636363637}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0], "episode_lengths": [8, 8, 10, 8, 10, 8, 8, 10, 9, 8, 8, 10, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0487571752057143, "mean_inference_ms": 25.747257735010816, "mean_action_processing_ms": 0.24439628551301223, "mean_env_wait_ms": 0.139274186289378, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 104832, "timesteps_this_iter": 32, "agent_timesteps_total": 314496, "timers": {"load_time_ms": 0.702, "load_throughput": 45588.712, "learn_time_ms": 239.279, "learn_throughput": 133.735, "update_time_ms": 114.681}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.38379669189453, "min_q": 4.825836658477783, "max_q": 60.76710510253906, "mean_td_error": 0.08520859479904175, "model": {}}, "td_error": [-0.3605632781982422, -0.14476776123046875, -0.12904739379882812, -0.2255840301513672, -0.19795799255371094, -0.19748687744140625, 0.6840896606445312, 0.13245773315429688, -0.4905691146850586, -0.44048118591308594, -0.004150390625, -0.04193878173828125, 1.8808479309082031, -0.30145263671875, 0.43633460998535156, 0.044559478759765625, -0.00885009765625, 0.035053253173828125, -0.00885009765625, -0.13333415985107422, -0.17876815795898438, -0.3605632781982422, -0.23867416381835938, -0.11725997924804688, -0.07640838623046875, -0.19387245178222656, -0.10495376586914062, -0.01250457763671875, -0.00885009765625, 3.845529556274414, -0.14476776123046875, -0.210540771484375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.24724197387695, "min_q": 5.787071228027344, "max_q": 61.05352783203125, "mean_td_error": 0.5885590314865112, "model": {}}, "td_error": [0.13345718383789062, 0.20633220672607422, -0.2693023681640625, -0.10106277465820312, -0.05792236328125, 0.00103759765625, -0.23388290405273438, -0.13348770141601562, 0.03096771240234375, 0.053119659423828125, -0.05792236328125, 0.13345718383789062, -0.29900360107421875, -0.05792236328125, -0.2693023681640625, 0.019189834594726562, -0.1709747314453125, -0.08441925048828125, -0.24065399169921875, 0.5436210632324219, 18.309978485107422, 2.4424285888671875, -0.34859657287597656, -0.10106277465820312, -0.2295536994934082, 0.053119659423828125, -0.05792236328125, -0.26665496826171875, -0.08441925048828125, 0.019189834594726562, -0.10106468200683594, 0.053119659423828125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.240402221679688, "min_q": 7.789491176605225, "max_q": 59.20711135864258, "mean_td_error": 0.5744962096214294, "model": {}}, "td_error": [1.90460205078125, -0.1379261016845703, -0.3207263946533203, -0.3207263946533203, -0.5872993469238281, -0.02567291259765625, 0.20947647094726562, -0.15060043334960938, 8.431190490722656, 0.3691387176513672, -0.2513084411621094, -0.14781951904296875, 0.058864593505859375, 0.20947647094726562, -0.0749211311340332, 0.01950836181640625, -0.07483100891113281, 0.386138916015625, 0.21646881103515625, 1.03045654296875, -0.16605377197265625, -0.26626014709472656, 0.5648956298828125, 0.8425827026367188, 0.0555267333984375, -0.021074295043945312, 0.20947647094726562, 2.7250022888183594, 0.10834217071533203, 4.056493759155273, -0.14781761169433594, -0.3207244873046875], "custom_metrics": {}}}, "num_steps_sampled": 104832, "num_agent_steps_sampled": 314496, "num_steps_trained": 207680, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 623040, "last_target_update_ts": 104432, "num_target_updates": 203}, "done": false, "episodes_total": 10735, "training_iteration": 104, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-32-06", "timestamp": 1648917126, "time_this_iter_s": 40.623122692108154, "time_total_s": 4145.930348873138, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72ddd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4145.930348873138, "timesteps_since_restore": 3328, "iterations_since_restore": 104, "perf": {"cpu_util_percent": 50.27413793103448, "ram_util_percent": 65.46379310344827}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.68595041322314, "episode_len_mean": 8.355371900826446, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.56198347107438, "policy1": 61.56198347107438, "policy2": 61.56198347107438}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0], "episode_lengths": [8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 10, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8], "policy_policy0_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.050967035814648, "mean_inference_ms": 25.816943966797705, "mean_action_processing_ms": 0.24494591381013064, "mean_env_wait_ms": 0.13961218217471907, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 105840, "timesteps_this_iter": 32, "agent_timesteps_total": 317520, "timers": {"load_time_ms": 0.612, "load_throughput": 52281.758, "learn_time_ms": 229.756, "learn_throughput": 139.278, "update_time_ms": 97.37}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.98651123046875, "min_q": 5.634382247924805, "max_q": 60.73360824584961, "mean_td_error": 0.32358279824256897, "model": {}}, "td_error": [0.1400775909423828, -0.02752685546875, -0.02752685546875, -0.033550262451171875, 2.1762781143188477, -0.02752685546875, 0.07814979553222656, 0.05916595458984375, 0.01739501953125, 0.15329742431640625, 0.6320877075195312, 0.133209228515625, 0.002101898193359375, 0.15511131286621094, 0.027858734130859375, 0.09563636779785156, 0.15329742431640625, 0.3184013366699219, 0.3382759094238281, 0.09563636779785156, 2.7188072204589844, 0.10947418212890625, 0.1889362335205078, 0.2730064392089844, 0.12778854370117188, 0.08952522277832031, 0.22795677185058594, 0.09563636779785156, 0.041469573974609375, 0.002101898193359375, 2.053640365600586, -0.033542633056640625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.001773834228516, "min_q": 8.256845474243164, "max_q": 61.228614807128906, "mean_td_error": 0.21536129713058472, "model": {}}, "td_error": [-0.08716583251953125, 0.166748046875, 0.019775390625, 0.00972747802734375, -0.045135498046875, -0.047695159912109375, -0.01639556884765625, -0.36128997802734375, 0.079498291015625, 1.3251953125, -0.0125885009765625, -0.00730133056640625, -0.045135498046875, -0.013885498046875, -0.011425018310546875, 0.0059375762939453125, -0.045135498046875, 0.2240009307861328, 0.03708076477050781, -0.047695159912109375, -3.012380599975586, 0.024684906005859375, 0.09250259399414062, -0.045135498046875, 7.474617004394531, 0.04332733154296875, -0.040618896484375, 0.03708076477050781, 0.011203765869140625, -0.013885498046875, 1.1351947784423828, 0.05785560607910156], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.924190521240234, "min_q": 7.533905029296875, "max_q": 60.52205276489258, "mean_td_error": -0.06505520641803741, "model": {}}, "td_error": [-0.6734285354614258, 0.10680961608886719, 0.14291763305664062, 0.1331329345703125, 0.2571086883544922, -0.11287689208984375, 0.07900047302246094, -0.2274932861328125, -0.06884765625, -0.9995627403259277, -0.0462188720703125, 0.07900047302246094, 0.5483932495117188, 0.10680961608886719, -0.15361595153808594, -0.20030593872070312, 0.0644845962524414, 0.15744972229003906, 0.07900047302246094, -0.13621139526367188, -0.21425247192382812, -0.12702560424804688, 0.10680961608886719, -0.2274932861328125, -0.2948570251464844, -0.21425247192382812, -0.20030593872070312, -0.19005584716796875, -0.2948570251464844, 0.1386861801147461, 0.058807373046875, 0.2414836883544922], "custom_metrics": {}}}, "num_steps_sampled": 105840, "num_agent_steps_sampled": 317520, "num_steps_trained": 209696, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 629088, "last_target_update_ts": 105456, "num_target_updates": 205}, "done": false, "episodes_total": 10856, "training_iteration": 105, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-32-47", "timestamp": 1648917167, "time_this_iter_s": 40.38744640350342, "time_total_s": 4186.317795276642, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72d170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72d170>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4186.317795276642, "timesteps_since_restore": 3360, "iterations_since_restore": 105, "perf": {"cpu_util_percent": 52.47543859649122, "ram_util_percent": 65.64035087719299}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 182.0, "episode_len_mean": 8.478632478632479, "episode_media": {}, "episodes_this_iter": 117, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.666666666666664, "policy1": 60.666666666666664, "policy2": 60.666666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 120.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 150.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 9, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 8, 10, 8, 8, 8, 8, 10], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 50.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 50.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0478326274160468, "mean_inference_ms": 25.691760834102375, "mean_action_processing_ms": 0.24391587515744917, "mean_env_wait_ms": 0.13912162305923342, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 106848, "timesteps_this_iter": 32, "agent_timesteps_total": 320544, "timers": {"load_time_ms": 0.618, "load_throughput": 51767.55, "learn_time_ms": 228.915, "learn_throughput": 139.79, "update_time_ms": 99.4}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.439855575561523, "min_q": 8.208691596984863, "max_q": 60.70882797241211, "mean_td_error": 0.0046340227127075195, "model": {}}, "td_error": [0.0397186279296875, 0.016834259033203125, -0.6982707977294922, 0.11127090454101562, 0.0397186279296875, -0.12387466430664062, -0.0644378662109375, -0.5175800323486328, -0.0694427490234375, 0.0434417724609375, -0.04327583312988281, 0.11127090454101562, 0.12502670288085938, 0.2187957763671875, -0.09472942352294922, 0.11127090454101562, 0.14253807067871094, 0.005603790283203125, -0.0006227493286132812, 0.0434417724609375, 0.06803703308105469, -0.2247772216796875, 0.033267974853515625, 0.12502670288085938, -0.0006227493286132812, -1.5903596878051758, -0.0006227493286132812, 0.1284923553466797, 0.13150787353515625, 0.12502670288085938, 2.721090316772461, -0.7644758224487305], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.731407165527344, "min_q": 4.759364604949951, "max_q": 61.326377868652344, "mean_td_error": 0.17912469804286957, "model": {}}, "td_error": [0.08352279663085938, 0.11203193664550781, -0.02474212646484375, 0.058643341064453125, -0.034465789794921875, 0.033985137939453125, -0.052303314208984375, 0.033985137939453125, 0.31870079040527344, 0.19971466064453125, 0.05065155029296875, 2.1949405670166016, 0.0684967041015625, -0.09535408020019531, -0.09535408020019531, 0.20717430114746094, 0.31870079040527344, 0.05065155029296875, 2.4192514419555664, 0.19971466064453125, 0.31870079040527344, -2.0543532371520996, 0.29828834533691406, -0.02474212646484375, 0.0684967041015625, 0.0047760009765625, -0.22635650634765625, 0.08352279663085938, 1.3515052795410156, -0.019832611083984375, -0.09535408020019531, -0.02060699462890625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.17982864379883, "min_q": 8.198176383972168, "max_q": 61.10908889770508, "mean_td_error": 0.4051300585269928, "model": {}}, "td_error": [-0.2661705017089844, 9.875152587890625, -0.10525894165039062, -0.08551025390625, 0.02629852294921875, -0.01242828369140625, -0.42136287689208984, -0.02361297607421875, 0.2034454345703125, -0.21440505981445312, 0.02629852294921875, 0.44879913330078125, -0.18080520629882812, -0.2674541473388672, 3.0566158294677734, -0.10525894165039062, 0.054294586181640625, -0.42136287689208984, 0.02629852294921875, 1.4209637641906738, 0.02629852294921875, 0.033351898193359375, -0.02361297607421875, 0.02629852294921875, -0.10525894165039062, -0.1928415298461914, -0.08551025390625, -0.01242828369140625, 0.00780487060546875, 0.11266326904296875, 0.24811553955078125, -0.105255126953125], "custom_metrics": {}}}, "num_steps_sampled": 106848, "num_agent_steps_sampled": 320544, "num_steps_trained": 211712, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 635136, "last_target_update_ts": 106480, "num_target_updates": 207}, "done": false, "episodes_total": 10973, "training_iteration": 106, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-33-26", "timestamp": 1648917206, "time_this_iter_s": 39.14923357963562, "time_total_s": 4225.4670288562775, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c698680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c698680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4225.4670288562775, "timesteps_since_restore": 3392, "iterations_since_restore": 106, "perf": {"cpu_util_percent": 51.60535714285714, "ram_util_percent": 65.45535714285714}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 182.9747899159664, "episode_len_mean": 8.420168067226891, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.99159663865546, "policy1": 60.99159663865546, "policy2": 60.99159663865546}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 10, 10, 10, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0494487486712478, "mean_inference_ms": 25.743802757065186, "mean_action_processing_ms": 0.24431044786640174, "mean_env_wait_ms": 0.1393128953276211, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 107856, "timesteps_this_iter": 32, "agent_timesteps_total": 323568, "timers": {"load_time_ms": 0.608, "load_throughput": 52640.596, "learn_time_ms": 228.774, "learn_throughput": 139.876, "update_time_ms": 103.596}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.208213806152344, "min_q": 9.003188133239746, "max_q": 61.19903564453125, "mean_td_error": 0.7137883901596069, "model": {}}, "td_error": [7.956287384033203, -0.011335372924804688, -0.40819549560546875, -0.40819549560546875, -0.4750404357910156, -0.15540695190429688, 3.5416412353515625, 0.23966026306152344, -0.23854446411132812, 1.6102752685546875, -0.011335372924804688, -0.2796974182128906, -0.26947975158691406, -0.5168037414550781, -0.20135498046875, -0.26947975158691406, 0.22238922119140625, 1.9124336242675781, -0.20135498046875, -0.3726768493652344, -0.20135498046875, -0.40819549560546875, 6.357606887817383, 0.977360725402832, -0.26947975158691406, -0.2917823791503906, -0.011629104614257812, -0.16198348999023438, -0.40819549560546875, 0.0031881332397460938, 2.230012893676758, 3.3618946075439453], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.76660919189453, "min_q": 5.303038597106934, "max_q": 61.15618896484375, "mean_td_error": 0.39705488085746765, "model": {}}, "td_error": [0.1472339630126953, -0.03415679931640625, -0.047908782958984375, 0.02704620361328125, -0.101837158203125, 0.0380401611328125, 0.11790847778320312, 0.0380401611328125, -0.340606689453125, 0.00323486328125, -0.39121437072753906, 0.18692588806152344, -0.02013397216796875, -0.13191986083984375, -0.8612432479858398, 0.083343505859375, 0.8597421646118164, 0.1472339630126953, 0.20006179809570312, 0.10327911376953125, 0.6701469421386719, 0.09034347534179688, 0.18692588806152344, 2.8554229736328125, 6.303038597106934, 0.00304412841796875, 0.083343505859375, -0.02013397216796875, 0.05314064025878906, 2.359193801879883, 0.20006179809570312, -0.10184097290039062], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.25349426269531, "min_q": 7.312270641326904, "max_q": 61.50468063354492, "mean_td_error": 0.2452346533536911, "model": {}}, "td_error": [0.07126712799072266, 0.9635505676269531, 0.00658416748046875, -0.2159252166748047, 9.024402618408203, 1.5116143226623535, -0.2426929473876953, -0.023822784423828125, -0.24419403076171875, -0.13320541381835938, -0.29274559020996094, 0.00658416748046875, -0.21985244750976562, -0.043346405029296875, -0.17150115966796875, -0.31584930419921875, -0.0079803466796875, -0.09507369995117188, -0.0079803466796875, 0.014934539794921875, -0.0079803466796875, -0.0079803466796875, -0.1799468994140625, 0.029415130615234375, 0.32344627380371094, -0.9222354888916016, -0.036876678466796875, -0.5055828094482422, -0.1583118438720703, -0.043346405029296875, -0.07021713256835938, -0.15764236450195312], "custom_metrics": {}}}, "num_steps_sampled": 107856, "num_agent_steps_sampled": 323568, "num_steps_trained": 213728, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 641184, "last_target_update_ts": 107504, "num_target_updates": 209}, "done": false, "episodes_total": 11092, "training_iteration": 107, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-34-06", "timestamp": 1648917246, "time_this_iter_s": 39.314340114593506, "time_total_s": 4264.781368970871, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7a84d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4264.781368970871, "timesteps_since_restore": 3424, "iterations_since_restore": 107, "perf": {"cpu_util_percent": 51.61428571428571, "ram_util_percent": 65.47857142857143}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.30327868852459, "episode_len_mean": 8.319672131147541, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.4344262295082, "policy1": 61.4344262295082, "policy2": 61.4344262295082}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 8, 9, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 10, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.049381643839137, "mean_inference_ms": 25.71308007578053, "mean_action_processing_ms": 0.24405206772654345, "mean_env_wait_ms": 0.1391598132261286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 108864, "timesteps_this_iter": 32, "agent_timesteps_total": 326592, "timers": {"load_time_ms": 0.64, "load_throughput": 49997.291, "learn_time_ms": 231.811, "learn_throughput": 138.044, "update_time_ms": 102.01}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.02460861206055, "min_q": 8.904786109924316, "max_q": 61.09865951538086, "mean_td_error": 0.14223888516426086, "model": {}}, "td_error": [0.11264801025390625, -0.15482330322265625, 0.11690902709960938, 7.978176116943359, -0.07122802734375, -0.685272216796875, -0.13619041442871094, 0.053516387939453125, -0.2560577392578125, 0.11264801025390625, 1.360147476196289, -0.28710174560546875, 0.26813316345214844, -0.22617530822753906, 0.018413543701171875, -0.04079437255859375, -0.8548374176025391, 0.2596855163574219, 0.17569732666015625, -1.7914199829101562, 0.11690902709960938, -0.08611679077148438, -0.07122802734375, -0.3965644836425781, -0.233734130859375, -0.11113357543945312, -0.0952138900756836, -0.22617530822753906, 0.20867156982421875, -0.34799766540527344, -0.07123184204101562, -0.08661460876464844], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.90725326538086, "min_q": 5.495331287384033, "max_q": 61.32909393310547, "mean_td_error": 0.48039138317108154, "model": {}}, "td_error": [-0.14259815216064453, -0.1303386688232422, 0.27904510498046875, 2.3196983337402344, 0.08754348754882812, -0.258575439453125, 2.7705230712890625, 0.1999664306640625, -0.28902673721313477, 0.42533302307128906, 0.10568809509277344, 0.09152984619140625, 0.09198760986328125, -0.15413665771484375, -0.07047271728515625, 0.15264129638671875, -0.15413665771484375, -0.15413665771484375, 0.13560867309570312, 0.13560867309570312, 0.13560867309570312, 0.25179100036621094, 0.30507659912109375, 0.3022193908691406, 0.0065765380859375, 0.062469482421875, -0.15413665771484375, 6.495331287384033, 0.2488269805908203, 0.1646442413330078, -0.07047653198242188, 2.182842254638672], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.20003890991211, "min_q": 7.542713642120361, "max_q": 60.74690246582031, "mean_td_error": -0.06959553062915802, "model": {}}, "td_error": [0.0012950897216796875, 0.2220783233642578, -0.38957977294921875, -0.1131591796875, -0.1983642578125, -0.3201789855957031, -0.12709426879882812, 0.08601760864257812, 0.17831802368164062, -0.052005767822265625, -0.2504119873046875, -1.1183204650878906, 0.08765029907226562, 0.059078216552734375, -0.5049762725830078, -0.3079195022583008, 0.17831802368164062, -0.04274177551269531, -0.33538246154785156, -0.5049762725830078, 3.101715087890625, -0.1983642578125, 0.059078216552734375, -0.5559749603271484, -0.4420318603515625, -0.1006622314453125, -0.10978507995605469, -0.37455129623413086, -0.12709426879882812, -0.052005767822265625, 0.17831802368164062, -0.15334320068359375], "custom_metrics": {}}}, "num_steps_sampled": 108864, "num_agent_steps_sampled": 326592, "num_steps_trained": 215744, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 647232, "last_target_update_ts": 108528, "num_target_updates": 211}, "done": false, "episodes_total": 11214, "training_iteration": 108, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-34-45", "timestamp": 1648917285, "time_this_iter_s": 39.63136553764343, "time_total_s": 4304.412734508514, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c5f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c5f80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4304.412734508514, "timesteps_since_restore": 3456, "iterations_since_restore": 108, "perf": {"cpu_util_percent": 53.04821428571428, "ram_util_percent": 65.49107142857142}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.76859504132233, "episode_len_mean": 8.413223140495868, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.256198347107436, "policy1": 61.256198347107436, "policy2": 61.256198347107436}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 183.0, 183.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 9, 9, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 10, 8, 10, 8, 8, 9, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 10, 9, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0489460742199204, "mean_inference_ms": 25.68838659029719, "mean_action_processing_ms": 0.24384049768445548, "mean_env_wait_ms": 0.13910011611629838, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 109872, "timesteps_this_iter": 32, "agent_timesteps_total": 329616, "timers": {"load_time_ms": 0.606, "load_throughput": 52820.83, "learn_time_ms": 233.465, "learn_throughput": 137.066, "update_time_ms": 101.454}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.60795974731445, "min_q": 8.936278343200684, "max_q": 61.19647979736328, "mean_td_error": 0.7991629838943481, "model": {}}, "td_error": [-0.21924972534179688, 0.34663963317871094, 17.40852928161621, 0.8941898345947266, -0.08965682983398438, 0.11603546142578125, -0.0637216567993164, -0.3740425109863281, -0.02332305908203125, -0.3261871337890625, -0.06389999389648438, 2.5621795654296875, -0.24630355834960938, -0.24630355834960938, -0.06389999389648438, -0.2676734924316406, -0.1515350341796875, 2.0274810791015625, 0.009314537048339844, 0.0033779144287109375, -0.028150558471679688, -0.07336807250976562, -0.12834548950195312, 2.5712432861328125, -0.39945220947265625, -0.21924972534179688, -0.12834548950195312, 2.694711685180664, 0.009314537048339844, -0.0637216567993164, 0.2581596374511719, -0.15153121948242188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.233707427978516, "min_q": 4.802582740783691, "max_q": 61.43359375, "mean_td_error": 0.3256222903728485, "model": {}}, "td_error": [5.802582740783691, -0.199615478515625, -0.2567863464355469, 0.5912036895751953, 0.8119125366210938, -0.5247001647949219, -0.06679534912109375, 0.19464111328125, -0.11371803283691406, -0.18415164947509766, 0.18033218383789062, 0.05036163330078125, 6.324375629425049, -0.04924774169921875, -0.22776031494140625, -0.08593368530273438, -0.18415164947509766, 0.12740516662597656, -0.49981689453125, -0.49981689453125, 0.032649993896484375, -0.8932056427001953, -0.06679534912109375, 0.05036163330078125, 0.05036163330078125, -0.04924774169921875, -0.10488510131835938, -0.49981689453125, -1.4084300994873047, 1.930990219116211, -0.00702667236328125, 0.19463729858398438], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.137489318847656, "min_q": 9.262160301208496, "max_q": 60.69343948364258, "mean_td_error": 0.05210182070732117, "model": {}}, "td_error": [0.20853042602539062, -0.0358123779296875, 0.03498268127441406, 0.03498268127441406, -0.021556854248046875, 0.101287841796875, -0.46788978576660156, -0.2164154052734375, -0.15943145751953125, 1.7285308837890625, -0.09805107116699219, 0.0093841552734375, -0.27080535888671875, -0.021556854248046875, -0.15840911865234375, -0.27080535888671875, -0.34478759765625, 0.2621603012084961, 0.20583724975585938, 0.101287841796875, -0.021556854248046875, -0.15943145751953125, 0.6158161163330078, 0.050998687744140625, 0.11840438842773438, 0.03498268127441406, -0.15943145751953125, -0.03099822998046875, 0.101287841796875, 0.5659713745117188, -0.02155303955078125, -0.048694610595703125], "custom_metrics": {}}}, "num_steps_sampled": 109872, "num_agent_steps_sampled": 329616, "num_steps_trained": 217760, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 653280, "last_target_update_ts": 109552, "num_target_updates": 213}, "done": false, "episodes_total": 11335, "training_iteration": 109, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-35-25", "timestamp": 1648917325, "time_this_iter_s": 39.8193085193634, "time_total_s": 4344.232043027878, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c2a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c2a70>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4344.232043027878, "timesteps_since_restore": 3488, "iterations_since_restore": 109, "perf": {"cpu_util_percent": 51.323214285714286, "ram_util_percent": 65.47678571428571}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 183.44628099173553, "episode_len_mean": 8.355371900826446, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.14876033057851, "policy1": 61.14876033057851, "policy2": 61.14876033057851}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 9, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0508181488198092, "mean_inference_ms": 25.7470528864743, "mean_action_processing_ms": 0.24426618330965152, "mean_env_wait_ms": 0.13932574305283754, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 110880, "timesteps_this_iter": 32, "agent_timesteps_total": 332640, "timers": {"load_time_ms": 0.669, "load_throughput": 47849.457, "learn_time_ms": 235.719, "learn_throughput": 135.755, "update_time_ms": 104.101}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.606353759765625, "min_q": 6.31527853012085, "max_q": 61.70323181152344, "mean_td_error": 0.2060261368751526, "model": {}}, "td_error": [-0.2268352508544922, 0.13417434692382812, 0.26833343505859375, -0.1421661376953125, -0.23982715606689453, 1.6815299987792969, -0.10388565063476562, 0.03348350524902344, 3.503406524658203, -0.11908721923828125, -0.1910228729248047, 0.05061912536621094, -0.6993012428283691, 2.1122989654541016, -0.22078704833984375, 0.03348350524902344, 0.019044876098632812, 0.00128173828125, 0.5440940856933594, 0.03348350524902344, 0.00128173828125, 1.2698044776916504, -0.00103759765625, -0.2571525573730469, -0.1986083984375, -0.1421661376953125, -0.1421661376953125, -0.1421661376953125, -0.12116718292236328, -0.05579185485839844, 0.030853271484375, -0.12116813659667969], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.462013244628906, "min_q": 4.134324073791504, "max_q": 61.02012252807617, "mean_td_error": 0.32567524909973145, "model": {}}, "td_error": [-0.14886474609375, -0.08575439453125, -0.034679412841796875, -0.50921630859375, -0.23590850830078125, -0.21917724609375, 1.9296951293945312, -0.15778350830078125, -0.0159912109375, -0.171783447265625, -0.14097976684570312, 0.2169170379638672, 0.18035316467285156, -0.13848876953125, -0.2572669982910156, 0.18035316467285156, -0.23590850830078125, -0.0704193115234375, 2.5325851440429688, 1.5603141784667969, -0.25797271728515625, 0.7423477172851562, -0.02063751220703125, 7.503288269042969, 0.10187911987304688, -0.171783447265625, 0.1793975830078125, 0.14818382263183594, -1.8274245262145996, -0.043811798095703125, -0.02063751220703125, -0.08921623229980469], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.357826232910156, "min_q": 3.5461478233337402, "max_q": 60.701236724853516, "mean_td_error": 0.42386314272880554, "model": {}}, "td_error": [-0.12328720092773438, -0.14691925048828125, -0.0019855499267578125, -0.14044952392578125, -0.12990188598632812, 0.18815040588378906, 0.5945663452148438, -0.06092071533203125, 4.54614782333374, -0.13711929321289062, -0.12990188598632812, -0.16318130493164062, -0.16255569458007812, -0.17327117919921875, -0.13711929321289062, 0.6020889282226562, 0.5945663452148438, 0.28801536560058594, -0.03526115417480469, -0.03526115417480469, -0.12328720092773438, 0.02246856689453125, -0.3219280242919922, 0.5618038177490234, 8.691873550415039, -0.11854171752929688, -0.12328720092773438, -0.2511749267578125, -0.11793136596679688, -0.0019855499267578125, 0.2561330795288086, -0.14692306518554688], "custom_metrics": {}}}, "num_steps_sampled": 110880, "num_agent_steps_sampled": 332640, "num_steps_trained": 219776, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 659328, "last_target_update_ts": 110576, "num_target_updates": 215}, "done": false, "episodes_total": 11456, "training_iteration": 110, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-36-06", "timestamp": 1648917366, "time_this_iter_s": 40.21549916267395, "time_total_s": 4384.447542190552, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c67fe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c67fe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4384.447542190552, "timesteps_since_restore": 3520, "iterations_since_restore": 110, "perf": {"cpu_util_percent": 51.36491228070176, "ram_util_percent": 65.26140350877193}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.109243697479, "episode_len_mean": 8.378151260504202, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.36974789915966, "policy1": 61.36974789915966, "policy2": 61.36974789915966}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 10, 10, 9, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.049576204470973, "mean_inference_ms": 25.677887108001638, "mean_action_processing_ms": 0.2436838646296257, "mean_env_wait_ms": 0.13904273269593678, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 111888, "timesteps_this_iter": 32, "agent_timesteps_total": 335664, "timers": {"load_time_ms": 0.603, "load_throughput": 53065.167, "learn_time_ms": 227.116, "learn_throughput": 140.897, "update_time_ms": 102.098}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.99281311035156, "min_q": 5.627574443817139, "max_q": 61.291263580322266, "mean_td_error": 0.34986525774002075, "model": {}}, "td_error": [0.04692840576171875, 0.2752799987792969, 0.08937835693359375, -0.2303924560546875, -0.001392364501953125, 0.22226333618164062, 0.15937042236328125, 0.3032073974609375, 1.7194976806640625, -0.17705535888671875, 0.04709625244140625, -0.2085742950439453, 0.23008346557617188, 0.22226333618164062, 0.0736083984375, 1.746133804321289, 0.1276111602783203, -0.20964431762695312, 0.04692840576171875, 0.038516998291015625, 0.16496658325195312, -0.2303924560546875, 0.08937835693359375, 0.16496658325195312, 0.012447357177734375, 0.04692840576171875, 6.627574443817139, 0.03240966796875, 0.07003211975097656, 0.05191993713378906, -0.1252593994140625, -0.2303924560546875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.287147521972656, "min_q": 6.520349025726318, "max_q": 60.4117317199707, "mean_td_error": 0.48473820090293884, "model": {}}, "td_error": [1.7018661499023438, 1.2265911102294922, -0.14998912811279297, 1.0844154357910156, -0.03779792785644531, -0.03779792785644531, 0.024829864501953125, 0.08069801330566406, -0.025684356689453125, 7.520349025726318, -0.3263969421386719, -0.1807403564453125, -0.11019515991210938, 0.018642425537109375, -0.13549423217773438, 0.06993484497070312, -0.14476776123046875, -0.13549423217773438, -0.13549423217773438, -0.23440933227539062, -0.11147689819335938, 5.358097076416016, 1.7018661499023438, -0.5578765869140625, -0.3754692077636719, 0.06892776489257812, 0.7317581176757812, -0.3178520202636719, -0.7163887023925781, -0.0963287353515625, -0.11120986938476562, -0.13549041748046875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.643108367919922, "min_q": 5.931455135345459, "max_q": 61.70794677734375, "mean_td_error": -0.12608398497104645, "model": {}}, "td_error": [0.27522850036621094, -0.0247802734375, -0.1371917724609375, -0.19043350219726562, -0.013370513916015625, -0.3379325866699219, 0.1383533477783203, -0.0247802734375, -0.041179656982421875, -0.0247802734375, -0.04414176940917969, -0.04414176940917969, -0.15687179565429688, 0.04778099060058594, -0.6927642822265625, -0.3760719299316406, -0.19043350219726562, -3.068544864654541, 0.04778099060058594, -0.2560539245605469, 0.04778099060058594, 0.0818328857421875, 0.04778099060058594, -0.0247802734375, -0.10182380676269531, 0.048206329345703125, 1.5101890563964844, 0.1383533477783203, -0.3379325866699219, -0.2122650146484375, 0.1383533477783203, -0.2560539245605469], "custom_metrics": {}}}, "num_steps_sampled": 111888, "num_agent_steps_sampled": 335664, "num_steps_trained": 221792, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 665376, "last_target_update_ts": 111600, "num_target_updates": 217}, "done": false, "episodes_total": 11575, "training_iteration": 111, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-36-45", "timestamp": 1648917405, "time_this_iter_s": 39.52502632141113, "time_total_s": 4423.972568511963, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c67f050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c67f050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4423.972568511963, "timesteps_since_restore": 3552, "iterations_since_restore": 111, "perf": {"cpu_util_percent": 52.521428571428565, "ram_util_percent": 65.29285714285714}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 183.0252100840336, "episode_len_mean": 8.487394957983193, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.00840336134454, "policy1": 61.00840336134454, "policy2": 61.00840336134454}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 90.0, 180.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 10, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 9, 8, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 10, 10, 8, 10, 8, 8, 10, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 30.0, 60.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 30.0, 60.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 30.0, 60.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.051649702285535, "mean_inference_ms": 25.746049450535754, "mean_action_processing_ms": 0.2441832994607471, "mean_env_wait_ms": 0.13938100605715295, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 112896, "timesteps_this_iter": 32, "agent_timesteps_total": 338688, "timers": {"load_time_ms": 0.638, "load_throughput": 50171.1, "learn_time_ms": 232.879, "learn_throughput": 137.41, "update_time_ms": 102.367}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.244388580322266, "min_q": 8.271045684814453, "max_q": 61.552040100097656, "mean_td_error": 0.06389150023460388, "model": {}}, "td_error": [-0.10468292236328125, -0.41363525390625, -0.25428199768066406, -0.6589031219482422, -0.3856849670410156, -0.4421806335449219, -0.5350494384765625, 1.3109073638916016, 0.07586669921875, -0.3343677520751953, 2.6483001708984375, 0.05912017822265625, -0.10468292236328125, -0.6084022521972656, -0.2417449951171875, -0.7289543151855469, 0.07586669921875, -0.00618743896484375, -0.2635040283203125, 3.4000539779663086, -0.43273162841796875, -0.25428199768066406, -0.07910919189453125, -0.25428199768066406, -0.1690673828125, -0.6341419219970703, -0.3982830047607422, -0.18410110473632812, -0.20434188842773438, -0.10468292236328125, -0.34354400634765625, 2.6152420043945312], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.734130859375, "min_q": 5.358682155609131, "max_q": 61.113502502441406, "mean_td_error": 0.3891623020172119, "model": {}}, "td_error": [0.0246429443359375, -0.2704505920410156, -0.5654544830322266, 0.14603805541992188, 6.358682155609131, -0.264251708984375, 0.148284912109375, -0.056015968322753906, 0.14278030395507812, 0.12804794311523438, 0.19404983520507812, -0.04457664489746094, 1.2688713073730469, 0.24650001525878906, -0.0521087646484375, 1.8626766204833984, -0.056015968322753906, 0.12025642395019531, -0.14383697509765625, 2.8873443603515625, 0.0246429443359375, 0.12025642395019531, -0.09984970092773438, 0.1058197021484375, 0.3575601577758789, 0.009143829345703125, 0.18141937255859375, 0.2696685791015625, -0.42040252685546875, 0.10715103149414062, -0.0521087646484375, -0.2255706787109375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.76946258544922, "min_q": 5.139645099639893, "max_q": 61.43046188354492, "mean_td_error": 0.149048313498497, "model": {}}, "td_error": [-0.18782424926757812, 0.0962066650390625, -0.038158416748046875, 0.6213059425354004, -0.16138839721679688, 0.056247711181640625, 0.24815940856933594, -0.13024044036865234, 0.4876117706298828, -0.18782424926757812, 0.23073768615722656, -0.16138839721679688, 1.6703414916992188, -0.0431060791015625, 0.054901123046875, -0.36426544189453125, 0.23073768615722656, 0.0364990234375, -0.13490867614746094, 0.5264892578125, 0.06198883056640625, 0.24815940856933594, 0.24815940856933594, 0.25092506408691406, -0.3378486633300781, 0.7007808685302734, 0.2266845703125, 0.056247711181640625, -0.17401504516601562, 0.053890228271484375, 0.4652118682861328, 0.11922836303710938], "custom_metrics": {}}}, "num_steps_sampled": 112896, "num_agent_steps_sampled": 338688, "num_steps_trained": 223808, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 671424, "last_target_update_ts": 112624, "num_target_updates": 219}, "done": false, "episodes_total": 11694, "training_iteration": 112, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-37-25", "timestamp": 1648917445, "time_this_iter_s": 39.76805830001831, "time_total_s": 4463.740626811981, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c50e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c50e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4463.740626811981, "timesteps_since_restore": 3584, "iterations_since_restore": 112, "perf": {"cpu_util_percent": 51.29473684210526, "ram_util_percent": 65.54385964912281}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 182.85, "episode_len_mean": 8.383333333333333, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.95, "policy1": 60.95, "policy2": 60.95}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 90.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 90.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 150.0, 186.0, 180.0, 183.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 10, 8, 10, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 10, 8, 10, 8, 10, 9, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 30.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 50.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0531222821956443, "mean_inference_ms": 25.778849635117684, "mean_action_processing_ms": 0.24446359864682882, "mean_env_wait_ms": 0.13954111566965655, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 113904, "timesteps_this_iter": 32, "agent_timesteps_total": 341712, "timers": {"load_time_ms": 0.613, "load_throughput": 52202.453, "learn_time_ms": 242.645, "learn_throughput": 131.88, "update_time_ms": 99.19}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.601184844970703, "min_q": 7.984624862670898, "max_q": 59.78403091430664, "mean_td_error": 0.4066452085971832, "model": {}}, "td_error": [-0.0248260498046875, 0.17217445373535156, 0.4063720703125, -0.18358802795410156, -0.2919120788574219, 0.17217445373535156, -0.2760505676269531, 0.17217445373535156, -0.05950927734375, 10.3327054977417, 0.17217445373535156, 0.0402984619140625, -0.2770805358886719, 0.0402984619140625, -0.021318435668945312, 0.133819580078125, 0.11661148071289062, -0.0248260498046875, 0.8087692260742188, 0.17217445373535156, 0.17217445373535156, 2.3109359741210938, 0.438385009765625, -0.05950927734375, -0.141876220703125, 0.042675018310546875, -0.46479225158691406, -0.141876220703125, -0.527557373046875, 1.0024147033691406, -0.18358802795410156, -1.0153751373291016], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.67812156677246, "min_q": 5.123432159423828, "max_q": 61.02937316894531, "mean_td_error": 0.9910865426063538, "model": {}}, "td_error": [0.017499923706054688, -0.16559982299804688, -0.13637733459472656, -0.00537109375, 0.2386455535888672, 0.14999771118164062, -0.13945388793945312, -0.13945388793945312, 0.033260345458984375, -2.116173267364502, -0.17370223999023438, -0.0029954910278320312, 2.242269515991211, 0.21045875549316406, -0.17249298095703125, 0.21045875549316406, 0.3076934814453125, -0.5882663726806641, -0.20198440551757812, -0.08454132080078125, 0.3163566589355469, 27.900737762451172, -1.9030537605285645, -0.06320571899414062, 0.21045875549316406, -0.0029954910278320312, -0.029453277587890625, -0.08050918579101562, 6.123432159423828, -0.36167335510253906, 0.20463180541992188, -0.08382987976074219], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.32130432128906, "min_q": 8.913208961486816, "max_q": 61.56290054321289, "mean_td_error": 0.060319721698760986, "model": {}}, "td_error": [0.05634307861328125, 0.09662246704101562, -0.031058311462402344, -0.2136993408203125, 0.04102325439453125, -0.3145561218261719, -0.16545867919921875, -0.1330547332763672, 0.036846160888671875, -0.18433380126953125, 0.0018157958984375, -0.022430419921875, -0.013397216796875, -0.006824493408203125, 0.04102325439453125, -0.04798698425292969, -0.007556915283203125, 0.09662246704101562, -0.14376068115234375, 0.021411895751953125, -0.21542739868164062, 0.04102325439453125, 1.915557861328125, -0.052669525146484375, -0.031058311462402344, -0.06360721588134766, 0.036846160888671875, -0.16545867919921875, -0.0867910385131836, 1.6730537414550781, -0.21542739868164062, -0.013401031494140625], "custom_metrics": {}}}, "num_steps_sampled": 113904, "num_agent_steps_sampled": 341712, "num_steps_trained": 225824, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 677472, "last_target_update_ts": 113648, "num_target_updates": 221}, "done": false, "episodes_total": 11814, "training_iteration": 113, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-38-06", "timestamp": 1648917486, "time_this_iter_s": 40.67976951599121, "time_total_s": 4504.420396327972, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6eb950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6eb950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4504.420396327972, "timesteps_since_restore": 3616, "iterations_since_restore": 113, "perf": {"cpu_util_percent": 51.35964912280702, "ram_util_percent": 65.61228070175439}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.45, "episode_len_mean": 8.433333333333334, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.483333333333334, "policy1": 61.483333333333334, "policy2": 61.483333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 180.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 180.0, 180.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 10, 9, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 10, 10, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 9, 10, 8, 10, 10, 9, 9, 10, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0535689196795242, "mean_inference_ms": 25.774811835626323, "mean_action_processing_ms": 0.2444779077446454, "mean_env_wait_ms": 0.13956677446577034, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 114912, "timesteps_this_iter": 32, "agent_timesteps_total": 344736, "timers": {"load_time_ms": 0.706, "load_throughput": 45334.638, "learn_time_ms": 231.884, "learn_throughput": 138.0, "update_time_ms": 114.932}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.17757797241211, "min_q": 8.773399353027344, "max_q": 60.831398010253906, "mean_td_error": 0.12314021587371826, "model": {}}, "td_error": [-0.16963958740234375, -0.21664810180664062, 0.019550323486328125, -0.2656097412109375, -0.042903900146484375, 2.8139686584472656, -0.048122406005859375, 0.025705337524414062, 0.05913543701171875, 2.3144493103027344, -0.021730422973632812, -0.021730422973632812, 0.5570735931396484, -0.002407073974609375, -0.12952423095703125, -0.31388282775878906, 0.18095779418945312, 0.18095779418945312, 0.0647125244140625, 0.044219970703125, -1.0341072082519531, -0.12952423095703125, -0.23638534545898438, 0.35529327392578125, -0.048122406005859375, 0.013042449951171875, -0.12952423095703125, -0.13479995727539062, -0.22660064697265625, 0.0647125244140625, 0.6543540954589844, -0.23638343811035156], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.972835540771484, "min_q": 5.607492923736572, "max_q": 61.09815216064453, "mean_td_error": 0.6180480718612671, "model": {}}, "td_error": [-0.6348695755004883, -0.13103485107421875, 0.0216827392578125, -0.07805633544921875, -0.09299850463867188, -0.13609695434570312, 7.159021377563477, -0.13103485107421875, 0.6033592224121094, 0.405303955078125, -0.0422821044921875, -0.059795379638671875, -0.0422821044921875, -0.11305427551269531, 0.024425506591796875, -0.071563720703125, -0.18473243713378906, -0.13103485107421875, -0.000335693359375, 0.024425506591796875, -0.44658470153808594, 2.4181785583496094, 0.14374160766601562, 6.607492923736572, -0.3831214904785156, 2.443408966064453, 0.1197967529296875, 0.12777328491210938, 0.14374160766601562, -0.07568359375, -0.07805252075195312, 2.3678016662597656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.070106506347656, "min_q": 8.649267196655273, "max_q": 61.15230941772461, "mean_td_error": 0.1770981252193451, "model": {}}, "td_error": [-0.2158966064453125, -0.05235481262207031, 2.000016212463379, -0.3641777038574219, -0.15276336669921875, -0.3548622131347656, -0.3548622131347656, -0.12760066986083984, 0.14058303833007812, -0.3548622131347656, -0.2548866271972656, -0.3895606994628906, 0.21148109436035156, 0.14006996154785156, -0.3895606994628906, -0.2943229675292969, -1.4833965301513672, -0.1444110870361328, 0.0499725341796875, -0.2874259948730469, -0.34015655517578125, -0.2620429992675781, -0.061840057373046875, 9.87239933013916, -0.13652610778808594, -0.35073280334472656, -0.07155799865722656, -0.21773529052734375, -0.3895606994628906, 0.6885948181152344, -0.044719696044921875, -0.3401603698730469], "custom_metrics": {}}}, "num_steps_sampled": 114912, "num_agent_steps_sampled": 344736, "num_steps_trained": 227840, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 683520, "last_target_update_ts": 114672, "num_target_updates": 223}, "done": false, "episodes_total": 11934, "training_iteration": 114, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-38-47", "timestamp": 1648917527, "time_this_iter_s": 40.838661432266235, "time_total_s": 4545.259057760239, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b55f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b55f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4545.259057760239, "timesteps_since_restore": 3648, "iterations_since_restore": 114, "perf": {"cpu_util_percent": 52.37413793103449, "ram_util_percent": 65.6103448275862}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.5, "episode_len_mean": 8.416666666666666, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.166666666666664, "policy1": 61.166666666666664, "policy2": 61.166666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 180.0, 183.0, 150.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0], "episode_lengths": [8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 10, 9, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 10, 8, 8, 10, 8, 8, 8, 9, 10, 10, 8, 8, 8, 9, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 10], "policy_policy0_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 61.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 61.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 60.0, 61.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.052417856850349, "mean_inference_ms": 25.718459964213967, "mean_action_processing_ms": 0.24403088308865048, "mean_env_wait_ms": 0.13941568328103457, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 115920, "timesteps_this_iter": 32, "agent_timesteps_total": 347760, "timers": {"load_time_ms": 0.713, "load_throughput": 44870.864, "learn_time_ms": 233.908, "learn_throughput": 136.806, "update_time_ms": 101.93}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.40209197998047, "min_q": 7.779180526733398, "max_q": 60.94473648071289, "mean_td_error": 0.19732606410980225, "model": {}}, "td_error": [-0.0773162841796875, -0.2760171890258789, -0.19426536560058594, 0.11714935302734375, 0.3716926574707031, 0.051174163818359375, 0.15500259399414062, -0.041950225830078125, -0.07555389404296875, 0.14267730712890625, 2.8379344940185547, -0.07250022888183594, -0.016717910766601562, 0.0198516845703125, -0.0773162841796875, -0.016717910766601562, -0.008580207824707031, -0.07250022888183594, -0.061214447021484375, 1.115091323852539, -0.039398193359375, 0.23542404174804688, 0.1842803955078125, -1.2208194732666016, -0.3189373016357422, 2.8559608459472656, 0.031162261962890625, -0.039398193359375, 0.7426261901855469, -0.053558349609375, 0.0659942626953125, 0.051174163818359375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.05713653564453, "min_q": 5.777156829833984, "max_q": 61.38702392578125, "mean_td_error": 0.013982385396957397, "model": {}}, "td_error": [-0.05404472351074219, 1.3521156311035156, -0.3448333740234375, 0.0560302734375, -0.21133804321289062, -0.3398303985595703, 0.42462158203125, -1.2270269393920898, -0.07455825805664062, 1.7183685302734375, 0.17212772369384766, -0.14751815795898438, 0.42462158203125, -0.1647186279296875, -0.1603221893310547, -0.6255588531494141, 0.20296478271484375, -0.01030731201171875, -0.3060722351074219, 0.42462158203125, -0.2545738220214844, 0.20296478271484375, 0.3856849670410156, 0.41976165771484375, 0.014232635498046875, 0.02429962158203125, 0.0095062255859375, 0.014232635498046875, -1.2578506469726562, 0.21795654296875, 0.014232635498046875, -0.45235347747802734], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.459083557128906, "min_q": 6.734193801879883, "max_q": 60.916900634765625, "mean_td_error": 0.2367311716079712, "model": {}}, "td_error": [0.2946281433105469, 1.7613906860351562, 1.7613906860351562, -0.093475341796875, -1.1048946380615234, 3.642892837524414, -0.07976818084716797, -0.9373970031738281, -0.09415054321289062, 0.061481475830078125, -0.10158920288085938, -0.11017894744873047, -0.09905815124511719, -0.093475341796875, -0.04144287109375, -0.12074947357177734, -0.19513893127441406, 0.41641998291015625, -0.5733108520507812, 0.13198471069335938, 0.46559906005859375, 2.7136802673339844, 0.0872793197631836, -0.17108154296875, 0.4768714904785156, 0.2233123779296875, 0.18300533294677734, -0.29736328125, -0.06755447387695312, -0.07976818084716797, -0.18862533569335938, -0.19551658630371094], "custom_metrics": {}}}, "num_steps_sampled": 115920, "num_agent_steps_sampled": 347760, "num_steps_trained": 229856, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 689568, "last_target_update_ts": 115696, "num_target_updates": 225}, "done": false, "episodes_total": 12054, "training_iteration": 115, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-39-27", "timestamp": 1648917567, "time_this_iter_s": 39.95232343673706, "time_total_s": 4585.211381196976, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6eb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6eb0e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4585.211381196976, "timesteps_since_restore": 3680, "iterations_since_restore": 115, "perf": {"cpu_util_percent": 51.487719298245615, "ram_util_percent": 65.44385964912281}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.4, "episode_len_mean": 8.366666666666667, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.46666666666667, "policy1": 61.46666666666667, "policy2": 61.46666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 183.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 9, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 9, 8, 10, 9, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 9, 10, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.05237151759806, "mean_inference_ms": 25.713896027984113, "mean_action_processing_ms": 0.24396731215456668, "mean_env_wait_ms": 0.1393711718215188, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 116928, "timesteps_this_iter": 32, "agent_timesteps_total": 350784, "timers": {"load_time_ms": 0.613, "load_throughput": 52196.363, "learn_time_ms": 244.427, "learn_throughput": 130.919, "update_time_ms": 102.848}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.474763870239258, "min_q": 5.939656734466553, "max_q": 61.400970458984375, "mean_td_error": 0.39908260107040405, "model": {}}, "td_error": [-0.11241912841796875, -0.8329925537109375, -0.11241912841796875, 0.25739097595214844, -0.3273582458496094, -0.341552734375, 0.009311676025390625, -0.08889007568359375, -0.40354156494140625, 0.02532958984375, 0.0368804931640625, 0.06052207946777344, 0.09053421020507812, -0.2540931701660156, 0.009304046630859375, -0.1744232177734375, 2.4745960235595703, -0.225433349609375, -0.08649444580078125, 0.09053421020507812, 1.1014595031738281, 0.023715972900390625, 2.3938980102539062, 0.07233047485351562, 0.04266357421875, -0.3273582458496094, -0.05883598327636719, 6.939656734466553, 0.0368804931640625, -0.05883598327636719, 0.019369125366210938, 2.4909133911132812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.93633270263672, "min_q": 8.1378755569458, "max_q": 60.217342376708984, "mean_td_error": -0.0413738489151001, "model": {}}, "td_error": [-0.33027076721191406, -0.07103347778320312, 0.08104896545410156, -0.22430038452148438, -0.4987373352050781, 2.130626678466797, -0.14020824432373047, 0.33568286895751953, 0.028860092163085938, -0.4634819030761719, -0.12455558776855469, 0.6018028259277344, -0.5338020324707031, -0.4381866455078125, 0.028860092163085938, -0.13672828674316406, -0.2926483154296875, -0.07103347778320312, 0.29393768310546875, -0.32492828369140625, -0.5338020324707031, -0.03726387023925781, 0.027940750122070312, -0.03726387023925781, -0.07103347778320312, 0.13515853881835938, 0.015262603759765625, -0.4381866455078125, -0.025774002075195312, 0.3812427520751953, -0.15296173095703125, -0.4381866455078125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.47181701660156, "min_q": 7.481751918792725, "max_q": 61.26910400390625, "mean_td_error": 0.10844734311103821, "model": {}}, "td_error": [-0.05866241455078125, 0.00891876220703125, 0.037555694580078125, 3.335324764251709, -0.034938812255859375, -0.0499420166015625, 0.0117950439453125, -1.047469139099121, -0.19730186462402344, -0.5601539611816406, -0.1229705810546875, 0.07685470581054688, -0.057765960693359375, -0.19730186462402344, 1.9489707946777344, -0.020166397094726562, -0.0499420166015625, -0.006504058837890625, -0.16420936584472656, 0.11910581588745117, -0.21421241760253906, -0.19730186462402344, 0.24010276794433594, 0.12572669982910156, -0.25004005432128906, 0.037555694580078125, 0.0117950439453125, 0.06343460083007812, 0.18360137939453125, -0.03023815155029297, 0.0375518798828125, 0.49114227294921875], "custom_metrics": {}}}, "num_steps_sampled": 116928, "num_agent_steps_sampled": 350784, "num_steps_trained": 231872, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 695616, "last_target_update_ts": 116720, "num_target_updates": 227}, "done": false, "episodes_total": 12174, "training_iteration": 116, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-40-07", "timestamp": 1648917607, "time_this_iter_s": 40.65269446372986, "time_total_s": 4625.864075660706, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a7440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a7440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4625.864075660706, "timesteps_since_restore": 3712, "iterations_since_restore": 116, "perf": {"cpu_util_percent": 51.23103448275862, "ram_util_percent": 65.70344827586206}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.86885245901638, "episode_len_mean": 8.295081967213115, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.622950819672134, "policy1": 61.622950819672134, "policy2": 61.622950819672134}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 150.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 9, 9, 8, 8, 9, 8, 8, 8, 9, 10, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0530646854496997, "mean_inference_ms": 25.714697747941347, "mean_action_processing_ms": 0.24398803093212693, "mean_env_wait_ms": 0.13936934255337624, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 117936, "timesteps_this_iter": 32, "agent_timesteps_total": 353808, "timers": {"load_time_ms": 0.764, "load_throughput": 41910.298, "learn_time_ms": 244.905, "learn_throughput": 130.663, "update_time_ms": 102.533}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.996639251708984, "min_q": 4.999774932861328, "max_q": 60.69023132324219, "mean_td_error": 0.47194862365722656, "model": {}}, "td_error": [-0.32743072509765625, -0.4253730773925781, -0.4699440002441406, -0.13295936584472656, -0.008554458618164062, -0.031414031982421875, -0.5305404663085938, -0.6209907531738281, -0.32743072509765625, -0.4253730773925781, -0.4253730773925781, 2.7374215126037598, -0.4253730773925781, 5.999774932861328, -0.5016059875488281, -0.022432327270507812, 2.710559844970703, -0.301910400390625, 0.6843509674072266, -0.031414031982421875, 0.11253166198730469, -0.5305404663085938, -0.5305404663085938, 0.2021312713623047, -0.056125640869140625, -0.5223312377929688, -0.5944976806640625, 2.4905929565429688, -0.5223312377929688, -0.2859535217285156, -0.29792213439941406, 8.513355255126953], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.516822814941406, "min_q": 7.446393966674805, "max_q": 60.825035095214844, "mean_td_error": 0.45628413558006287, "model": {}}, "td_error": [0.08428668975830078, 0.16623687744140625, 1.4642391204833984, 1.6641502380371094, 0.09897804260253906, 0.066680908203125, -0.23231124877929688, 0.35100555419921875, -0.18809890747070312, -0.23231124877929688, -0.6345500946044922, -0.055324554443359375, -0.06018829345703125, -0.01424407958984375, 0.07527542114257812, 0.13976287841796875, 0.06293296813964844, 0.023792266845703125, -0.23666000366210938, -0.2628822326660156, -0.8373832702636719, 0.08127212524414062, -0.23231124877929688, 9.776710510253906, -0.047119140625, -0.06018829345703125, 0.013265609741210938, 1.5111713409423828, 0.15291786193847656, 2.4187355041503906, -0.19386672973632812, -0.2628822326660156], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.610666275024414, "min_q": 5.560293674468994, "max_q": 61.19523620605469, "mean_td_error": 0.06915484368801117, "model": {}}, "td_error": [-0.47113800048828125, 3.448179244995117, 0.2147979736328125, -0.2697257995605469, 0.13834381103515625, -0.2573661804199219, -0.22672653198242188, -0.0670166015625, 0.15829849243164062, -0.3045825958251953, -0.048175811767578125, 0.09813690185546875, -0.1621847152709961, -0.17914962768554688, -0.24254703521728516, -0.6093940734863281, -0.031719207763671875, -0.025394439697265625, -0.048175811767578125, -0.0670166015625, 2.903841018676758, -0.28374481201171875, 2.1373519897460938, -3.439706325531006, 0.09819793701171875, -0.0009002685546875, 0.17516326904296875, 0.2147979736328125, -0.3045825958251953, 0.2586231231689453, -0.28894710540771484, -0.3045825958251953], "custom_metrics": {}}}, "num_steps_sampled": 117936, "num_agent_steps_sampled": 353808, "num_steps_trained": 233888, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 701664, "last_target_update_ts": 117744, "num_target_updates": 229}, "done": false, "episodes_total": 12296, "training_iteration": 117, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-40-49", "timestamp": 1648917649, "time_this_iter_s": 41.60060524940491, "time_total_s": 4667.4646809101105, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4667.4646809101105, "timesteps_since_restore": 3744, "iterations_since_restore": 117, "perf": {"cpu_util_percent": 52.23898305084746, "ram_util_percent": 65.86610169491526}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.51239669421489, "episode_len_mean": 8.330578512396695, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.50413223140496, "policy1": 61.50413223140496, "policy2": 61.50413223140496}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 186.0, 183.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 180.0, 180.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 9, 8, 8, 10, 10, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 10, 10, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 60.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0542954483912153, "mean_inference_ms": 25.74194283227773, "mean_action_processing_ms": 0.2442208596396049, "mean_env_wait_ms": 0.13950037201267307, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 118944, "timesteps_this_iter": 32, "agent_timesteps_total": 356832, "timers": {"load_time_ms": 0.663, "load_throughput": 48232.913, "learn_time_ms": 236.814, "learn_throughput": 135.127, "update_time_ms": 103.879}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.365734100341797, "min_q": 8.605437278747559, "max_q": 60.461273193359375, "mean_td_error": -0.001977980136871338, "model": {}}, "td_error": [0.12725830078125, -0.580657958984375, -0.221649169921875, 0.12725830078125, 0.42659664154052734, -0.5301055908203125, 0.32689857482910156, -0.013721466064453125, -0.3945627212524414, -0.5194473266601562, -0.05283355712890625, 0.5828933715820312, -0.013721466064453125, 0.19706153869628906, 0.11496353149414062, -0.19097900390625, 0.20222091674804688, -0.5527000427246094, -0.13109207153320312, 0.12725830078125, 0.5828933715820312, 1.5556793212890625, -0.08955192565917969, -0.608062744140625, -0.03419303894042969, 0.1275005340576172, -0.12584686279296875, 0.017698287963867188, -0.2739219665527344, 0.12725830078125, -0.12585067749023438, -0.24783706665039062], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.28485870361328, "min_q": 8.897143363952637, "max_q": 61.306480407714844, "mean_td_error": 0.7927814722061157, "model": {}}, "td_error": [0.8951988220214844, -0.02906036376953125, 27.06388282775879, -0.048191070556640625, 0.0140228271484375, -0.11411285400390625, -0.1015472412109375, -0.30493927001953125, 0.6544933319091797, -0.24740982055664062, -0.1015472412109375, -0.06931686401367188, 0.022380828857421875, -0.126861572265625, -0.24335670471191406, 0.0140228271484375, -0.2787437438964844, 0.040435791015625, -0.06931686401367188, -0.0395965576171875, -0.1015472412109375, -0.11411285400390625, -0.21999359130859375, -0.23706626892089844, 0.044281005859375, -0.10285663604736328, -0.04769134521484375, -0.220489501953125, -0.10783767700195312, -0.2819404602050781, -0.06931877136230469, -0.10285568237304688], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.67640686035156, "min_q": 8.678080558776855, "max_q": 61.11164093017578, "mean_td_error": -0.09933456778526306, "model": {}}, "td_error": [-0.14483261108398438, -0.012281417846679688, -0.17392349243164062, -0.20195960998535156, -0.14483261108398438, 0.054443359375, 0.4999542236328125, -0.06055259704589844, 0.011251449584960938, -0.25337982177734375, -0.14862823486328125, -0.17392349243164062, -0.25314998626708984, -0.11533355712890625, -0.17392349243164062, -0.1538829803466797, -0.14136123657226562, -0.03844451904296875, -0.29129791259765625, -0.1538829803466797, -0.14483261108398438, 0.015508651733398438, -0.16532516479492188, -0.32191944122314453, 0.13164138793945312, -0.11533355712890625, -0.1611471176147461, -0.0030670166015625, -0.011341094970703125, -0.11533355712890625, -0.07625389099121094, -0.14136123657226562], "custom_metrics": {}}}, "num_steps_sampled": 118944, "num_agent_steps_sampled": 356832, "num_steps_trained": 235904, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 707712, "last_target_update_ts": 118768, "num_target_updates": 231}, "done": false, "episodes_total": 12417, "training_iteration": 118, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-41-30", "timestamp": 1648917690, "time_this_iter_s": 40.52138614654541, "time_total_s": 4707.986067056656, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4707.986067056656, "timesteps_since_restore": 3776, "iterations_since_restore": 118, "perf": {"cpu_util_percent": 51.521052631578954, "ram_util_percent": 65.45087719298246}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.2, "episode_len_mean": 8.433333333333334, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.4, "policy1": 61.4, "policy2": 61.4}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 9, 8, 8, 8, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 10, 10, 8, 10, 8, 8, 8, 10, 10, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8], "policy_policy0_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0543620843319261, "mean_inference_ms": 25.727151010232227, "mean_action_processing_ms": 0.24415893669806407, "mean_env_wait_ms": 0.13956171299427064, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 119952, "timesteps_this_iter": 32, "agent_timesteps_total": 359856, "timers": {"load_time_ms": 0.638, "load_throughput": 50146.732, "learn_time_ms": 244.333, "learn_throughput": 130.969, "update_time_ms": 105.644}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.439668655395508, "min_q": 4.798038959503174, "max_q": 60.9265022277832, "mean_td_error": 0.6825363636016846, "model": {}}, "td_error": [-0.22732162475585938, -0.023134231567382812, -0.22732162475585938, -0.11724090576171875, -0.01348876953125, 1.9860401153564453, 0.00766754150390625, -0.01348876953125, 0.12049674987792969, 0.14780426025390625, 0.004161834716796875, -0.07790756225585938, -0.0843505859375, 5.798038959503174, -2.280024528503418, 8.599180221557617, -0.09125518798828125, 0.4385185241699219, 0.2245922088623047, -0.5834693908691406, -0.1529388427734375, 0.1397867202758789, 0.31624794006347656, 2.8120079040527344, 0.24770736694335938, 0.14780426025390625, 0.5048274993896484, 0.08754730224609375, 0.32767295837402344, 2.486495018005371, 1.08880615234375, 0.24770355224609375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.512393951416016, "min_q": 6.713326930999756, "max_q": 61.309791564941406, "mean_td_error": 0.17781049013137817, "model": {}}, "td_error": [-0.21473407745361328, -0.17444992065429688, -0.3461418151855469, -0.28105926513671875, -0.2659931182861328, -1.3681740760803223, -0.27437782287597656, -0.19652938842773438, 3.1942033767700195, -0.17444992065429688, -0.15779876708984375, -0.5111618041992188, -0.21113967895507812, 7.713326930999756, -0.230255126953125, -0.20043563842773438, 0.6603240966796875, -0.14983558654785156, 0.08690643310546875, -0.21113967895507812, -0.230255126953125, -0.14488601684570312, -0.20885562896728516, -0.08948707580566406, -0.12290573120117188, -0.21506881713867188, -0.07346725463867188, -0.19974327087402344, -0.18134307861328125, -0.20043563842773438, 0.8742809295654297, -0.20498275756835938], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.31959533691406, "min_q": -0.05687904357910156, "max_q": 61.373619079589844, "mean_td_error": 0.14024944603443146, "model": {}}, "td_error": [0.15958023071289062, -0.2063770294189453, 0.15597152709960938, -0.21591472625732422, 0.076873779296875, 0.11089324951171875, 1.2733755111694336, 0.21132278442382812, -0.2949638366699219, 1.5195503234863281, 0.11089324951171875, 0.43074798583984375, -0.3694877624511719, 0.09732818603515625, -0.36956214904785156, -0.24542617797851562, 0.09732818603515625, -0.4109649658203125, 1.3862419128417969, -0.4342174530029297, -0.21015548706054688, 0.09732818603515625, -1.3382391929626465, 0.15597152709960938, -0.05232810974121094, 0.15597152709960938, 0.04257965087890625, 0.2050018310546875, -0.3531990051269531, 0.19296646118164062, 0.34922027587890625, 2.1596717834472656], "custom_metrics": {}}}, "num_steps_sampled": 119952, "num_agent_steps_sampled": 359856, "num_steps_trained": 237920, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 713760, "last_target_update_ts": 119792, "num_target_updates": 233}, "done": false, "episodes_total": 12537, "training_iteration": 119, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-42-11", "timestamp": 1648917731, "time_this_iter_s": 40.91611433029175, "time_total_s": 4748.902181386948, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64a3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64a3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4748.902181386948, "timesteps_since_restore": 3808, "iterations_since_restore": 119, "perf": {"cpu_util_percent": 51.546551724137935, "ram_util_percent": 65.71896551724137}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 184.075, "episode_len_mean": 8.308333333333334, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.358333333333334, "policy1": 61.358333333333334, "policy2": 61.358333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 120.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 180.0], "episode_lengths": [8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 10, 8, 8, 9, 8, 8, 10, 8, 10, 10, 8, 9, 8, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 10, 8, 8, 9, 8, 10], "policy_policy0_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0], "policy_policy1_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0], "policy_policy2_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 40.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0528107740410146, "mean_inference_ms": 25.6551961119186, "mean_action_processing_ms": 0.24366975625592555, "mean_env_wait_ms": 0.13924667784857145, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 120960, "timesteps_this_iter": 32, "agent_timesteps_total": 362880, "timers": {"load_time_ms": 0.648, "load_throughput": 49344.753, "learn_time_ms": 238.451, "learn_throughput": 134.199, "update_time_ms": 113.975}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.299232482910156, "min_q": 8.88583755493164, "max_q": 61.34526824951172, "mean_td_error": 0.07987764477729797, "model": {}}, "td_error": [-0.07680130004882812, -0.17660903930664062, 1.3163375854492188, -0.10633468627929688, -0.04975128173828125, 0.07947540283203125, 2.2690467834472656, -0.24924087524414062, -0.17694473266601562, -0.37115478515625, 0.1546030044555664, -0.7484550476074219, -0.021833419799804688, 1.2182731628417969, 0.09515380859375, -0.10633468627929688, -0.048614501953125, -1.9448833465576172, -0.03611183166503906, -0.11416244506835938, -0.27034759521484375, -0.12174224853515625, 0.1740570068359375, -0.17694473266601562, -0.021833419799804688, -0.10633468627929688, 1.8924884796142578, 0.21554183959960938, -0.021833419799804688, -0.021833419799804688, 0.2155437469482422, -0.10633468627929688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 39.06049346923828, "min_q": 2.0661473274230957, "max_q": 61.1001091003418, "mean_td_error": 0.05611279606819153, "model": {}}, "td_error": [-0.04128265380859375, -0.08208847045898438, 0.02972888946533203, 0.058513641357421875, -0.14014053344726562, -0.033115386962890625, -0.12343215942382812, -0.033115386962890625, -0.08208847045898438, 0.039424896240234375, -0.20188522338867188, -0.9063477516174316, 3.0661473274230957, -0.20188522338867188, 1.7795276641845703, 0.15274620056152344, -0.08208847045898438, -0.06719970703125, -0.20188522338867188, 0.10187721252441406, -0.00423431396484375, -0.08495330810546875, 0.3600578308105469, -0.07076263427734375, -0.12343215942382812, -0.00423431396484375, -0.3144187927246094, -0.14014053344726562, -0.29302215576171875, -0.07076263427734375, -0.17126846313476562, -0.3186302185058594], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.52882385253906, "min_q": 6.460636138916016, "max_q": 61.608543395996094, "mean_td_error": 0.27242690324783325, "model": {}}, "td_error": [0.12065505981445312, -0.3679237365722656, 0.9394187927246094, -0.2760124206542969, -0.017093658447265625, -0.216522216796875, -0.22109603881835938, 1.3485984802246094, 0.03354072570800781, 0.22699928283691406, 1.8205986022949219, 2.8697853088378906, 0.10976219177246094, -0.112213134765625, -0.2718009948730469, 0.12065505981445312, -0.017093658447265625, 4.0140228271484375, 0.26102161407470703, -0.22109603881835938, 0.12065505981445312, -0.22109603881835938, -0.1598358154296875, 0.26102161407470703, -0.09918403625488281, -0.14865684509277344, 0.4179553985595703, -0.6506462097167969, -0.2718009948730469, -0.8189201354980469, 0.1222991943359375, 0.021663665771484375], "custom_metrics": {}}}, "num_steps_sampled": 120960, "num_agent_steps_sampled": 362880, "num_steps_trained": 239936, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 719808, "last_target_update_ts": 120816, "num_target_updates": 235}, "done": false, "episodes_total": 12657, "training_iteration": 120, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-42-52", "timestamp": 1648917772, "time_this_iter_s": 41.20977210998535, "time_total_s": 4790.111953496933, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64ae60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4790.111953496933, "timesteps_since_restore": 3840, "iterations_since_restore": 120, "perf": {"cpu_util_percent": 52.03389830508474, "ram_util_percent": 65.58813559322033}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.2396694214876, "episode_len_mean": 8.421487603305785, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.413223140495866, "policy1": 61.413223140495866, "policy2": 61.413223140495866}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0], "episode_lengths": [8, 8, 10, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0552599788137966, "mean_inference_ms": 25.744190412123697, "mean_action_processing_ms": 0.24435642935633528, "mean_env_wait_ms": 0.13964957585326937, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 121968, "timesteps_this_iter": 32, "agent_timesteps_total": 365904, "timers": {"load_time_ms": 0.608, "load_throughput": 52650.921, "learn_time_ms": 233.043, "learn_throughput": 137.314, "update_time_ms": 105.601}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.8928337097168, "min_q": 8.767667770385742, "max_q": 61.28554153442383, "mean_td_error": 0.16455677151679993, "model": {}}, "td_error": [0.1307392120361328, -0.43923377990722656, -0.9365310668945312, 0.1307392120361328, 0.3294239044189453, 1.9942626953125, 0.24629974365234375, 0.05289459228515625, -0.2323322296142578, -0.247039794921875, 0.21901321411132812, 0.1735992431640625, -0.3701667785644531, -0.05088043212890625, 0.007814407348632812, 2.7720603942871094, 0.11699676513671875, -0.06619071960449219, -0.03129768371582031, -0.12153816223144531, 0.3067779541015625, 2.2377967834472656, -0.36499786376953125, -0.18610763549804688, 0.1572704315185547, -0.43923377990722656, 0.11699676513671875, -0.04590892791748047, -0.3522148132324219, -0.18610763549804688, 0.37549591064453125, -0.03258323669433594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.67505645751953, "min_q": 8.969050407409668, "max_q": 61.4324836730957, "mean_td_error": 0.034215062856674194, "model": {}}, "td_error": [-0.049442291259765625, -0.049442291259765625, -0.03094959259033203, -0.244598388671875, 0.06429481506347656, 0.14600753784179688, -0.14368820190429688, 0.1732769012451172, -0.049442291259765625, 0.1732769012451172, -0.1132354736328125, 0.14428329467773438, 0.14428329467773438, -0.13763809204101562, 0.09069061279296875, -0.01471710205078125, -0.049442291259765625, 0.23069381713867188, 0.6781826019287109, -0.18799209594726562, -0.22273635864257812, 0.06760406494140625, 0.1732769012451172, 0.00916290283203125, 0.18159866333007812, -0.22273635864257812, 0.088775634765625, -0.2537727355957031, 0.1584606170654297, 0.09069061279296875, -0.08616065979003906, 0.3363170623779297], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.740434646606445, "min_q": 6.347232818603516, "max_q": 61.42960739135742, "mean_td_error": 0.4892970323562622, "model": {}}, "td_error": [-0.33437156677246094, 0.6285400390625, -0.2304086685180664, 7.824474334716797, 0.0023632049560546875, -0.29788970947265625, -0.3341360092163086, 0.012350082397460938, 0.3611793518066406, -0.19958877563476562, 0.14455032348632812, 0.012350082397460938, -0.01219940185546875, -0.14458847045898438, 0.06982803344726562, 0.015057563781738281, -0.0071468353271484375, -0.1397228240966797, -0.29788970947265625, 0.3611793518066406, -0.12503814697265625, -0.039653778076171875, -0.4321608543395996, 0.8139152526855469, -0.29788970947265625, -0.20098495483398438, 8.295722961425781, 0.030529022216796875, -0.039653778076171875, 0.1692514419555664, 0.030529022216796875, 0.019008636474609375], "custom_metrics": {}}}, "num_steps_sampled": 121968, "num_agent_steps_sampled": 365904, "num_steps_trained": 241952, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 725856, "last_target_update_ts": 121840, "num_target_updates": 237}, "done": false, "episodes_total": 12778, "training_iteration": 121, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-43-34", "timestamp": 1648917814, "time_this_iter_s": 41.28220081329346, "time_total_s": 4831.394154310226, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6647a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6647a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4831.394154310226, "timesteps_since_restore": 3872, "iterations_since_restore": 121, "perf": {"cpu_util_percent": 50.81034482758621, "ram_util_percent": 65.66724137931035}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 182.925, "episode_len_mean": 8.441666666666666, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.975, "policy1": 60.975, "policy2": 60.975}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 120.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 10, 8, 9, 8, 10, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 9, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0545599303568916, "mean_inference_ms": 25.708951260291734, "mean_action_processing_ms": 0.24403526950103513, "mean_env_wait_ms": 0.1394728719364203, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 122976, "timesteps_this_iter": 32, "agent_timesteps_total": 368928, "timers": {"load_time_ms": 0.677, "load_throughput": 47284.738, "learn_time_ms": 225.809, "learn_throughput": 141.713, "update_time_ms": 117.884}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.52549743652344, "min_q": 8.637289047241211, "max_q": 60.773250579833984, "mean_td_error": 0.38428041338920593, "model": {}}, "td_error": [-0.199554443359375, 0.06247711181640625, 9.637289047241211, 0.5132484436035156, 2.0916175842285156, 0.02521514892578125, -0.3181648254394531, 0.32799530029296875, -0.227325439453125, -0.18413734436035156, -0.0341339111328125, -0.0341339111328125, -0.199554443359375, 0.3646583557128906, -0.0003643035888671875, -0.11672210693359375, 0.2672462463378906, 0.055332183837890625, 0.2721824645996094, 0.13907623291015625, -0.227325439453125, -0.2306671142578125, 0.2672462463378906, 1.4146137237548828, -0.0341339111328125, -0.2784004211425781, -0.1388864517211914, -0.06570816040039062, -0.15815162658691406, -0.0003643035888671875, -0.6822357177734375, -0.011260986328125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.48235321044922, "min_q": 4.348241329193115, "max_q": 61.05753707885742, "mean_td_error": 0.1931144893169403, "model": {}}, "td_error": [-0.11231613159179688, -0.15364456176757812, 0.15862274169921875, 0.21814346313476562, -1.5119080543518066, -0.15330123901367188, -0.10651397705078125, -0.10651397705078125, 0.6025447845458984, 0.21814346313476562, 0.27890968322753906, -0.1129302978515625, 0.15862274169921875, 0.34391021728515625, 0.07021141052246094, -0.08306884765625, 0.349212646484375, 0.015380859375, -0.001392364501953125, 0.27809715270996094, -0.15364456176757812, 0.1381816864013672, 0.17538070678710938, 0.1349506378173828, 5.348241329193115, -0.1389617919921875, -0.024566650390625, 0.02982330322265625, 0.349212646484375, -0.16321945190429688, -0.024566650390625, 0.15862274169921875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.22018814086914, "min_q": 5.5177459716796875, "max_q": 61.02073287963867, "mean_td_error": -0.037342995405197144, "model": {}}, "td_error": [0.7481918334960938, 0.10581207275390625, -0.01728057861328125, 0.28216552734375, -0.24098682403564453, 0.23064804077148438, 0.05782890319824219, -0.06374549865722656, 0.45786476135253906, -0.09190177917480469, -0.04859352111816406, 0.21126365661621094, 0.5767250061035156, -3.4822540283203125, -0.06374549865722656, -0.0234375, 0.057891845703125, -0.5529708862304688, -0.01728057861328125, -0.06940078735351562, 1.9458808898925781, -0.06940078735351562, 0.07263755798339844, -0.01728057861328125, -0.08443069458007812, -0.08089447021484375, -0.5680427551269531, -0.14154815673828125, -0.06374549865722656, -0.12186050415039062, -0.0844268798828125, -0.03865814208984375], "custom_metrics": {}}}, "num_steps_sampled": 122976, "num_agent_steps_sampled": 368928, "num_steps_trained": 243968, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 731904, "last_target_update_ts": 122864, "num_target_updates": 239}, "done": false, "episodes_total": 12898, "training_iteration": 122, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-44-14", "timestamp": 1648917854, "time_this_iter_s": 40.053224325180054, "time_total_s": 4871.4473786354065, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c664c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c664c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4871.4473786354065, "timesteps_since_restore": 3904, "iterations_since_restore": 122, "perf": {"cpu_util_percent": 50.808771929824566, "ram_util_percent": 65.46842105263158}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.7, "episode_len_mean": 8.35, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.56666666666667, "policy1": 61.56666666666667, "policy2": 61.56666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 10, 8, 8, 8, 9, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0544118002221965, "mean_inference_ms": 25.704996641302856, "mean_action_processing_ms": 0.24392564292799662, "mean_env_wait_ms": 0.13942667856237043, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 123984, "timesteps_this_iter": 32, "agent_timesteps_total": 371952, "timers": {"load_time_ms": 0.665, "load_throughput": 48118.785, "learn_time_ms": 226.28, "learn_throughput": 141.418, "update_time_ms": 106.283}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.721633911132812, "min_q": 8.670014381408691, "max_q": 59.32994079589844, "mean_td_error": -0.03606191277503967, "model": {}}, "td_error": [-0.3898887634277344, -0.35760498046875, -0.128509521484375, -0.222808837890625, -0.35760498046875, -0.3898887634277344, -0.05843162536621094, 0.1373767852783203, -0.2743339538574219, 0.031401634216308594, -0.3898887634277344, -0.24149322509765625, 2.8037843704223633, -0.3898887634277344, -0.3558616638183594, -0.04844093322753906, -0.32193756103515625, -0.2743339538574219, 0.08699417114257812, -0.055164337158203125, -0.3898887634277344, -0.3191490173339844, 0.11971664428710938, -0.01819610595703125, -0.2743339538574219, -0.1302814483642578, 0.11971664428710938, 0.2631092071533203, -0.3299856185913086, -0.3213043212890625, 1.5646324157714844, -0.24149322509765625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.8447380065918, "min_q": 1.0569086074829102, "max_q": 61.025245666503906, "mean_td_error": 0.16123104095458984, "model": {}}, "td_error": [-0.24683380126953125, -0.1084136962890625, 0.10284423828125, 1.5304393768310547, 0.07000160217285156, 0.4052114486694336, 0.113250732421875, -0.16520309448242188, 0.07590866088867188, -0.8014793395996094, -0.6224479675292969, 0.10284423828125, 0.13963699340820312, 0.6389122009277344, 0.47052574157714844, -0.6224479675292969, 0.08090782165527344, -0.023830413818359375, 0.08906173706054688, 0.07590866088867188, 0.07986640930175781, -0.24683380126953125, -0.8120956420898438, -0.2764415740966797, 0.4161109924316406, -0.6690254211425781, -0.6384620666503906, 0.07590866088867188, -0.6224479675292969, 0.07590866088867188, 1.9218730926513672, 4.550234794616699], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.05785369873047, "min_q": 8.281710624694824, "max_q": 60.6743278503418, "mean_td_error": -0.15449002385139465, "model": {}}, "td_error": [0.40598201751708984, -0.22030258178710938, -0.08328628540039062, -0.2908172607421875, -0.15882110595703125, -0.033412933349609375, -0.21664047241210938, 0.2880210876464844, -0.0870065689086914, -0.19090652465820312, 1.1571464538574219, -0.1269683837890625, -0.3191547393798828, -0.3694190979003906, -0.1269683837890625, -0.21664047241210938, -0.08328628540039062, -0.2908172607421875, -0.9408016204833984, -0.6785564422607422, -0.18134307861328125, -0.17979812622070312, -0.5130081176757812, -0.5130081176757812, -0.15882110595703125, 0.5281400680541992, -0.12301445007324219, -0.2908172607421875, -0.18134307861328125, -0.249053955078125, -0.3191547393798828, -0.17980194091796875], "custom_metrics": {}}}, "num_steps_sampled": 123984, "num_agent_steps_sampled": 371952, "num_steps_trained": 245984, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 737952, "last_target_update_ts": 123888, "num_target_updates": 241}, "done": false, "episodes_total": 13018, "training_iteration": 123, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-44-53", "timestamp": 1648917893, "time_this_iter_s": 39.25746488571167, "time_total_s": 4910.704843521118, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b5950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b5950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4910.704843521118, "timesteps_since_restore": 3936, "iterations_since_restore": 123, "perf": {"cpu_util_percent": 52.300000000000004, "ram_util_percent": 65.22321428571429}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 184.925, "episode_len_mean": 8.358333333333333, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.641666666666666, "policy1": 61.641666666666666, "policy2": 61.641666666666666}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0], "episode_lengths": [8, 8, 9, 8, 8, 10, 8, 8, 9, 8, 8, 9, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 9, 8, 9, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 9, 9, 9, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8], "policy_policy0_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0539741702123873, "mean_inference_ms": 25.69835635352208, "mean_action_processing_ms": 0.24376899674437044, "mean_env_wait_ms": 0.13935886584051846, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 124992, "timesteps_this_iter": 32, "agent_timesteps_total": 374976, "timers": {"load_time_ms": 0.613, "load_throughput": 52220.733, "learn_time_ms": 228.976, "learn_throughput": 139.752, "update_time_ms": 124.58}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.520421981811523, "min_q": 6.743223190307617, "max_q": 61.77011489868164, "mean_td_error": -0.1085827648639679, "model": {}}, "td_error": [-0.12433815002441406, -0.3972816467285156, -0.5337104797363281, -0.20878219604492188, 0.04015350341796875, 0.14497947692871094, -0.17955398559570312, -0.10057830810546875, -0.18142127990722656, -0.2927398681640625, -0.40821075439453125, -0.04708385467529297, 0.2511100769042969, -0.10057830810546875, -0.26438188552856445, -0.5337104797363281, -0.04708385467529297, 2.3613829612731934, -0.2773599624633789, -0.024951934814453125, -0.5337104797363281, 0.3041515350341797, -0.2561149597167969, -0.5337104797363281, -0.40821075439453125, -0.35202789306640625, 0.059986114501953125, 0.059986114501953125, -0.4324607849121094, -0.4060020446777344, -0.4367666244506836, 0.3843727111816406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 39.511863708496094, "min_q": 7.95778751373291, "max_q": 60.88701248168945, "mean_td_error": 0.06633642315864563, "model": {}}, "td_error": [-0.16256332397460938, -0.16256332397460938, 0.11228179931640625, 0.7787399291992188, -0.17417526245117188, 0.11228179931640625, 0.10723495483398438, -0.023471832275390625, 0.10723495483398438, 0.2629985809326172, -0.236419677734375, -0.16256332397460938, 0.1553192138671875, -0.013220787048339844, -0.2314300537109375, 0.005809783935546875, 2.2819480895996094, -0.019817352294921875, -0.019817352294921875, -0.09926795959472656, -0.22799110412597656, -0.2314300537109375, -0.035251617431640625, 0.12504959106445312, 0.10723495483398438, 0.0132904052734375, -0.019817352294921875, 0.0264739990234375, -0.5496501922607422, -0.024753570556640625, 0.20878982543945312, 0.11228179931640625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.299739837646484, "min_q": 5.5161895751953125, "max_q": 61.398155212402344, "mean_td_error": 0.5813108682632446, "model": {}}, "td_error": [0.25508689880371094, -0.21027755737304688, 0.3167991638183594, 8.500709533691406, 0.11200332641601562, -0.3208332061767578, 0.3022117614746094, -0.33293724060058594, 0.12213897705078125, -0.5353431701660156, 0.2767667770385742, 0.09935760498046875, 6.5161895751953125, 0.13265609741210938, 0.3698883056640625, 0.11200332641601562, 0.008022308349609375, 0.3167991638183594, 0.3432636260986328, -0.036479949951171875, -0.08843612670898438, -0.2564845085144043, -0.06069755554199219, -0.1795654296875, 0.4312705993652344, 0.1629180908203125, 0.11200332641601562, 0.7387008666992188, 0.22899246215820312, 0.9049091339111328, 0.11200332641601562, 0.14830970764160156], "custom_metrics": {}}}, "num_steps_sampled": 124992, "num_agent_steps_sampled": 374976, "num_steps_trained": 248000, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 744000, "last_target_update_ts": 124912, "num_target_updates": 243}, "done": false, "episodes_total": 13138, "training_iteration": 124, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-45-33", "timestamp": 1648917933, "time_this_iter_s": 39.966899156570435, "time_total_s": 4950.671742677689, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c703680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c703680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4950.671742677689, "timesteps_since_restore": 3968, "iterations_since_restore": 124, "perf": {"cpu_util_percent": 50.230357142857144, "ram_util_percent": 65.0875}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.8181818181818, "episode_len_mean": 8.396694214876034, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.27272727272727, "policy1": 61.27272727272727, "policy2": 61.27272727272727}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0], "episode_lengths": [9, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 9, 10, 10, 8, 10, 8, 10, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 10, 8, 10, 10, 8, 10, 8], "policy_policy0_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0545448925428416, "mean_inference_ms": 25.72294696597551, "mean_action_processing_ms": 0.24391768296406321, "mean_env_wait_ms": 0.13945156229199387, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 126000, "timesteps_this_iter": 32, "agent_timesteps_total": 378000, "timers": {"load_time_ms": 0.765, "load_throughput": 41837.14, "learn_time_ms": 228.932, "learn_throughput": 139.78, "update_time_ms": 115.215}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.699121475219727, "min_q": 9.077996253967285, "max_q": 61.92575454711914, "mean_td_error": 0.06416657567024231, "model": {}}, "td_error": [-0.3172874450683594, -0.4009819030761719, -0.0976409912109375, 0.23361968994140625, -0.17468643188476562, -0.09814834594726562, 0.3196849822998047, 0.13422203063964844, 0.057506561279296875, 0.1500377655029297, 0.07799625396728516, 0.0479736328125, -0.09814834594726562, 0.17334556579589844, 0.10183143615722656, 0.10183143615722656, 0.0479736328125, -0.3557777404785156, 0.18585205078125, 0.10669708251953125, 0.057506561279296875, -0.09814834594726562, 0.39781761169433594, 1.9024200439453125, -0.3557777404785156, 0.10183143615722656, 0.2127532958984375, 0.26658058166503906, -0.22516441345214844, -0.3172874450683594, -0.0976409912109375, 0.012538909912109375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.893585205078125, "min_q": 9.145197868347168, "max_q": 61.03164291381836, "mean_td_error": 0.05247807502746582, "model": {}}, "td_error": [0.373931884765625, -0.49350738525390625, -0.009023666381835938, 0.26638031005859375, -0.07958221435546875, -0.009023666381835938, -0.009023666381835938, 0.289520263671875, 0.15967178344726562, -0.13414764404296875, -0.01764678955078125, 0.19122886657714844, -0.09665870666503906, -0.3653106689453125, -0.3571815490722656, 0.17240333557128906, -0.3653106689453125, -0.1786041259765625, 0.14519786834716797, 0.2626209259033203, 0.15967178344726562, -0.11032485961914062, 0.15967178344726562, -0.01764678955078125, 1.9460029602050781, -0.1532745361328125, 0.15967178344726562, -0.3583946228027344, 0.007068634033203125, -0.009023666381835938, -0.09666061401367188, 0.24660205841064453], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.473251342773438, "min_q": 8.718925476074219, "max_q": 61.21379089355469, "mean_td_error": 0.2558557391166687, "model": {}}, "td_error": [-0.011232376098632812, 0.44025421142578125, 0.025112152099609375, 1.0684051513671875, 0.3811798095703125, -0.011232376098632812, 0.37317657470703125, 0.3248329162597656, 2.378190040588379, 0.07431411743164062, -0.11797904968261719, -0.28107452392578125, 0.03096771240234375, 0.20587921142578125, 0.44025421142578125, -0.021448135375976562, -0.011232376098632812, 0.3345298767089844, 0.057567596435546875, 0.44025421142578125, 0.37317657470703125, 0.14136886596679688, -0.15398788452148438, -0.2510557174682617, 0.3345298767089844, -0.021448135375976562, 0.1182403564453125, 0.600982666015625, 0.14136886596679688, -0.07350921630859375, 0.10014152526855469, 0.7568569183349609], "custom_metrics": {}}}, "num_steps_sampled": 126000, "num_agent_steps_sampled": 378000, "num_steps_trained": 250016, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 750048, "last_target_update_ts": 125936, "num_target_updates": 245}, "done": false, "episodes_total": 13259, "training_iteration": 125, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-46-13", "timestamp": 1648917973, "time_this_iter_s": 39.50991177558899, "time_total_s": 4990.181654453278, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64cd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64cd40>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 4990.181654453278, "timesteps_since_restore": 4000, "iterations_since_restore": 125, "perf": {"cpu_util_percent": 50.63214285714286, "ram_util_percent": 65.06964285714285}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 183.75, "episode_len_mean": 8.416666666666666, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.25, "policy1": 61.25, "policy2": 61.25}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 120.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0], "episode_lengths": [9, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 9, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 8, 9, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 9, 10, 8, 8, 8, 9, 8, 8], "policy_policy0_reward": [61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0], "policy_policy1_reward": [61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0], "policy_policy2_reward": [61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.053570574769237, "mean_inference_ms": 25.69333518602242, "mean_action_processing_ms": 0.24356700467548265, "mean_env_wait_ms": 0.13926829953263192, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 127008, "timesteps_this_iter": 32, "agent_timesteps_total": 381024, "timers": {"load_time_ms": 0.633, "load_throughput": 50564.244, "learn_time_ms": 223.851, "learn_throughput": 142.952, "update_time_ms": 116.444}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 39.78650665283203, "min_q": 8.453619003295898, "max_q": 62.3744010925293, "mean_td_error": 0.1711384654045105, "model": {}}, "td_error": [0.04749298095703125, 0.3741950988769531, -0.5463809967041016, 0.3076362609863281, -0.028583526611328125, -0.08573341369628906, 3.116954803466797, 0.0070648193359375, -0.2561149597167969, -0.3150444030761719, -0.13852691650390625, -0.028583526611328125, -0.06346893310546875, 2.73052978515625, 0.2906150817871094, 0.3741950988769531, -0.3092479705810547, 0.08570098876953125, 0.0316925048828125, -0.4480857849121094, 0.3076362609863281, -0.2561149597167969, -0.1650848388671875, -0.5277748107910156, 0.5659370422363281, 0.004940032958984375, 0.5359535217285156, 0.09434127807617188, 0.06640625, 0.20173263549804688, -0.8054885864257812, 0.30764007568359375], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.316757202148438, "min_q": 8.946476936340332, "max_q": 59.27299880981445, "mean_td_error": 0.604703426361084, "model": {}}, "td_error": [-0.08281707763671875, 0.07684326171875, 0.3494415283203125, 0.239593505859375, 0.2581214904785156, 0.12905502319335938, 0.08153533935546875, 0.3073234558105469, -0.00994873046875, 2.9691076278686523, 17.617673873901367, -0.4929771423339844, 0.2822990417480469, -0.5093917846679688, -0.153045654296875, -0.5928688049316406, -0.08721923828125, -0.011829376220703125, 0.08007621765136719, -0.05352306365966797, 0.034763336181640625, 0.08153533935546875, -0.5093917846679688, 0.08007621765136719, -0.4929771423339844, 0.1049346923828125, 0.04952049255371094, -0.05352306365966797, -0.36934852600097656, 0.08153533935546875, -0.05323028564453125, -0.0008335113525390625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.16301345825195, "min_q": 5.098958492279053, "max_q": 61.53750228881836, "mean_td_error": 0.5159792304039001, "model": {}}, "td_error": [6.098958492279053, 0.302642822265625, 2.9615230560302734, 0.23670196533203125, 0.23345565795898438, -0.087982177734375, 0.12589263916015625, 0.028348922729492188, -0.11574172973632812, 0.3704948425292969, 0.08350372314453125, 0.028348922729492188, -0.25342369079589844, -0.5996589660644531, -0.10125732421875, 0.302642822265625, -0.025394439697265625, 0.061126708984375, 0.028348922729492188, 0.10811996459960938, 1.9968757629394531, 2.1762218475341797, 0.210174560546875, 0.18697738647460938, 0.18581008911132812, 0.3704948425292969, 0.8890495300292969, -0.057861328125, -0.027776718139648438, 0.12387466430664062, 0.43738555908203125, 0.2334575653076172], "custom_metrics": {}}}, "num_steps_sampled": 127008, "num_agent_steps_sampled": 381024, "num_steps_trained": 252032, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 756096, "last_target_update_ts": 126960, "num_target_updates": 247}, "done": false, "episodes_total": 13379, "training_iteration": 126, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-46-53", "timestamp": 1648918013, "time_this_iter_s": 40.29792761802673, "time_total_s": 5030.479582071304, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64cf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c64cf80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5030.479582071304, "timesteps_since_restore": 4032, "iterations_since_restore": 126, "perf": {"cpu_util_percent": 51.53684210526316, "ram_util_percent": 65.11929824561403}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.675, "episode_len_mean": 8.358333333333333, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.55833333333333, "policy1": 61.55833333333333, "policy2": 61.55833333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 150.0], "episode_lengths": [8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 10, 8, 10, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 9, 8, 10, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 50.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0532236343211558, "mean_inference_ms": 25.689644505380066, "mean_action_processing_ms": 0.24345800484653962, "mean_env_wait_ms": 0.13927275033343037, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 128016, "timesteps_this_iter": 32, "agent_timesteps_total": 384048, "timers": {"load_time_ms": 0.602, "load_throughput": 53157.641, "learn_time_ms": 231.672, "learn_throughput": 138.126, "update_time_ms": 116.604}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 39.103538513183594, "min_q": 9.051711082458496, "max_q": 61.012725830078125, "mean_td_error": 0.13030359148979187, "model": {}}, "td_error": [0.051711082458496094, -0.447418212890625, -0.3683738708496094, -0.03693389892578125, -0.016483306884765625, 0.139129638671875, 2.31396484375, -0.447418212890625, -0.016483306884765625, 0.07516860961914062, 1.5878124237060547, -0.11529350280761719, 0.2785940170288086, -0.5146312713623047, -0.1670684814453125, -0.016483306884765625, -0.2601966857910156, -0.6926536560058594, 2.059131622314453, 0.2173614501953125, -0.16820144653320312, -0.9384326934814453, -0.3151702880859375, -0.016483306884765625, 0.1751232147216797, -0.19780349731445312, 0.2282419204711914, -0.016483306884765625, -0.6087913513183594, 0.2474365234375, -0.16588401794433594, 2.3227272033691406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.882747650146484, "min_q": 9.091851234436035, "max_q": 61.171573638916016, "mean_td_error": 0.00874510407447815, "model": {}}, "td_error": [-0.020450592041015625, 0.07625579833984375, -0.035297393798828125, -0.3975353240966797, -0.2553672790527344, 0.08926010131835938, 0.09185123443603516, -0.06877517700195312, -0.1995391845703125, 0.08863449096679688, -0.27231597900390625, -0.1380767822265625, 0.09185123443603516, 0.11927986145019531, -0.2900238037109375, 0.3232841491699219, -0.11823463439941406, 1.0788536071777344, -0.2553672790527344, -0.1995391845703125, -0.0046329498291015625, 0.07625579833984375, 0.3202552795410156, 0.11927986145019531, -0.0046329498291015625, 0.3232841491699219, 0.11437225341796875, 0.09185123443603516, 0.017475128173828125, -0.5994186401367188, 0.028371810913085938, 0.08863449096679688], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.174652099609375, "min_q": 0.23251128196716309, "max_q": 60.81512451171875, "mean_td_error": 0.36009740829467773, "model": {}}, "td_error": [2.6906189918518066, 2.723978042602539, -0.12237167358398438, 1.30755615234375, -0.23968505859375, -0.23348236083984375, 1.297515869140625, 2.310527801513672, 0.1825103759765625, 0.1682262420654297, -0.29555702209472656, 0.055896759033203125, 0.055896759033203125, 0.23620223999023438, -0.14427566528320312, 2.2405548095703125, -0.059215545654296875, -0.23968505859375, 0.06260299682617188, 0.31552886962890625, 0.28781700134277344, -0.045841217041015625, -0.23968505859375, 0.23690032958984375, -0.1108403205871582, -1.1383800506591797, -0.08139991760253906, -0.00417327880859375, 0.04306221008300781, -0.08139991760253906, 0.05590057373046875, 0.2878131866455078], "custom_metrics": {}}}, "num_steps_sampled": 128016, "num_agent_steps_sampled": 384048, "num_steps_trained": 254048, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 762144, "last_target_update_ts": 127984, "num_target_updates": 249}, "done": false, "episodes_total": 13499, "training_iteration": 127, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-47-33", "timestamp": 1648918053, "time_this_iter_s": 39.7144992351532, "time_total_s": 5070.1940813064575, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b5950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6b5950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5070.1940813064575, "timesteps_since_restore": 4064, "iterations_since_restore": 127, "perf": {"cpu_util_percent": 51.073684210526324, "ram_util_percent": 65.25087719298246}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 183.975, "episode_len_mean": 8.341666666666667, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.325, "policy1": 61.325, "policy2": 61.325}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 90.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 9, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 9, 10, 8, 8, 8, 8, 8, 8, 10, 9, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 9, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0533394757586063, "mean_inference_ms": 25.686018913329868, "mean_action_processing_ms": 0.2433949268606675, "mean_env_wait_ms": 0.1391712936357375, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 129024, "timesteps_this_iter": 32, "agent_timesteps_total": 387072, "timers": {"load_time_ms": 0.672, "load_throughput": 47608.445, "learn_time_ms": 237.381, "learn_throughput": 134.804, "update_time_ms": 102.465}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 27.90529441833496, "min_q": 8.014823913574219, "max_q": 60.669368743896484, "mean_td_error": 0.032525867223739624, "model": {}}, "td_error": [0.20590972900390625, 0.14727783203125, -0.19127178192138672, -0.9962062835693359, 2.742706298828125, -0.19127178192138672, -0.82330322265625, -0.1715869903564453, -0.9962062835693359, -1.1804180145263672, -0.9372177124023438, 0.21641921997070312, -0.24137115478515625, 1.527552604675293, -0.1715869903564453, 2.4075794219970703, 0.3972015380859375, 0.2982902526855469, 0.062175750732421875, 0.062175750732421875, -1.1375885009765625, 0.015272140502929688, -0.46322154998779297, -0.6364250183105469, 0.3106842041015625, -0.1715869903564453, 0.5453338623046875, -0.29282188415527344, -0.24137115478515625, 0.2828655242919922, 0.057430267333984375, 0.6054086685180664], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.0467643737793, "min_q": 1.9321954250335693, "max_q": 61.29378128051758, "mean_td_error": 0.18020790815353394, "model": {}}, "td_error": [0.5636634826660156, 3.2402305603027344, -0.002910614013671875, 0.09438133239746094, 0.0059356689453125, 0.008026123046875, -0.48540496826171875, 0.03943634033203125, -0.48540496826171875, 6.650484085083008, -0.39909934997558594, 0.11684036254882812, 0.049221038818359375, -0.4950904846191406, -0.002910614013671875, 0.0064239501953125, 0.6926612854003906, 0.0064239501953125, 0.0064239501953125, -0.33881568908691406, -0.48540496826171875, -1.9426727294921875, -0.41658973693847656, 0.059917449951171875, 0.08391952514648438, -0.22667312622070312, 0.008026123046875, 0.08391952514648438, 0.11684036254882812, 0.039073944091796875, -0.33881378173828125, -0.48540496826171875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.42974090576172, "min_q": 9.010381698608398, "max_q": 61.24123764038086, "mean_td_error": 0.31685778498649597, "model": {}}, "td_error": [0.21337127685546875, 0.3323173522949219, 1.7897872924804688, 0.21337127685546875, 10.010381698608398, -0.2362651824951172, -0.301788330078125, 0.26575469970703125, -0.7656173706054688, 0.21337127685546875, 0.3938331604003906, -0.164337158203125, -0.5227565765380859, -0.40586090087890625, -0.14977645874023438, 0.2501945495605469, -0.2362651824951172, -0.8535671234130859, -0.2362651824951172, -0.5989341735839844, 0.2501945495605469, 0.09868812561035156, 0.1733722686767578, 0.26575469970703125, -0.34796905517578125, 0.1733722686767578, -0.1830902099609375, -0.164337158203125, 0.059493064880371094, 0.2028484344482422, -0.164337158203125, 0.5645103454589844], "custom_metrics": {}}}, "num_steps_sampled": 129024, "num_agent_steps_sampled": 387072, "num_steps_trained": 256064, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 768192, "last_target_update_ts": 129008, "num_target_updates": 251}, "done": false, "episodes_total": 13619, "training_iteration": 128, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-48-13", "timestamp": 1648918093, "time_this_iter_s": 40.40841221809387, "time_total_s": 5110.602493524551, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7745f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c7745f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5110.602493524551, "timesteps_since_restore": 4096, "iterations_since_restore": 128, "perf": {"cpu_util_percent": 51.02105263157895, "ram_util_percent": 65.27719298245614}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.6198347107438, "episode_len_mean": 8.380165289256198, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.20661157024794, "policy1": 61.20661157024794, "policy2": 61.20661157024794}, "custom_metrics": {}, "hist_stats": {"episode_reward": [150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 180.0, 183.0, 150.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 8, 8, 8, 8, 8, 10, 9, 8, 8, 9, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 9, 8, 8, 8, 9, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 9, 8, 10, 9, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 61.0, 50.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0523131910353585, "mean_inference_ms": 25.644617863146788, "mean_action_processing_ms": 0.24300966406952654, "mean_env_wait_ms": 0.1390049988452905, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 130032, "timesteps_this_iter": 32, "agent_timesteps_total": 390096, "timers": {"load_time_ms": 0.741, "load_throughput": 43160.989, "learn_time_ms": 222.454, "learn_throughput": 143.85, "update_time_ms": 117.626}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.595252990722656, "min_q": 4.944890022277832, "max_q": 59.994483947753906, "mean_td_error": 0.2732907235622406, "model": {}}, "td_error": [-0.2508049011230469, -0.22907257080078125, -0.3686962127685547, -0.0162200927734375, -0.3894462585449219, -0.15604782104492188, -0.2598152160644531, -0.22591400146484375, -0.2598152160644531, -0.27005767822265625, -0.22501754760742188, -0.17202377319335938, -2.7869949340820312, -0.22048568725585938, -0.5136394500732422, 1.9062271118164062, -0.17202377319335938, 0.17451095581054688, 0.06884002685546875, 5.944890022277832, -1.0203828811645508, 9.50502872467041, -0.23115921020507812, -0.0029964447021484375, -0.3686962127685547, -0.7276687622070312, -0.24465179443359375, 1.623117446899414, -0.2508049011230469, -0.7276687622070312, -0.15604782104492188, -0.23115921020507812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.30521011352539, "min_q": 7.650704860687256, "max_q": 60.710330963134766, "mean_td_error": 0.07611940801143646, "model": {}}, "td_error": [0.08045005798339844, -0.4115409851074219, -0.327545166015625, -0.327545166015625, -0.06396865844726562, -0.21187210083007812, -0.1295013427734375, -0.4115409851074219, -0.15320205688476562, -0.3199920654296875, -0.3450889587402344, -0.030881881713867188, -0.22069931030273438, 0.08045005798339844, 0.3116950988769531, -0.18358469009399414, -0.21187210083007812, -0.30925750732421875, -0.3199920654296875, 2.5654029846191406, -0.30925750732421875, -0.11383056640625, -0.3450889587402344, 0.0015468597412109375, 0.08045005798339844, 0.36119842529296875, 4.3875579833984375, -0.0844879150390625, -0.11383056640625, -0.06396865844726562, -0.30925750732421875, -0.11512374877929688], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.64034652709961, "min_q": 9.045756340026855, "max_q": 60.61962127685547, "mean_td_error": -0.009965062141418457, "model": {}}, "td_error": [-0.11396026611328125, -0.2330169677734375, 1.3749923706054688, -0.098052978515625, 0.017080307006835938, -0.1082611083984375, 0.28453636169433594, -0.0011768341064453125, -0.8511486053466797, 0.0233917236328125, -0.1657428741455078, 0.15300941467285156, -0.15413284301757812, -0.37805747985839844, 0.04575634002685547, -0.14925003051757812, 0.0233917236328125, -0.1587810516357422, -0.24239349365234375, -0.2781658172607422, -0.02017974853515625, 0.03789520263671875, -0.14772605895996094, -0.4049186706542969, 0.0745697021484375, -0.0011768341064453125, -0.4355812072753906, -0.1390361785888672, 0.5517349243164062, 1.240518569946289, -0.12655258178710938, 0.061553001403808594], "custom_metrics": {}}}, "num_steps_sampled": 130032, "num_agent_steps_sampled": 390096, "num_steps_trained": 258080, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 774240, "last_target_update_ts": 130032, "num_target_updates": 253}, "done": false, "episodes_total": 13740, "training_iteration": 129, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-48-53", "timestamp": 1648918133, "time_this_iter_s": 39.822394609451294, "time_total_s": 5150.424888134003, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a1320>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5150.424888134003, "timesteps_since_restore": 4128, "iterations_since_restore": 129, "perf": {"cpu_util_percent": 51.873684210526314, "ram_util_percent": 65.01052631578948}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 184.1, "episode_len_mean": 8.383333333333333, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.36666666666667, "policy1": 61.36666666666667, "policy2": 61.36666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 90.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 9, 10, 9, 8, 10, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 10, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0529771737827347, "mean_inference_ms": 25.67291615635974, "mean_action_processing_ms": 0.2431806883842952, "mean_env_wait_ms": 0.13912134906143167, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 131040, "timesteps_this_iter": 32, "agent_timesteps_total": 393120, "timers": {"load_time_ms": 0.666, "load_throughput": 48080.863, "learn_time_ms": 227.517, "learn_throughput": 140.649, "update_time_ms": 110.334}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.60492706298828, "min_q": 9.74341869354248, "max_q": 60.50799560546875, "mean_td_error": 0.3536142408847809, "model": {}}, "td_error": [0.11091232299804688, 0.11063957214355469, 0.029857635498046875, 0.01192474365234375, 0.36229705810546875, 0.11104965209960938, 0.11063957214355469, 1.1609344482421875, 0.6952629089355469, 0.4818706512451172, 0.029857635498046875, 0.36229705810546875, 0.10626983642578125, 0.6952629089355469, -0.2958831787109375, 3.6021547317504883, 2.4546871185302734, 0.4966850280761719, 0.029857635498046875, 0.36229705810546875, -0.1656341552734375, -0.2671642303466797, 0.10626983642578125, 0.5395050048828125, -0.02706146240234375, 0.20824813842773438, -0.1656341552734375, 0.10626983642578125, 0.029857635498046875, -0.1656341552734375, 0.20185279846191406, -0.11409378051757812], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.10295867919922, "min_q": 8.747586250305176, "max_q": 61.61595916748047, "mean_td_error": 0.030181884765625, "model": {}}, "td_error": [0.181610107421875, 0.10982704162597656, 0.04754638671875, -0.091217041015625, 0.11774063110351562, -0.011963844299316406, 1.27398681640625, -0.15466690063476562, 2.467374801635742, -0.04068183898925781, -0.2802867889404297, -0.011963844299316406, -0.32861328125, 0.08384323120117188, -0.11866378784179688, -0.15466690063476562, -0.165740966796875, 0.05002593994140625, 0.07712936401367188, -1.2471427917480469, -0.165740966796875, -0.165740966796875, 0.05002593994140625, -0.22306251525878906, -0.165740966796875, -0.165740966796875, 0.32590770721435547, -0.13939666748046875, -0.2524137496948242, 0.11774063110351562, -0.171234130859375, 0.11774063110351562], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.92449951171875, "min_q": 8.882905960083008, "max_q": 60.94019317626953, "mean_td_error": -0.12916621565818787, "model": {}}, "td_error": [-0.4142608642578125, 0.1730670928955078, -0.019560813903808594, -0.4503059387207031, -0.19459152221679688, -0.40692138671875, -0.40692138671875, -0.2803916931152344, 0.10171031951904297, -0.21640777587890625, 0.07305908203125, -0.4272422790527344, -0.11709403991699219, 0.07373809814453125, -0.17529678344726562, -0.40692138671875, -0.07794189453125, 0.11985397338867188, -0.019560813903808594, -0.11909103393554688, -0.3454856872558594, -0.40692138671875, 0.4018573760986328, -0.40692138671875, -0.17529678344726562, 0.1730670928955078, -0.27448081970214844, -0.40692138671875, 0.16031265258789062, 0.40817832946777344, 0.28145599365234375, -0.35108184814453125], "custom_metrics": {}}}, "num_steps_sampled": 131040, "num_agent_steps_sampled": 393120, "num_steps_trained": 260096, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 780288, "last_target_update_ts": 130544, "num_target_updates": 254}, "done": false, "episodes_total": 13860, "training_iteration": 130, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-49-33", "timestamp": 1648918173, "time_this_iter_s": 39.69831657409668, "time_total_s": 5190.123204708099, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5190.123204708099, "timesteps_since_restore": 4160, "iterations_since_restore": 130, "perf": {"cpu_util_percent": 50.64107142857143, "ram_util_percent": 65.0875}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.46280991735537, "episode_len_mean": 8.347107438016529, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.48760330578512, "policy1": 61.48760330578512, "policy2": 61.48760330578512}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 183.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 150.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 10, 8, 8, 8, 10, 10, 9, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 9, 8, 9, 8, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0505306160055852, "mean_inference_ms": 25.565858956384403, "mean_action_processing_ms": 0.24231435403403068, "mean_env_wait_ms": 0.1386537299655601, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 132048, "timesteps_this_iter": 32, "agent_timesteps_total": 396144, "timers": {"load_time_ms": 0.663, "load_throughput": 48265.869, "learn_time_ms": 225.382, "learn_throughput": 141.981, "update_time_ms": 113.41}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.004661560058594, "min_q": 8.563956260681152, "max_q": 59.84230422973633, "mean_td_error": 0.23064875602722168, "model": {}}, "td_error": [-0.04146575927734375, -0.49443817138671875, 0.06061744689941406, 7.27580451965332, -0.3626708984375, -0.43604373931884766, -0.3063240051269531, 0.13721466064453125, -0.22934722900390625, 0.44170570373535156, -0.4682025909423828, 3.289104461669922, -0.23724079132080078, -0.2693519592285156, -0.07510566711425781, -0.30672454833984375, -0.429229736328125, -0.3245658874511719, -0.30672454833984375, 0.06061744689941406, 0.9283657073974609, 0.0054912567138671875, -0.4262580871582031, -0.19146156311035156, 0.3407402038574219, -0.11960411071777344, -0.3149566650390625, -0.1205596923828125, -0.3245658874511719, -0.3245658874511719, -0.19287109375, 1.1433773040771484], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.65885925292969, "min_q": 6.931095123291016, "max_q": 60.88051223754883, "mean_td_error": -0.11616535484790802, "model": {}}, "td_error": [-0.4271888732910156, -0.16774749755859375, -0.15287399291992188, -0.3471794128417969, 5.008306503295898, -0.26567840576171875, 0.028984546661376953, -0.4271888732910156, -0.6400184631347656, -0.24858474731445312, -0.396697998046875, -0.18981170654296875, 0.014605522155761719, -0.518951416015625, -0.26442527770996094, -0.24194717407226562, -0.6886653900146484, 0.014605522155761719, -0.3921661376953125, -0.3740997314453125, -0.3775596618652344, -0.15903854370117188, -0.15903854370117188, 0.014605522155761719, -0.330841064453125, -0.3473014831542969, -0.16916656494140625, -0.16916656494140625, -0.5398979187011719, -0.4063434600830078, -0.19711685180664062, -0.19970321655273438], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.461753845214844, "min_q": 5.8530426025390625, "max_q": 61.65576934814453, "mean_td_error": -0.015602797269821167, "model": {}}, "td_error": [-0.009246826171875, -0.1121368408203125, -0.04474067687988281, -0.1470623016357422, -0.010730743408203125, 1.1945915222167969, -0.07971572875976562, -0.010730743408203125, -0.07581901550292969, -0.07971572875976562, 0.033969879150390625, 1.8986835479736328, -0.010730743408203125, 0.17798614501953125, 0.00550079345703125, 0.039005279541015625, 0.033504486083984375, -0.2562694549560547, -0.0851898193359375, 0.04164314270019531, 0.07330894470214844, 0.04838752746582031, 0.31295108795166016, -0.18280029296875, 0.027456283569335938, -0.0503082275390625, 0.12735939025878906, -0.010730743408203125, -0.01580047607421875, -0.33835601806640625, -3.1469573974609375, 0.15340423583984375], "custom_metrics": {}}}, "num_steps_sampled": 132048, "num_agent_steps_sampled": 396144, "num_steps_trained": 262112, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 786336, "last_target_update_ts": 131568, "num_target_updates": 256}, "done": false, "episodes_total": 13981, "training_iteration": 131, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-50-12", "timestamp": 1648918212, "time_this_iter_s": 38.91215658187866, "time_total_s": 5229.035361289978, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734cb0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5229.035361289978, "timesteps_since_restore": 4192, "iterations_since_restore": 131, "perf": {"cpu_util_percent": 51.27272727272727, "ram_util_percent": 65.22727272727273}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.56198347107437, "episode_len_mean": 8.314049586776859, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.52066115702479, "policy1": 61.52066115702479, "policy2": 61.52066115702479}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 10, 9, 8, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 9, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0536169076810165, "mean_inference_ms": 25.68873591755293, "mean_action_processing_ms": 0.24321884684261524, "mean_env_wait_ms": 0.1391653395224438, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 133056, "timesteps_this_iter": 32, "agent_timesteps_total": 399168, "timers": {"load_time_ms": 0.691, "load_throughput": 46304.329, "learn_time_ms": 229.703, "learn_throughput": 139.31, "update_time_ms": 118.783}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.855831146240234, "min_q": 9.023658752441406, "max_q": 61.44334411621094, "mean_td_error": 0.13772594928741455, "model": {}}, "td_error": [2.4097938537597656, -0.2292308807373047, 0.4160499572753906, 0.02365875244140625, -0.22268295288085938, 0.13852691650390625, 0.3586282730102539, -0.3363971710205078, -0.00421905517578125, 0.4160499572753906, 0.34430885314941406, -0.2576160430908203, -0.2886695861816406, 2.802248001098633, -0.022020339965820312, -0.22988128662109375, -0.060207366943359375, 0.13852691650390625, 0.13852691650390625, 0.4160499572753906, 0.13852691650390625, -0.22988128662109375, -0.39145469665527344, -0.11803817749023438, -0.4265003204345703, 0.3378877639770508, -0.006946563720703125, 0.22762107849121094, -0.28590965270996094, -0.39128875732421875, -0.0069446563720703125, -0.3912849426269531], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.3531494140625, "min_q": 1.6637277603149414, "max_q": 60.825340270996094, "mean_td_error": -0.12877178192138672, "model": {}}, "td_error": [-3.745086669921875, 0.10012054443359375, -0.036182403564453125, 0.10012054443359375, -0.24225997924804688, -0.12652969360351562, -0.011478424072265625, -0.07728004455566406, -0.13556766510009766, -0.1509113311767578, -0.17264175415039062, -0.07789039611816406, -0.2125225067138672, -0.13556766510009766, -0.052349090576171875, -0.12652969360351562, -0.17264175415039062, 0.4510383605957031, -0.03352546691894531, 0.20985794067382812, 3.6261119842529297, -0.17264175415039062, -0.07789039611816406, -2.4781761169433594, -0.03968620300292969, 0.1044158935546875, -0.2125225067138672, -0.07789039611816406, -0.009250640869140625, 0.014179229736328125, -0.07728004455566406, -0.07223892211914062], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.642236709594727, "min_q": 6.344593048095703, "max_q": 61.98555374145508, "mean_td_error": 0.4506600499153137, "model": {}}, "td_error": [-0.46748828887939453, -0.032863616943359375, -0.10991477966308594, -0.08909225463867188, 0.4264049530029297, -0.10991477966308594, -0.10991477966308594, 0.23433303833007812, 0.11618804931640625, 0.10750579833984375, 0.25635337829589844, 0.47093963623046875, -0.08909225463867188, 0.10750579833984375, -0.3760566711425781, 0.07750320434570312, 0.20568084716796875, 0.021121978759765625, 0.47702598571777344, 0.021121978759765625, 0.19040489196777344, -0.5278067588806152, 5.133092880249023, 0.2789440155029297, -0.0593719482421875, 0.21849441528320312, -0.09168815612792969, 8.056079864501953, -0.5748720169067383, -0.032863616943359375, 0.7700958251953125, -0.07673454284667969], "custom_metrics": {}}}, "num_steps_sampled": 133056, "num_agent_steps_sampled": 399168, "num_steps_trained": 264128, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 792384, "last_target_update_ts": 132592, "num_target_updates": 258}, "done": false, "episodes_total": 14102, "training_iteration": 132, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-50-52", "timestamp": 1648918252, "time_this_iter_s": 39.92752957344055, "time_total_s": 5268.962890863419, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5268.962890863419, "timesteps_since_restore": 4224, "iterations_since_restore": 132, "perf": {"cpu_util_percent": 51.69824561403509, "ram_util_percent": 65.04736842105264}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.7, "episode_len_mean": 8.433333333333334, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.233333333333334, "policy1": 61.233333333333334, "policy2": 61.233333333333334}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 10, 8, 10, 10, 8, 10, 8, 10, 8, 8, 8, 8, 10, 10, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 9, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0540215692565573, "mean_inference_ms": 25.704944388001987, "mean_action_processing_ms": 0.24330378357648577, "mean_env_wait_ms": 0.1391674759476863, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 134064, "timesteps_this_iter": 32, "agent_timesteps_total": 402192, "timers": {"load_time_ms": 0.656, "load_throughput": 48792.252, "learn_time_ms": 224.122, "learn_throughput": 142.78, "update_time_ms": 126.598}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.83015441894531, "min_q": 8.989611625671387, "max_q": 60.832767486572266, "mean_td_error": 0.3961871266365051, "model": {}}, "td_error": [0.034145355224609375, 2.2809906005859375, 2.2638397216796875, -0.5775623321533203, -0.17214202880859375, 0.10072898864746094, -0.011997222900390625, 2.433786392211914, 1.2612762451171875, 0.001800537109375, 0.5322914123535156, 0.20820236206054688, 0.001800537109375, -0.010388374328613281, 0.009889602661132812, 0.1906270980834961, 0.043498992919921875, 0.026444435119628906, 0.10072898864746094, -0.32704925537109375, 0.003414154052734375, 0.08344268798828125, 0.08344268798828125, 0.1357421875, -0.17214202880859375, -0.17214202880859375, -0.010388374328613281, 3.768789291381836, 0.10072898864746094, 0.21294021606445312, 0.001800537109375, 0.2514476776123047], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.549274444580078, "min_q": 7.377658367156982, "max_q": 61.45543670654297, "mean_td_error": -0.030009448528289795, "model": {}}, "td_error": [0.06890487670898438, -0.24842453002929688, -0.08131027221679688, -0.20135498046875, -0.20135498046875, -0.32610130310058594, -0.17711639404296875, -0.020511627197265625, -0.15947723388671875, -0.08131027221679688, 0.5864448547363281, 0.06442642211914062, -0.020511627197265625, -0.158111572265625, 0.2928924560546875, 0.1602153778076172, 0.7943849563598633, -0.5667934417724609, -0.15947723388671875, -0.2714500427246094, 0.42725372314453125, -0.39527320861816406, 0.06442642211914062, -0.040500640869140625, -0.040500640869140625, -0.3463706970214844, -0.020511627197265625, -0.18365859985351562, -0.0002384185791015625, -0.2225360870361328, -0.00023746490478515625, 0.5038814544677734], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.08333969116211, "min_q": 8.840662002563477, "max_q": 61.094547271728516, "mean_td_error": 0.7018047571182251, "model": {}}, "td_error": [-0.08655738830566406, -0.14072036743164062, 0.21459388732910156, -0.15933799743652344, 0.10562705993652344, -0.1768646240234375, 3.345287322998047, -0.2537422180175781, 0.35619163513183594, 2.067683219909668, -0.16456985473632812, -0.26847076416015625, -0.5358257293701172, 0.18467140197753906, -0.13646697998046875, 0.3784637451171875, 17.595504760742188, 2.7870922088623047, -0.17110443115234375, -0.2857780456542969, -0.6385040283203125, -0.2857780456542969, -0.1768646240234375, -0.18017005920410156, -0.06546401977539062, -0.7522239685058594, 0.1386566162109375, -0.20923805236816406, 0.18467140197753906, -0.2537422180175781, 0.1272907257080078, -0.08655738830566406], "custom_metrics": {}}}, "num_steps_sampled": 134064, "num_agent_steps_sampled": 402192, "num_steps_trained": 266144, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 798432, "last_target_update_ts": 133616, "num_target_updates": 260}, "done": false, "episodes_total": 14222, "training_iteration": 133, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-51-32", "timestamp": 1648918292, "time_this_iter_s": 39.54402685165405, "time_total_s": 5308.506917715073, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c655c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c655c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5308.506917715073, "timesteps_since_restore": 4256, "iterations_since_restore": 133, "perf": {"cpu_util_percent": 50.34363636363636, "ram_util_percent": 65.13636363636364}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 183.07563025210084, "episode_len_mean": 8.38655462184874, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.02521008403362, "policy1": 61.02521008403362, "policy2": 61.02521008403362}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 90.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0], "episode_lengths": [8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9], "policy_policy0_reward": [62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 30.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 30.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 30.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0497443090456227, "mean_inference_ms": 25.53625777634192, "mean_action_processing_ms": 0.24192868718718483, "mean_env_wait_ms": 0.13847138448264654, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 135072, "timesteps_this_iter": 32, "agent_timesteps_total": 405216, "timers": {"load_time_ms": 0.672, "load_throughput": 47598.315, "learn_time_ms": 226.403, "learn_throughput": 141.341, "update_time_ms": 115.615}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.129615783691406, "min_q": -1.001501441001892, "max_q": 60.303680419921875, "mean_td_error": 0.3057834506034851, "model": {}}, "td_error": [1.8585891723632812, 0.047702789306640625, 0.08380508422851562, 0.9144496917724609, -0.13051223754882812, 0.17292404174804688, 0.053958892822265625, 0.13744258880615234, 0.055023193359375, 0.047702789306640625, -0.060794830322265625, 0.055023193359375, 0.055023193359375, 0.05853080749511719, 0.053958892822265625, -0.13884353637695312, -0.2461376190185547, -0.0015014410018920898, 0.03996849060058594, 0.1016998291015625, 1.8640918731689453, 0.047954559326171875, 2.788837432861328, 0.047702789306640625, 0.04567909240722656, 1.3183155059814453, -0.10837173461914062, 0.7617034912109375, -0.32120513916015625, 0.055023193359375, 0.047698974609375, 0.07962799072265625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.462562561035156, "min_q": 8.995379447937012, "max_q": 61.40650939941406, "mean_td_error": 0.060402899980545044, "model": {}}, "td_error": [0.01532745361328125, 0.029541015625, -0.31957435607910156, 0.057804107666015625, 0.10992813110351562, -0.14567184448242188, -0.45864105224609375, -0.0051670074462890625, 2.3316574096679688, 2.6529922485351562, -0.45864105224609375, -0.45864105224609375, -0.25383758544921875, -0.3301353454589844, -0.097503662109375, 0.05147361755371094, 0.4095783233642578, -0.07505035400390625, -0.28310585021972656, -0.004620552062988281, -0.07505035400390625, -0.05643272399902344, 0.029541015625, 0.05155372619628906, 0.01532745361328125, -0.041889190673828125, -0.168060302734375, 0.01532745361328125, -0.09429931640625, 0.10992813110351562, -0.4644889831542969, -0.15627670288085938], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.220359802246094, "min_q": 9.071935653686523, "max_q": 61.607418060302734, "mean_td_error": 0.28168797492980957, "model": {}}, "td_error": [-0.6065311431884766, 0.20251846313476562, -0.025600433349609375, 0.1719207763671875, 0.3308525085449219, -0.025600433349609375, -0.21921157836914062, 0.0754547119140625, 1.1925506591796875, 0.5735034942626953, 0.13489341735839844, 0.4493865966796875, 0.14801025390625, 0.3161354064941406, 0.44809722900390625, 0.41140174865722656, 0.1719207763671875, 1.0405216217041016, 0.27977752685546875, 0.3332538604736328, 0.1719207763671875, -0.2350921630859375, 0.24590396881103516, 2.3107872009277344, 0.1411733627319336, 0.27977752685546875, 0.2545166015625, 0.07193565368652344, -0.19716262817382812, -0.1077728271484375, 0.4114055633544922, 0.26336669921875], "custom_metrics": {}}}, "num_steps_sampled": 135072, "num_agent_steps_sampled": 405216, "num_steps_trained": 268160, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 804480, "last_target_update_ts": 134640, "num_target_updates": 262}, "done": false, "episodes_total": 14341, "training_iteration": 134, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-52-11", "timestamp": 1648918331, "time_this_iter_s": 39.48301339149475, "time_total_s": 5347.989931106567, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c673680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c673680>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5347.989931106567, "timesteps_since_restore": 4288, "iterations_since_restore": 134, "perf": {"cpu_util_percent": 51.21785714285714, "ram_util_percent": 65.24464285714285}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 183.07563025210084, "episode_len_mean": 8.470588235294118, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.02521008403362, "policy1": 61.02521008403362, "policy2": 61.02521008403362}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 180.0, 180.0, 150.0, 180.0, 186.0, 180.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 120.0, 180.0, 186.0, 186.0, 150.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 10, 8, 8, 8, 10, 8, 9, 8, 10, 10, 10, 10, 8, 10, 8, 9, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 10, 8, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 50.0, 60.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 60.0, 62.0, 62.0, 50.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 50.0, 60.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 60.0, 62.0, 62.0, 50.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 60.0, 60.0, 50.0, 60.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 40.0, 60.0, 62.0, 62.0, 50.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0533798241326853, "mean_inference_ms": 25.667598962560785, "mean_action_processing_ms": 0.24292958281375115, "mean_env_wait_ms": 0.13900348983358618, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 136080, "timesteps_this_iter": 32, "agent_timesteps_total": 408240, "timers": {"load_time_ms": 0.648, "load_throughput": 49359.27, "learn_time_ms": 230.473, "learn_throughput": 138.845, "update_time_ms": 116.656}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.825531005859375, "min_q": 6.470062255859375, "max_q": 60.64763259887695, "mean_td_error": 0.380395770072937, "model": {}}, "td_error": [2.1912803649902344, -0.6095657348632812, 0.5801324844360352, -0.2753105163574219, 0.17791175842285156, 0.03216552734375, 2.9212570190429688, 0.07229423522949219, 3.837615966796875, -0.2464447021484375, -0.13520050048828125, 0.18103981018066406, 0.21810150146484375, 0.048603057861328125, 0.18103981018066406, 0.1535930633544922, 0.40918445587158203, -0.28084564208984375, -0.650604248046875, 2.9006710052490234, 0.21054649353027344, -2.529937744140625, -0.17181396484375, 0.09012222290039062, 0.07229423522949219, 0.36141395568847656, -0.0247955322265625, 3.074331283569336, -0.2753105163574219, -0.45697021484375, 0.3911762237548828, -0.2753105163574219], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.45277404785156, "min_q": 8.48855209350586, "max_q": 61.05614471435547, "mean_td_error": 0.06678083539009094, "model": {}}, "td_error": [-0.38480472564697266, -0.19073104858398438, -0.105255126953125, -0.4580535888671875, -0.4694099426269531, 2.451343536376953, 0.09029006958007812, 0.036640167236328125, 0.09029006958007812, -0.2582359313964844, 0.09029006958007812, -0.3056449890136719, 0.31098175048828125, -0.1845531463623047, 0.09029006958007812, -1.7896499633789062, -1.3282451629638672, -0.5114479064941406, -0.2595233917236328, 0.07796859741210938, 0.1409454345703125, -0.3058624267578125, -0.2517528533935547, -0.07550239562988281, 0.1601409912109375, 2.353118896484375, 0.03968238830566406, 0.006237030029296875, -0.3056449890136719, 0.09029006958007812, 1.1944446563720703, 2.0983505249023438], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.40646743774414, "min_q": 7.572577476501465, "max_q": 60.79616165161133, "mean_td_error": 0.8965544700622559, "model": {}}, "td_error": [0.0036468505859375, -0.15285491943359375, 0.1531524658203125, 0.13454627990722656, 0.20546531677246094, 0.037631988525390625, 0.05815887451171875, 1.3328018188476562, -0.15845870971679688, -0.11275863647460938, 0.054195404052734375, -0.08173465728759766, 0.02320098876953125, 0.1531524658203125, -0.21303558349609375, -0.15285491943359375, -0.017398834228515625, 0.037631988525390625, -1.0104360580444336, -0.10229873657226562, 27.224760055541992, 0.0036468505859375, 0.19681739807128906, 0.011507034301757812, 0.06267547607421875, 0.06267547607421875, 0.20546531677246094, 0.014873504638671875, 0.044368743896484375, 0.3951530456542969, 0.3176155090332031, -0.041568756103515625], "custom_metrics": {}}}, "num_steps_sampled": 136080, "num_agent_steps_sampled": 408240, "num_steps_trained": 270176, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 810528, "last_target_update_ts": 135664, "num_target_updates": 264}, "done": false, "episodes_total": 14460, "training_iteration": 135, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-52-52", "timestamp": 1648918372, "time_this_iter_s": 40.59777235984802, "time_total_s": 5388.587703466415, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c673dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c673dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5388.587703466415, "timesteps_since_restore": 4320, "iterations_since_restore": 135, "perf": {"cpu_util_percent": 51.54827586206897, "ram_util_percent": 65.41206896551725}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 184.0, "episode_len_mean": 8.416666666666666, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.333333333333336, "policy1": 61.333333333333336, "policy2": 61.333333333333336}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 9, 10, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 10, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 10, 8, 9, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.052786279030059, "mean_inference_ms": 25.635168316783556, "mean_action_processing_ms": 0.24270491705357347, "mean_env_wait_ms": 0.1389003542937177, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 137088, "timesteps_this_iter": 32, "agent_timesteps_total": 411264, "timers": {"load_time_ms": 0.602, "load_throughput": 53166.064, "learn_time_ms": 222.423, "learn_throughput": 143.87, "update_time_ms": 121.431}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.668216705322266, "min_q": 8.25424575805664, "max_q": 60.82360076904297, "mean_td_error": -0.10614290833473206, "model": {}}, "td_error": [0.05364418029785156, -1.0341815948486328, -0.09824371337890625, 0.229278564453125, 0.2605171203613281, 0.18539810180664062, -0.13515472412109375, -0.13515472412109375, -0.041835784912109375, -0.5039997100830078, -0.3700904846191406, -0.236328125, -0.054431915283203125, -0.25667381286621094, -0.05455780029296875, -0.09824371337890625, -0.6336631774902344, -0.3392477035522461, -0.1229705810546875, -0.5057563781738281, -0.023609161376953125, -0.6959571838378906, -0.15452194213867188, -0.05455780029296875, -0.054431915283203125, 2.09649658203125, -0.3074073791503906, 0.025897979736328125, 0.03745269775390625, -0.07556915283203125, -0.023609161376953125, -0.27506065368652344], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.90213394165039, "min_q": 9.086028099060059, "max_q": 60.234466552734375, "mean_td_error": -0.06109139323234558, "model": {}}, "td_error": [-0.09493446350097656, 0.0494384765625, -0.4253578186035156, 0.0860280990600586, 0.46054840087890625, -0.21671676635742188, -0.09493446350097656, 0.07934951782226562, 0.09930229187011719, 0.13541412353515625, -0.007289886474609375, -0.4424400329589844, -0.17723464965820312, -0.36287879943847656, 0.20470046997070312, -0.007289886474609375, 0.8086624145507812, 0.006633758544921875, -0.40143585205078125, -0.21959304809570312, -0.21671676635742188, -0.09493446350097656, 0.0211944580078125, 0.46054840087890625, 0.09050750732421875, -0.4424400329589844, -0.21959304809570312, -0.5015544891357422, -0.2978096008300781, 0.2734184265136719, 0.010179519653320312, -0.5176963806152344], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.69047546386719, "min_q": 8.43054485321045, "max_q": 60.700008392333984, "mean_td_error": 0.3627011179924011, "model": {}}, "td_error": [-0.015453338623046875, 0.5332145690917969, 0.9411544799804688, 0.9202461242675781, -0.3100624084472656, 2.1160812377929688, 0.2666206359863281, 0.07614898681640625, -0.20434951782226562, 0.4216804504394531, -0.126251220703125, 8.296642303466797, -0.0614776611328125, -0.10559654235839844, 0.07614898681640625, 0.07249832153320312, 0.27828407287597656, 0.1133575439453125, -1.1761455535888672, 0.0543365478515625, 0.07658004760742188, 0.4551677703857422, -0.1081085205078125, 0.17015838623046875, 0.22040367126464844, -0.5166893005371094, 0.04143524169921875, -0.5166893005371094, -0.7064743041992188, -0.2688732147216797, 0.3251962661743164, 0.26725101470947266], "custom_metrics": {}}}, "num_steps_sampled": 137088, "num_agent_steps_sampled": 411264, "num_steps_trained": 272192, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 816576, "last_target_update_ts": 136688, "num_target_updates": 266}, "done": false, "episodes_total": 14580, "training_iteration": 136, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-53-32", "timestamp": 1648918412, "time_this_iter_s": 40.153913497924805, "time_total_s": 5428.74161696434, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c63de60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c63de60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5428.74161696434, "timesteps_since_restore": 4352, "iterations_since_restore": 136, "perf": {"cpu_util_percent": 50.824561403508774, "ram_util_percent": 65.28771929824562}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.52459016393442, "episode_len_mean": 8.327868852459016, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.50819672131148, "policy1": 61.50819672131148, "policy2": 61.50819672131148}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 150.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 8, 10, 8, 8, 10, 8, 8, 8, 8, 10, 8, 9, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0522961476421389, "mean_inference_ms": 25.622914618142556, "mean_action_processing_ms": 0.24252014723025722, "mean_env_wait_ms": 0.1388066612606189, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 138096, "timesteps_this_iter": 32, "agent_timesteps_total": 414288, "timers": {"load_time_ms": 0.695, "load_throughput": 46046.977, "learn_time_ms": 222.114, "learn_throughput": 144.07, "update_time_ms": 121.461}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.20121383666992, "min_q": 8.791131973266602, "max_q": 60.573970794677734, "mean_td_error": 0.6728448867797852, "model": {}}, "td_error": [9.87004566192627, -0.022497177124023438, 0.10479354858398438, -0.04082489013671875, 2.250490188598633, -0.022497177124023438, 1.212106704711914, -0.06871414184570312, -0.1066131591796875, -0.0020294189453125, -0.208282470703125, 2.1176681518554688, -0.10701560974121094, 2.1176681518554688, 3.051759719848633, -0.20886802673339844, -0.05293846130371094, -0.02747631072998047, 0.10479354858398438, 0.30350494384765625, -0.0020294189453125, -0.035778045654296875, 1.7113304138183594, -0.051666259765625, -0.02747631072998047, 0.3313140869140625, -0.18780517578125, -0.022497177124023438, -0.0495758056640625, -0.035778045654296875, -0.1969585418701172, -0.16711807250976562], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.73169708251953, "min_q": 8.768696784973145, "max_q": 60.648563385009766, "mean_td_error": 0.04442620277404785, "model": {}}, "td_error": [0.0274200439453125, -0.06983089447021484, 0.13835716247558594, -0.023441314697265625, -0.06983089447021484, -0.03332328796386719, 0.11931991577148438, -0.06983089447021484, -0.009113311767578125, -0.5664596557617188, 0.06873321533203125, 0.10898208618164062, 0.6987075805664062, 0.00848388671875, -0.23130321502685547, 0.2577857971191406, 0.021070480346679688, 0.0579986572265625, -0.023441314697265625, -0.04678535461425781, 0.13140869140625, 0.11931991577148438, 0.13065338134765625, 0.10644149780273438, 0.1905231475830078, -0.09426116943359375, -0.023441314697265625, 0.2948036193847656, 0.021070480346679688, 0.10644149780273438, 0.2579460144042969, -0.18276596069335938], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.73323059082031, "min_q": 6.969254970550537, "max_q": 61.05820846557617, "mean_td_error": 0.030682027339935303, "model": {}}, "td_error": [-0.24557113647460938, -0.23707962036132812, 0.16790103912353516, 0.043994903564453125, -0.6548995971679688, -0.4726543426513672, -0.138031005859375, 0.49800777435302734, -0.2619171142578125, -0.20984649658203125, -0.8613834381103516, -0.4169883728027344, -0.14001846313476562, -0.2619171142578125, -0.24557113647460938, -0.18701934814453125, -0.13867950439453125, 0.21300697326660156, -0.31055259704589844, 2.1488513946533203, -0.3442955017089844, -0.2619171142578125, -0.13867950439453125, -0.2302093505859375, -0.35893821716308594, -0.138031005859375, 0.18912696838378906, 1.8613014221191406, 0.18189525604248047, 0.19120121002197266, 1.7057304382324219, 0.035007476806640625], "custom_metrics": {}}}, "num_steps_sampled": 138096, "num_agent_steps_sampled": 414288, "num_steps_trained": 274208, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 822624, "last_target_update_ts": 137712, "num_target_updates": 268}, "done": false, "episodes_total": 14702, "training_iteration": 137, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-54-12", "timestamp": 1648918452, "time_this_iter_s": 39.51665019989014, "time_total_s": 5468.25826716423, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c63df80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c63df80>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5468.25826716423, "timesteps_since_restore": 4384, "iterations_since_restore": 137, "perf": {"cpu_util_percent": 50.39454545454545, "ram_util_percent": 65.08909090909091}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.98319327731093, "episode_len_mean": 8.420168067226891, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.32773109243698, "policy1": 61.32773109243698, "policy2": 61.32773109243698}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 150.0, 186.0, 186.0, 150.0, 186.0, 150.0, 180.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 9, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 9, 8, 10, 8, 8, 10, 8, 10, 10, 8, 9, 8, 8, 9, 8, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 10, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 10, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 50.0, 62.0, 62.0, 50.0, 62.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0513593828602952, "mean_inference_ms": 25.588405580926167, "mean_action_processing_ms": 0.24221544444526008, "mean_env_wait_ms": 0.13866464347453053, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 139104, "timesteps_this_iter": 32, "agent_timesteps_total": 417312, "timers": {"load_time_ms": 0.666, "load_throughput": 48030.965, "learn_time_ms": 223.0, "learn_throughput": 143.498, "update_time_ms": 118.042}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.346023559570312, "min_q": 8.04244613647461, "max_q": 61.03339385986328, "mean_td_error": -0.1355731189250946, "model": {}}, "td_error": [-1.7095279693603516, 0.13147735595703125, -0.074371337890625, -0.058712005615234375, -0.18290233612060547, 0.7394199371337891, -0.08723640441894531, -0.33214569091796875, -0.08771133422851562, -0.128326416015625, -0.9929828643798828, -0.07935333251953125, -0.4375114440917969, -0.06331443786621094, -0.003047943115234375, -0.06331443786621094, -0.13861083984375, -0.10473442077636719, -0.20472335815429688, -0.14876937866210938, 1.0237674713134766, -0.3841705322265625, -0.40480804443359375, -0.128326416015625, -0.08723640441894531, -0.003047943115234375, -0.28128623962402344, -0.13016510009765625, -0.074371337890625, -0.2611274719238281, 0.7509727478027344, -0.3321418762207031], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.11704635620117, "min_q": 8.910861015319824, "max_q": 61.12117004394531, "mean_td_error": 0.0842527449131012, "model": {}}, "td_error": [0.17120361328125, -0.018306732177734375, -0.4162406921386719, -0.2505836486816406, -0.09172439575195312, 0.0169219970703125, 0.0169219970703125, -0.08913898468017578, -0.26415252685546875, -0.1367168426513672, 0.17120361328125, -0.10915374755859375, -0.44200706481933594, 0.09176445007324219, -0.005687713623046875, -0.15614700317382812, -0.15614700317382812, -0.09172439575195312, -1.120269775390625, -0.15614700317382812, 3.254301071166992, -0.0155029296875, -0.059299468994140625, 2.5856704711914062, 1.0189952850341797, -0.19631385803222656, -0.0155029296875, -0.072174072265625, -0.09172439575195312, -0.083740234375, -0.5007686614990234, -0.0917205810546875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.59716796875, "min_q": 6.769229412078857, "max_q": 61.6105842590332, "mean_td_error": 1.0596811771392822, "model": {}}, "td_error": [-0.11728668212890625, -0.3118858337402344, 0.4935188293457031, -0.11212730407714844, -0.05279541015625, -0.04164886474609375, 1.3812255859375, 1.6121978759765625, -0.040839195251464844, -0.17960357666015625, 0.15157222747802734, -0.04164886474609375, 0.050884246826171875, -0.3847484588623047, -0.230804443359375, -0.6201572418212891, -0.04164886474609375, 7.769229412078857, -0.25296783447265625, -0.11212730407714844, -0.4492149353027344, 26.938823699951172, -0.208038330078125, 0.15460205078125, -0.11673927307128906, -0.23722076416015625, 0.2480010986328125, -0.5645217895507812, -0.13597869873046875, -0.17960357666015625, -0.46491432189941406, 0.006267547607421875], "custom_metrics": {}}}, "num_steps_sampled": 139104, "num_agent_steps_sampled": 417312, "num_steps_trained": 276224, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 828672, "last_target_update_ts": 138736, "num_target_updates": 270}, "done": false, "episodes_total": 14821, "training_iteration": 138, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-54-52", "timestamp": 1648918492, "time_this_iter_s": 39.79980826377869, "time_total_s": 5508.058075428009, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c655c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c655c20>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5508.058075428009, "timesteps_since_restore": 4416, "iterations_since_restore": 138, "perf": {"cpu_util_percent": 51.67368421052631, "ram_util_percent": 65.01403508771931}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.54918032786884, "episode_len_mean": 8.319672131147541, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.51639344262295, "policy1": 61.51639344262295, "policy2": 61.51639344262295}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 183.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 150.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 10, 8, 8, 9, 9, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 9, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 9, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 50.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0536019721016843, "mean_inference_ms": 25.679798367039457, "mean_action_processing_ms": 0.24287071980087754, "mean_env_wait_ms": 0.139054080488849, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 140112, "timesteps_this_iter": 32, "agent_timesteps_total": 420336, "timers": {"load_time_ms": 0.607, "load_throughput": 52690.193, "learn_time_ms": 226.174, "learn_throughput": 141.484, "update_time_ms": 123.642}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.40521240234375, "min_q": 8.969056129455566, "max_q": 61.118045806884766, "mean_td_error": 0.22459650039672852, "model": {}}, "td_error": [0.09065628051757812, 0.027667999267578125, 0.021930694580078125, -0.069793701171875, 0.06551742553710938, -0.1645050048828125, 0.027667999267578125, -0.09714508056640625, -0.1645050048828125, 0.04834747314453125, -0.08168411254882812, -0.122283935546875, 0.027667999267578125, -0.7108802795410156, 0.009885787963867188, 0.06443405151367188, 3.4086036682128906, 2.580242156982422, -0.021921157836914062, -0.031429290771484375, -0.04389381408691406, 0.07320404052734375, 0.0364837646484375, -0.1645050048828125, -0.07848739624023438, -0.105987548828125, -0.030943870544433594, -0.0677337646484375, 0.04537677764892578, 0.03668212890625, 2.52984619140625, 0.048572540283203125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.660064697265625, "min_q": 7.565262794494629, "max_q": 62.02104568481445, "mean_td_error": 0.0771380066871643, "model": {}}, "td_error": [0.1892242431640625, -0.14342498779296875, 0.21155548095703125, -0.058376312255859375, -0.14342498779296875, 0.210052490234375, 0.3368682861328125, 0.33712005615234375, 0.12863731384277344, 0.15668106079101562, -0.035243988037109375, -0.3083381652832031, -0.12385272979736328, -0.012257575988769531, 0.33712005615234375, -0.07912445068359375, 0.1761302947998047, -0.14342498779296875, 0.1761302947998047, 0.9769439697265625, -0.029430389404296875, 0.33712005615234375, 0.1264019012451172, -0.050518035888671875, -0.09559249877929688, -0.6500015258789062, -0.6441249847412109, -0.10425186157226562, 0.00787353515625, 0.6838951110839844, 0.5088253021240234, 0.1892242431640625], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.29351806640625, "min_q": 9.422517776489258, "max_q": 61.05720138549805, "mean_td_error": 0.19283634424209595, "model": {}}, "td_error": [0.4598884582519531, -0.03957939147949219, 0.08853912353515625, -0.14348220825195312, 0.22574615478515625, -0.11037445068359375, -0.3510284423828125, 0.211669921875, 0.07570266723632812, 0.211669921875, -0.3367958068847656, 0.211669921875, -0.03957939147949219, 0.08853912353515625, 2.4421958923339844, -0.10125923156738281, 0.19636917114257812, 0.09170722961425781, 0.0643157958984375, 0.2421703338623047, 2.2694053649902344, -0.1300830841064453, 0.4225177764892578, 0.05254364013671875, -0.12182044982910156, -0.03957939147949219, -0.03957939147949219, 0.08853912353515625, 0.08337211608886719, -0.22027206420898438, 0.08853912353515625, 0.229095458984375], "custom_metrics": {}}}, "num_steps_sampled": 140112, "num_agent_steps_sampled": 420336, "num_steps_trained": 278240, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 834720, "last_target_update_ts": 139760, "num_target_updates": 272}, "done": false, "episodes_total": 14943, "training_iteration": 139, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-55-32", "timestamp": 1648918532, "time_this_iter_s": 39.91822910308838, "time_total_s": 5547.976304531097, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5fc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5fc7a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5547.976304531097, "timesteps_since_restore": 4448, "iterations_since_restore": 139, "perf": {"cpu_util_percent": 50.28035714285714, "ram_util_percent": 65.10178571428573}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 183.59504132231405, "episode_len_mean": 8.305785123966942, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.19834710743802, "policy1": 61.19834710743802, "policy2": 61.19834710743802}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 90.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0512346590730992, "mean_inference_ms": 25.585392621400988, "mean_action_processing_ms": 0.24208070442921348, "mean_env_wait_ms": 0.1386618149205262, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 141120, "timesteps_this_iter": 32, "agent_timesteps_total": 423360, "timers": {"load_time_ms": 0.642, "load_throughput": 49852.441, "learn_time_ms": 223.091, "learn_throughput": 143.439, "update_time_ms": 117.582}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.723018646240234, "min_q": 7.972761631011963, "max_q": 60.873435974121094, "mean_td_error": 0.48755401372909546, "model": {}}, "td_error": [-0.246307373046875, 4.147930145263672, 0.5583715438842773, 0.2854042053222656, -0.24274063110351562, -0.5316390991210938, -0.14729690551757812, 2.422250747680664, -0.24274063110351562, 7.979673385620117, -0.24274063110351562, 0.19256210327148438, 0.038312435150146484, -0.11577224731445312, -0.0077075958251953125, -0.1651325225830078, -0.2513694763183594, -0.3163414001464844, -0.3003730773925781, -0.20035362243652344, 1.8661975860595703, 0.25592994689941406, 2.4579334259033203, 0.29679393768310547, -0.14729690551757812, -0.32713890075683594, 0.13040542602539062, -0.189300537109375, -0.1651325225830078, -0.24274063110351562, -0.4559040069580078, -0.4920082092285156], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.81873321533203, "min_q": 8.594393730163574, "max_q": 60.988834381103516, "mean_td_error": 0.020119458436965942, "model": {}}, "td_error": [0.12404632568359375, -0.01224517822265625, 0.00605010986328125, 1.7022323608398438, -0.3251781463623047, -0.3893241882324219, -0.053417205810546875, -0.22815227508544922, -0.22815227508544922, -0.16730499267578125, -0.16749954223632812, 0.14220428466796875, 0.017467498779296875, -0.10995674133300781, -0.10544204711914062, -0.019174575805664062, 0.8220863342285156, 0.017467498779296875, 0.057781219482421875, -0.041164398193359375, 0.00605010986328125, 0.02667236328125, 0.06674957275390625, 0.15373802185058594, -0.023998260498046875, 0.14220428466796875, -0.25000762939453125, 0.00605010986328125, -0.4056062698364258, -0.2830047607421875, 0.06674957275390625, 0.0959014892578125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 26.27322769165039, "min_q": 8.670219421386719, "max_q": 60.39471435546875, "mean_td_error": 0.4151194989681244, "model": {}}, "td_error": [-0.3421173095703125, -0.002696990966796875, 1.925811767578125, -0.21642780303955078, 0.3092212677001953, 0.04958915710449219, -0.31421661376953125, -0.09887313842773438, -0.07270050048828125, 0.05340766906738281, -0.32978057861328125, 0.19137001037597656, 0.2655029296875, 6.943300247192383, -0.18033409118652344, -0.03094482421875, -0.3151092529296875, -0.13669204711914062, -0.11844158172607422, 6.943300247192383, -0.012615203857421875, 0.06666755676269531, -0.09887313842773438, -0.262481689453125, -0.09887313842773438, -0.25370025634765625, -0.03094482421875, -0.06938457489013672, -0.07270050048828125, -0.002899169921875, -0.3785591125488281, -0.024980545043945312], "custom_metrics": {}}}, "num_steps_sampled": 141120, "num_agent_steps_sampled": 423360, "num_steps_trained": 280256, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 840768, "last_target_update_ts": 140784, "num_target_updates": 274}, "done": false, "episodes_total": 15064, "training_iteration": 140, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-56-11", "timestamp": 1648918571, "time_this_iter_s": 39.34985041618347, "time_total_s": 5587.326154947281, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62a4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62a4d0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5587.326154947281, "timesteps_since_restore": 4480, "iterations_since_restore": 140, "perf": {"cpu_util_percent": 51.208928571428565, "ram_util_percent": 65.23392857142856}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.672131147541, "episode_len_mean": 8.278688524590164, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.557377049180324, "policy1": 61.557377049180324, "policy2": 61.557377049180324}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0], "episode_lengths": [8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0535049471629472, "mean_inference_ms": 25.67267018032382, "mean_action_processing_ms": 0.24266589393649982, "mean_env_wait_ms": 0.1389818596187395, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 142128, "timesteps_this_iter": 32, "agent_timesteps_total": 426384, "timers": {"load_time_ms": 0.66, "load_throughput": 48461.051, "learn_time_ms": 225.042, "learn_throughput": 142.196, "update_time_ms": 117.909}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.820858001708984, "min_q": 9.047769546508789, "max_q": 61.131473541259766, "mean_td_error": 0.13636374473571777, "model": {}}, "td_error": [0.04776954650878906, 0.16938018798828125, 0.055713653564453125, 0.11766815185546875, -2.5631141662597656, 0.07590866088867188, 0.09291648864746094, 0.01834869384765625, 0.358673095703125, 2.390439987182617, 0.9080371856689453, 0.3295326232910156, -0.07929229736328125, 0.00858306884765625, 0.07997512817382812, 0.048736572265625, 0.23757553100585938, 0.07293319702148438, 0.0729217529296875, 0.23757553100585938, 1.5890522003173828, -0.07929229736328125, 0.0162811279296875, 0.37727928161621094, 0.07997512817382812, 0.23757553100585938, -0.9783039093017578, 0.09291648864746094, 0.07997512817382812, 0.048736572265625, 0.18738937377929688, 0.031772613525390625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.70580291748047, "min_q": 8.84471321105957, "max_q": 61.2962532043457, "mean_td_error": -0.03673097491264343, "model": {}}, "td_error": [-0.4259681701660156, -0.015287399291992188, 0.5889015197753906, 0.11681556701660156, -0.015287399291992188, -0.05962371826171875, 0.021816253662109375, -0.03134918212890625, -0.17123031616210938, 0.11681556701660156, -0.0904226303100586, 0.0021505355834960938, 0.07327842712402344, -0.11911392211914062, -0.234771728515625, 0.0626220703125, -0.11616134643554688, -0.14307022094726562, -0.27519989013671875, -0.11475372314453125, -0.11616134643554688, -0.12537193298339844, 0.05106353759765625, -0.049602508544921875, -0.016063690185546875, -0.1552867889404297, 0.0626220703125, 0.015382766723632812, 0.17744827270507812, 0.08119010925292969, -0.2729225158691406, 0.0021505355834960938], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.363502502441406, "min_q": 7.574317455291748, "max_q": 61.35321044921875, "mean_td_error": 0.035785794258117676, "model": {}}, "td_error": [0.06424331665039062, 0.1466655731201172, 0.03381919860839844, -0.09870529174804688, -0.2519702911376953, -0.15221405029296875, -0.08525848388671875, -0.283693790435791, -0.038471221923828125, -0.2519702911376953, 0.6721935272216797, -0.08525848388671875, 0.14295387268066406, 0.18207550048828125, 0.14295387268066406, -0.2519702911376953, 0.5625643730163574, -0.1613006591796875, -0.222076416015625, -0.5043830871582031, -0.1613006591796875, 0.17227554321289062, -0.07029342651367188, -0.038471221923828125, 0.06424331665039062, -0.1613006591796875, 0.0010986328125, -0.1613006591796875, 0.041248321533203125, 0.09347820281982422, 1.6623191833496094, 0.14295196533203125], "custom_metrics": {}}}, "num_steps_sampled": 142128, "num_agent_steps_sampled": 426384, "num_steps_trained": 282272, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 846816, "last_target_update_ts": 141808, "num_target_updates": 276}, "done": false, "episodes_total": 15186, "training_iteration": 141, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-56-51", "timestamp": 1648918611, "time_this_iter_s": 40.07010459899902, "time_total_s": 5627.39625954628, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62a950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62a950>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5627.39625954628, "timesteps_since_restore": 4512, "iterations_since_restore": 141, "perf": {"cpu_util_percent": 52.022807017543855, "ram_util_percent": 65.23684210526316}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.64754098360655, "episode_len_mean": 8.28688524590164, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.549180327868854, "policy1": 61.549180327868854, "policy2": 61.549180327868854}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0], "episode_lengths": [8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 9, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10], "policy_policy0_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0519961217568405, "mean_inference_ms": 25.612448054307137, "mean_action_processing_ms": 0.24216381541271123, "mean_env_wait_ms": 0.13876080710418853, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 143136, "timesteps_this_iter": 32, "agent_timesteps_total": 429408, "timers": {"load_time_ms": 0.649, "load_throughput": 49328.431, "learn_time_ms": 234.876, "learn_throughput": 136.242, "update_time_ms": 118.991}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.81123352050781, "min_q": 14.0499849319458, "max_q": 61.13964080810547, "mean_td_error": 0.1452835500240326, "model": {}}, "td_error": [-0.11982345581054688, -0.08385848999023438, 0.09269905090332031, 0.03691864013671875, -0.031894683837890625, 0.09269905090332031, 0.022563934326171875, -0.031894683837890625, 0.0880889892578125, -0.13563156127929688, -0.1619548797607422, -0.043453216552734375, -0.0067596435546875, 0.114349365234375, 0.2184906005859375, -0.049976348876953125, 0.16211318969726562, -0.049976348876953125, 0.09269905090332031, -0.06780815124511719, -0.043453216552734375, -2.813258171081543, 2.556163787841797, -0.14992332458496094, 0.114349365234375, -0.021575927734375, -0.06789970397949219, -0.08572006225585938, -0.16065597534179688, 2.4465065002441406, 2.6722450256347656, 0.06470489501953125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.07318115234375, "min_q": 8.84740924835205, "max_q": 61.45564270019531, "mean_td_error": 0.012351840734481812, "model": {}}, "td_error": [0.12453079223632812, -0.4705486297607422, -0.08780097961425781, 1.0306682586669922, 0.604156494140625, 0.12453079223632812, -0.010868072509765625, -0.4705486297607422, -0.08780097961425781, -0.31014251708984375, -0.19934654235839844, -0.18196868896484375, -0.008716583251953125, 0.12453079223632812, 0.1653594970703125, -0.09730720520019531, 0.3306159973144531, -0.18196868896484375, 0.12453079223632812, -0.008716583251953125, -0.08780097961425781, 0.15697097778320312, 0.15697097778320312, 0.12453079223632812, -0.15259075164794922, -0.3769989013671875, 0.1653594970703125, 0.3300666809082031, -0.23130226135253906, -0.18196868896484375, -0.16353225708007812, 0.142364501953125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.99713134765625, "min_q": 8.029698371887207, "max_q": 61.83264923095703, "mean_td_error": -0.23134323954582214, "model": {}}, "td_error": [-0.530364990234375, -0.8109817504882812, -0.42354583740234375, -0.18759536743164062, -0.32039833068847656, -0.6162319183349609, -0.28564453125, -0.36029624938964844, 0.054653167724609375, -0.2060985565185547, -0.11584091186523438, -0.4493980407714844, -0.39211368560791016, -0.4493980407714844, -0.21973419189453125, -0.30851173400878906, -0.21973419189453125, 0.06144142150878906, 0.06144142150878906, -0.06923675537109375, -0.4082832336425781, 0.233856201171875, -0.0646820068359375, -0.13518524169921875, 0.0867919921875, -0.12807846069335938, -0.3512420654296875, -0.11113739013671875, -0.3510284423828125, -0.34081363677978516, -0.045012474060058594, -0.000579833984375], "custom_metrics": {}}}, "num_steps_sampled": 143136, "num_agent_steps_sampled": 429408, "num_steps_trained": 284288, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 852864, "last_target_update_ts": 142832, "num_target_updates": 278}, "done": false, "episodes_total": 15308, "training_iteration": 142, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-57-32", "timestamp": 1648918652, "time_this_iter_s": 40.7217378616333, "time_total_s": 5668.117997407913, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a15f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5668.117997407913, "timesteps_since_restore": 4544, "iterations_since_restore": 142, "perf": {"cpu_util_percent": 50.66491228070176, "ram_util_percent": 65.47719298245613}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 185.2377049180328, "episode_len_mean": 8.254098360655737, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.74590163934426, "policy1": 61.74590163934426, "policy2": 61.74590163934426}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 180.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 9, 8, 8, 10, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 9, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.052008379217392, "mean_inference_ms": 25.608697396325397, "mean_action_processing_ms": 0.24210109446932157, "mean_env_wait_ms": 0.1387087939520689, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 144144, "timesteps_this_iter": 32, "agent_timesteps_total": 432432, "timers": {"load_time_ms": 0.61, "load_throughput": 52428.8, "learn_time_ms": 232.177, "learn_throughput": 137.826, "update_time_ms": 112.254}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.22188949584961, "min_q": 8.39720630645752, "max_q": 61.33705520629883, "mean_td_error": 0.4522626996040344, "model": {}}, "td_error": [2.3152389526367188, -0.0493316650390625, 0.16789627075195312, 0.01204681396484375, -0.1737194061279297, 0.011554718017578125, 0.019056320190429688, 0.7668609619140625, -0.2862281799316406, -0.1886749267578125, -0.10955810546875, 3.0842151641845703, 2.9756622314453125, -0.1595630645751953, 0.32616424560546875, -0.36094093322753906, -0.3787803649902344, 2.7010021209716797, 0.2364959716796875, 0.0599822998046875, -0.09737777709960938, 0.4004402160644531, 2.8449602127075195, 0.23739242553710938, -0.10955810546875, -0.6027936935424805, 0.32616424560546875, 0.12897109985351562, 0.2915306091308594, 0.214263916015625, 0.002956390380859375, -0.13392257690429688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.522930145263672, "min_q": 5.135347843170166, "max_q": 61.11787796020508, "mean_td_error": -0.07840503752231598, "model": {}}, "td_error": [0.04601478576660156, 6.135347843170166, -0.3051605224609375, -0.1375408172607422, -0.22589683532714844, -0.4085350036621094, -0.17093276977539062, -0.32843971252441406, -0.4411659240722656, 0.3172340393066406, -0.011188507080078125, -0.19409465789794922, -0.10929679870605469, -1.7116546630859375, -0.4657020568847656, -0.24561691284179688, -0.46392345428466797, -0.1864776611328125, -0.1708526611328125, -0.20439529418945312, -0.2407398223876953, -0.40948486328125, -0.3936805725097656, -0.4638252258300781, -0.13384437561035156, -0.32909393310546875, 0.5425796508789062, -0.03391265869140625, -0.8219509124755859, -0.46392345428466797, -0.4411659240722656, -0.03764152526855469], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.42131805419922, "min_q": -0.85345458984375, "max_q": 63.288089752197266, "mean_td_error": 0.38767802715301514, "model": {}}, "td_error": [-0.31760406494140625, 0.9766817092895508, 0.03995990753173828, 0.18855857849121094, 0.7429084777832031, 0.16263961791992188, 0.696746826171875, -0.15566635131835938, 0.5154457092285156, 0.22915077209472656, 0.1716461181640625, 0.696746826171875, 1.0781898498535156, 0.6146831512451172, 0.22915077209472656, -0.18148040771484375, 0.22915077209472656, 0.2923126220703125, 0.16263961791992188, 0.4923133850097656, -0.3095836639404297, -0.18148040771484375, 0.3044013977050781, 0.4410133361816406, 0.3237342834472656, 2.329509735107422, 2.371326446533203, -0.27655029296875, 0.3237342834472656, -0.4395427703857422, 0.16263961791992188, 0.4923210144042969], "custom_metrics": {}}}, "num_steps_sampled": 144144, "num_agent_steps_sampled": 432432, "num_steps_trained": 286304, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 858912, "last_target_update_ts": 143856, "num_target_updates": 280}, "done": false, "episodes_total": 15430, "training_iteration": 143, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-58-13", "timestamp": 1648918693, "time_this_iter_s": 40.32952094078064, "time_total_s": 5708.447518348694, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c6ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c6ef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5708.447518348694, "timesteps_since_restore": 4576, "iterations_since_restore": 143, "perf": {"cpu_util_percent": 50.62241379310345, "ram_util_percent": 65.59482758620689}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.04237288135593, "episode_len_mean": 8.398305084745763, "episode_media": {}, "episodes_this_iter": 118, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.347457627118644, "policy1": 61.347457627118644, "policy2": 61.347457627118644}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 180.0, 180.0, 180.0, 186.0, 150.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 9, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 9, 10, 8, 9, 8, 8, 8, 8, 8, 8, 10, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 9, 8, 10, 10, 10, 8, 10, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 60.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 60.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 60.0, 60.0, 62.0, 50.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0517468236817447, "mean_inference_ms": 25.60433976746897, "mean_action_processing_ms": 0.24203134364753598, "mean_env_wait_ms": 0.13870619390422417, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 145152, "timesteps_this_iter": 32, "agent_timesteps_total": 435456, "timers": {"load_time_ms": 0.64, "load_throughput": 50027.108, "learn_time_ms": 224.105, "learn_throughput": 142.79, "update_time_ms": 118.023}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.41006851196289, "min_q": 5.729119300842285, "max_q": 60.97439193725586, "mean_td_error": 0.23583808541297913, "model": {}}, "td_error": [-0.06504058837890625, -0.06504058837890625, -0.19949722290039062, 6.729119300842285, -0.12836074829101562, -0.29694175720214844, 0.15689659118652344, 0.02980804443359375, -0.2021961212158203, -0.023876190185546875, -0.16505813598632812, -0.25589752197265625, -0.2742118835449219, 0.061141014099121094, -0.31620025634765625, -0.25589752197265625, -0.0159759521484375, 1.5239906311035156, -0.0159759521484375, -0.25589752197265625, 0.2044353485107422, 0.10547065734863281, -0.31620025634765625, -0.31620025634765625, 0.1885223388671875, 0.24138832092285156, 0.39159679412841797, 0.7097129821777344, 0.05789947509765625, -0.04648113250732422, 0.4082679748535156, -0.04648113250732422], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.496875762939453, "min_q": 5.218479156494141, "max_q": 60.633060455322266, "mean_td_error": 0.14994089305400848, "model": {}}, "td_error": [0.09331893920898438, 0.11939620971679688, 1.2173099517822266, -0.057086944580078125, 0.3441505432128906, 0.4048442840576172, 0.5466079711914062, 0.09391403198242188, 0.10156440734863281, -0.038829803466796875, 0.5213947296142578, 0.09331893920898438, -0.09197711944580078, 0.20751571655273438, 0.3441505432128906, 0.05757904052734375, -1.394925594329834, 0.4013710021972656, 0.5079460144042969, -0.048274993896484375, 0.3441505432128906, 0.3441505432128906, 0.29080677032470703, 0.1725921630859375, 0.018589019775390625, 0.26102638244628906, 0.078704833984375, 0.39641475677490234, 0.078704833984375, 0.12635421752929688, 0.034427642822265625, -0.7711009979248047], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 28.600360870361328, "min_q": 7.607965469360352, "max_q": 61.92317581176758, "mean_td_error": 0.3499123752117157, "model": {}}, "td_error": [-0.13162803649902344, 0.12496185302734375, 0.1076202392578125, 0.17284393310546875, -0.09806156158447266, -0.1289825439453125, -0.057094573974609375, -0.13162803649902344, -0.057094573974609375, 0.4369831085205078, -0.15664386749267578, 0.12394142150878906, 0.1725482940673828, 0.042682647705078125, 0.03576087951660156, 0.43239784240722656, 0.20686912536621094, 0.12496185302734375, 0.24071502685546875, -0.046421051025390625, 0.17284393310546875, -0.07073593139648438, -0.004425048828125, 0.24071502685546875, -0.1159505844116211, -0.053768157958984375, 0.503143310546875, 0.03576087951660156, 8.607965469360352, 0.22183990478515625, 0.023235321044921875, 0.22183990478515625], "custom_metrics": {}}}, "num_steps_sampled": 145152, "num_agent_steps_sampled": 435456, "num_steps_trained": 288320, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 864960, "last_target_update_ts": 144880, "num_target_updates": 282}, "done": false, "episodes_total": 15548, "training_iteration": 144, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-58-53", "timestamp": 1648918733, "time_this_iter_s": 40.28767371177673, "time_total_s": 5748.735192060471, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5748.735192060471, "timesteps_since_restore": 4608, "iterations_since_restore": 144, "perf": {"cpu_util_percent": 52.12280701754387, "ram_util_percent": 65.57368421052631}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 183.6198347107438, "episode_len_mean": 8.380165289256198, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.20661157024794, "policy1": 61.20661157024794, "policy2": 61.20661157024794}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 90.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 9, 8, 8, 8, 9, 10, 10, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 8, 8, 10, 8, 9, 10, 8, 8, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0525960024105676, "mean_inference_ms": 25.632967882099702, "mean_action_processing_ms": 0.24223273152888106, "mean_env_wait_ms": 0.13880846433753796, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 146160, "timesteps_this_iter": 32, "agent_timesteps_total": 438480, "timers": {"load_time_ms": 0.662, "load_throughput": 48356.293, "learn_time_ms": 230.89, "learn_throughput": 138.594, "update_time_ms": 116.355}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.16000747680664, "min_q": 5.725964546203613, "max_q": 60.63096618652344, "mean_td_error": 0.2848752737045288, "model": {}}, "td_error": [1.725210189819336, -0.19189453125, -0.47183990478515625, -0.15756797790527344, -0.4470252990722656, -0.1154022216796875, 0.08138847351074219, -0.086639404296875, -0.5334434509277344, -0.026737213134765625, 0.00862884521484375, -0.21300125122070312, -0.22414398193359375, 0.31238555908203125, 1.8843746185302734, -0.47183990478515625, -0.49444580078125, -0.009281158447265625, -0.17629623413085938, -0.9840259552001953, -0.06562423706054688, 6.725964546203613, -0.0431060791015625, -0.2476959228515625, 0.10907745361328125, 2.2528305053710938, -0.14756393432617188, 0.08138847351074219, 1.5064582824707031, -0.20432090759277344, -0.1338357925415039, -0.12596702575683594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.47130584716797, "min_q": 8.828871726989746, "max_q": 60.92180633544922, "mean_td_error": -0.028657883405685425, "model": {}}, "td_error": [-0.523773193359375, -0.21866798400878906, -0.28711509704589844, -0.09989547729492188, -0.08202362060546875, -0.21866798400878906, -0.21053504943847656, -0.2464752197265625, 0.035259246826171875, -0.4061088562011719, -0.6290664672851562, -0.3514842987060547, -0.7827262878417969, -0.6149063110351562, -0.3817558288574219, -0.09989547729492188, -0.15740585327148438, -0.523773193359375, -0.5010414123535156, -0.19822120666503906, -0.1711282730102539, -0.19822120666503906, -0.47797393798828125, -0.2791404724121094, -0.22852706909179688, 0.07358169555664062, -0.10535812377929688, -0.5010414123535156, -0.1701812744140625, 8.081504821777344, -0.2440662384033203, -0.19822120666503906], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.980295181274414, "min_q": 7.939399719238281, "max_q": 61.56728744506836, "mean_td_error": 0.18854382634162903, "model": {}}, "td_error": [0.12627410888671875, -0.06396865844726562, -0.07283592224121094, 0.2987213134765625, 0.30495262145996094, 0.15410614013671875, 0.0502777099609375, 0.20662689208984375, 0.09088325500488281, 0.1984710693359375, 0.12233924865722656, -0.5055809020996094, -0.061740875244140625, -0.013638496398925781, 0.24866485595703125, 0.4524250030517578, 0.2393207550048828, 0.4400672912597656, 0.41366004943847656, 0.08377838134765625, 0.4825763702392578, 0.19426441192626953, -0.00972747802734375, 0.2961921691894531, 0.07527923583984375, 0.36846256256103516, 0.000339508056640625, 1.6439056396484375, -0.01671600341796875, 0.046360015869140625, 0.000339508056640625, 0.23932266235351562], "custom_metrics": {}}}, "num_steps_sampled": 146160, "num_agent_steps_sampled": 438480, "num_steps_trained": 290336, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 871008, "last_target_update_ts": 145904, "num_target_updates": 284}, "done": false, "episodes_total": 15669, "training_iteration": 145, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_09-59-33", "timestamp": 1648918773, "time_this_iter_s": 39.766955852508545, "time_total_s": 5788.502147912979, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6757a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6757a0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5788.502147912979, "timesteps_since_restore": 4640, "iterations_since_restore": 145, "perf": {"cpu_util_percent": 50.71785714285714, "ram_util_percent": 65.20535714285714}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.875, "episode_len_mean": 8.458333333333334, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.291666666666664, "policy1": 61.291666666666664, "policy2": 61.291666666666664}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 183.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 180.0, 186.0, 183.0, 186.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0], "episode_lengths": [9, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 10, 10, 10, 8, 8, 10, 8, 8, 10, 9, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 9, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 10, 10, 10, 8, 8, 9, 8, 10, 8], "policy_policy0_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 61.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.053461844503865, "mean_inference_ms": 25.665208815605993, "mean_action_processing_ms": 0.242425145608179, "mean_env_wait_ms": 0.13897200686285832, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 147168, "timesteps_this_iter": 32, "agent_timesteps_total": 441504, "timers": {"load_time_ms": 0.769, "load_throughput": 41616.61, "learn_time_ms": 221.288, "learn_throughput": 144.608, "update_time_ms": 108.161}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.74758529663086, "min_q": 6.753392696380615, "max_q": 60.481971740722656, "mean_td_error": -0.1240793913602829, "model": {}}, "td_error": [-0.18849563598632812, 0.3266887664794922, -0.0922393798828125, -0.7453651428222656, -0.005213260650634766, -0.0318756103515625, 0.050052642822265625, -1.714874267578125, -0.21966934204101562, -0.0059032440185546875, -0.29763221740722656, 0.021373748779296875, 0.05770111083984375, 0.32025909423828125, 0.031475067138671875, -0.5045032501220703, -0.13910865783691406, -0.19586181640625, 0.3982219696044922, -0.2514533996582031, -0.5028076171875, 1.6122303009033203, 0.014249801635742188, -0.21966934204101562, -0.5028076171875, -0.4771232604980469, -0.0922393798828125, 0.021373748779296875, -0.5028076171875, -0.23749542236328125, -0.5045032501220703, 0.6074819564819336], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.21790313720703, "min_q": 8.13636302947998, "max_q": 61.630157470703125, "mean_td_error": 0.16020789742469788, "model": {}}, "td_error": [0.2348623275756836, 0.15204620361328125, 0.00235748291015625, 0.2885265350341797, 0.003772735595703125, -0.3273162841796875, 0.05742645263671875, 0.00235748291015625, 0.2971935272216797, 0.18912315368652344, -0.5867996215820312, 0.04723548889160156, 0.16315841674804688, 0.05742645263671875, -0.21295547485351562, -0.10268402099609375, 1.6376266479492188, -0.0652008056640625, -0.10268402099609375, 0.1062164306640625, -0.008846282958984375, 0.15204620361328125, 2.8460941314697266, -0.12678146362304688, -0.04446601867675781, -0.12678146362304688, 0.5940971374511719, 0.16446304321289062, -0.21376800537109375, 0.010850906372070312, 0.003772735595703125, 0.034282684326171875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.560516357421875, "min_q": 1.1075732707977295, "max_q": 61.16241455078125, "mean_td_error": -0.33471933007240295, "model": {}}, "td_error": [-0.2768211364746094, -0.3090667724609375, -0.4122428894042969, -0.3637847900390625, -0.0396728515625, -0.025691986083984375, -0.11338043212890625, -0.8443012237548828, -0.30804443359375, -4.625863075256348, -0.7851600646972656, -0.17433452606201172, -0.007529258728027344, -0.13581466674804688, 0.06091880798339844, -0.13581466674804688, -0.2768211364746094, -0.16289520263671875, -0.09438323974609375, -0.19883346557617188, 0.088470458984375, -0.2897510528564453, -0.09981536865234375, -0.09981536865234375, -0.13581466674804688, -0.21669769287109375, -0.2375812530517578, 0.21211624145507812, -0.32649803161621094, -0.1923828125, -0.2034454345703125, 0.019733428955078125], "custom_metrics": {}}}, "num_steps_sampled": 147168, "num_agent_steps_sampled": 441504, "num_steps_trained": 292352, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 877056, "last_target_update_ts": 146928, "num_target_updates": 286}, "done": false, "episodes_total": 15789, "training_iteration": 146, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-00-12", "timestamp": 1648918812, "time_this_iter_s": 39.622894048690796, "time_total_s": 5828.12504196167, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c61a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c61a440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5828.12504196167, "timesteps_since_restore": 4672, "iterations_since_restore": 146, "perf": {"cpu_util_percent": 50.841071428571425, "ram_util_percent": 65.18571428571428}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.88429752066116, "episode_len_mean": 8.289256198347108, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.62809917355372, "policy1": 61.62809917355372, "policy2": 61.62809917355372}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 183.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 183.0], "episode_lengths": [8, 9, 8, 10, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 10, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 10, 8, 10, 10, 8, 8, 8, 8, 8, 9, 10, 8, 9], "policy_policy0_reward": [62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0], "policy_policy1_reward": [62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0], "policy_policy2_reward": [62.0, 61.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0493130261888874, "mean_inference_ms": 25.50188238537524, "mean_action_processing_ms": 0.24110209156269805, "mean_env_wait_ms": 0.1382627776203202, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 148176, "timesteps_this_iter": 32, "agent_timesteps_total": 444528, "timers": {"load_time_ms": 0.704, "load_throughput": 45446.696, "learn_time_ms": 230.24, "learn_throughput": 138.985, "update_time_ms": 114.152}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.6942138671875, "min_q": -0.6613608002662659, "max_q": 60.58133316040039, "mean_td_error": 0.13396808505058289, "model": {}}, "td_error": [-0.3478050231933594, 0.17479515075683594, 0.17479515075683594, 0.35825347900390625, -0.03346824645996094, 0.00264739990234375, 0.14084243774414062, 0.33863919973373413, -0.2536048889160156, 2.0656471252441406, 0.02907562255859375, 0.46291351318359375, 0.1325359344482422, -0.007266998291015625, -0.1743316650390625, 0.9807472229003906, 0.17479515075683594, -0.03879547119140625, 0.021549224853515625, -0.13976287841796875, -0.085968017578125, -0.18486404418945312, 0.008525848388671875, -0.007678985595703125, 0.30899620056152344, 0.001953125, -0.4337310791015625, -0.035858154296875, 0.35825347900390625, 0.15563392639160156, -0.036266326904296875, 0.17578125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.87702941894531, "min_q": 7.656816005706787, "max_q": 61.095916748046875, "mean_td_error": 0.4491496682167053, "model": {}}, "td_error": [0.2534065246582031, 0.21846771240234375, 0.21846771240234375, -0.2490711212158203, 0.11203193664550781, -0.10208892822265625, 7.351083755493164, -0.011157989501953125, 0.1860198974609375, 0.603668212890625, 0.3862113952636719, -0.1724720001220703, -0.11926651000976562, -0.25435781478881836, 0.09001922607421875, -0.11011219024658203, -0.13562393188476562, 0.06780242919921875, 0.12228012084960938, 0.45166587829589844, -0.37700843811035156, -0.0009937286376953125, -0.408203125, -0.15196609497070312, -0.2165660858154297, 0.11230850219726562, 4.459606170654297, 1.7392044067382812, 0.1653900146484375, 0.12228012084960938, -0.14362716674804688, 0.1653900146484375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.094276428222656, "min_q": 2.9292707443237305, "max_q": 61.28438186645508, "mean_td_error": 0.20445263385772705, "model": {}}, "td_error": [0.0543365478515625, -0.14438247680664062, 0.7430801391601562, 0.12108612060546875, -0.130950927734375, -0.09918212890625, -0.13286113739013672, 0.3639984130859375, 2.3344268798828125, -0.0048370361328125, -0.19469642639160156, 0.00576019287109375, -0.20277786254882812, 0.15102195739746094, -0.20205307006835938, 0.7767581939697266, -0.023492813110351562, -0.20758819580078125, -0.1999053955078125, -0.031951904296875, -0.13286113739013672, -0.13792800903320312, -0.1555328369140625, -0.13792800903320312, -0.1555328369140625, 0.08681297302246094, 3.9292707443237305, 0.13668060302734375, 0.1616678237915039, 0.01076507568359375, -0.20758819580078125, 0.1688690185546875], "custom_metrics": {}}}, "num_steps_sampled": 148176, "num_agent_steps_sampled": 444528, "num_steps_trained": 294368, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 883104, "last_target_update_ts": 147952, "num_target_updates": 288}, "done": false, "episodes_total": 15910, "training_iteration": 147, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-00-53", "timestamp": 1648918853, "time_this_iter_s": 40.146260261535645, "time_total_s": 5868.271302223206, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62ab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c62ab90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5868.271302223206, "timesteps_since_restore": 4704, "iterations_since_restore": 147, "perf": {"cpu_util_percent": 52.15438596491229, "ram_util_percent": 65.16315789473684}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.56198347107437, "episode_len_mean": 8.314049586776859, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.52066115702479, "policy1": 61.52066115702479, "policy2": 61.52066115702479}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 10, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 9, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.05211447179331, "mean_inference_ms": 25.62248516378591, "mean_action_processing_ms": 0.2419752691012309, "mean_env_wait_ms": 0.13870303952828392, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 149184, "timesteps_this_iter": 32, "agent_timesteps_total": 447552, "timers": {"load_time_ms": 0.669, "load_throughput": 47857.988, "learn_time_ms": 224.01, "learn_throughput": 142.85, "update_time_ms": 113.151}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.29283905029297, "min_q": 9.234413146972656, "max_q": 61.26183319091797, "mean_td_error": 0.06608524918556213, "model": {}}, "td_error": [-0.058757781982421875, -0.265960693359375, 0.10455703735351562, 0.33266258239746094, -0.032123565673828125, 0.6515083312988281, 1.1964645385742188, 0.08149337768554688, 0.4420318603515625, -0.2986335754394531, -0.5317287445068359, 0.21614837646484375, -3.779149055480957, 0.3747978210449219, -0.30162620544433594, -0.5317287445068359, 0.23441314697265625, 0.20784568786621094, 0.29306602478027344, 0.33444976806640625, -0.3355255126953125, -0.07654380798339844, 2.627155303955078, -0.0329437255859375, 0.33444976806640625, 0.4388618469238281, 0.4032402038574219, -0.39189720153808594, 0.21614837646484375, 0.09671592712402344, -0.2986335754394531, 0.4639701843261719], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.05125045776367, "min_q": 8.16039752960205, "max_q": 62.834415435791016, "mean_td_error": 0.23295915126800537, "model": {}}, "td_error": [-0.461029052734375, 0.11412811279296875, 0.21062088012695312, 0.10103034973144531, 0.27268409729003906, 0.30121612548828125, 0.3686332702636719, 0.21486473083496094, 0.5867519378662109, 0.5867519378662109, 0.3686332702636719, 0.4680614471435547, 0.12069320678710938, 0.010562896728515625, 0.10297775268554688, 0.02125072479248047, 0.27268409729003906, 0.12069320678710938, 0.5806961059570312, 0.21062088012695312, 0.04677104949951172, 0.2624492645263672, 0.20517349243164062, 0.2954730987548828, -0.12604522705078125, 0.052154541015625, 1.0251045227050781, 0.4571533203125, 0.08258438110351562, -0.10090255737304688, 0.10058212280273438, 0.5816688537597656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.66878128051758, "min_q": 7.4380927085876465, "max_q": 61.41529083251953, "mean_td_error": 0.17567063868045807, "model": {}}, "td_error": [-0.12187576293945312, 0.15807342529296875, 0.0686798095703125, -0.09850311279296875, -0.12187576293945312, 0.33234405517578125, 0.0424041748046875, 0.26316070556640625, -0.07189750671386719, 0.0424041748046875, -0.012179374694824219, 4.309595108032227, 0.03916358947753906, -0.07189750671386719, 0.101409912109375, -1.5619072914123535, -0.14426612854003906, -0.11634159088134766, -0.3588752746582031, -0.0727081298828125, -0.027550697326660156, -0.04919242858886719, -0.040149688720703125, 0.14658355712890625, 0.10259246826171875, 0.101409912109375, 0.25087738037109375, -0.16851425170898438, 0.26316070556640625, 0.0628204345703125, -0.04793548583984375, 2.4224510192871094], "custom_metrics": {}}}, "num_steps_sampled": 149184, "num_agent_steps_sampled": 447552, "num_steps_trained": 296384, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 889152, "last_target_update_ts": 148976, "num_target_updates": 290}, "done": false, "episodes_total": 16031, "training_iteration": 148, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-01-34", "timestamp": 1648918894, "time_this_iter_s": 41.21595358848572, "time_total_s": 5909.487255811691, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75c050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c75c050>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5909.487255811691, "timesteps_since_restore": 4736, "iterations_since_restore": 148, "perf": {"cpu_util_percent": 50.81724137931034, "ram_util_percent": 65.04827586206896}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.01652892561984, "episode_len_mean": 8.413223140495868, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.33884297520661, "policy1": 61.33884297520661, "policy2": 61.33884297520661}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 150.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 150.0, 180.0, 186.0, 186.0, 180.0, 186.0], "episode_lengths": [8, 8, 8, 8, 9, 8, 10, 8, 8, 9, 10, 8, 8, 8, 10, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 9, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 9, 9, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 9, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 10, 10, 8, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 10, 8, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 50.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0522872405669468, "mean_inference_ms": 25.627094284095637, "mean_action_processing_ms": 0.2419644568058408, "mean_env_wait_ms": 0.13876574631774538, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 150192, "timesteps_this_iter": 32, "agent_timesteps_total": 450576, "timers": {"load_time_ms": 0.648, "load_throughput": 49419.245, "learn_time_ms": 221.166, "learn_throughput": 144.687, "update_time_ms": 121.11}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.966217041015625, "min_q": 0.5349545478820801, "max_q": 61.50716018676758, "mean_td_error": 0.19205528497695923, "model": {}}, "td_error": [-0.2456207275390625, 0.0648956298828125, 0.0415191650390625, 0.2717876434326172, 0.3411445617675781, 0.13827133178710938, -0.42271995544433594, -0.08234405517578125, 0.0415191650390625, -0.5460643768310547, 2.6156768798828125, 0.2717876434326172, 1.53495454788208, 0.2717876434326172, 0.14969635009765625, 0.13827133178710938, -0.1954517364501953, 0.03971290588378906, -0.12520503997802734, 0.06497955322265625, 2.0293846130371094, -0.3783397674560547, -0.17398452758789062, -0.082183837890625, 1.5639915466308594, -0.29148435592651367, -0.5939846038818359, -0.07201004028320312, -0.37190818786621094, -0.017414093017578125, -0.42272186279296875, 0.5878257751464844], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.116355895996094, "min_q": 5.460817337036133, "max_q": 61.74607849121094, "mean_td_error": 0.6692603230476379, "model": {}}, "td_error": [-0.3175506591796875, -0.5483779907226562, 1.0988426208496094, -0.3097076416015625, -0.36811065673828125, -0.6295967102050781, -0.2917938232421875, 26.940153121948242, 0.05647706985473633, 0.34732818603515625, -0.4028358459472656, -0.07291793823242188, -0.20810699462890625, -0.366180419921875, -0.5000267028808594, -0.05878448486328125, -0.37421607971191406, -0.40305328369140625, 1.3353004455566406, -0.5633430480957031, -0.4099903106689453, 0.08351516723632812, -0.19860076904296875, 0.004383087158203125, -0.3175506591796875, -0.5635604858398438, -0.34272193908691406, -0.195098876953125, -0.19689178466796875, -0.7639827728271484, -0.21882247924804688, 0.17215347290039062], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.399085998535156, "min_q": 8.76786994934082, "max_q": 60.93370056152344, "mean_td_error": 0.188323974609375, "model": {}}, "td_error": [0.3069610595703125, -0.09770011901855469, 0.25321388244628906, -0.4047431945800781, 2.1270008087158203, 1.9401988983154297, 0.3198738098144531, -0.13357925415039062, 0.15945816040039062, 0.08640670776367188, 0.8388214111328125, 0.08220672607421875, 0.15945816040039062, -0.1269855499267578, 0.15945816040039062, 0.2393341064453125, -0.15481948852539062, -0.13357925415039062, -0.18571853637695312, -0.18024063110351562, 0.8388214111328125, -0.150909423828125, 0.33470916748046875, -0.1392822265625, 0.0492095947265625, -0.031223297119140625, 0.6171226501464844, -0.12415695190429688, -0.1392822265625, -0.2321300506591797, -0.18571853637695312, -0.06581878662109375], "custom_metrics": {}}}, "num_steps_sampled": 150192, "num_agent_steps_sampled": 450576, "num_steps_trained": 298400, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 895200, "last_target_update_ts": 150000, "num_target_updates": 292}, "done": false, "episodes_total": 16152, "training_iteration": 149, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-02-14", "timestamp": 1648918934, "time_this_iter_s": 40.361671447753906, "time_total_s": 5949.848927259445, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a2dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a2dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5949.848927259445, "timesteps_since_restore": 4768, "iterations_since_restore": 149, "perf": {"cpu_util_percent": 50.5280701754386, "ram_util_percent": 65.11228070175439}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 184.890756302521, "episode_len_mean": 8.369747899159664, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.63025210084034, "policy1": 61.63025210084034, "policy2": 61.63025210084034}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 183.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 180.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [9, 8, 10, 8, 8, 8, 10, 10, 8, 8, 9, 10, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 10, 8, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 9, 9, 8, 8, 8, 10, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8], "policy_policy0_reward": [61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0521079215706597, "mean_inference_ms": 25.621086413913932, "mean_action_processing_ms": 0.2419109312304026, "mean_env_wait_ms": 0.13869974437758822, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 151200, "timesteps_this_iter": 32, "agent_timesteps_total": 453600, "timers": {"load_time_ms": 0.671, "load_throughput": 47677.783, "learn_time_ms": 232.982, "learn_throughput": 137.35, "update_time_ms": 106.827}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.38133239746094, "min_q": 8.367980003356934, "max_q": 60.9744758605957, "mean_td_error": -0.01570191979408264, "model": {}}, "td_error": [0.14730072021484375, -0.008310317993164062, -0.39050865173339844, -0.2129497528076172, -0.023067474365234375, 0.14730072021484375, 0.07357406616210938, -1.0171680450439453, 0.14730072021484375, -0.0009002685546875, -0.1706533432006836, 1.8351554870605469, 0.07357406616210938, 0.4681739807128906, -0.3057708740234375, -0.024694442749023438, 0.035953521728515625, -0.09897232055664062, -0.24186325073242188, -0.034534454345703125, 0.4219856262207031, -0.21342849731445312, -0.28209877014160156, -0.39050865173339844, 0.29517173767089844, -0.0766143798828125, -0.01720428466796875, 0.4219856262207031, -0.6320199966430664, -0.11983585357666016, -0.3057746887207031, -0.00305938720703125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.29124069213867, "min_q": 7.3917083740234375, "max_q": 61.19907760620117, "mean_td_error": -0.14748650789260864, "model": {}}, "td_error": [0.31520843505859375, -0.2663536071777344, -0.3438577651977539, -0.24600601196289062, -0.3730583190917969, -0.2855052947998047, -0.06671524047851562, -0.6306953430175781, 1.7579879760742188, -0.383392333984375, -0.1282672882080078, -0.06671524047851562, -0.04698944091796875, 0.11787796020507812, -0.2855052947998047, -0.6306953430175781, -0.2469482421875, -0.013225555419921875, -0.484588623046875, 0.024749755859375, -0.4722576141357422, -0.17794036865234375, -0.4722576141357422, -0.3173713684082031, -0.06671524047851562, -0.24403762817382812, -0.43173694610595703, 0.4309043884277344, 0.09053802490234375, -0.0370330810546875, -0.3555774688720703, -0.3833885192871094], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.36056137084961, "min_q": 8.731200218200684, "max_q": 61.75352096557617, "mean_td_error": 0.07157346606254578, "model": {}}, "td_error": [0.2791328430175781, 0.06652450561523438, 0.07118606567382812, -0.2865791320800781, -0.044101715087890625, -0.292144775390625, 0.08197212219238281, -0.266082763671875, 1.9369773864746094, -0.19466590881347656, 0.15578460693359375, -0.2687997817993164, -0.372039794921875, 0.1435546875, 0.07607650756835938, -0.045867919921875, -0.19466590881347656, 0.0501708984375, 0.08197212219238281, -0.18383407592773438, 0.06529426574707031, 0.07118606567382812, 0.3437843322753906, -0.09389877319335938, -0.0016632080078125, -0.045867919921875, 0.24303627014160156, -0.0496673583984375, 0.045257568359375, 0.55682373046875, 0.0665283203125, 0.2949676513671875], "custom_metrics": {}}}, "num_steps_sampled": 151200, "num_agent_steps_sampled": 453600, "num_steps_trained": 300416, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 901248, "last_target_update_ts": 151024, "num_target_updates": 294}, "done": false, "episodes_total": 16271, "training_iteration": 150, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-02-55", "timestamp": 1648918975, "time_this_iter_s": 40.499064207077026, "time_total_s": 5990.347991466522, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a20e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6a20e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 5990.347991466522, "timesteps_since_restore": 4800, "iterations_since_restore": 150, "perf": {"cpu_util_percent": 51.75, "ram_util_percent": 65.35862068965517}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 184.73553719008265, "episode_len_mean": 8.421487603305785, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.578512396694215, "policy1": 61.578512396694215, "policy2": 61.578512396694215}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 183.0, 183.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 180.0, 180.0, 186.0, 183.0, 186.0, 186.0, 183.0], "episode_lengths": [10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 10, 8, 10, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 10, 8, 10, 8, 9, 9, 8, 9, 8, 8, 9, 8, 8, 8, 10, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 10, 10, 10, 8, 9, 8, 8, 9], "policy_policy0_reward": [60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0], "policy_policy1_reward": [60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0], "policy_policy2_reward": [60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 61.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0506270781491247, "mean_inference_ms": 25.56784833287051, "mean_action_processing_ms": 0.24145095091407506, "mean_env_wait_ms": 0.13852698822438672, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 152208, "timesteps_this_iter": 32, "agent_timesteps_total": 456624, "timers": {"load_time_ms": 0.637, "load_throughput": 50255.636, "learn_time_ms": 236.003, "learn_throughput": 135.592, "update_time_ms": 114.607}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.164981842041016, "min_q": 7.782168388366699, "max_q": 62.027931213378906, "mean_td_error": 0.0876295268535614, "model": {}}, "td_error": [1.1417617797851562, -0.20287322998046875, -0.4412117004394531, 0.013759613037109375, -0.42131519317626953, -0.2620716094970703, 0.32068634033203125, -0.13373947143554688, -0.048553466796875, 0.3108558654785156, 0.027767181396484375, 0.18195343017578125, 0.3078346252441406, 2.067249298095703, 0.07014083862304688, -0.29222869873046875, 0.32068634033203125, 0.1690998077392578, -0.2667579650878906, 0.5286445617675781, -0.1690387725830078, -0.10558700561523438, -0.4109535217285156, 0.23132705688476562, -0.33013343811035156, 0.2598724365234375, 0.18195343017578125, -0.09813308715820312, 0.39987945556640625, 0.06898880004882812, -0.2620716094970703, -0.35364723205566406], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.12293243408203, "min_q": 8.795904159545898, "max_q": 61.504180908203125, "mean_td_error": -0.09943580627441406, "model": {}}, "td_error": [-0.09505462646484375, 0.3078498840332031, 0.176025390625, -0.13794708251953125, -0.5089111328125, 0.0054454803466796875, 0.019184112548828125, -0.5208816528320312, -0.5673847198486328, -0.01873779296875, -0.04796600341796875, -0.3381919860839844, 0.2741851806640625, -0.32955169677734375, -0.3427581787109375, -0.04296875, -0.12156295776367188, -0.20409584045410156, 0.019184112548828125, -0.3559303283691406, 0.10776901245117188, -0.24395751953125, 0.3142204284667969, 0.10776901245117188, -0.3559303283691406, -0.085968017578125, -0.17759132385253906, -0.05162811279296875, -0.01873779296875, 0.10776901245117188, -0.085968017578125, 0.030376434326171875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.435916900634766, "min_q": 6.807400703430176, "max_q": 61.63616943359375, "mean_td_error": 0.5230958461761475, "model": {}}, "td_error": [2.706472396850586, 0.9348239898681641, 0.17455291748046875, 0.2874336242675781, 0.0065765380859375, 0.3595428466796875, 0.2856864929199219, 0.21522903442382812, 0.2517547607421875, 0.806884765625, 0.11581850051879883, 0.35532379150390625, 0.15682411193847656, 0.39931488037109375, 2.3302059173583984, 0.2349987030029297, 0.2349987030029297, 2.684568405151367, 0.3593864440917969, 0.3481178283691406, 0.3481178283691406, 0.39931488037109375, 0.30843257904052734, -0.12997055053710938, 0.2664794921875, 0.39931488037109375, 0.9225406646728516, 0.25481414794921875, 0.17455291748046875, 0.26812744140625, 0.17455291748046875, 0.10427474975585938], "custom_metrics": {}}}, "num_steps_sampled": 152208, "num_agent_steps_sampled": 456624, "num_steps_trained": 302432, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 907296, "last_target_update_ts": 152048, "num_target_updates": 296}, "done": false, "episodes_total": 16392, "training_iteration": 151, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-03-36", "timestamp": 1648919016, "time_this_iter_s": 40.96004819869995, "time_total_s": 6031.308039665222, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5be830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5be830>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6031.308039665222, "timesteps_since_restore": 4832, "iterations_since_restore": 151, "perf": {"cpu_util_percent": 51.225862068965505, "ram_util_percent": 65.53448275862068}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 185.28099173553719, "episode_len_mean": 8.239669421487603, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.760330578512395, "policy1": 61.760330578512395, "policy2": 61.760330578512395}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 9, 8, 8, 10, 8, 10, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 9, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0519181152307766, "mean_inference_ms": 25.620000633260215, "mean_action_processing_ms": 0.24179673946189234, "mean_env_wait_ms": 0.13865428079058986, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 153216, "timesteps_this_iter": 32, "agent_timesteps_total": 459648, "timers": {"load_time_ms": 0.641, "load_throughput": 49911.765, "learn_time_ms": 232.671, "learn_throughput": 137.533, "update_time_ms": 122.854}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.47540283203125, "min_q": 8.790571212768555, "max_q": 61.79086685180664, "mean_td_error": 0.5050273537635803, "model": {}}, "td_error": [0.1829700469970703, 0.012462615966796875, 0.4263782501220703, 0.07694625854492188, 0.001621246337890625, 0.221038818359375, -0.7338390350341797, 0.012462615966796875, 0.039585113525390625, 3.3357787132263184, 0.3778877258300781, 2.2445316314697266, 0.18596839904785156, 0.179595947265625, -0.029510498046875, -0.016078948974609375, 0.012462615966796875, 0.12177371978759766, 0.01509857177734375, 0.12177371978759766, -0.11802864074707031, -0.2094287872314453, -0.029510498046875, 0.25252532958984375, 0.07694625854492188, -0.11314773559570312, -0.025848388671875, 0.07694625854492188, 0.14189720153808594, 0.22283172607421875, 9.07745361328125, 0.019330978393554688], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.93818283081055, "min_q": 17.89491081237793, "max_q": 61.245975494384766, "mean_td_error": -0.033379316329956055, "model": {}}, "td_error": [-0.22165679931640625, -0.08463668823242188, 0.10601234436035156, -0.21085739135742188, 0.2651939392089844, -0.11003875732421875, 0.13608932495117188, 0.17800140380859375, -0.1982097625732422, -0.1863861083984375, -0.4054756164550781, -0.16072845458984375, 0.2336559295654297, -0.2592144012451172, -0.11003875732421875, -0.1982097625732422, -0.052913665771484375, 0.13608932495117188, 0.06807327270507812, -0.032222747802734375, -0.3332252502441406, -0.0798492431640625, -0.01009368896484375, -0.32032203674316406, -0.16072845458984375, 0.12923240661621094, -0.1150360107421875, 0.8253459930419922, 0.06807327270507812, 0.11714935302734375, -0.2592144012451172, 0.17800331115722656], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.1822566986084, "min_q": 8.702211380004883, "max_q": 59.968841552734375, "mean_td_error": 0.15002989768981934, "model": {}}, "td_error": [-0.04518318176269531, -0.1702289581298828, -0.2067737579345703, 0.7260894775390625, -0.04518318176269531, 0.7694778442382812, 0.07157516479492188, 0.7260894775390625, 0.0505218505859375, -0.2977886199951172, 0.06657028198242188, -0.06186676025390625, 0.022064208984375, -0.18485260009765625, 0.015005111694335938, -0.0651845932006836, 0.8472537994384766, -0.06805801391601562, -0.1904296875, 0.2756204605102539, 0.2521228790283203, -0.15157127380371094, 0.1841583251953125, 0.041259765625, 0.19554901123046875, -0.1847515106201172, 0.5248908996582031, 1.5885238647460938, 0.107269287109375, -0.15157127380371094, 0.18416595458984375, -0.023807525634765625], "custom_metrics": {}}}, "num_steps_sampled": 153216, "num_agent_steps_sampled": 459648, "num_steps_trained": 304448, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 913344, "last_target_update_ts": 153072, "num_target_updates": 298}, "done": false, "episodes_total": 16513, "training_iteration": 152, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-04-16", "timestamp": 1648919056, "time_this_iter_s": 39.798287868499756, "time_total_s": 6071.106327533722, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c734b90>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6071.106327533722, "timesteps_since_restore": 4864, "iterations_since_restore": 152, "perf": {"cpu_util_percent": 50.926785714285714, "ram_util_percent": 65.29821428571428}}
{"episode_reward_max": 186.0, "episode_reward_min": 90.0, "episode_reward_mean": 182.975, "episode_len_mean": 8.425, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 30.0, "policy1": 30.0, "policy2": 30.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 60.99166666666667, "policy1": 60.99166666666667, "policy2": 60.99166666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 183.0, 183.0, 180.0, 186.0, 180.0, 180.0, 180.0, 186.0, 186.0, 90.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 180.0, 180.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 8, 8, 8, 9, 8, 10, 8, 9, 8, 8, 8, 8, 10, 10, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 10, 8, 10, 8, 9, 9, 10, 8, 10, 10, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 10, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8], "policy_policy0_reward": [60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 60.0, 62.0, 60.0, 60.0, 60.0, 62.0, 62.0, 30.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 60.0, 60.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0516791433309007, "mean_inference_ms": 25.604298728935664, "mean_action_processing_ms": 0.24162984250107558, "mean_env_wait_ms": 0.13857042843771286, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 154224, "timesteps_this_iter": 32, "agent_timesteps_total": 462672, "timers": {"load_time_ms": 0.669, "load_throughput": 47830.7, "learn_time_ms": 236.952, "learn_throughput": 135.048, "update_time_ms": 127.833}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.121395111083984, "min_q": 8.6304931640625, "max_q": 61.44240188598633, "mean_td_error": 0.21654123067855835, "model": {}}, "td_error": [0.4568309783935547, 0.04744720458984375, 0.11457443237304688, -0.32928466796875, 0.4314746856689453, 0.24692153930664062, -0.028093338012695312, 0.06563568115234375, 0.04744720458984375, -0.24201202392578125, 0.06563568115234375, 0.023923873901367188, -0.3695068359375, 1.9686012268066406, 0.09417057037353516, 0.5645256042480469, 0.14038848876953125, 0.335662841796875, -0.248016357421875, -0.2578277587890625, 0.0981903076171875, 2.0689048767089844, 0.045017242431640625, -0.2578277587890625, 0.015269279479980469, 2.2703819274902344, 0.24692153930664062, 0.027851104736328125, -0.248016357421875, 0.06678009033203125, -0.2846355438232422, -0.248016357421875], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.99073791503906, "min_q": 9.142444610595703, "max_q": 61.65005111694336, "mean_td_error": -0.017467409372329712, "model": {}}, "td_error": [-0.2840423583984375, -0.042865753173828125, 0.14244461059570312, -0.351409912109375, 0.21741676330566406, -0.08185958862304688, -0.03591156005859375, -0.43822479248046875, -0.351409912109375, -0.042865753173828125, 0.5636405944824219, 0.5636405944824219, -0.4642181396484375, -0.088714599609375, -0.14203643798828125, 0.13902854919433594, -0.5804634094238281, -0.4879188537597656, -0.001186370849609375, 0.0722808837890625, -0.14203643798828125, -0.14203643798828125, -0.08185958862304688, -0.03591156005859375, 0.9928436279296875, -0.12127304077148438, 0.3211860656738281, 0.026123046875, -0.17933082580566406, 0.09503746032714844, 0.14244461059570312, 0.2605314254760742], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.343017578125, "min_q": 12.50446891784668, "max_q": 61.126731872558594, "mean_td_error": 0.2551896572113037, "model": {}}, "td_error": [-0.06516265869140625, -0.06516265869140625, -0.00165557861328125, -0.06516265869140625, 1.1702213287353516, -0.32297325134277344, 0.48439788818359375, -0.42298316955566406, -0.00165557861328125, -0.1353588104248047, 0.6641769409179688, 0.17421913146972656, 0.20767593383789062, 0.04259490966796875, -0.06416130065917969, -0.3428382873535156, -0.3386554718017578, -0.14195632934570312, 2.388721466064453, 8.929679870605469, -0.289459228515625, 0.04259490966796875, -0.4296588897705078, -0.00165557861328125, 0.04259490966796875, -0.31904029846191406, -3.78057861328125, -0.1625347137451172, 0.5325851440429688, 0.21945571899414062, 0.21945953369140625, -0.00165557861328125], "custom_metrics": {}}}, "num_steps_sampled": 154224, "num_agent_steps_sampled": 462672, "num_steps_trained": 306464, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 919392, "last_target_update_ts": 154096, "num_target_updates": 300}, "done": false, "episodes_total": 16633, "training_iteration": 153, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-04-59", "timestamp": 1648919099, "time_this_iter_s": 43.25425148010254, "time_total_s": 6114.3605790138245, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c72d440>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6114.3605790138245, "timesteps_since_restore": 4896, "iterations_since_restore": 153, "perf": {"cpu_util_percent": 52.29032258064517, "ram_util_percent": 65.49032258064517}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.925, "episode_len_mean": 8.441666666666666, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.30833333333333, "policy1": 61.30833333333333, "policy2": 61.30833333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [10, 8, 8, 10, 8, 8, 9, 8, 9, 8, 8, 9, 8, 8, 8, 9, 8, 9, 10, 8, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 9, 10, 8, 8, 10, 8, 10, 8, 10, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 10, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0517151597362688, "mean_inference_ms": 25.61067025728861, "mean_action_processing_ms": 0.24164084683660356, "mean_env_wait_ms": 0.13861264026064563, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 155232, "timesteps_this_iter": 32, "agent_timesteps_total": 465696, "timers": {"load_time_ms": 0.715, "load_throughput": 44775.063, "learn_time_ms": 248.225, "learn_throughput": 128.915, "update_time_ms": 105.071}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.30907440185547, "min_q": 8.083797454833984, "max_q": 60.70346450805664, "mean_td_error": -0.21337926387786865, "model": {}}, "td_error": [-0.1701984405517578, -0.304931640625, 0.03424072265625, -0.4913787841796875, -0.08345413208007812, -0.04804039001464844, -0.6455612182617188, -0.15766143798828125, 0.16546058654785156, -0.6282272338867188, -0.4082489013671875, -0.4913787841796875, -0.4913787841796875, -0.3383941650390625, -0.2436199188232422, -0.399627685546875, -0.28017425537109375, 0.02751922607421875, -0.6282272338867188, -0.11101531982421875, -0.11101531982421875, -0.04836273193359375, 0.03424072265625, 0.142791748046875, -0.399627685546875, -0.3948173522949219, -0.4913787841796875, 0.026294708251953125, 1.0256195068359375, -0.4913787841796875, -0.15777587890625, -0.2684288024902344], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 40.953590393066406, "min_q": 7.710904121398926, "max_q": 60.468631744384766, "mean_td_error": -0.1702682077884674, "model": {}}, "td_error": [0.3792877197265625, -0.06985092163085938, -0.2521400451660156, -0.3148345947265625, -0.4649515151977539, -0.455047607421875, -0.11695098876953125, -0.02362060546875, -0.013210296630859375, 0.18819046020507812, -0.21672439575195312, -0.116546630859375, -0.22295761108398438, -0.455047607421875, 0.05439949035644531, -0.27318763732910156, 0.28870391845703125, 0.3792877197265625, -0.03025054931640625, -0.3018646240234375, -0.2860527038574219, -0.03025054931640625, -0.15290069580078125, -0.8362693786621094, -0.3493232727050781, -0.2521400451660156, -0.8915748596191406, -0.19291305541992188, -0.03025054931640625, -0.395416259765625, -0.012847900390625, 0.018672943115234375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.961395263671875, "min_q": 9.076255798339844, "max_q": 61.47608947753906, "mean_td_error": 0.38895541429519653, "model": {}}, "td_error": [0.3746929168701172, -0.06391525268554688, -0.12908935546875, -0.08042526245117188, -0.1362152099609375, 0.07625579833984375, -0.326416015625, 0.09223556518554688, 0.2738189697265625, -0.25163841247558594, -0.18323898315429688, -0.4736518859863281, -0.18207931518554688, -0.25163841247558594, 0.20968246459960938, 0.09223556518554688, 0.10733413696289062, 9.210285186767578, 0.29553890228271484, 2.7454891204833984, -0.21229171752929688, 0.27973175048828125, -0.08042526245117188, 0.318603515625, 1.0429801940917969, 0.16242313385009766, 0.318603515625, -0.4736518859863281, 0.3862342834472656, -0.18323898315429688, -0.08203315734863281, -0.4296226501464844], "custom_metrics": {}}}, "num_steps_sampled": 155232, "num_agent_steps_sampled": 465696, "num_steps_trained": 308480, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 925440, "last_target_update_ts": 155120, "num_target_updates": 302}, "done": false, "episodes_total": 16753, "training_iteration": 154, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-05-40", "timestamp": 1648919140, "time_this_iter_s": 40.603049755096436, "time_total_s": 6154.963628768921, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c6dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c6c6dd0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6154.963628768921, "timesteps_since_restore": 4928, "iterations_since_restore": 154, "perf": {"cpu_util_percent": 51.03157894736842, "ram_util_percent": 65.10000000000001}}
{"episode_reward_max": 186.0, "episode_reward_min": 180.0, "episode_reward_mean": 185.0082644628099, "episode_len_mean": 8.330578512396695, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 60.0, "policy1": 60.0, "policy2": 60.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.66942148760331, "policy1": 61.66942148760331, "policy2": 61.66942148760331}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0], "episode_lengths": [8, 10, 8, 9, 8, 8, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 9, 10, 10, 8, 10, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 9, 10, 10, 8, 8, 8, 10, 8, 8, 9, 8, 9, 8, 8], "policy_policy0_reward": [62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.052653986093803, "mean_inference_ms": 25.652618734411735, "mean_action_processing_ms": 0.2418950580956764, "mean_env_wait_ms": 0.13877598546373476, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 156240, "timesteps_this_iter": 32, "agent_timesteps_total": 468720, "timers": {"load_time_ms": 0.638, "load_throughput": 50129.875, "learn_time_ms": 235.509, "learn_throughput": 135.876, "update_time_ms": 120.298}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.404647827148438, "min_q": 6.376717567443848, "max_q": 61.66333770751953, "mean_td_error": -0.06649181246757507, "model": {}}, "td_error": [-0.2806358337402344, -2.4022645950317383, -0.17322540283203125, -0.3563041687011719, -0.2597160339355469, -0.6848058700561523, -0.30634498596191406, -0.19304275512695312, -0.1656017303466797, -0.1708984375, 2.4772987365722656, -0.23432350158691406, -0.1388530731201172, -0.5468788146972656, 0.20389080047607422, -0.27709197998046875, 0.1630725860595703, -0.2506866455078125, 0.2551765441894531, -0.20370864868164062, -0.6530933380126953, -0.8899803161621094, -0.7122325897216797, 0.2406005859375, -0.34117889404296875, -0.022314071655273438, 2.182952880859375, -0.13350677490234375, 0.2406005859375, -0.34032249450683594, 0.3733062744140625, 1.4723739624023438], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.891504287719727, "min_q": 7.828296661376953, "max_q": 61.52081298828125, "mean_td_error": -0.14852377772331238, "model": {}}, "td_error": [-0.4000816345214844, -0.4122810363769531, -0.31290245056152344, 0.08700180053710938, 0.0854339599609375, -0.41832733154296875, -0.31290245056152344, -0.088287353515625, -0.4000816345214844, 0.0478515625, -0.19908428192138672, 0.01830291748046875, 0.0931243896484375, 0.13433074951171875, -0.09548187255859375, -0.21639156341552734, 0.2426013946533203, -0.4122810363769531, -0.19725608825683594, -0.31290245056152344, -0.11141204833984375, -0.3138160705566406, 0.0478515625, -0.45191192626953125, -0.6982440948486328, 0.30939483642578125, -0.3243865966796875, 0.011180877685546875, -0.11773395538330078, -0.4000816345214844, 0.026760101318359375, 0.3392524719238281], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.678489685058594, "min_q": 17.621261596679688, "max_q": 61.466270446777344, "mean_td_error": 0.416864275932312, "model": {}}, "td_error": [-0.263031005859375, -0.4050884246826172, -0.3194732666015625, 0.14017868041992188, -0.5274925231933594, 2.341571807861328, 1.669851303100586, 8.475616455078125, -0.28461456298828125, 0.08160018920898438, 0.08345794677734375, 2.6147689819335938, 0.10225677490234375, -0.11902618408203125, -0.22908401489257812, 0.060504913330078125, 0.056797027587890625, 0.028293609619140625, -0.263031005859375, -0.41756248474121094, 2.087371826171875, -0.15552139282226562, 0.2266845703125, -0.22908401489257812, -0.11902618408203125, 0.0656890869140625, 0.0026264190673828125, -0.0890350341796875, -0.4570579528808594, -0.2773418426513672, 0.06050682067871094, -0.6026496887207031], "custom_metrics": {}}}, "num_steps_sampled": 156240, "num_agent_steps_sampled": 468720, "num_steps_trained": 310496, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 931488, "last_target_update_ts": 156144, "num_target_updates": 304}, "done": false, "episodes_total": 16874, "training_iteration": 155, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-06-21", "timestamp": 1648919181, "time_this_iter_s": 41.327420234680176, "time_total_s": 6196.291049003601, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5dbe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5dbe60>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6196.291049003601, "timesteps_since_restore": 4960, "iterations_since_restore": 155, "perf": {"cpu_util_percent": 51.19322033898306, "ram_util_percent": 65.13389830508474}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.51239669421489, "episode_len_mean": 8.330578512396695, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.50413223140496, "policy1": 61.50413223140496, "policy2": 61.50413223140496}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 180.0, 186.0, 186.0, 150.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 10, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 9, 8, 10, 10, 8, 8, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 62.0, 50.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0520449774666778, "mean_inference_ms": 25.624902675513063, "mean_action_processing_ms": 0.24163928565168277, "mean_env_wait_ms": 0.13864312047374666, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 157248, "timesteps_this_iter": 32, "agent_timesteps_total": 471744, "timers": {"load_time_ms": 0.664, "load_throughput": 48161.952, "learn_time_ms": 245.892, "learn_throughput": 130.138, "update_time_ms": 123.023}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.824363708496094, "min_q": 8.908270835876465, "max_q": 61.497440338134766, "mean_td_error": -0.04779946804046631, "model": {}}, "td_error": [0.5519351959228516, -0.0368804931640625, -0.27474212646484375, -0.23334503173828125, -0.12126350402832031, -0.08589363098144531, -0.35144805908203125, 0.10457611083984375, 0.23015594482421875, -0.27529335021972656, -0.191162109375, -0.313751220703125, -0.09172916412353516, -0.2752418518066406, 1.3001117706298828, 0.03582572937011719, -0.2752418518066406, -0.003265380859375, -0.32773590087890625, 0.114471435546875, -0.24306488037109375, -0.052135467529296875, -0.27474212646484375, 0.114471435546875, -0.2752418518066406, -0.3057365417480469, 0.20280075073242188, -0.09172916412353516, -0.0022525787353515625, -0.012115478515625, 0.00733184814453125, -0.07725143432617188], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.42273712158203, "min_q": 8.912049293518066, "max_q": 61.47712326049805, "mean_td_error": -0.09442463517189026, "model": {}}, "td_error": [-0.03292083740234375, -0.15524864196777344, -0.083221435546875, 0.4802436828613281, 0.32045745849609375, 0.40546417236328125, -0.104522705078125, -0.09136009216308594, 0.12247467041015625, 0.00457000732421875, 0.004909515380859375, -0.2163982391357422, 0.1374053955078125, -0.1615753173828125, 0.49079132080078125, -0.6017360687255859, -0.4795818328857422, 0.027957916259765625, -0.12934494018554688, 0.32045745849609375, -0.6627388000488281, -0.6627388000488281, -0.5400733947753906, -0.33545684814453125, -0.1615753173828125, -0.8087844848632812, 0.0154876708984375, 0.052379608154296875, 0.085357666015625, -0.14793777465820312, -0.0879507064819336, -0.026378631591796875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 30.415245056152344, "min_q": 6.830877780914307, "max_q": 62.035560607910156, "mean_td_error": 0.07954582571983337, "model": {}}, "td_error": [0.3397216796875, 0.08658981323242188, 1.0984954833984375, -0.019775390625, 0.15516281127929688, -0.5474739074707031, -0.793212890625, -0.4135551452636719, -0.49040794372558594, 0.3933219909667969, -0.3203396797180176, 0.08386802673339844, 0.020278453826904297, 0.3834953308105469, -0.46506500244140625, 0.22866058349609375, 0.6029796600341797, 0.22866058349609375, 2.262333869934082, -0.22280120849609375, 0.1694507598876953, -0.3718223571777344, 0.3630561828613281, -0.6372966766357422, -0.2898378372192383, 0.3347206115722656, 0.4330024719238281, -0.30035972595214844, 0.14722442626953125, 0.28000640869140625, -0.4135570526123047, 0.2199420928955078], "custom_metrics": {}}}, "num_steps_sampled": 157248, "num_agent_steps_sampled": 471744, "num_steps_trained": 312512, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 937536, "last_target_update_ts": 157168, "num_target_updates": 306}, "done": false, "episodes_total": 16995, "training_iteration": 156, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-07-07", "timestamp": 1648919227, "time_this_iter_s": 45.09216380119324, "time_total_s": 6241.383212804794, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5e5200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5e5200>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6241.383212804794, "timesteps_since_restore": 4992, "iterations_since_restore": 156, "perf": {"cpu_util_percent": 52.64687500000001, "ram_util_percent": 65.1171875}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.9, "episode_len_mean": 8.366666666666667, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.3, "policy1": 61.3, "policy2": 61.3}, "custom_metrics": {}, "hist_stats": {"episode_reward": [183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 180.0, 150.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 150.0, 186.0, 183.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [9, 8, 8, 8, 8, 8, 8, 9, 10, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 10, 8, 8, 10, 8, 8, 8, 10, 10, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 9, 8, 10, 8, 9, 9, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 60.0, 50.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 50.0, 62.0, 61.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.054552563008415, "mean_inference_ms": 25.722306218603844, "mean_action_processing_ms": 0.24237955614351328, "mean_env_wait_ms": 0.1390392620414163, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 158256, "timesteps_this_iter": 32, "agent_timesteps_total": 474768, "timers": {"load_time_ms": 0.652, "load_throughput": 49054.394, "learn_time_ms": 231.829, "learn_throughput": 138.033, "update_time_ms": 130.682}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.859745025634766, "min_q": 7.926376819610596, "max_q": 61.55561065673828, "mean_td_error": 0.07383309304714203, "model": {}}, "td_error": [-0.40218353271484375, -0.2786827087402344, -0.18028640747070312, -0.2732696533203125, -0.5073966979980469, -0.5073966979980469, 1.32415771484375, -0.4035987854003906, -0.4843463897705078, -0.09593582153320312, -0.37607574462890625, -0.16823577880859375, -0.2732696533203125, 1.6114006042480469, -0.2348480224609375, 0.12592506408691406, -0.16823577880859375, 0.008877277374267578, -0.9616107940673828, -0.7143764495849609, 1.8603172302246094, 0.12592506408691406, 2.544706344604492, 0.17287158966064453, -0.3786897659301758, 0.16828536987304688, 0.04051780700683594, 2.4433326721191406, -0.3480558395385742, -0.4128456115722656, -0.5156288146972656, -0.3786888122558594], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.53632354736328, "min_q": 7.901082515716553, "max_q": 61.86766052246094, "mean_td_error": 0.07994277775287628, "model": {}}, "td_error": [0.2152099609375, 0.05611991882324219, 0.3648643493652344, 0.19909286499023438, 0.1795501708984375, -0.3155841827392578, 0.2152099609375, -0.3155841827392578, 0.15517044067382812, 0.09082269668579102, -0.12648963928222656, -0.2877006530761719, 0.0269775390625, -0.20058059692382812, 1.3481178283691406, 0.24631881713867188, 0.2288970947265625, 0.1990814208984375, 0.05611991882324219, 0.004756927490234375, 0.03612518310546875, 0.15814971923828125, -0.059078216552734375, 0.1990814208984375, -0.09326934814453125, -0.102783203125, -0.09326934814453125, 0.034130096435546875, 0.24631881713867188, -0.35564613342285156, 0.0898895263671875, 0.15814971923828125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.25164031982422, "min_q": 8.074943542480469, "max_q": 61.72881317138672, "mean_td_error": 0.33453357219696045, "model": {}}, "td_error": [0.16373634338378906, -0.15137672424316406, 0.3321533203125, -0.1713085174560547, 0.2519569396972656, -0.22484207153320312, -0.3753662109375, -0.2610750198364258, 0.056217193603515625, 0.13357925415039062, 0.08112335205078125, 2.24993896484375, -0.1240386962890625, -0.04070091247558594, 0.07461357116699219, 0.018663406372070312, 0.27440738677978516, 3.0060997009277344, 2.1653881072998047, -0.4346923828125, 2.2346935272216797, -0.3753662109375, 0.07738113403320312, 1.0279273986816406, -0.2652721405029297, -0.2928199768066406, 0.10979461669921875, -0.08736801147460938, -0.2928199768066406, 1.8169288635253906, -0.18511199951171875, -0.08736991882324219], "custom_metrics": {}}}, "num_steps_sampled": 158256, "num_agent_steps_sampled": 474768, "num_steps_trained": 314528, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 943584, "last_target_update_ts": 158192, "num_target_updates": 308}, "done": false, "episodes_total": 17115, "training_iteration": 157, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-07-49", "timestamp": 1648919269, "time_this_iter_s": 42.23080015182495, "time_total_s": 6283.614012956619, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5eeef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5eeef0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6283.614012956619, "timesteps_since_restore": 5024, "iterations_since_restore": 157, "perf": {"cpu_util_percent": 50.09322033898305, "ram_util_percent": 65.50508474576272}}
{"episode_reward_max": 186.0, "episode_reward_min": 120.0, "episode_reward_mean": 184.30327868852459, "episode_len_mean": 8.319672131147541, "episode_media": {}, "episodes_this_iter": 122, "policy_reward_min": {"policy0": 40.0, "policy1": 40.0, "policy2": 40.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.4344262295082, "policy1": 61.4344262295082, "policy2": 61.4344262295082}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 120.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 8, 8, 8, 9, 9, 8, 8, 9, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 9, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 40.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0527241374833738, "mean_inference_ms": 25.661213625527207, "mean_action_processing_ms": 0.24182290802603054, "mean_env_wait_ms": 0.13871634722250611, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 159264, "timesteps_this_iter": 32, "agent_timesteps_total": 477792, "timers": {"load_time_ms": 0.62, "load_throughput": 51648.027, "learn_time_ms": 239.281, "learn_throughput": 133.734, "update_time_ms": 113.183}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.9395866394043, "min_q": 8.781335830688477, "max_q": 61.53156661987305, "mean_td_error": -0.20893356204032898, "model": {}}, "td_error": [0.03960418701171875, -0.9696216583251953, -0.5310382843017578, -0.44019317626953125, 0.06673812866210938, -0.9254932403564453, -0.37066650390625, -0.19704437255859375, -0.3104877471923828, 0.09421634674072266, -0.37066650390625, -0.2962226867675781, 0.2381153106689453, -0.8121356964111328, -0.2962226867675781, -0.35037994384765625, -0.35037994384765625, -0.0654296875, -0.08011817932128906, 0.1079559326171875, -0.21677398681640625, -0.09602928161621094, -0.0654296875, -0.37066650390625, 0.23524093627929688, 0.3554267883300781, 0.5227832794189453, -0.21866416931152344, 0.44094085693359375, -0.2596168518066406, -0.5968074798583984, -0.5968074798583984], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.19200134277344, "min_q": 8.978035926818848, "max_q": 61.462928771972656, "mean_td_error": -0.100588858127594, "model": {}}, "td_error": [-0.235076904296875, -0.019743919372558594, 0.3567619323730469, -0.1327362060546875, -0.1421375274658203, -0.25896644592285156, -0.054897308349609375, -0.09051322937011719, 0.08625221252441406, -0.43929290771484375, -0.1327362060546875, -0.021964073181152344, 0.10147476196289062, 0.16408920288085938, 0.061664581298828125, -0.09051322937011719, -0.20412063598632812, 0.10147476196289062, -0.43929290771484375, -0.43929290771484375, -0.24787521362304688, -0.235076904296875, 0.125396728515625, 0.125396728515625, 0.020399093627929688, -0.07322502136230469, -0.17676544189453125, -0.17886734008789062, -0.4097442626953125, 0.07997703552246094, 0.0204010009765625, -0.43929290771484375], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 31.941207885742188, "min_q": 7.205650806427002, "max_q": 61.3920783996582, "mean_td_error": 0.5896678566932678, "model": {}}, "td_error": [0.09460830688476562, -0.26315879821777344, -0.09033203125, -0.13916587829589844, -0.02079486846923828, 2.2806529998779297, 0.026502609252929688, -0.377960205078125, -0.12734603881835938, -0.09033203125, -0.21336746215820312, -0.0732879638671875, 0.026502609252929688, -0.34644126892089844, -0.43512916564941406, 2.171598434448242, -0.6612129211425781, 0.12430572509765625, -0.017838478088378906, -0.3843388557434082, 0.09460830688476562, -0.06274795532226562, -0.04817962646484375, 0.09460830688476562, 0.0770721435546875, -0.0732879638671875, 17.49214744567871, 0.026502609252929688, -0.39882898330688477, 0.2645988464355469, -0.06274795532226562, -0.0178375244140625], "custom_metrics": {}}}, "num_steps_sampled": 159264, "num_agent_steps_sampled": 477792, "num_steps_trained": 316544, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 949632, "last_target_update_ts": 159216, "num_target_updates": 310}, "done": false, "episodes_total": 17237, "training_iteration": 158, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-08-30", "timestamp": 1648919310, "time_this_iter_s": 41.13893413543701, "time_total_s": 6324.752947092056, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c65e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c65e710>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6324.752947092056, "timesteps_since_restore": 5056, "iterations_since_restore": 158, "perf": {"cpu_util_percent": 51.07118644067796, "ram_util_percent": 65.035593220339}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.95, "episode_len_mean": 8.35, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.31666666666667, "policy1": 61.31666666666667, "policy2": 61.31666666666667}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 150.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0], "episode_lengths": [8, 8, 10, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 10, 8, 9, 10, 8, 8, 8, 10, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 9, 8, 8, 8, 10, 8, 10, 9, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 10, 8, 8, 8, 10, 8], "policy_policy0_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.052745353038385, "mean_inference_ms": 25.67022360719798, "mean_action_processing_ms": 0.24185790296801132, "mean_env_wait_ms": 0.13882556857867734, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 160272, "timesteps_this_iter": 32, "agent_timesteps_total": 480816, "timers": {"load_time_ms": 0.61, "load_throughput": 52496.471, "learn_time_ms": 228.528, "learn_throughput": 140.026, "update_time_ms": 114.308}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 37.693092346191406, "min_q": 8.856171607971191, "max_q": 60.7116813659668, "mean_td_error": 0.0740136206150055, "model": {}}, "td_error": [2.0875205993652344, 0.37366485595703125, -0.6515007019042969, 0.48786163330078125, -0.1482868194580078, -0.4550800323486328, -0.3202056884765625, 2.4914093017578125, -0.10564231872558594, 0.48786163330078125, -0.4863319396972656, -0.17979812622070312, -0.2677803039550781, -0.1192474365234375, 0.011379241943359375, -0.1688098907470703, 1.7478046417236328, -0.3946952819824219, -0.6515007019042969, 0.10737228393554688, -0.3386344909667969, 0.3457984924316406, -0.1438283920288086, -0.3946952819824219, 0.2786102294921875, -0.20912742614746094, -0.11523056030273438, -0.4863319396972656, 0.4446525573730469, -0.5263519287109375, -0.07553482055664062, -0.2568855285644531], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.232154846191406, "min_q": 8.889111518859863, "max_q": 61.314544677734375, "mean_td_error": 0.20595040917396545, "model": {}}, "td_error": [-0.05272674560546875, -0.14249420166015625, 0.12415695190429688, 0.03286933898925781, -0.04747200012207031, 0.3025169372558594, -0.13086891174316406, 0.08579635620117188, 0.019466400146484375, -0.2699394226074219, -0.04747200012207031, -0.04747200012207031, -0.09902572631835938, 0.018924713134765625, -0.19235992431640625, -0.4561805725097656, 0.02928924560546875, -0.025127410888671875, -0.24549293518066406, 1.6356067657470703, -0.05551338195800781, 0.03286933898925781, -0.4782371520996094, 0.12415695190429688, -0.029529571533203125, -0.4782371520996094, -0.06313705444335938, 0.5502777099609375, -0.19235992431640625, 0.16296768188476562, -0.052730560302734375, 6.5778913497924805], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 35.20866012573242, "min_q": 8.282054901123047, "max_q": 60.87831115722656, "mean_td_error": -0.1656475067138672, "model": {}}, "td_error": [0.058441162109375, 0.10979080200195312, -0.049266815185546875, -0.049266815185546875, -0.17562103271484375, -0.0127716064453125, 0.07173538208007812, -0.48199462890625, 0.2756500244140625, -0.48199462890625, -0.14092445373535156, -0.07549285888671875, -0.2791004180908203, -0.14275550842285156, -0.7179450988769531, -0.24766159057617188, -0.1770782470703125, -0.11107158660888672, -0.24766159057617188, 0.06450653076171875, -1.0140857696533203, -0.09412002563476562, 0.026988983154296875, -0.049266815185546875, 0.2756500244140625, -0.27734375, -0.18737411499023438, -0.3653526306152344, -0.0880727767944336, -0.17562103271484375, -0.1762866973876953, -0.3653526306152344], "custom_metrics": {}}}, "num_steps_sampled": 160272, "num_agent_steps_sampled": 480816, "num_steps_trained": 318560, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 955680, "last_target_update_ts": 160240, "num_target_updates": 312}, "done": false, "episodes_total": 17357, "training_iteration": 159, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-09-10", "timestamp": 1648919350, "time_this_iter_s": 40.00689125061035, "time_total_s": 6364.759838342667, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5ee9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c5ee9e0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6364.759838342667, "timesteps_since_restore": 5088, "iterations_since_restore": 159, "perf": {"cpu_util_percent": 52.03214285714285, "ram_util_percent": 65.10714285714286}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.41322314049586, "episode_len_mean": 8.363636363636363, "episode_media": {}, "episodes_this_iter": 121, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.47107438016529, "policy1": 61.47107438016529, "policy2": 61.47107438016529}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 150.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 183.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 180.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 10, 8, 8, 8, 8, 10, 9, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 9, 8, 10, 8, 8, 8, 10, 8, 8, 9, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 9, 10, 8, 8, 8, 9, 8, 8, 8, 8, 8, 10, 8, 8, 9, 8, 10, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 50.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 61.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0539646634932607, "mean_inference_ms": 25.722943803991303, "mean_action_processing_ms": 0.2422219423926904, "mean_env_wait_ms": 0.138992943884287, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 161280, "timesteps_this_iter": 32, "agent_timesteps_total": 483840, "timers": {"load_time_ms": 0.611, "load_throughput": 52402.19, "learn_time_ms": 245.37, "learn_throughput": 130.416, "update_time_ms": 114.048}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 32.1168098449707, "min_q": 6.799002170562744, "max_q": 60.62543869018555, "mean_td_error": 0.12979984283447266, "model": {}}, "td_error": [-0.6510944366455078, -0.03398704528808594, -0.3544960021972656, 1.5847816467285156, -0.4090003967285156, -0.6487274169921875, 0.4345855712890625, -0.5847320556640625, -0.3981781005859375, 2.552978515625, 1.3424835205078125, -0.31451988220214844, -0.1335582733154297, -0.29555702209472656, -0.8721466064453125, -0.1335582733154297, -0.02835369110107422, 0.4345855712890625, -0.09030532836914062, -0.3341827392578125, -0.037410736083984375, 2.4487719535827637, 0.5669898986816406, -0.6231479644775391, 0.18584442138671875, 0.09476089477539062, -0.04361248016357422, 1.4755134582519531, -0.3544960021972656, -0.10866689682006836, -0.6478157043457031, 0.12984657287597656], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 29.932594299316406, "min_q": 8.539982795715332, "max_q": 60.946311950683594, "mean_td_error": -0.06677445769309998, "model": {}}, "td_error": [-0.46001720428466797, -0.2085437774658203, 0.18036270141601562, 0.028337478637695312, 0.17228317260742188, -0.27846717834472656, -0.18738746643066406, 0.18036270141601562, 0.0947113037109375, -0.14776992797851562, -0.2085437774658203, -0.1439056396484375, 0.12598037719726562, 0.34173583984375, -0.27846717834472656, -0.23269271850585938, -0.0274505615234375, 0.23070335388183594, 0.012603759765625, 0.148712158203125, -0.12268257141113281, 0.22128677368164062, -0.016300201416015625, -0.12268257141113281, -0.41402244567871094, -0.31484031677246094, -0.38323974609375, -0.19102096557617188, 0.0947113037109375, -0.14776992797851562, -0.016300201416015625, -0.06646919250488281], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.22905731201172, "min_q": 8.971132278442383, "max_q": 61.04314041137695, "mean_td_error": 0.052290529012680054, "model": {}}, "td_error": [-0.12651443481445312, 0.00792694091796875, -0.2648963928222656, -0.1764678955078125, -0.015264511108398438, -0.11386871337890625, -0.3512420654296875, 0.283843994140625, -0.2852935791015625, -0.06727027893066406, -0.06727027893066406, 0.11639118194580078, -0.7853622436523438, 0.2704448699951172, -0.07251739501953125, -0.23592376708984375, -0.4786720275878906, 0.09942436218261719, -0.028867721557617188, -0.5587921142578125, 0.054492950439453125, -0.4663276672363281, -0.42762184143066406, -0.24695396423339844, -0.30963897705078125, 0.8263912200927734, -0.23630523681640625, -0.0136566162109375, -0.3512420654296875, -0.25173187255859375, -0.6508674621582031, 6.596950531005859], "custom_metrics": {}}}, "num_steps_sampled": 161280, "num_agent_steps_sampled": 483840, "num_steps_trained": 320576, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 961728, "last_target_update_ts": 161264, "num_target_updates": 314}, "done": false, "episodes_total": 17478, "training_iteration": 160, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-09-55", "timestamp": 1648919395, "time_this_iter_s": 44.34038805961609, "time_total_s": 6409.100226402283, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c65e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c65e5f0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6409.100226402283, "timesteps_since_restore": 5120, "iterations_since_restore": 160, "perf": {"cpu_util_percent": 51.24126984126984, "ram_util_percent": 65.3873015873016}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 183.9327731092437, "episode_len_mean": 8.436974789915967, "episode_media": {}, "episodes_this_iter": 119, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.3109243697479, "policy1": 61.3109243697479, "policy2": 61.3109243697479}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 183.0, 186.0, 183.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 183.0, 186.0, 186.0, 186.0, 183.0, 150.0, 180.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 10, 8, 8, 10, 8, 10, 8, 8, 9, 10, 8, 8, 8, 10, 8, 9, 8, 8, 8, 8, 10, 8, 9, 8, 9, 8, 8, 8, 9, 8, 8, 8, 8, 8, 8, 10, 10, 8, 8, 8, 8, 8, 8, 9, 10, 8, 10, 8, 8, 9, 8, 8, 9, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 9, 9, 8, 8, 8, 8, 8, 9, 8, 9, 9, 8, 8, 8, 9, 10, 10, 8, 8, 10, 8, 8, 8, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 61.0, 62.0, 61.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 61.0, 62.0, 62.0, 62.0, 61.0, 50.0, 60.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.0526959411096966, "mean_inference_ms": 25.67038103148454, "mean_action_processing_ms": 0.2417756971336802, "mean_env_wait_ms": 0.13880484543278562, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 162288, "timesteps_this_iter": 32, "agent_timesteps_total": 486864, "timers": {"load_time_ms": 0.714, "load_throughput": 44791.499, "learn_time_ms": 254.293, "learn_throughput": 125.839, "update_time_ms": 133.991}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.204166412353516, "min_q": 5.72340202331543, "max_q": 60.35638427734375, "mean_td_error": 0.3073592483997345, "model": {}}, "td_error": [0.02364349365234375, -0.01982879638671875, 0.11407852172851562, -0.058185577392578125, -1.0904111862182617, 0.1010589599609375, 1.9196014404296875, 0.13761520385742188, 0.046504974365234375, 0.11023712158203125, -0.13980865478515625, 0.08414268493652344, -0.01982879638671875, -0.13980865478515625, 0.2926826477050781, 0.094818115234375, -0.05818939208984375, 6.72340202331543, 0.094818115234375, 0.09577369689941406, 0.039218902587890625, 0.16648483276367188, -0.13624954223632812, 1.401031494140625, -0.0155792236328125, -0.0937652587890625, 0.1504802703857422, -0.16858673095703125, -0.22124862670898438, -0.19219207763671875, 0.3029823303222656, 0.2906036376953125], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 36.45649719238281, "min_q": 7.88034725189209, "max_q": 61.39044952392578, "mean_td_error": 0.07144254446029663, "model": {}}, "td_error": [-0.07718467712402344, -0.3852710723876953, -0.022247314453125, 0.07612228393554688, 0.10797882080078125, 1.5840816497802734, 0.08190155029296875, 0.0086669921875, -0.7156391143798828, -0.11290931701660156, 0.17057418823242188, 0.11085128784179688, -0.005615234375, 0.06532478332519531, 0.1875, 0.07612228393554688, 0.10797882080078125, -0.3233680725097656, 0.0512542724609375, -0.11647224426269531, -0.10486030578613281, 0.06532478332519531, 0.10797882080078125, 0.12566375732421875, 0.10797882080078125, 0.277801513671875, 0.42511558532714844, -0.05788993835449219, 0.11328887939453125, 0.34387969970703125, 0.07611846923828125, -0.0638885498046875], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 38.204376220703125, "min_q": 8.73721981048584, "max_q": 61.592979431152344, "mean_td_error": 0.09101378917694092, "model": {}}, "td_error": [0.23652076721191406, -0.2024078369140625, -0.14545059204101562, -0.12390899658203125, -0.14677810668945312, 0.23017597198486328, -0.25322914123535156, -0.26278018951416016, 0.2804069519042969, -0.14677810668945312, 0.07163810729980469, -0.060184478759765625, -0.01897430419921875, 0.27440834045410156, -0.026096343994140625, -0.046337127685546875, -0.3002738952636719, 0.0983428955078125, 0.09817886352539062, 0.017974853515625, 0.9344673156738281, -0.044895172119140625, 2.7784347534179688, -0.07819557189941406, -0.17270278930664062, 0.0983428955078125, -0.01897430419921875, -0.09767913818359375, -0.025499343872070312, 0.14386749267578125, -0.3002738952636719, 0.12110137939453125], "custom_metrics": {}}}, "num_steps_sampled": 162288, "num_agent_steps_sampled": 486864, "num_steps_trained": 322592, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 967776, "last_target_update_ts": 162288, "num_target_updates": 316}, "done": false, "episodes_total": 17597, "training_iteration": 161, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-10-37", "timestamp": 1648919437, "time_this_iter_s": 41.8218834400177, "time_total_s": 6450.9221098423, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c637b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c637b00>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6450.9221098423, "timesteps_since_restore": 5152, "iterations_since_restore": 161, "perf": {"cpu_util_percent": 50.74576271186441, "ram_util_percent": 65.28983050847458}}
{"episode_reward_max": 186.0, "episode_reward_min": 150.0, "episode_reward_mean": 184.3, "episode_len_mean": 8.4, "episode_media": {}, "episodes_this_iter": 120, "policy_reward_min": {"policy0": 50.0, "policy1": 50.0, "policy2": 50.0}, "policy_reward_max": {"policy0": 62.0, "policy1": 62.0, "policy2": 62.0}, "policy_reward_mean": {"policy0": 61.43333333333333, "policy1": 61.43333333333333, "policy2": 61.43333333333333}, "custom_metrics": {}, "hist_stats": {"episode_reward": [186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 183.0, 186.0, 186.0, 186.0, 150.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 150.0, 186.0, 183.0, 186.0, 183.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 183.0, 186.0, 183.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 180.0, 186.0, 186.0, 183.0, 186.0, 186.0, 180.0, 180.0, 186.0, 183.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 180.0, 180.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 180.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 186.0, 183.0, 186.0, 186.0, 186.0], "episode_lengths": [8, 8, 8, 8, 10, 8, 10, 9, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 10, 8, 10, 8, 9, 8, 9, 10, 8, 8, 8, 8, 8, 9, 8, 8, 10, 8, 8, 8, 9, 8, 9, 8, 10, 8, 8, 8, 8, 10, 8, 10, 8, 8, 9, 8, 8, 10, 10, 8, 9, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 9, 10, 10, 10, 8, 8, 8, 8, 8, 8, 8, 8, 8, 8, 10, 8, 8, 8, 8, 8, 8, 8, 8, 9, 8, 8, 8], "policy_policy0_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy1_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0], "policy_policy2_reward": [62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 61.0, 62.0, 62.0, 62.0, 50.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 50.0, 62.0, 61.0, 62.0, 61.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 61.0, 62.0, 61.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 60.0, 62.0, 62.0, 61.0, 62.0, 62.0, 60.0, 60.0, 62.0, 61.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 60.0, 60.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 60.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 62.0, 61.0, 62.0, 62.0, 62.0]}, "sampler_perf": {"mean_raw_obs_processing_ms": 1.055654154039933, "mean_inference_ms": 25.786816924171656, "mean_action_processing_ms": 0.24263611339164962, "mean_env_wait_ms": 0.1392386242865932, "mean_env_render_ms": 0.0}, "off_policy_estimator": {}, "num_healthy_workers": 4, "timesteps_total": 163296, "timesteps_this_iter": 32, "agent_timesteps_total": 489888, "timers": {"load_time_ms": 0.625, "load_throughput": 51169.549, "learn_time_ms": 250.563, "learn_throughput": 127.712, "update_time_ms": 125.241}, "info": {"learner": {"policy0": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 33.5804557800293, "min_q": 7.546233654022217, "max_q": 60.95960235595703, "mean_td_error": -0.16112880408763885, "model": {}}, "td_error": [-0.1265125274658203, -0.2623319625854492, -0.23003768920898438, -0.3517417907714844, -0.36853981018066406, -0.2924346923828125, -0.3724021911621094, -0.39122772216796875, -0.3422355651855469, -0.059558868408203125, -0.3422355651855469, -0.5382080078125, -0.05772209167480469, 0.09563446044921875, -0.4934501647949219, 1.662923812866211, -0.11831808090209961, 1.3327980041503906, -0.11324501037597656, -0.3348064422607422, -0.4679718017578125, -0.37870121002197266, -0.05772209167480469, -0.2606477737426758, -0.05772209167480469, -0.4024219512939453, -0.2606477737426758, -0.4808349609375, -0.3422355651855469, -0.24615859985351562, -0.28649139404296875, -0.21091461181640625], "custom_metrics": {}}, "policy1": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 34.281822204589844, "min_q": 7.811677932739258, "max_q": 61.426700592041016, "mean_td_error": 0.10210105776786804, "model": {}}, "td_error": [0.06013679504394531, 0.014850616455078125, 0.3251380920410156, 0.3623085021972656, -0.018911361694335938, 0.2833099365234375, -0.09320068359375, 0.4414329528808594, 0.3614234924316406, -0.017866134643554688, 0.3826103210449219, -0.10784912109375, -0.018911361694335938, 0.2833099365234375, 0.048244476318359375, 0.03302955627441406, -0.019250869750976562, -0.017866134643554688, -0.09320068359375, -0.018911361694335938, -0.18885040283203125, -0.034626007080078125, 0.2833099365234375, -0.009740829467773438, -0.1901102066040039, 0.050975799560546875, 0.13946151733398438, 0.4414329528808594, 0.6198577880859375, 0.04329681396484375, -0.04297447204589844, -0.034626007080078125], "custom_metrics": {}}, "policy2": {"learner_stats": {"cur_lr": 4.999999873689376e-05, "mean_q": 39.05072021484375, "min_q": 6.456337928771973, "max_q": 61.81047058105469, "mean_td_error": -0.009745597839355469, "model": {}}, "td_error": [0.2639904022216797, 0.0612640380859375, -0.0240325927734375, 0.3240470886230469, -0.12058258056640625, 0.13448333740234375, 0.3240470886230469, -0.13808441162109375, 0.18886947631835938, 0.24010848999023438, 0.12763595581054688, -0.1437225341796875, -0.18312835693359375, -0.26719188690185547, 0.08155059814453125, 0.12480926513671875, -0.003086090087890625, 0.3689842224121094, -0.4235248565673828, 0.5006904602050781, -0.3900642395019531, -0.12058258056640625, -0.3463287353515625, 0.2276458740234375, -0.003086090087890625, -0.35353851318359375, -0.12058258056640625, -0.10277938842773438, 0.16519546508789062, -0.12058258056640625, -0.21055221557617188, -0.3737306594848633], "custom_metrics": {}}}, "num_steps_sampled": 163296, "num_agent_steps_sampled": 489888, "num_steps_trained": 324608, "num_steps_trained_this_iter": 32, "num_agent_steps_trained": 973824, "last_target_update_ts": 162800, "num_target_updates": 317}, "done": false, "episodes_total": 17717, "training_iteration": 162, "trial_id": "b7659_00000", "experiment_id": "a02f22ee13d24f53a010944ce03a41a8", "date": "2022-04-02_10-11-20", "timestamp": 1648919480, "time_this_iter_s": 43.44022583961487, "time_total_s": 6494.362335681915, "pid": 170, "hostname": "1d29a0c222c3", "node_ip": "172.17.0.2", "config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": true, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"num_workers": 4, "num_envs_per_worker": 1, "create_env_on_driver": false, "rollout_fragment_length": 4, "batch_mode": "truncate_episodes", "gamma": 0.99, "lr": 5e-05, "train_batch_size": 32, "model": {"_use_default_native_models": false, "_disable_preprocessor_api": false, "fcnet_hiddens": [256, 256], "fcnet_activation": "tanh", "conv_filters": null, "conv_activation": "relu", "post_fcnet_hiddens": [], "post_fcnet_activation": "relu", "free_log_std": false, "no_final_linear": false, "vf_share_layers": true, "use_lstm": false, "max_seq_len": 20, "lstm_cell_size": 256, "lstm_use_prev_action": false, "lstm_use_prev_reward": false, "_time_major": false, "use_attention": false, "attention_num_transformer_units": 1, "attention_dim": 64, "attention_num_heads": 1, "attention_head_dim": 32, "attention_memory_inference": 50, "attention_memory_training": 50, "attention_position_wise_mlp_dim": 32, "attention_init_gru_gate_bias": 2.0, "attention_use_n_prev_actions": 0, "attention_use_n_prev_rewards": 0, "framestack": true, "dim": 84, "grayscale": false, "zero_mean": true, "custom_model": null, "custom_model_config": {}, "custom_action_dist": null, "custom_preprocessor": null, "lstm_use_prev_action_reward": -1}, "optimizer": {}, "horizon": null, "soft_horizon": false, "no_done_at_end": false, "env": "foodenv", "observation_space": null, "action_space": null, "env_config": {"agents": [0, 1, 2], "food_loc": {"food1": [3, 3], "food2": [5, 5], "food3": [8, 6], "food4": [1, 5], "food5": [9, 2], "food6": [4, 9], "food7": [8, 3]}, "agent_loc": {"0": [4, 4], "1": [6, 8], "2": [9, 4]}, "board_size": [10, 10], "mode": "coop", "time_limit": 10, "trainer": "dqn"}, "remote_worker_envs": false, "remote_env_batch_wait_ms": 0, "env_task_fn": null, "render_env": false, "record_env": false, "clip_rewards": null, "normalize_actions": true, "clip_actions": false, "preprocessor_pref": "deepmind", "log_level": "WARN", "callbacks": "<class 'ray.rllib.agents.callbacks.DefaultCallbacks'>", "ignore_worker_failures": false, "log_sys_usage": true, "fake_sampler": false, "framework": "tf", "eager_tracing": false, "eager_max_retraces": 20, "explore": false, "exploration_config": {"type": "EpsilonGreedy", "initial_epsilon": 1.0, "final_epsilon": 0.025, "epsilon_timesteps": 100000}, "evaluation_interval": null, "evaluation_duration": 10, "evaluation_duration_unit": "episodes", "evaluation_parallel_to_training": false, "in_evaluation": false, "evaluation_config": {"explore": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "evaluation_num_workers": 0, "custom_eval_function": null, "always_attach_evaluation_results": false, "sample_async": false, "sample_collector": "<class 'ray.rllib.evaluation.collectors.simple_list_collector.SimpleListCollector'>", "observation_filter": "NoFilter", "synchronize_filters": true, "tf_session_args": {"intra_op_parallelism_threads": 2, "inter_op_parallelism_threads": 2, "gpu_options": {"allow_growth": true}, "log_device_placement": false, "device_count": {"CPU": 1}, "allow_soft_placement": true}, "local_tf_session_args": {"intra_op_parallelism_threads": 8, "inter_op_parallelism_threads": 8}, "compress_observations": false, "metrics_episode_collection_timeout_s": 180, "metrics_num_episodes_for_smoothing": 100, "min_time_s_per_reporting": 1, "min_train_timesteps_per_reporting": null, "min_sample_timesteps_per_reporting": 1000, "seed": null, "extra_python_environs_for_driver": {}, "extra_python_environs_for_worker": {}, "num_gpus": 0, "_fake_gpus": false, "num_cpus_per_worker": 1, "num_gpus_per_worker": 0, "custom_resources_per_worker": {}, "num_cpus_for_driver": 1, "placement_strategy": "PACK", "input": "sampler", "input_config": {}, "actions_in_input_normalized": false, "input_evaluation": ["is", "wis"], "postprocess_inputs": false, "shuffle_buffer_size": 0, "output": null, "output_compress_columns": ["obs", "new_obs"], "output_max_file_size": 67108864, "multiagent": {"policies": {"policy0": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 0}], "policy1": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 1}], "policy2": ["<class 'ray.rllib.policy.tf_policy_template.DQNTFPolicy'>", "MultiDiscrete([10 10 10 10 10 10 11 11 11 11 11 11 11 11 11 11 11 11 11 11])", "Discrete(4)", {"agent_id": 2}]}, "policy_map_capacity": 100, "policy_map_cache": null, "policy_mapping_fn": "<function <lambda> at 0x7f547c68d3b0>", "policies_to_train": null, "observation_fn": null, "replay_mode": "independent", "count_steps_by": "env_steps"}, "logger_config": null, "_tf_policy_handles_more_than_one_loss": false, "_disable_preprocessor_api": false, "_disable_action_flattening": false, "_disable_execution_plan_api": false, "simple_optimizer": false, "monitor": -1, "evaluation_num_episodes": -1, "metrics_smoothing_episodes": -1, "timesteps_per_iteration": 1000, "min_iter_time_s": 1, "collect_metrics_timeout": -1, "target_network_update_freq": 500, "buffer_size": 8000, "replay_buffer_config": {"type": "MultiAgentReplayBuffer", "capacity": 50000}, "store_buffer_in_checkpoints": false, "replay_sequence_length": 1, "lr_schedule": null, "adam_epsilon": 1e-08, "grad_clip": 40, "learning_starts": 1000, "num_atoms": 1, "v_min": -10.0, "v_max": 10.0, "noisy": false, "sigma0": 0.5, "dueling": true, "hiddens": [30000], "double_q": true, "n_step": 1, "prioritized_replay": true, "prioritized_replay_alpha": 0.6, "prioritized_replay_beta": 0.4, "final_prioritized_replay_beta": 0.4, "prioritized_replay_beta_annealing_timesteps": 20000, "prioritized_replay_eps": 1e-06, "before_learn_on_batch": null, "training_intensity": null, "worker_side_prioritization": false}, "time_since_restore": 6494.362335681915, "timesteps_since_restore": 5184, "iterations_since_restore": 162, "perf": {"cpu_util_percent": 51.92096774193548, "ram_util_percent": 65.41774193548387}}
